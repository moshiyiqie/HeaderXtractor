<abstract>  Abstract  </abstract>::line_number::6
<abstract> The problem of collecting responses in multi-hop radio networks is considered. A given node, called the source, is to collect a specified number of  </abstract>::line_number::7
<abstract> responses from nodes in a radio network. The problem arises in several  </abstract>::line_number::8
<abstract> applications of distributed systems. A deterministic and a randomized protocol for the problem are presented. The two protocols are analyzed and  </abstract>::line_number::9
<abstract> their performance is compared. Conclusions are drawn about the suitability  </abstract>::line_number::10
<abstract> of our protocols in various network environments.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Proc. of the Int'l Symposium on High Performance  </abstract>::line_number::8
<abstract> Computer Architecture (HPCA '95), pp. 200-209.  </abstract>::line_number::9
<abstract> This paper presents a new approach to implement fast barrier synchronization in wormhole k-ary  </abstract>::line_number::10
<abstract> n-cubes. The novelty lies in using multidestination  </abstract>::line_number::11
<abstract> messages instead of the traditional single destination  </abstract>::line_number::12
<abstract> messages. Two different multidestination worm types,  </abstract>::line_number::13
<abstract> gather and broadcasting, are introduced to implement  </abstract>::line_number::14
<abstract> the report and wake-up phases of barrier synchronization, respectively. Algorithms for complete and arbitrary set barrier synchronization are presented using  </abstract>::line_number::15
<abstract> these new worms. It is shown that complete barrier  </abstract>::line_number::16
<abstract> synchronization in a k-ary n-cube system with e-cube  </abstract>::line_number::17
<abstract> routing can be implemented with 2n communication  </abstract>::line_number::18
<abstract> start-ups as compared to 2n log 2 k start-ups needed  </abstract>::line_number::19
<abstract> with unicast-based message passing. For arbitrary set  </abstract>::line_number::20
<abstract> barrier, an interesting trend is observed where the synchronization cost keeps on reducing beyond a certain  </abstract>::line_number::21
<abstract> number of participating nodes.   </abstract>::line_number::22
<abstract>  Abstract| This paper focuses on efficient multicasting in  </abstract>::line_number::4
<abstract> wormhole-routed networks. A trip-based model is proposed  </abstract>::line_number::5
<abstract> to support adaptive, distributed, and deadlock-free multiple  </abstract>::line_number::6
<abstract> multicast on any network with arbitrary topology using at  </abstract>::line_number::7
<abstract> most two virtual channels per physical channel. This model  </abstract>::line_number::8
<abstract> significantly generalizes the path-based model proposed earlier [21], [22], which works only for Hamiltonian networks  </abstract>::line_number::9
<abstract> and can not be applicable to networks with arbitrary topology resulted due to system faults. Fundamentals of the trip-based model, including the necessary and sufficient condition to be deadlock-free, and the use of appropriate number  </abstract>::line_number::10
<abstract> of virtual channels to avoid deadlock are investigated. The  </abstract>::line_number::11
<abstract> potential of this model is illustrated by applying it to hyper-cubes with faulty nodes. Simulation results indicate that the  </abstract>::line_number::12
<abstract> proposed model can implement multiple multicast on faulty  </abstract>::line_number::13
<abstract> hypercubes with negligible performance degradation.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In this paper we introduce a new approach to the deformation of surface and raster  </abstract>::line_number::6
<abstract> models in two and three dimensions. Rather then deforming the objects in the  </abstract>::line_number::7
<abstract> model, we deform the rays used to render the scene. The mechanism to specify the  </abstract>::line_number::8
<abstract> deformation, which we call a deector, is a vector of gravity positioned in space.  </abstract>::line_number::9
<abstract> This gravity vector bends any ray that travels through its field of gravity. Images  </abstract>::line_number::10
<abstract> generated by these curved rays give the impression of a deformed space. Unlike  </abstract>::line_number::11
<abstract> previous methods that deform all the objects in the scene, our approach deforms  </abstract>::line_number::12
<abstract> only those parts of the model that contribute to the final image. In addition, using  </abstract>::line_number::13
<abstract> deectors, our approach can deform any object type that can be rendered by a ray  </abstract>::line_number::14
<abstract> casting algorithm, providing a unified solution to space deformation.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::6
<abstract> It has previously been shown that there exists a minimum degree ordering for regular grids that is considerably worse than nested dissection  </abstract>::line_number::7
<abstract> in terms of fill-in and operations for factorization [1]. This paper proves  </abstract>::line_number::8
<abstract> the existence of a minimum degree ordering for regular grids that has the  </abstract>::line_number::9
<abstract> same optimal asymptotic order complexity for fill-in and operation count  </abstract>::line_number::10
<abstract> as nested dissection. The analysis is verified by showing exact match between analytical prediction and experimental measurement. The analysis  </abstract>::line_number::11
<abstract> motivates a peripheral preordering strategy for use with the popular multiple minimum degree (MMD) algorithm, and is shown to consistently  </abstract>::line_number::12
<abstract> reduce fill-in and operation count for regular grids.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Implicit curves are widely used in computer graphics because of their powerful features for modeling and their ability for general function description. The most popular rasterization techniques for implicit curves are space subdivision and curve  </abstract>::line_number::7
<abstract> tracking. In this paper we are introducing an efficient curve tracking algorithm that  </abstract>::line_number::8
<abstract> is also more robust then existing methods. We employ the Predictor-Corrector  </abstract>::line_number::9
<abstract> Method on the implicit function to get a very accurate curve approximation in a  </abstract>::line_number::10
<abstract> short time. Speedup is achieved by adapting the step size to the curvature. In addition, we provide mechanisms to detect and properly handle bifurcation points,  </abstract>::line_number::11
<abstract> where the curve intersects itself. Finally, the algorithm allows the user to trade-off  </abstract>::line_number::12
<abstract> accuracy for speed and vice a versa. We conclude by providing examples that dem-onstrate the capabilities of our algorithm.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::13
<abstract> Since multimedia systems typically require storage, retrieval, and manipulation  </abstract>::line_number::14
<abstract> of huge amount of information, database systems play key role in the design of high-performance multimedia systems. This article examines the issues in the design of  </abstract>::line_number::15
<abstract> multimedia database systems and explores the current state of the art.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper identifies performance degradation in wormhole routed k-ary n-cube networks due  </abstract>::line_number::9
<abstract> to limited number of router-to-processor consumption channels at each node. Many recent research  </abstract>::line_number::10
<abstract> in wormhole routing have advocated the advantages of adaptive routing and virtual channel flow  </abstract>::line_number::11
<abstract> control schemes to deliver better network performance. This paper indicates that the advantages  </abstract>::line_number::12
<abstract> associated with these schemes can not be realized with limited consumption capacity. To alleviate  </abstract>::line_number::13
<abstract> such performance bottleneck, a new network interface design using multiple consumption channels  </abstract>::line_number::14
<abstract> is proposed. To match virtual multiplexing on network channels, we also propose each consumption  </abstract>::line_number::15
<abstract> channel to support multiple virtual consumption channels. The impact of message arrival rate at  </abstract>::line_number::16
<abstract> a node on the required number of consumption channel is studied analytically. It is shown that  </abstract>::line_number::17
<abstract> wormhole networks with higher routing adaptivity, dimensionality, degree of hot-spot traffic, and  </abstract>::line_number::18
<abstract> number of virtual lanes have to take advantage of multiple consumption channels to deliver better  </abstract>::line_number::19
<abstract> performance. The interplay between system topology, routing algorithm, number of virtual lanes,  </abstract>::line_number::20
<abstract> messaging overheads, and communication traffic is studied through simulation to derive the effective  </abstract>::line_number::21
<abstract> number of consumption channels required in a system. Using the on-going technological trend, it is  </abstract>::line_number::22
<abstract> shown that wormhole-routed systems can use up to 2-4 consumption channels per node to deliver  </abstract>::line_number::23
<abstract> better system performance.   </abstract>::line_number::24
<abstract>  Abstract: How do we formally specify the relation between a base class and a  </abstract>::line_number::6
<abstract> derived class? This question has two parts, a syntactic one, and a semantic one.  </abstract>::line_number::7
<abstract> The syntactic part is of course the easier of the two and the answer to that part is  </abstract>::line_number::8
<abstract> the standard contra/co- variance requirement on the arguments and result of any  </abstract>::line_number::9
<abstract> base class method redefined in the derived class. Our concern in the current paper  </abstract>::line_number::10
<abstract> is with the semantic part of the question, i.e., how do we specify the behavioral  </abstract>::line_number::11
<abstract> relation between the base class and the derived class? We show that the standard  </abstract>::line_number::12
<abstract> answer -which is the semantic counterpart of contra/co-variance- is too rigid, and  </abstract>::line_number::13
<abstract> does not allow some natural and common forms of inheritance. We then propose a  </abstract>::line_number::14
<abstract> more flexible way to specify the relation, and show how different types of behavioral relations between base classes and derived classes may be specified using our  </abstract>::line_number::15
<abstract> notation.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> ATM Forum specifies public key cryptography to be the default ATM authentication mechanism and directory services like X.509 to be the infrastructure for public  </abstract>::line_number::8
<abstract> key distribution and certification. Authenticated signaling, widely acknowledged  </abstract>::line_number::9
<abstract> as a necessary security feature of ATM network, requires the signaling message to  </abstract>::line_number::10
<abstract> be authenticated with a digital signature signed by the private key of the calling  </abstract>::line_number::11
<abstract> party. To verify the digital signature, the called party needs to obtain the public  </abstract>::line_number::12
<abstract> key of the calling party and a proof of the calling party's ownership to that public  </abstract>::line_number::13
<abstract> key. In X.509, the standard form of such a proof is a chain of public key certificates, called the certificate path between two parties. Certificate exchange protocol  </abstract>::line_number::14
<abstract> (CEP), proposed by ATM Forum, requires that another bi-directional connection  </abstract>::line_number::15
<abstract> be established between two parties to exchange public keys and certificate paths  </abstract>::line_number::16
<abstract> before an authenticated connection can be set up, which is not an ideal approach.  </abstract>::line_number::17
<abstract> We propose an algorithm which is embedded into ATM routing protocols to generate a certificate path inside a signaling message on-the-fly as the signaling message  </abstract>::line_number::18
<abstract> travels through the ATM network. In this approach, all that a calling party needs  </abstract>::line_number::19
<abstract> to know for authentication purpose is its own public key certificate and the ATM  </abstract>::line_number::20
<abstract> network builds the rest of the certificate path for it. Related issues like distribution  </abstract>::line_number::21
<abstract> of public key certificates and optimization of CA hierarchy are also addressed in  </abstract>::line_number::22
<abstract> this paper.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::9
<abstract> A neural network approach to the classic  </abstract>::line_number::10
<abstract> inverted pendulum task is presented. This task is the  </abstract>::line_number::11
<abstract> task of keeping a rigid pole, hinged to a cart and free  </abstract>::line_number::12
<abstract> to fall in a plane, in a roughly vertical orientation by  </abstract>::line_number::13
<abstract> moving the cart horizontally in the plane while keeping the cart within some maximum distance of its  </abstract>::line_number::14
<abstract> starting position. This task constitutes a difficult control problem if the parameters of the cart-pole system  </abstract>::line_number::15
<abstract> are not known precisely or are variable. It also forms  </abstract>::line_number::16
<abstract> the basis of an even more complex control-learning  </abstract>::line_number::17
<abstract> problem if the controller must learn the proper actions  </abstract>::line_number::18
<abstract> for successfully balancing the pole given only the current state of the system and a failure signal when the  </abstract>::line_number::19
<abstract> pole angle from the vertical becomes too great or the  </abstract>::line_number::20
<abstract> cart exceeds one of the boundaries placed on its position.  </abstract>::line_number::21
<abstract> The approach presented is demonstrated to  </abstract>::line_number::22
<abstract> be effective for the real-time control of a small, self-contained mini-robot, specially outfitted for the task.  </abstract>::line_number::23
<abstract> Origins and details of the learning scheme, specifics  </abstract>::line_number::24
<abstract> of the mini-robot hardware, and results of actual  </abstract>::line_number::25
<abstract> learning trials are presented.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::6
<abstract> According to space-based theory, visual attention is limited to a local region in space  </abstract>::line_number::7
<abstract> called the attentional field. Visual information within the attentional field is enhanced  </abstract>::line_number::8
<abstract> for further processing while information outside is suppressed. There is evidence that  </abstract>::line_number::9
<abstract> enhancement and suppression are achieved with dynamic weighting of network activity.  </abstract>::line_number::10
<abstract> This paper discusses a neural network that generates the appropriate weights, called the  </abstract>::line_number::11
<abstract> attentional spotlight, given the size and the position of the intended attentional field.  </abstract>::line_number::12
<abstract> The network has three layers. A shunting feedback network serves as the output layer  </abstract>::line_number::13
<abstract> and performs a critical task which cannot be accomplished by feedforward networks.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The problem of concurrent mapping and localization has received considerable attention in the mobile robotics community. With few exceptions, existing approaches can largely be  </abstract>::line_number::8
<abstract> grouped into two distinct paradigms: topological and metric.  </abstract>::line_number::9
<abstract> This paper proposes a method that integrates both paradigms.  </abstract>::line_number::10
<abstract> It poses the mapping problem as a statistical maximum likelihood problem, and devises an efficient algorithm for search  </abstract>::line_number::11
<abstract> in likelihood space. Based on that, it presents an novel mapping algorithm that integrates two phases: a topological and a  </abstract>::line_number::12
<abstract> metric mapping phase. The topological mapping phase solves a  </abstract>::line_number::13
<abstract> global position alignment problem between potentially indistinguishable, significant places. The subsequent metric mapping  </abstract>::line_number::14
<abstract> phase produces a fine-grained metric map of the environment  </abstract>::line_number::15
<abstract> in floating-point resolution. Experimental results in cyclic environments of sizes up to 80 by 25 meters demonstrate the  </abstract>::line_number::16
<abstract> appropriateness of this approach.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This work presents a study of the applicability of a massively parallel computing paradigm  </abstract>::line_number::9
<abstract> to Monte Carlo techniques for device simulation. A unique mapping of Monte Carlo to SIMD  </abstract>::line_number::10
<abstract> fine-grained parallelism has been developed, decoupling the problem into separate computational domains. For MOSFET simulation, this novel mapping allows estimated speeds of  </abstract>::line_number::11
<abstract> over 200,000 scatterings processed per second on a 65,536 processor Connection Machine,  </abstract>::line_number::12
<abstract> nearly a factor of six over the fastest known to date.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A simple polygon P is said to have a Hamilitonian Triangulation if it has a triangulation  </abstract>::line_number::7
<abstract> whose dual graph contains a Hamiltonian path. Such triangulations are useful in fast  </abstract>::line_number::8
<abstract> rendering engines in Computer Graphics. Arkin et al. [AHMS] observed that a polygon  </abstract>::line_number::9
<abstract> has a Hamiltonian triangulation if and only if it is Discretely Straight Walkable, a concept  </abstract>::line_number::10
<abstract> that is a discrete version of Straight Walkability concept as introduced by Icking and Klein  </abstract>::line_number::11
<abstract> [IK]. Using this characterization, Arkin et al. also showed an algorithm to recognize such  </abstract>::line_number::12
<abstract> polygons in time that is linear in the size of the visibility polygon of the given polygon P .  </abstract>::line_number::13
<abstract> The size of the visbility polygon of P could be quadratic in the size of P and hence their  </abstract>::line_number::14
<abstract> algorithm could be very inefficient even for nearly convex polygons.  </abstract>::line_number::15
<abstract> We give a new characterization of polygons with Hamiltonian triangulations. We use  </abstract>::line_number::16
<abstract> this characterization to present the following algorithms:  </abstract>::line_number::17
<abstract> * An O(n log n)-time algorithm to recognize polygons with a Hamiltonian triangulation.  </abstract>::line_number::18
<abstract> * An O(n log n)-time algorithm to construct such a triangulation.  </abstract>::line_number::19
<abstract> * Given vertices p and q on a simple polygon, an O(n)-time algorithm to determine  </abstract>::line_number::20
<abstract> whether the polygon is discretely straight walkable with respect to the two vertices.  </abstract>::line_number::21
<abstract> * An O(n log n)-time algorithm to list out all pairs of points on a simple polygon with  </abstract>::line_number::22
<abstract> respect to which the polygon is discretely straight walkable.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We describe SAMOS, an active object-oriented database management system prototype. SAMOS offers a powerful rule definition language, including a small yet powerful set of event definition facilities. It is able to detect primitive and composite events  </abstract>::line_number::5
<abstract> automatically and efficiently. Upon event detection, SAMOS executes rules attached  </abstract>::line_number::6
<abstract> to the occurred events.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The V -cycle of the wavelet variation of the "Frequency decomposition multigrid method" of Hackbusch [Numer. Math., 56, pp.  </abstract>::line_number::7
<abstract> 229-245, 1989] is considered.  </abstract>::line_number::8
<abstract> It is shown that its convergence speed is not affected by the presence of anisotropy provided that the corresponding coarse grid correction is damped sufficiently strong. Our analysis is based on properties  </abstract>::line_number::9
<abstract> of wavelet packets which are supplied and proved.  </abstract>::line_number::10
<abstract> Numerical approximations to the speed of convergence illustrate  </abstract>::line_number::11
<abstract> the theoretical results.   </abstract>::line_number::12
<abstract>  ABSTRACT  </abstract>::line_number::4
<abstract> This paper discusses several current attempts to use acoustic and electromagnetic wave propagation for modeling  </abstract>::line_number::5
<abstract> physical phenomena and the role that wavelet analysis is playing in these efforts. The first problem involves recent  </abstract>::line_number::6
<abstract> application of wavelets to computational fluid dynamics. The second problem involves geophysical modeling of the  </abstract>::line_number::7
<abstract> ocean floor, using acoustic waves, and wavelets have recently been shown to play an important role here already.  </abstract>::line_number::8
<abstract> The third problem involves modeling of SAR radar images in the context of automatic target recognition efforts.  </abstract>::line_number::9
<abstract> The fourth problem is global illumination in computer graphics, i.e., simulation of reflected and absorbed light  </abstract>::line_number::10
<abstract> for everyday environments. The role of wavelets is more embryonic in these latter two areas, but there are some  </abstract>::line_number::11
<abstract> common principles in all of these modeling efforts, and the methodology of wavelets seems well suited to certain  </abstract>::line_number::12
<abstract> aspects of these problems.   </abstract>::line_number::13
<abstract>  Abstract| Barlow's seminal work on minimal entropy codes and unsupervised learning is  </abstract>::line_number::5
<abstract> reiterated. In particular, the need to transmit the probability of events is put in a practical  </abstract>::line_number::6
<abstract> neuronal framework for detecting suspicious events. A variant of the BCM learning rule [15]  </abstract>::line_number::7
<abstract> is presented together with some mathematical results suggesting optimal minimal entropy  </abstract>::line_number::8
<abstract> coding.   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::10
<abstract> Computer security professionals and researchers do not have a history of sharing and analyzing computer  </abstract>::line_number::11
<abstract> vulnerability information. Scientists and engineers from older or more established fields have long understood  </abstract>::line_number::12
<abstract> that publicizing, analyzing, and learning from other people's mistakes is essential to the stepwise refinement  </abstract>::line_number::13
<abstract> of complex systems. Computer scientists, however, have not followed suit. Programmers reinvent classical  </abstract>::line_number::14
<abstract> programming mistakes, contributing to the reappearance of known vulnerabilities.  </abstract>::line_number::15
<abstract> In the recent past, computer systems have come to be a part of critical systems that have a direct effect  </abstract>::line_number::16
<abstract> on the safety and well-being of human beings and hence we must have lower tolerance for software failures.  </abstract>::line_number::17
<abstract> In the dissertation I will attempt to show that computer vulnerability information presents important  </abstract>::line_number::18
<abstract> regularities and these can be detected, and possibly visualized, providing important insight about the reason  </abstract>::line_number::19
<abstract> of their prevalence and existence. The information derived from these observations could be used to improve on  </abstract>::line_number::20
<abstract> all phases of the development of software systems, as could be in the design, development, debugging, testing  </abstract>::line_number::21
<abstract> and maintenance of complex computer systems that must implement a set of policies defined by security  </abstract>::line_number::22
<abstract> analysis.  </abstract>::line_number::23
<abstract> A significant portion of the work that must be performed will concentrate on the development of classifications and taxonomies that will permit the visualization and analysis of computer vulnerability information.  </abstract>::line_number::24
<abstract> I hope that these classifications and taxonomies applied to a collection of vulnerabilities will provide a set  </abstract>::line_number::25
<abstract> of features whose analysis will show that there are clear statistical clusterings and patterns caused because  </abstract>::line_number::26
<abstract> developers and programmers are not learning from each others mistakes. This analysis may be performed by  </abstract>::line_number::27
<abstract> applying statistical analysis and knowledge discovery tools.   </abstract>::line_number::28
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> Many operating systems have long had pseudo-teletypes, inter-process  </abstract>::line_number::6
<abstract> communication channels that provide terminal semantics on one end,  </abstract>::line_number::7
<abstract> and a smart server program on the other. We describe an analogous  </abstract>::line_number::8
<abstract> concept, pseudo-network drivers. One end of the driver appears to be  </abstract>::line_number::9
<abstract> a real network device, with the appropriate interface and semantics;  </abstract>::line_number::10
<abstract> data written to it goes to a program, however, rather than to a physical  </abstract>::line_number::11
<abstract> medium. Using this and some auxiliary mechanisms, we present a  </abstract>::line_number::12
<abstract> variety of applications, including system test, network monitoring,  </abstract>::line_number::13
<abstract> dial-up TCP/IP, and ways to both improve and subvert network  </abstract>::line_number::14
<abstract> security. Most notably, we show how pseudo-network devices can be  </abstract>::line_number::15
<abstract> used to create virtual networks and to provide encrypted  </abstract>::line_number::16
<abstract> communications capability. We describe two implementations, one  </abstract>::line_number::17
<abstract> using a conventional driver for socket-based systems, and one using  </abstract>::line_number::18
<abstract> stream pipes for System V.   </abstract>::line_number::19
<abstract>  This paper presents an overview of mpi, a proposed  </abstract>::line_number::3
<abstract> standard message passing interface for MIMD distributed memory concurrent computers. The design  </abstract>::line_number::4
<abstract> of mpi has been a collective effort involving researchers  </abstract>::line_number::5
<abstract> in the United States and Europe from many organizations and institutions. mpi includes point-to-point  </abstract>::line_number::6
<abstract> and collective communication routines, as well as support for process groups, communication contexts, and  </abstract>::line_number::7
<abstract> application topologies. While making use of new ideas  </abstract>::line_number::8
<abstract> where appropriate, the mpi standard is based largely  </abstract>::line_number::9
<abstract> on current practice.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::8
<abstract> In 1972, Reynolds outlined a general method for eliminating functional arguments known as defunctionalization. The  </abstract>::line_number::9
<abstract> idea underlying defunctionalization is encoding functional  </abstract>::line_number::10
<abstract> values as first-order data, and then to realized the applications of the encoded function via an apply function. Although this process is simple enough, problems arise when  </abstract>::line_number::11
<abstract> defunctionalization is used in a polymorphic language. In  </abstract>::line_number::12
<abstract> such a language, a functional argument of a higher-order  </abstract>::line_number::13
<abstract> function can take different type instances in different applications. As a consequence, its associated apply function can  </abstract>::line_number::14
<abstract> be untypable in the soucre language. In the paper we present  </abstract>::line_number::15
<abstract> a defunctionalization transformation which preserves typa-bility. Moreover, the transformation imposes no restriction  </abstract>::line_number::16
<abstract> on functional arguments of recursive functions, and it handles functions as results as well as functions encapsulated in  </abstract>::line_number::17
<abstract> constructors or tuples. The key to this success is the use  </abstract>::line_number::18
<abstract> of type information in the defunctionalization transformation. Run-time characteristics are preserved by defunction-alization; hence, there is no performance improvement coming from the transformation itself. However closures need  </abstract>::line_number::19
<abstract> not be implemented to compile the transformed program.  </abstract>::line_number::20
<abstract> Since the defunctionalization is driven by type information,  </abstract>::line_number::21
<abstract> it can also easily perform a specialization of higher-order  </abstract>::line_number::22
<abstract> functions with respect to the values of their functional arguments, hence gaining a real run-time improvement of the  </abstract>::line_number::23
<abstract> transformed program.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Reactive systems respond to concurrent, possibly unsynchronized streams of input events. Programming  </abstract>::line_number::6
<abstract> reactive systems is challenging without language support for event-triggered actions. It is even more  </abstract>::line_number::7
<abstract> challenging to reason about reactive systems. This paper explores a new conceptual basis for applying  </abstract>::line_number::8
<abstract> functional programming techniques to the design and formal verification of reactive systems. The  </abstract>::line_number::9
<abstract> mathematical foundation for this approach is based upon signature coalgebras and derived proof rules  </abstract>::line_number::10
<abstract> for coinduction. The concepts are illustrated with an example that has been used with the language  </abstract>::line_number::11
<abstract> Esterel.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Recent advances in the Domain Name System (DNS) and the Dynamic Host Configuration  </abstract>::line_number::5
<abstract> Protocol (DHCP) have enabled a new approach to supporting mobile users: location independent  </abstract>::line_number::6
<abstract> naming. In this approach, machines use the same hostname from any internet location, but use an  </abstract>::line_number::7
<abstract> IP address that corresponds to their current location. We describe a protocol that implements  </abstract>::line_number::8
<abstract> location independent naming for nomadic computers, i.e., machines that do not need transparent  </abstract>::line_number::9
<abstract> mobility. Our protocol allows hosts to move across security domains, uses existing protocols, and  </abstract>::line_number::10
<abstract> preserves existing trust relationships. Therefore, it preserves the performance and security of  </abstract>::line_number::11
<abstract> normal IP for nomadic computers at the expense of not providing the transparent mobility of  </abstract>::line_number::12
<abstract> Mobile IP. We contend that this is a reasonable tradeoff for nomadic computing.  </abstract>::line_number::13
<abstract>  </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::12
<abstract> We give a review of basic statistical and neural techniques for classification. Statistical techniques are based on the idea of estimating class-conditional likelihoods and using Bayes rule  </abstract>::line_number::13
<abstract> to convert these to posterior class probabilities whereas neural techniques estimate directly the  </abstract>::line_number::14
<abstract> posteriors. Statistical techniques include (i) Parametric (Gaussian) Bayes classifiers, (ii) Non-parametric kernel-based density estimators like k-nearest neighbor and Parzen windows, and  </abstract>::line_number::15
<abstract> (iii) mixtures of (Gaussian) densities (a special case of which is the Learning Vector Quantization). As neural classifiers, we include simple perceptrons and multilayer perceptrons with  </abstract>::line_number::16
<abstract> sigmoid and Gaussian hidden units. The neural and statistical techniques are quite similar in  </abstract>::line_number::17
<abstract> many respects and many approaches have been discovered independently twice, once in 1960s  </abstract>::line_number::18
<abstract> by statisticians and once in 1980s by the neural network researchers. One of the aims of this article is to make this link more apparent. We also discuss two, most popular, pattern recognition  </abstract>::line_number::19
<abstract> applications: Optical character recognition and speech recognition. Though they seem different,  </abstract>::line_number::20
<abstract> in many respects, the two applications are similar and in the past, almost the same techniques  </abstract>::line_number::21
<abstract> have been applied for their implementation. We implement the well known statistical and neural  </abstract>::line_number::22
<abstract> classification techniques for two datasets of these applications and compare them in terms of  </abstract>::line_number::23
<abstract> generalization accuracy, memory requirement and learning time. We especially advise to take  </abstract>::line_number::24
<abstract> into account statistics of the sample even if a neural classifier is to be used. The similarity  </abstract>::line_number::25
<abstract> between statistical and neural techniques is greater than generally agreed and simple statistical  </abstract>::line_number::26
<abstract> methods like k-NN perform generally quite well and much of the functionality of neural networks like distributed parallel computation can be obtained by such methods without requiring  </abstract>::line_number::27
<abstract> complicated computation and precise error minimization procedures.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We define a standard of effectiveness for a database calculus  </abstract>::line_number::8
<abstract> relative to a query language. Effectiveness judges suitability  </abstract>::line_number::9
<abstract> to serve as a processing framework for the query language,  </abstract>::line_number::10
<abstract> and comprises aspects of coverage, manipulability and  </abstract>::line_number::11
<abstract> efficient evaluation. We present the monoid calculus, and  </abstract>::line_number::12
<abstract> argue its effectiveness for object-oriented query languages,  </abstract>::line_number::13
<abstract> exemplified by OQL of ODMG-93. The monoid calculus  </abstract>::line_number::14
<abstract> readily captures such features as multiple collection types,  </abstract>::line_number::15
<abstract> aggregations, arbitrary composition of type constructors and  </abstract>::line_number::16
<abstract> nested query expressions. We also show how to extend  </abstract>::line_number::17
<abstract> the monoid calculus to deal with vectors and arrays in  </abstract>::line_number::18
<abstract> more expressive ways than current query languages do, and  </abstract>::line_number::19
<abstract> illustrate how it can handle identity and updates.   </abstract>::line_number::20
<abstract>  Abstract. Continuation-passing style (CPS) is a good abstract representation to use  </abstract>::line_number::7
<abstract> for compilation and optimization: it has a clean semantics and is easily manipulated.  </abstract>::line_number::8
<abstract> We examine how CPS expresses the saving and restoring of registers in source-language  </abstract>::line_number::9
<abstract> procedure calls. In most CPS-based compilers, the context of the calling procedure is  </abstract>::line_number::10
<abstract> saved in a "continuation closure"|a single variable that is passed as an argument to the  </abstract>::line_number::11
<abstract> function being called. This closure is a record containing bindings of all the free variables  </abstract>::line_number::12
<abstract> of the continuation; that is, registers that hold values needed by the caller "after the call"  </abstract>::line_number::13
<abstract> are written to memory in the closure, and fetched back after the call.  </abstract>::line_number::14
<abstract> Consider the procedure-call mechanisms used by conventional compilers. In particular,  </abstract>::line_number::15
<abstract> registers holding values needed after the call must be saved and later restored. The  </abstract>::line_number::16
<abstract> responsibility for saving registers can lie with the caller (a "caller-saves" convention)  </abstract>::line_number::17
<abstract> or with the called function ("callee-saves"). In practice, to optimize memory traffic,  </abstract>::line_number::18
<abstract> compilers find it useful to have some caller-saves registers and some callee-saves.  </abstract>::line_number::19
<abstract> "Conventional" CPS-based compilers that pass a pointer to a record containing all  </abstract>::line_number::20
<abstract> the variables needed after the call (i.e., the continuation closure), are using a caller-saves  </abstract>::line_number::21
<abstract> convention. We explain how to express callee-save registers in Continuation-Passing  </abstract>::line_number::22
<abstract> Style, and give measurements showing the resulting improvement in execution time.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We propose several new techniques for resource management in a replicated object server. By coordinating cache  </abstract>::line_number::7
<abstract> and disk usage among the replicas, these techniques increase throughput and reduce fetch latency. Cache splitting  </abstract>::line_number::8
<abstract> speeds up fetches by avoiding redundant cache entries, effectively increasing the cache size. Coordinated writing  </abstract>::line_number::9
<abstract> coordinates disk writes to ensure that one replica is always  </abstract>::line_number::10
<abstract> available to service fetches. We investigate the performance  </abstract>::line_number::11
<abstract> of a replicated server using these techniques, and we present  </abstract>::line_number::12
<abstract> simulation results showing that these techniques provide  </abstract>::line_number::13
<abstract> substantial performance improvements across a variety of  </abstract>::line_number::14
<abstract> workloads.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Partial determinations are an interesting  </abstract>::line_number::8
<abstract> form of dependency between attributes in a  </abstract>::line_number::9
<abstract> relation. They generalize functional dependencies by allowing exceptions. We modify a known MDL formula for evaluating  </abstract>::line_number::10
<abstract> such partial determinations to allow for its  </abstract>::line_number::11
<abstract> use in an admissible heuristic in exhaustive  </abstract>::line_number::12
<abstract> search. Furthermore we describe an efficient  </abstract>::line_number::13
<abstract> preprocessing-based approach for handling  </abstract>::line_number::14
<abstract> numerical attributes. An empirical investigation tries to evaluate the viability of the  </abstract>::line_number::15
<abstract> presented ideas.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A digraph D is called a quasi-transitive digraph (QTD) if for any  </abstract>::line_number::7
<abstract> triple x; ; of distinct vertices of D such that (x; ) and (; ) are  </abstract>::line_number::8
<abstract> arcs of D there is at least one arc from x to or from to x. Solving  </abstract>::line_number::9
<abstract> a conjecture by J. Bang-Jensen and J. Huang (J. Graph Theory, to  </abstract>::line_number::10
<abstract> appear), G. Gutin (Australas. J. Combin., to appear) described polynomial algorithms for finding a Hamiltonian cycle and a Hamiltonian  </abstract>::line_number::11
<abstract> path (if it exists) in a QTD. The approach taken in that paper cannot  </abstract>::line_number::12
<abstract> be used to find a longest path or cycle in polynomial time. We present  </abstract>::line_number::13
<abstract> a principally new approach that leads to polynomial algorithms for  </abstract>::line_number::14
<abstract> finding vertex heaviest paths and cycles in QTD's with non-negative  </abstract>::line_number::15
<abstract> weights on the vertices. This, in particular, provides an answer to a  </abstract>::line_number::16
<abstract> question by N. Alon on longest paths and cycles in QTD's.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper describes several of our experiences with a real-time scheduler. Using a robot control application program, we motivate the importance of supporting multiple schedulers within the same application  </abstract>::line_number::9
<abstract> program. We demonstrate the utility of speculative task execution in dynamic real-time systems, and describe the implementation of a scheduler for performing speculative execution and recovery. We show that  </abstract>::line_number::10
<abstract> existing real-time scheduler interfaces have scope for improvement, especially when scheduling latency must  </abstract>::line_number::11
<abstract> be low and when multiple schedulers used by a single application must co-exist on a single processor. A new  </abstract>::line_number::12
<abstract> scheduler interface is specified and its basic costs are evaluated experimentally. Preliminary measurements on  </abstract>::line_number::13
<abstract> a KSR-1 machine are quoted. The measurements demonstrate how the execution times of temporal queries  </abstract>::line_number::14
<abstract> may be reduced by use of access structures to scheduler data structures. Finally, there are several overheads  </abstract>::line_number::15
<abstract> associated with speculative execution, and multiple schedulers in a single application. We consider the problem of on-line reconfiguration of the several overheads associated with the speculative-execution paradigm  </abstract>::line_number::16
<abstract> for optimal performance in the face of these overheads. Initial performance measurements of the PORTS  </abstract>::line_number::17
<abstract> scheduler indicate that it is possible to perform real-time scheduling with latencies approximating those of  </abstract>::line_number::18
<abstract> proposed specialized scheduling co-processors.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Multicast routing is an important topic of both theoretical and practical  </abstract>::line_number::8
<abstract> interest. Some recently-proposed multicast routing algorithms involve the  </abstract>::line_number::9
<abstract> designation of one or more network nodes as the "center" of the routing  </abstract>::line_number::10
<abstract> tree for each multicast group address. The choice of this designated router  </abstract>::line_number::11
<abstract> (which we refer to as the "core") influences the shape of the multicast routing  </abstract>::line_number::12
<abstract> tree, and thus influences performance of the routing scheme. In this paper we  </abstract>::line_number::13
<abstract> investigate the relationship between the choice of core and three performance  </abstract>::line_number::14
<abstract> measures. Specifically, we compare various methods of selecting a core with  </abstract>::line_number::15
<abstract> respect to their effect on bandwidth, delay, and traffic concentration. We  </abstract>::line_number::16
<abstract> conclude that simple methods are adequate for widely distributed groups,  </abstract>::line_number::17
<abstract> but that the addition of group information can be leveraged to improve  </abstract>::line_number::18
<abstract> performance especially when the group is small or exhibits a high degree  </abstract>::line_number::19
<abstract> of locality. We also conclude that core choice has a significant impact on  </abstract>::line_number::20
<abstract> traffic concentration, in fact traffic concentration effects can be ameliorated  </abstract>::line_number::21
<abstract> by appropriate core choice policies.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::2
<abstract> This paper describes a general architecture for an interactive model-based vision system. A  </abstract>::line_number::3
<abstract> human specifies a limited amount of information which establishes a context for autonomous interpretation of images. Object models are described by constraints specifying necessary geometrical  </abstract>::line_number::4
<abstract> properties and relationships between objects. The use of constraints allows for flexible object in-stantiation. A user can indicate an object in a scene and this directs perceptual processing routines  </abstract>::line_number::5
<abstract> as well as constraining future object instantiations. This interactive model-based concept has been  </abstract>::line_number::6
<abstract> applied to the domain of vehicle tracking, and this paper concludes with several processing examples  </abstract>::line_number::7
<abstract> from this domain.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Formal models of animal sensorimotor behavior can  </abstract>::line_number::9
<abstract> provide effective methods for generating robotic intelligence. In this paper we describe how schema-theoretic  </abstract>::line_number::10
<abstract> models of the praying mantis are implemented on a  </abstract>::line_number::11
<abstract> hexapod robot equipped with a real-time color vision  </abstract>::line_number::12
<abstract> system. The model upon which the implementation  </abstract>::line_number::13
<abstract> is based was developed by ethologists studying man-tids. This implementation incorporates a wide range  </abstract>::line_number::14
<abstract> of behaviors, including obstacle avoidance, prey acquisition, predator avoidance, mating, and chantlitaxia  </abstract>::line_number::15
<abstract> behaviors.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Using the Trellis human/computer interaction model as an implementation vehicle, we demonstrate  </abstract>::line_number::8
<abstract> how to use concurrency-supporting hypertext to provide visual displays of the execution flows through  </abstract>::line_number::9
<abstract> a parallel Lisp program. In addition to displays, the hypertext interface allows injection of control  </abstract>::line_number::10
<abstract> flow into an otherwise functional computation, and therefore provides reader control over the order of  </abstract>::line_number::11
<abstract> evaluation of expressions. The resulting system, termed Trellis, can be thought of as a concurrent control  </abstract>::line_number::12
<abstract> flow browser for composing functional computations, providing a visual implementation of kernel-control  </abstract>::line_number::13
<abstract> decomposition. The advantages of Trellis are ease of exploring program side effects; ease of debugging  </abstract>::line_number::14
<abstract> parallel code; aid in teaching functional languages; and the ability to construct hypertext documents  </abstract>::line_number::15
<abstract> that have parallel execution semantics and flexible browsing behaviors.  </abstract>::line_number::16
<abstract> Key words: functional programming, parallelism, kernel-control decomposition, Lisp, hypertext, exe  </abstract>::line_number::17
<abstract> cution visualization.   </abstract>::line_number::18
<abstract>  Computer networks hold the potential to coordinate the activities of multiple machines so that their combined computational abilities can be applied to solving a single problem. Several methods have been developed over the years to  </abstract>::line_number::4
<abstract> harness the power of networked systems for solving certain classes of problems. One such class of problems is the distributed producer/consumer problem, in which a set of producer processes supply items to a set of consumer processes. Each  </abstract>::line_number::5
<abstract> of the processes involved resides on a different machine, with the machines being connected by a network and the processes communicating via message passing. The problem, then, is how to coordinate the activities of the producers and consumers so that an acceptable level of throughput can be maintained with a minimal amount of overhead. This paper  </abstract>::line_number::6
<abstract> presents a simple solution to the distributed producer/consumer problem. This solution, which is based upon the notion of  </abstract>::line_number::7
<abstract> a distributed pool, is described in detail and its performance analyzed. As the analysis shows, the distributed pools algorithm presented herein is a simple, efficient solution to the distributed producer/consumer problem, and is capable of better than 90% efficiency under common conditions. Its major failing is that it needs the production rates of the producers  </abstract>::line_number::8
<abstract> to be reasonably similar.   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::11
<abstract> A new, efficient selection predicate indexing scheme for active database systems is introduced.  </abstract>::line_number::12
<abstract> The selection predicate index proposed uses an interval index on an attribute of a relation or  </abstract>::line_number::13
<abstract> object collection when one or more rule condition clauses are defined on that attribute. The  </abstract>::line_number::14
<abstract> selection predicate index uses a new type of interval index called the interval skip list (IS-list).  </abstract>::line_number::15
<abstract> The IS-list is designed to allow efficient retrieval of all intervals that overlap a point, while allowing  </abstract>::line_number::16
<abstract> dynamic insertion and deletion of intervals. IS-list algorithms are described in detail. The IS-list  </abstract>::line_number::17
<abstract> allows efficient on-line searches, insertions, and deletions, yet is much simpler to implement than  </abstract>::line_number::18
<abstract> other comparable interval index data structures such as the priority search tree and balanced  </abstract>::line_number::19
<abstract> interval binary search tree (IBS-tree). IS-lists require only one third as much code to implement  </abstract>::line_number::20
<abstract> as balanced IBS-trees. The combination of simplicity, performance, and dynamic updateability  </abstract>::line_number::21
<abstract> of the IS-list is unmatched by any other interval index data structure. This makes the IS-list a  </abstract>::line_number::22
<abstract> good interval index structure for implementation in an active database predicate index.    </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Shape modeling is an important constituent of computer vision as well as computer graphics  </abstract>::line_number::9
<abstract> research. Shape models aid the tasks of object representation and recognition. This paper  </abstract>::line_number::10
<abstract> presents a new approach to shape modeling which retains some of the attractive features of  </abstract>::line_number::11
<abstract> existing methods, and overcomes some of their limitations. Our techniques can be applied to  </abstract>::line_number::12
<abstract> model arbitrarily complex shapes, which include shapes with significant protrusions, and to  </abstract>::line_number::13
<abstract> situations where no a priori assumption about the object's topology is made. A single instance  </abstract>::line_number::14
<abstract> of our model, when presented with an image having more than one object of interest, has the  </abstract>::line_number::15
<abstract> ability to split freely to represent each object. This method is based on the ideas developed  </abstract>::line_number::16
<abstract> by Osher and Sethian to model propagating solid/liquid interfaces with curvature-dependent  </abstract>::line_number::17
<abstract> speeds. The interface (front) is a closed, nonintersecting, hypersurface flowing along its gradient  </abstract>::line_number::18
<abstract> field with constant speed or a speed that depends on the curvature. It is moved by solving a  </abstract>::line_number::19
<abstract> "Hamilton-Jacobi" type equation written for a function in which the interface is a particular  </abstract>::line_number::20
<abstract> level set. A speed term synthesized from the image is used to stop the interface in the vicinity of  </abstract>::line_number::21
<abstract> object boundaries. The resulting equation of motion is solved by employing entropy-satisfying  </abstract>::line_number::22
<abstract> upwind finite difference schemes. We present a variety of ways of computing evolving front,  </abstract>::line_number::23
<abstract> including narrow bands, reinitializations, and different stopping criteria. The efficacy of the  </abstract>::line_number::24
<abstract> scheme is demonstrated with numerical experiments on some synthesized images and some low  </abstract>::line_number::25
<abstract> contrast medical images.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The role of the systems analyst in the implementation process has changed  </abstract>::line_number::8
<abstract> dramatically in recent times because of changes to organisational boundaries, the  </abstract>::line_number::9
<abstract> need to align IT with business objectives and the complexity of the systems now  </abstract>::line_number::10
<abstract> required. Some organisations are finding themselves in a continually changing  </abstract>::line_number::11
<abstract> environment and being involved in multi-organisational structures. Establishing  </abstract>::line_number::12
<abstract> strategies and requirements for these organisations requires a new understanding  </abstract>::line_number::13
<abstract> of the implementation process. Implementation is concerned with behavioural  </abstract>::line_number::14
<abstract> phenomena since people are involved from the inception of the idea, as well as  </abstract>::line_number::15
<abstract> being involved in the development process. They are also affected by the changes  </abstract>::line_number::16
<abstract> which the new system brings to the organisation. The research is attempting to  </abstract>::line_number::17
<abstract> understand the critical factors associated with the implementation process and  </abstract>::line_number::18
<abstract> consequently develop an appropriate model.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Two-way authentication methods are inefficient when used to authenticate multiple users who wish to communicate securely with each other. M-way, also called conference authentication, is designed to efficiently authenticate many users and distribute a secure common conference key. Unfortunately, few if any conference  </abstract>::line_number::10
<abstract> authentication schemes have been developed and/or performance tested in a real distributed system. This report  </abstract>::line_number::11
<abstract> attempts to rectify this problem. Specifically, it presents the performance of both a star and a ring-based conference authentication scheme that has been developed for the RHODOS distributed operating system. As with most  </abstract>::line_number::12
<abstract> systems, RHODOS does not have any special hardware, thus, a software based solution is utilised. This report  </abstract>::line_number::13
<abstract> also attempts to shed some light upon how viable and secure a conference authentication scheme would be when  </abstract>::line_number::14
<abstract> used in a distributed system.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::11
<abstract> The appearance of an object or a face changes continuously as the observer  </abstract>::line_number::12
<abstract> moves through the environment or as a face changes expression or pose. Recognizing an object or a face despite these image changes is a challenging problem  </abstract>::line_number::13
<abstract> for computer vision systems, yet we perform the task quickly and easily. This  </abstract>::line_number::14
<abstract> simulation investigates the ability of an unsupervised learning mechanism to  </abstract>::line_number::15
<abstract> acquire representations that are tolerant to such changes in the image. The  </abstract>::line_number::16
<abstract> learning mechanism finds these representations by capturing temporal relationships between 2-D patterns. Previous models of temporal association learning  </abstract>::line_number::17
<abstract> have used idealized input representations. The input to this model consists of  </abstract>::line_number::18
<abstract> graylevel images of faces. A two-layer network learned face representations that  </abstract>::line_number::19
<abstract> incorporated changes of pose up to 30 ffi . A second network learned representations that were independent of facial expression.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The game of Go has a high branching factor that defeats the tree  </abstract>::line_number::8
<abstract> search approach used in computer chess, and long-range spa-tiotemporal interactions that make position evaluation extremely  </abstract>::line_number::9
<abstract> difficult. Development of conventional Go programs is hampered  </abstract>::line_number::10
<abstract> by their knowledge-intensive nature. We demonstrate a viable  </abstract>::line_number::11
<abstract> alternative by training networks to evaluate Go positions via temporal difference (TD) learning.  </abstract>::line_number::12
<abstract> Our approach is based on network architectures that reflect the  </abstract>::line_number::13
<abstract> spatial organization of both input and reinforcement signals on  </abstract>::line_number::14
<abstract> the Go board, and training protocols that provide exposure to  </abstract>::line_number::15
<abstract> competent (though unlabelled) play. These techniques yield far  </abstract>::line_number::16
<abstract> better performance than undifferentiated networks trained by self-play alone. A network with less than 500 weights learned within  </abstract>::line_number::17
<abstract> 3,000 games of 9x9 Go a position evaluation function that enables  </abstract>::line_number::18
<abstract> a primitive one-ply search to defeat a commercial Go program at  </abstract>::line_number::19
<abstract> a low playing level.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::3
<abstract> This paper describes how to generate a single image which, when viewed in the  </abstract>::line_number::4
<abstract> appropriate way, appears to the brain as a 3D scene. The image is a stereogram composed  </abstract>::line_number::5
<abstract> of seemingly random dots. A new, simple and symmetric algorithm for generating such  </abstract>::line_number::6
<abstract> images from a solid model is given, along with the design parameters and their influence  </abstract>::line_number::7
<abstract> on the display. The algorithm improves on previously-described ones in several ways: it  </abstract>::line_number::8
<abstract> is symmetric and hence free from directional (right-to-left or left-to-right) bias, it corrects  </abstract>::line_number::9
<abstract> a slight distortion in the rendering of depth, it removes hidden parts of surfaces, and it  </abstract>::line_number::10
<abstract> also eliminates a type of artifact that we call an echo.  </abstract>::line_number::11
<abstract> Random dot stereograms have one remaining problem: difficulty of initial viewing. If  </abstract>::line_number::12
<abstract> a computer screen rather than paper is used for output, the problem can be ameliorated by  </abstract>::line_number::13
<abstract> shimmering, or time-multiplexing of pixel values. We also describe a simple  </abstract>::line_number::14
<abstract> computational technique for determining what is present in a stereogram so that, if  </abstract>::line_number::15
<abstract> viewing is difficult, one can ascertain what to look for.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Current Remote Procedure Call (RPC) services implement a variety of semantics, with many of the differences  </abstract>::line_number::6
<abstract> related to how communication and server failures are handled. The list increases even more when considering group  </abstract>::line_number::7
<abstract> RPC, a variant of RPC often used for fault-tolerance where  </abstract>::line_number::8
<abstract> an invocation is sent to a group of servers rather than one.  </abstract>::line_number::9
<abstract> This paper presents an approach to constructing group  </abstract>::line_number::10
<abstract> RPC in which a single configurable system is used to build  </abstract>::line_number::11
<abstract> different variants of the service. The approach is based on  </abstract>::line_number::12
<abstract> implementing each property as a separate software module  </abstract>::line_number::13
<abstract> called a micro-protocol, and then configuring the micro-protocols needed to implement the desired service together  </abstract>::line_number::14
<abstract> using a software framework based on the x-kernel. The  </abstract>::line_number::15
<abstract> properties of point-to-point and group RPC are identified  </abstract>::line_number::16
<abstract> and classified, and the general execution model described.  </abstract>::line_number::17
<abstract> An example consisting of a modular implementation of a  </abstract>::line_number::18
<abstract> group RPC service is given to illustrate the approach. Dependency issues that restrict configurability are also addressed.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> The NASA Numerical Propulsion System Simulation  </abstract>::line_number::6
<abstract> (NPSS) project is exploring the use of computer simulation  </abstract>::line_number::7
<abstract> to facilitate the design of new jet engines. Several key issues  </abstract>::line_number::8
<abstract> raised in this research are being examined in an NPSS-related research project: zooming, monitoring and control,  </abstract>::line_number::9
<abstract> and support for heterogeneity. The design of a simulation  </abstract>::line_number::10
<abstract> executive that addresses each of these issues is described.  </abstract>::line_number::11
<abstract> In this work, the strategy of zooming, which allows codes  </abstract>::line_number::12
<abstract> that model at different levels of fidelity to be integrated  </abstract>::line_number::13
<abstract> within a single simulation, is applied to the fan component  </abstract>::line_number::14
<abstract> of a turbofan propulsion system. A prototype monitoring  </abstract>::line_number::15
<abstract> and control system has been designed for this simulation to  </abstract>::line_number::16
<abstract> support experimentation with expert system techniques for  </abstract>::line_number::17
<abstract> active control of the simulation. An interconnection system  </abstract>::line_number::18
<abstract> provides a transparent means of connecting the heterogeneous systems that comprise the prototype.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> The task of information browsers is (1) to aid in navigating through a  </abstract>::line_number::6
<abstract> large database to locate the item of interest and (2) to inspect or otherwise  </abstract>::line_number::7
<abstract> manipulate this item once found. This document describes three experiments in constructing tools for information browsing: TkMan for UNIX  </abstract>::line_number::8
<abstract> manual pages, NBT for files in a hierarchical file system, and FoSel for  </abstract>::line_number::9
<abstract> bitmap fonts. Each exploits the large-scale natural organization of data  </abstract>::line_number::10
<abstract> and the fine-grained structure of each datum with a graphical user interface to provide a powerful yet intuitive tool. The lessons learned in implementing the browsers point to general principles that should guide the  </abstract>::line_number::11
<abstract> design of all information browsers.   </abstract>::line_number::12
<abstract>  ABSTRACT  </abstract>::line_number::8
<abstract> This paper evaluates several hardware platforms and operating systems using a set of benchmarks  </abstract>::line_number::9
<abstract> that stress kernel entry/exit, file systems, and other things related to operating systems. The  </abstract>::line_number::10
<abstract> overall conclusion is that operating system performance is not improving at the same rate as the  </abstract>::line_number::11
<abstract> base speed of the underlying hardware. The most obvious ways to remedy this situation are to  </abstract>::line_number::12
<abstract> improve memory bandwidth and reduce operating systems' tendency to wait for disk operations to  </abstract>::line_number::13
<abstract> complete.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::9
<abstract> This paper describes the application of Parallel Distributed Genetic Programming (PDGP) to the problem of inducing programs for natural language processing.  </abstract>::line_number::10
<abstract> PDGP is a new form of Genetic Programming (GP) which is suitable for the development of programs with a high degree of parallelism and an efficient and effective  </abstract>::line_number::11
<abstract> reuse of partial results. Programs are represented in PDGP as graphs with nodes  </abstract>::line_number::12
<abstract> representing functions and terminals, and links representing the flow of control and  </abstract>::line_number::13
<abstract> results. PDGP allows the exploration of a large space of possible programs including standard tree-like programs, logic networks, neural networks, finite state  </abstract>::line_number::14
<abstract> automata, Recursive Transition Networks (RTNs), etc. The paper describes the  </abstract>::line_number::15
<abstract> representations, the operators and the interpreters used in PDGP, and illustrates  </abstract>::line_number::16
<abstract> its behaviour on the problem of inducing RTN-based recognisers for natural lan  </abstract>::line_number::17
<abstract> guage from positive and negative examples.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::7
<abstract> In artificial evolution individuals which perform as their parents are usually rewarded identically  </abstract>::line_number::8
<abstract> to their parents. We note that Nature is more dynamic and there may be a penalty to pay for doing  </abstract>::line_number::9
<abstract> the same thing as your parents. We report two sets of experiments where static fitness functions  </abstract>::line_number::10
<abstract> are firstly augmented by a penalty for unchanged offspring and secondly the static fitness case  </abstract>::line_number::11
<abstract> is replaced by randomly generated dynamic test cases. We conclude genetic programming, when  </abstract>::line_number::12
<abstract> evolving artificial ant control programs, is surprisingly little effected by large penalties and program  </abstract>::line_number::13
<abstract> growth is observed in all our experiments.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The problem of programming an artificial ant to follow the Santa Fe trail is used as an example  </abstract>::line_number::8
<abstract> program search space. Analysis of shorter solutions shows they have many of the characteristics  </abstract>::line_number::9
<abstract> often ascribed to manually coded programs. Enumeration of a small fraction of the total search  </abstract>::line_number::10
<abstract> space and random sampling characterise it as rugged with many multiple plateaus split by deep  </abstract>::line_number::11
<abstract> valleys and many local and global optima. This suggests it is difficult for hill climbing algorithms.  </abstract>::line_number::12
<abstract> Analysis of the program search space in terms of fixed length schema suggests it is highly deceptive  </abstract>::line_number::13
<abstract> and that for the simplest solutions large building blocks must be assembled before they have above  </abstract>::line_number::14
<abstract> average fitness. In some cases we show solutions cannot be assembled using a fixed representation  </abstract>::line_number::15
<abstract> from small building blocks of above average fitness. These suggest the Ant problem is difficult for  </abstract>::line_number::16
<abstract> Genetic Algorithms.  </abstract>::line_number::17
<abstract> Random sampling of the program search space suggests on average the density of global optima  </abstract>::line_number::18
<abstract> changes only slowly with program size but the density of neutral networks linking points of the same  </abstract>::line_number::19
<abstract> fitness grows approximately linearly with program length. This is part of the cause of bloat.  </abstract>::line_number::20
<abstract> Previously reported genetic programming, simulated annealing and hill climbing performance is  </abstract>::line_number::21
<abstract> shown not to be much better than random search on the Ant problem.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::18
<abstract> In this paper we present the GP-Music System, an interactive system which allows users to evolve short musical sequences  </abstract>::line_number::19
<abstract> using interactive genetic programming, and its extensions aimed at making the system fully automated. The basic GP-system works by using a genetic programming algorithm, a small set of functions for creating musical sequences, and a user  </abstract>::line_number::20
<abstract> interface which allows the user to rate individual sequences. With this user interactive technique it was possible to generate  </abstract>::line_number::21
<abstract> pleasant tunes over runs of 20 individuals over 10 generations. As the user is the bottleneck in interactive systems, the  </abstract>::line_number::22
<abstract> system takes rating data from a users run and uses it to train a neural network based automatic rater, or auto rater, which  </abstract>::line_number::23
<abstract> can replace the user in bigger runs. Using this auto rater we were able to make runs of up to 50 generations with 500  </abstract>::line_number::24
<abstract> individuals per generation. The best of run pieces generated by the auto raters were pleasant but were not, in general, as  </abstract>::line_number::25
<abstract> nice as those generated in user interactive runs.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We introduce the concept of energy per operation as  </abstract>::line_number::5
<abstract> a measure of performance of an asynchronous circuit.  </abstract>::line_number::6
<abstract> We show how to model energy consumption based on  </abstract>::line_number::7
<abstract> the high-level language specification. This model is independent of voltage and timing considerations. We  </abstract>::line_number::8
<abstract> apply this model to memory design. We show first  </abstract>::line_number::9
<abstract> how to dimension a memory array, and how to break  </abstract>::line_number::10
<abstract> up this memory array into smaller arrays to minimize  </abstract>::line_number::11
<abstract> the energy per access. We then show how to use cache  </abstract>::line_number::12
<abstract> memory and pre-fetch mechanisms to further reduce  </abstract>::line_number::13
<abstract> energy per access.   </abstract>::line_number::14
<abstract>  Abstract. A critical challenge faced by the developer of a software system is to understand whether the system's components correctly integrate. While type theory has provided substantial help in detecting and  </abstract>::line_number::12
<abstract> preventing errors in mismatched static properties, much work remains  </abstract>::line_number::13
<abstract> in the area of dynamics. In particular, components make assumptions  </abstract>::line_number::14
<abstract> about their behavioral interaction with other components, but currently  </abstract>::line_number::15
<abstract> we have only limited ways in which to state those assumptions and to  </abstract>::line_number::16
<abstract> analyze those assumptions for correctness.  </abstract>::line_number::17
<abstract> We have begun to formulate a method that addresses this problem. The  </abstract>::line_number::18
<abstract> method operates at the architectural level so that behavioral integration  </abstract>::line_number::19
<abstract> errors, such as deadlock, can be revealed early in development. For each  </abstract>::line_number::20
<abstract> component, a specification is given both of its own interaction behavior  </abstract>::line_number::21
<abstract> and of the assumptions that it makes about the interaction behavior of  </abstract>::line_number::22
<abstract> the external context in which it expects to operate. We have defined an  </abstract>::line_number::23
<abstract> algorithm that, given such specifications for a set of components, performs "adequacy" checks between the component context assumptions  </abstract>::line_number::24
<abstract> and the component interaction behaviors. A configuration of a system is  </abstract>::line_number::25
<abstract> possible if and only if a successful way of "matching" actual behaviors  </abstract>::line_number::26
<abstract> with assumptions can be found. In effect, we are extending the usual no  </abstract>::line_number::27
<abstract> tion of type checking to include the checking of behavioral compatibility.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::9
<abstract> This paper presents a method that can be used for  </abstract>::line_number::10
<abstract> the elicitation and specification of requirements and  </abstract>::line_number::11
<abstract> high-level design. It supports stakeholder-based modeling, rapid feasibility feedback to marketing, and the  </abstract>::line_number::12
<abstract> interpersonal dynamics that are necessary to develop  </abstract>::line_number::13
<abstract> a product. The method centers on the role of the facilitator, an independent agent whose purpose is to build  </abstract>::line_number::14
<abstract> the Integrated System Model (ISM). The ISM is the result of merging the independent system views from all  </abstract>::line_number::15
<abstract> stakeholders at any given abstraction level. Formulation of this method was based on the real-world experience of developing a complex, high-technology medical  </abstract>::line_number::16
<abstract> product with critical time-to-market pressures. It has  </abstract>::line_number::17
<abstract> proven to be a practical approach to the evolution of  </abstract>::line_number::18
<abstract> requirements definition and provides a necessary link  </abstract>::line_number::19
<abstract> to the marketing aspect of a product.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Software distribution is evolving from a physical media  </abstract>::line_number::9
<abstract> approach to one where it is practical and advantageous to  </abstract>::line_number::10
<abstract> leverage the connectivity of networks. Network distribution of software systems provides timeliness and continuity  </abstract>::line_number::11
<abstract> of evolution not possible with physical media distribution  </abstract>::line_number::12
<abstract> methods. To support network-based software distribution,  </abstract>::line_number::13
<abstract> companies and organizations such as Microsoft, Marimba,  </abstract>::line_number::14
<abstract> and the Desktop Management Task Force (DMTF) are  </abstract>::line_number::15
<abstract> strengthening their efforts to package software systems in  </abstract>::line_number::16
<abstract> a way that is conducive to network distribution and management. The result of these efforts has led to the creation  </abstract>::line_number::17
<abstract> of software description languages and schema such as the  </abstract>::line_number::18
<abstract> Open Software Description format created by Microsoft and  </abstract>::line_number::19
<abstract> Marimba and the Management Information Format created  </abstract>::line_number::20
<abstract> by DMTF. While these efforts are steps in the right direction, they do not address deployment issues in a complete  </abstract>::line_number::21
<abstract> and systematic fashion. The contribution of this paper is to  </abstract>::line_number::22
<abstract> evaluate these leading software description technologies.   </abstract>::line_number::23
<abstract>  Abstract. The problem of finding the naturally occurring structure of a protein is believed to correspond to minimizing the free, or potential, energy of  </abstract>::line_number::6
<abstract> the protein. This is generally a very difficult global optimization problem, with  </abstract>::line_number::7
<abstract> a large number of parameters and a huge number of local minimizers including many with function values near that of the global minimizer. This paper  </abstract>::line_number::8
<abstract> presents a new global optimization method for such problems. The method  </abstract>::line_number::9
<abstract> consists of an initial phase that locates some reasonably low local minimizers of  </abstract>::line_number::10
<abstract> the energy function, followed by the main phase that progresses from the best  </abstract>::line_number::11
<abstract> current local minimizers to even lower local minimizers. The method combines  </abstract>::line_number::12
<abstract> portions that work on small subsets of the parameters, including small-scale  </abstract>::line_number::13
<abstract> global optimizations using stochastic methods, with local minimizations involving all the parameters. In computational tests on the protein polyalanine  </abstract>::line_number::14
<abstract> with up to 58 amino acids (116 internal parameters), the method appears to  </abstract>::line_number::15
<abstract> be very successful in finding the lowest energy structures. The largest case  </abstract>::line_number::16
<abstract> is particularly significant because the lowest energy structures that are found  </abstract>::line_number::17
<abstract> include ones that exhibit interesting tertiary as opposed to just secondary  </abstract>::line_number::18
<abstract> structure.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::6
<abstract> In this position paper we raise the question of whether Configuration Management (CM)  </abstract>::line_number::7
<abstract> research has a future. The new standard in CM systems|typified by commercial products  </abstract>::line_number::8
<abstract> such as Adele, ADC, ClearCase, Continuus/CM, and CCC/Harvest|largely satisfies the CM  </abstract>::line_number::9
<abstract> functionality requirements posed by Dart. This implies that research in the area of CM is either  </abstract>::line_number::10
<abstract> unnecessary or that we must find new challenges in CM on which to focus. We believe that  </abstract>::line_number::11
<abstract> these challenges indeed exist. Here we present some areas that we feel are good opportunities  </abstract>::line_number::12
<abstract> for new or continued CM research, and therefore conclude that CM research does have a future.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::7
<abstract> In this paper we propose a new framework for  </abstract>::line_number::8
<abstract> studying Markov decision processes (MDPs),  </abstract>::line_number::9
<abstract> based on ideas from statistical mechanics. The  </abstract>::line_number::10
<abstract> goal of learning in MDPs is to find a policy  </abstract>::line_number::11
<abstract> that yields the maximum expected return over  </abstract>::line_number::12
<abstract> time. In choosing policies, agents must therefore weigh the prospects of short-term versus  </abstract>::line_number::13
<abstract> long-term gains. We study a simple MDP in  </abstract>::line_number::14
<abstract> which the agent must constantly decide between exploratory jumps and local reward mining in state space. The number of policies to  </abstract>::line_number::15
<abstract> choose from grows exponentially with the size  </abstract>::line_number::16
<abstract> of the state space, N . We view the expected returns as defining an energy landscape over policy space. Methods from statistical mechanics  </abstract>::line_number::17
<abstract> are used to analyze this landscape in the thermodynamic limit N ! 1. We calculate the  </abstract>::line_number::18
<abstract> overall distribution of expected returns, as well  </abstract>::line_number::19
<abstract> as the distribution of returns for policies at a  </abstract>::line_number::20
<abstract> fixed Hamming distance from the optimal one.  </abstract>::line_number::21
<abstract> We briefly discuss the problem of learning optimal policies from empirical estimates of the  </abstract>::line_number::22
<abstract> expected return. As a first step, we relate our  </abstract>::line_number::23
<abstract> findings for the entropy to the limit of high-temperature learning. Numerical simulations  </abstract>::line_number::24
<abstract> support the theoretical results.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::7
<abstract> I present a modular network architecture and a learning algorithm based  </abstract>::line_number::8
<abstract> on incremental dynamic programming that allows a single learning agent  </abstract>::line_number::9
<abstract> to learn to solve multiple Markovian decision tasks (MDTs) with significant transfer of learning across the tasks. I consider a class of MDTs,  </abstract>::line_number::10
<abstract> called composite tasks, formed by temporally concatenating a number of  </abstract>::line_number::11
<abstract> simpler, elemental MDTs. The architecture is trained on a set of composite and elemental MDTs. The temporal structure of a composite task is  </abstract>::line_number::12
<abstract> assumed to be unknown and the architecture learns to produce a temporal decomposition. It is shown that under certain conditions the solution  </abstract>::line_number::13
<abstract> of a composite MDT can be constructed by computationally inexpensive  </abstract>::line_number::14
<abstract> modifications of the solutions of its constituent elemental MDTs.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::4
<abstract> A novel approach to constant-magnification imaging is proposed. Magnification variations due to  </abstract>::line_number::5
<abstract> changes in focus setting pose problems for important  </abstract>::line_number::6
<abstract> vision techniques, such as, depth from defocus. It  </abstract>::line_number::7
<abstract> is shown that magnification of a conventional lens  </abstract>::line_number::8
<abstract> can be made invariant to defocus by simply adding  </abstract>::line_number::9
<abstract> an aperture at an analytically derived location. The  </abstract>::line_number::10
<abstract> resulting optical configuration is called "telecentric."  </abstract>::line_number::11
<abstract> It is shown that most commercially available lenses  </abstract>::line_number::12
<abstract> can be turned into telecentric ones. The procedure  </abstract>::line_number::13
<abstract> for calculating the position of the additional aperture  </abstract>::line_number::14
<abstract> and a detailed analysis of the photometric and geometric properties of telecentric lenses are discussed.  </abstract>::line_number::15
<abstract> The magnification invariance of telecentric optics and  </abstract>::line_number::16
<abstract> its application to the problem of depth from defocus  </abstract>::line_number::17
<abstract> are experimentally demonstrated in [ Watanabe and  </abstract>::line_number::18
<abstract> Nayar-1995 ] . The proposed optics was found to result in significantly improved depth maps than those  </abstract>::line_number::19
<abstract> obtained using a conventional lens.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::9
<abstract> There is increasing interest in the recovery of generalized cylinders (GCs) with curved spines. However,  </abstract>::line_number::10
<abstract> existing formulations of such GCs, for example those  </abstract>::line_number::11
<abstract> based on the Frenet-Serret frame or the tube model,  </abstract>::line_number::12
<abstract> suffer serious drawbacks: discontinuities, a lack of expressive power, "narrowing" in the plane normal to  </abstract>::line_number::13
<abstract> the spine, non-intuitive twisting behavior, and/or off-axis nonorthogonality of their local coordinate systems.  </abstract>::line_number::14
<abstract> We discuss some of the problems associated with the  </abstract>::line_number::15
<abstract> non-orthogonality of the coordinate system based on  </abstract>::line_number::16
<abstract> the Frenet-Serret frame. This non-orthogonality is induced by torsion effects and we show how to correct for  </abstract>::line_number::17
<abstract> it. We then introduce a new model, the extruded GC  </abstract>::line_number::18
<abstract> (EGC) model, which overcomes all the problems mentioned above. For complex axes, the EGC model is also  </abstract>::line_number::19
<abstract> simpler to understand and use than existing models.  </abstract>::line_number::20
<abstract> The EGC model is further extended by including local surface deformations. Recovery of the deformable  </abstract>::line_number::21
<abstract> EGC via a physically-motivated paradigm is demonstrated on pre-segmented data from a human carotid  </abstract>::line_number::22
<abstract> artery.   </abstract>::line_number::23
<abstract>  Abstract. Let F be a class of functions defined on a d-dimensional domain. Our task is  </abstract>::line_number::11
<abstract> to compute H m -norm "-approximations to solutions of 2mth-order elliptic boundary-value  </abstract>::line_number::12
<abstract> problems Lu = f for a fixed L and for f 2 F . We assume that the only information we  </abstract>::line_number::13
<abstract> can compute about f 2 F is the value of a finite number of continuous linear functionals  </abstract>::line_number::14
<abstract> of f, each evaluation having cost c(d). Previous work has assumed that F was the unit  </abstract>::line_number::15
<abstract> ball of a Sobolev space H r of fixed smoothness r, and it was found that the complexity of  </abstract>::line_number::16
<abstract> computing an "-approximation was comp("; d) = fi(c(d)(1=") d=(r+m) ). Since the exponent  </abstract>::line_number::17
<abstract> of 1=" depends on d, we see that the problem is intractable in 1=" for any such F of fixed  </abstract>::line_number::18
<abstract> smoothness r. In this paper, we ask whether we can break intractability by letting F be the  </abstract>::line_number::19
<abstract> unit ball of a space of infinite smoothness. To be specific, we let F be the unit ball of a  </abstract>::line_number::20
<abstract> Hardy space of analytic functions defined over a complex d-dimensional ball of radius greater  </abstract>::line_number::21
<abstract> than one. We then show that the problem is tractable in 1=". More precisely, we prove that  </abstract>::line_number::22
<abstract> comp("; d) = fi(c(d)(ln 1=") d ), where the fi-constant depends on d. Since for any p &gt; 0, there  </abstract>::line_number::23
<abstract> is a function K() such that comp("; d) c(d)K(d)(1=") p for sufficiently small ", we see that  </abstract>::line_number::24
<abstract> the problem is tractable, with (minimal) exponent 0. Furthermore, we show how to construct  </abstract>::line_number::25
<abstract> a finite element p-method (in the sense of Babuska) that can compute an "-approximation  </abstract>::line_number::26
<abstract> with cost fi(c(d)(ln 1=") d ). Hence this finite element method is a nearly optimal complexity  </abstract>::line_number::27
<abstract> algorithm for d-dimensional elliptic problems with analytic data.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Expert Databases are environments that support the processing of rule programs against a disk resident database.  </abstract>::line_number::9
<abstract> They occupy a position intermediate between active and deductive databases, with respect to the level of abstraction  </abstract>::line_number::10
<abstract> of the underlying rule language. The operational semantics  </abstract>::line_number::11
<abstract> of the rule language influences the problem solving strategy,  </abstract>::line_number::12
<abstract> while the architecture of the processing environment determines efficiency and scalability.  </abstract>::line_number::13
<abstract> In this paper, we present elements of the PARADISER  </abstract>::line_number::14
<abstract> architecture and its kernel rule language, PARULEL. The  </abstract>::line_number::15
<abstract> PARADISER environment provides support for parallel and  </abstract>::line_number::16
<abstract> distributed evaluation of rule programs, as well as static  </abstract>::line_number::17
<abstract> and dynamic load balancing protocols that predictively  </abstract>::line_number::18
<abstract> balance a computation at runtime. This combination of  </abstract>::line_number::19
<abstract> features results in a scalable database rule and complex  </abstract>::line_number::20
<abstract> query processing architecture. We validate our claims by  </abstract>::line_number::21
<abstract> analyzing the performance of the system for two realistic  </abstract>::line_number::22
<abstract> test cases. In particular, we show how the performance of a  </abstract>::line_number::23
<abstract> parallel implementation of transitive closure is significantly  </abstract>::line_number::24
<abstract> improved by predictive dynamic load balancing.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::11
<abstract> We present a multi-dimensional database model,  </abstract>::line_number::12
<abstract> which we believe can serve as a conceptual model  </abstract>::line_number::13
<abstract> for On-Line Analytical Processing (OLAP)-based  </abstract>::line_number::14
<abstract> applications. Apart from providing the functionalities necessary for OLAP-based applications, the  </abstract>::line_number::15
<abstract> main feature of the model we propose is a clear  </abstract>::line_number::16
<abstract> separation between structural aspects and the contents. This separation of concerns allows us to define data manipulation languages in a reasonably  </abstract>::line_number::17
<abstract> simple, transparent way. In particular, we show  </abstract>::line_number::18
<abstract> that the data cube operator can be expressed easily. Concretely, we define an algebra and a calculus  </abstract>::line_number::19
<abstract> and show them to be equivalent. We conclude by  </abstract>::line_number::20
<abstract> comparing our approach to related work.  </abstract>::line_number::21
<abstract> The conceptual multi-dimensional database model  </abstract>::line_number::22
<abstract> developed here is orthogonal to its implementa  </abstract>::line_number::23
<abstract> tion, which is not a subject of the present paper.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We consider the family of lines that are area bisectors of a polygon (possibly with  </abstract>::line_number::9
<abstract> holes) in the plane. We say that two bisectors of a polygon P are combinatorially  </abstract>::line_number::10
<abstract> distinct if they induce different partitionings of the vertices of P . We derive an algebraic  </abstract>::line_number::11
<abstract> characterization of area bisectors. We then show that there are simple polygons with n  </abstract>::line_number::12
<abstract> vertices that have (n 2 ) combinatorially distinct area bisectors (matching the obvious  </abstract>::line_number::13
<abstract> upper bound), and present an output-sensitive algorithm for computing an explicit  </abstract>::line_number::14
<abstract> representation of all the bisectors of a given polygon. Our study is motivated by the  </abstract>::line_number::15
<abstract> development of novel, flexible feeding devices for parts positioning and orienting. The  </abstract>::line_number::16
<abstract> question of determining all the bisectors of polygonal parts arises in connection with  </abstract>::line_number::17
<abstract> the development of efficient part positioning strategies when using these devices.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We propose a new algorithm for computing the Riemann mapping of the  </abstract>::line_number::5
<abstract> unit disk to a polygon, also known as the Schwarz-Christoffel transformation.  </abstract>::line_number::6
<abstract> The new algorithm, CRDT, is based on cross-ratios of the prevertices, and also  </abstract>::line_number::7
<abstract> on cross-ratios of quadrilaterals in a Delaunay triangulation of the polygon.  </abstract>::line_number::8
<abstract> The CRDT algorithm produces an accurate representation of the Riemann  </abstract>::line_number::9
<abstract> mapping even in the presence of arbitrary long, thin regions in the polygon,  </abstract>::line_number::10
<abstract> unlike any previous conformal mapping algorithm. We believe that CRDT can  </abstract>::line_number::11
<abstract> never fail to converge to the correct Riemann mapping, but the correctness and  </abstract>::line_number::12
<abstract> convergence proof depend on conjectures that we have so far not been able to  </abstract>::line_number::13
<abstract> prove. We demonstrate convergence with computational experiments.  </abstract>::line_number::14
<abstract> The Riemann mapping has applications to problems in two-dimensional  </abstract>::line_number::15
<abstract> potential theory and to finite-difference mesh generation. We use CRDT to  </abstract>::line_number::16
<abstract> produce a mapping and solve a boundary value problem on long, thin regions  </abstract>::line_number::17
<abstract> for which no other algorithm can solve these problems.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We give asymptotically equal lower and upper bounds for the number of parallel I/O operations required to perform bit-matrix-multiply/complement (BMMC) permutations on parallel  </abstract>::line_number::8
<abstract> disk systems. In a BMMC permutation on N records, where N is a power of 2, each (lg N )-bit  </abstract>::line_number::9
<abstract> source address x maps to a corresponding (lg N)-bit target address by the matrix equation  </abstract>::line_number::10
<abstract> = A x c, where matrix multiplication is performed over GF (2). The characteristic matrix A  </abstract>::line_number::11
<abstract> is (lg N )fi(lg N ) and nonsingular over GF (2). Under the Vitter-Shriver parallel-disk model with  </abstract>::line_number::12
<abstract> N records, D disks, B records per block, and M records of memory, we show a universal lower  </abstract>::line_number::13
<abstract> bound of   </abstract>::line_number::14
<abstract> BD  </abstract>::line_number::15
<abstract> 1 + rank   </abstract>::line_number::16
<abstract> lg(M=B)  </abstract>::line_number::17
<abstract> parallel I/Os for performing a BMMC permutation, where   </abstract>::line_number::18
<abstract> is the lower left lg(N=B) fi lg B submatrix of the characteristic matrix. We also present an algo  </abstract>::line_number::19
<abstract> rithm that uses at most 2N  </abstract>::line_number::20
<abstract> BD  </abstract>::line_number::21
<abstract> rank   </abstract>::line_number::22
<abstract> lg(M=B)  </abstract>::line_number::23
<abstract> + 2  </abstract>::line_number::24
<abstract> parallel I/Os, which asymptotically matches the  </abstract>::line_number::25
<abstract> lower bound and improves upon the BMMC and bit-permute/complement (BPC) algorithms in  </abstract>::line_number::26
<abstract> [4]. When rank is low, this method is an improvement over the general-permutation bound of  </abstract>::line_number::27
<abstract> fi  </abstract>::line_number::28
<abstract> N  </abstract>::line_number::29
<abstract> lg(N=B)  </abstract>::line_number::30
<abstract> We introduce a new subclass of BMMC permutations, called memoryload-dispersal (MLD)  </abstract>::line_number::31
<abstract> permutations, which can be performed in one pass. This subclass, which is used in the BMMC  </abstract>::line_number::32
<abstract> algorithm, extends the catalog of one-pass permutations appearing in [4].  </abstract>::line_number::33
<abstract> Although many BMMC permutations of practical interest fall into subclasses that might be  </abstract>::line_number::34
<abstract> explicitly invoked within the source code, we show how to detect in at most N=BD+  </abstract>::line_number::35
<abstract> l  </abstract>::line_number::36
<abstract> D  </abstract>::line_number::37
<abstract> parallel I/Os whether a given vector of target addresses specifies a BMMC permutation. Thus,  </abstract>::line_number::38
<abstract> one can determine efficiently at run time whether a permutation to be performed is BMMC and  </abstract>::line_number::39
<abstract> then avoid the general-permutation algorithm and save parallel I/Os by using our algorithm.   </abstract>::line_number::40
<abstract>  Abstract  </abstract>::line_number::10
<abstract> In recent years, there has been an explosive growth in the amount of  </abstract>::line_number::11
<abstract> information available to our society. In particular, the amount of  </abstract>::line_number::12
<abstract> information available online through vast networks like the global  </abstract>::line_number::13
<abstract> Internet has been growing at a staggering rate. This growth rate has by far  </abstract>::line_number::14
<abstract> exceeded the rate of growth in network speeds, as has the number of  </abstract>::line_number::15
<abstract> individuals and organizations seeking access to this information. There is  </abstract>::line_number::16
<abstract> thus a motivation to find abstract methods of manipulating this online  </abstract>::line_number::17
<abstract> data in ways that both serve the needs of end users efficiently and use  </abstract>::line_number::18
<abstract> network resources intelligently. In lieu of a traditional clientserver model  </abstract>::line_number::19
<abstract> of information processing, which is both inflexible and potentially very  </abstract>::line_number::20
<abstract> inefficient, a Transportable Intelligent Agent system has the potential to  </abstract>::line_number::21
<abstract> achieve a more efficient and flexible network system. An intelligent agent  </abstract>::line_number::22
<abstract> is a program that models the information space for a user, and allows the  </abstract>::line_number::23
<abstract> user to specify how the information is to be processed. A transportable  </abstract>::line_number::24
<abstract> agent can suspend its execution, transport itself to a new location on a  </abstract>::line_number::25
<abstract> network, and resume execution at the new location. This is a particularly  </abstract>::line_number::26
<abstract> attractive model for both wireless and dialup networks where a user might  </abstract>::line_number::27
<abstract> not be able to maintain a permanent network connection, as well as for  </abstract>::line_number::28
<abstract> situations where the amount of information to be processed is large  </abstract>::line_number::29
<abstract> relative to the network bandwidth. Preliminary work in the field has  </abstract>::line_number::30
<abstract> shown that such agent systems are possible and deserve further study.  </abstract>::line_number::31
<abstract> This thesis describes a prototype transportable intelligent agent system that  </abstract>::line_number::32
<abstract> extends work already done in the field. Agents are written in a modified  </abstract>::line_number::33
<abstract> version of the Tcl programming language and transported using TCP/IP  </abstract>::line_number::34
<abstract> connections. Several simple examples demonstrate the properties of the  </abstract>::line_number::35
<abstract> system.   </abstract>::line_number::36
<abstract>  Most current multiprocessor file systems are designed to use multiple disks  </abstract>::line_number::6
<abstract> in parallel, using the high aggregate bandwidth to meet the growing I/O  </abstract>::line_number::7
<abstract> requirements of parallel scientific applications. Many multiprocessor file  </abstract>::line_number::8
<abstract> systems provide applications with a conventional Unix-like interface, allowing the application to access multiple disks transparently. This interface conceals the parallelism within the file system, increasing the ease  </abstract>::line_number::9
<abstract> of programmability, but making it difficult or impossible for sophisticated programmers and libraries to use knowledge about their I/O needs  </abstract>::line_number::10
<abstract> to exploit that parallelism. In addition to providing an insufficient interface, most current multiprocessor file systems are optimized for a different  </abstract>::line_number::11
<abstract> workload than they are being asked to support. We introduce Galley, a  </abstract>::line_number::12
<abstract> new parallel file system that is intended to efficiently support realistic  </abstract>::line_number::13
<abstract> scientific multiprocessor workloads. We discuss Galley's file structure and  </abstract>::line_number::14
<abstract> application interface, as well as the performance advantages offered by  </abstract>::line_number::15
<abstract> that interface.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper presents a new atomic commitment protocol, enhanced three phase commit  </abstract>::line_number::9
<abstract> (E3PC ), that always allows a quorum in the system to make progress. Previously suggested  </abstract>::line_number::10
<abstract> quorum-based protocols (e.g., the quorum-based three phase commit (3PC) [Ske82]) allow a  </abstract>::line_number::11
<abstract> quorum to make progress in case of one failure. If failures cascade, however, and the quorum  </abstract>::line_number::12
<abstract> in the system is "lost" (i.e., at a given time no quorum component exists), a quorum can later  </abstract>::line_number::13
<abstract> become connected and still remain blocked. With our protocol, a connected quorum never  </abstract>::line_number::14
<abstract> blocks. E3PC is based on the quorum-based 3PC [Ske82], and it does not require more time  </abstract>::line_number::15
<abstract> or communication than 3PC. We describe how this protocol can be exploited in a replicated  </abstract>::line_number::16
<abstract> database setting, making the database always available to a majority of the sites.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Most theories of language processing and acquisition make the assumption that  </abstract>::line_number::5
<abstract> perception and comprehension are related to production, but few have anything say  </abstract>::line_number::6
<abstract> about how. This paper describes a performance-oriented connectionist model of  </abstract>::line_number::7
<abstract> the acquisition of morphology in which production builds on representations which  </abstract>::line_number::8
<abstract> develop during the learning of word recognition. Using artificial language stimuli  </abstract>::line_number::9
<abstract> embodying simple suffixation, prefixation, and template rules, I demonstrate that  </abstract>::line_number::10
<abstract> the model generalizes to novel combinations of roots and inflections for both word  </abstract>::line_number::11
<abstract> recognition and production. I argue that the capacity of connectionist networks to  </abstract>::line_number::12
<abstract> develop intermediate distributed representations which not only enable the solving  </abstract>::line_number::13
<abstract> of the task at hand but also facilitate another task offers a plausible account of how  </abstract>::line_number::14
<abstract> comprehension and production come to share phonological knowledge as words are  </abstract>::line_number::15
<abstract> learned.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Most data models and query languages, provide mechanisms for dealing with sets  </abstract>::line_number::9
<abstract> of objects. Many applications nowadays, however, are list-oriented, i.e., deal with  </abstract>::line_number::10
<abstract> collections or aggregates of objects in which their order is important. A formal model  </abstract>::line_number::11
<abstract> and an algebra for representing and manipulating list-oriented data are presented in  </abstract>::line_number::12
<abstract> this paper. We also give the criteria that were used in the design of the algebra and  </abstract>::line_number::13
<abstract> show how the algebra satisfies these criteria.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Data- and task-parallelism are two important parallel programming models. Object-oriented paradigm  </abstract>::line_number::9
<abstract> in parallelism provides a good way of abstracting out various aspects of computations and computing resources. Using an object-oriented language like C++, one can compose data and control representations  </abstract>::line_number::10
<abstract> into a single active object.  </abstract>::line_number::11
<abstract> We propose a thread model of parallelism that addresses both data and task parallelism. Computation  </abstract>::line_number::12
<abstract> and communication can be overlapped by suspending a thread of computation which is waiting for an  </abstract>::line_number::13
<abstract> event and running an eligible thread of computation in its place. Threads naturally subsume task-parallelism. Threads are encapsulated into thread objects may be grouped into rope objects [22, 20], that  </abstract>::line_number::14
<abstract> span the parallel machine domain, for collective computation and communication. Thus data-parallelism  </abstract>::line_number::15
<abstract> can be supported. Since rope objects are parallel objects, they can be customized, interestingly, in a  </abstract>::line_number::16
<abstract> serial or a parallel manner. Spatial transparency of objects is achieved by global pointer templates.  </abstract>::line_number::17
<abstract> We present results from a prototype system running on the SGI Challenge and the Intel Paragon.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::4
<abstract> This paper proposes a framework for predicate detection in systems of processes with approximately-synchronized real-time clocks. Timestamps from these clocks are used to define two orderings on  </abstract>::line_number::5
<abstract> events: "definitely occurred before" and "possibly occurred before". These orderings lead naturally  </abstract>::line_number::6
<abstract> to definitions of 3 distinct detection modalities, i.e., 3 meanings of "predicate held during a computation", namely: Poss T (" possibly held"), Def T (" definitely held"), and Inst ("  </abstract>::line_number::7
<abstract> definitely held at a specific instant"). This paper defines these modalities and gives efficient algorithms for detecting them; the algorithms are based on algorithms of Cooper and Marzullo, Garg  </abstract>::line_number::8
<abstract> and Waldecker, and Fromentin and Raynal.   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::3
<abstract> This study describes a new Hidden Markov Model (HMM) system for segmenting uncharacterized genomic DNA sequences into exons, introns, and intergenic  </abstract>::line_number::4
<abstract> regions. Separate HMM modules were designed and trained for specific regions of  </abstract>::line_number::5
<abstract> DNA: exons, introns, intergenic regions, and splice sites. The models were then  </abstract>::line_number::6
<abstract> tied together to form a biologically feasible topology. The integrated HMM was  </abstract>::line_number::7
<abstract> trained further on a set of eukaryotic DNA sequences, and tested by using it to  </abstract>::line_number::8
<abstract> segment a separate set of sequences. The resulting HMM system, which is called  </abstract>::line_number::9
<abstract> VEIL (Viterbi Exon-Intron Locator), obtains an overall accuracy on test data of  </abstract>::line_number::10
<abstract> 92% of total bases correctly labelled, with a correlation coefficient of 0.68. Using the more stringent test of exact exon prediction, VEIL correctly located both  </abstract>::line_number::11
<abstract> ends of 46% of the exons. Moreover, more than 50% of the exons it predicts are  </abstract>::line_number::12
<abstract> exactly correct. These results compare favorably to the best previous results for  </abstract>::line_number::13
<abstract> gene structure prediction, and demonstrate the benefits of using HMMs for this  </abstract>::line_number::14
<abstract> problem.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The Two-Level Hypermedia Paradigm sees an  </abstract>::line_number::8
<abstract> Information Retrieval System as consisting of  </abstract>::line_number::9
<abstract> a document network (the Hyperbase) and a  </abstract>::line_number::10
<abstract> descriptor (term) network (the Hyperindex).  </abstract>::line_number::11
<abstract> Query by Navigation is a process whereby the  </abstract>::line_number::12
<abstract> searcher gives a description of the Information Need by travelling through the descriptor  </abstract>::line_number::13
<abstract> network. This paper presents a formalism for  </abstract>::line_number::14
<abstract> expressing the effects of traversing the Hyper-index on the elements of the Hyperindex. This  </abstract>::line_number::15
<abstract> formalism makes use of probabilities for mod-elling the searcher's behavious. The events  </abstract>::line_number::16
<abstract> which can occur during the search process  </abstract>::line_number::17
<abstract> are discussed and modelled. Some important  </abstract>::line_number::18
<abstract> properties, which are reasonable to demand of  </abstract>::line_number::19
<abstract> a retrieval system, can be proven to be valid  </abstract>::line_number::20
<abstract> if this formalism is adopted. A mechanism  </abstract>::line_number::21
<abstract> for assigning a measure of relevance to documents is presented. This uses the formalism  </abstract>::line_number::22
<abstract> mentioned above. An example will show the  </abstract>::line_number::23
<abstract> effectiveness of The aspect of relevance feedback and its role in Query by Navigation is  </abstract>::line_number::24
<abstract> introduced by examining the different level on  </abstract>::line_number::25
<abstract> which the searcher can offer information for  </abstract>::line_number::26
<abstract> weeding out unwanted sections of the search  </abstract>::line_number::27
<abstract> space. In order to illustrate the workings of  </abstract>::line_number::28
<abstract> Query by Navigation a small example is included.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::13
<abstract> For succesful information systems development, conceptual data modelling is essential.  </abstract>::line_number::14
<abstract> Nowadays many techniques for conceptual data modelling exist, examples are NIAM, FORM,  </abstract>::line_number::15
<abstract> PSM, many (E)ER variants, IFO, and FDM. In-depth comparisons of concepts of these techniques is very difficult as the mathematical formalisations of these techniques, if existing at  </abstract>::line_number::16
<abstract> all, are very different. As such there is a need for a unifying formal framework providing a  </abstract>::line_number::17
<abstract> sufficiently high level of abstraction. In this paper the use of category theory for this purpose  </abstract>::line_number::18
<abstract> is addressed. Well-known conceptual data modelling concepts are discussed from a category  </abstract>::line_number::19
<abstract> theoretic point of view. Advantages and disadvantages of the approach chosen will be outlined.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::9
<abstract> In this paper we present results of experiments carried out with a route learning system for a  </abstract>::line_number::10
<abstract> mobile robot, conducted in a `real world' environment covering distances of several hundred metres.  </abstract>::line_number::11
<abstract> The system uses no odometry and is based on a self-organising mapbuilding process using perceptual  </abstract>::line_number::12
<abstract> landmarks.  </abstract>::line_number::13
<abstract> A performance metric is defined and used to measure the robot's ability to traverse the route.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::7
<abstract> It is argued that the following three properties are foundations of robust robot  </abstract>::line_number::8
<abstract> navigation:  </abstract>::line_number::9
<abstract> * The use of landmarks (and, in particular, the use of a compass sense),  </abstract>::line_number::10
<abstract> * the use of canonical paths, and  </abstract>::line_number::11
<abstract> * the use of topological rather than geometrical maps.  </abstract>::line_number::12
<abstract> Some examples of successful animal navigation are presented that support this view.  </abstract>::line_number::13
<abstract> We have performed initial experiments with mobile robots to investigate mechanisms  </abstract>::line_number::14
<abstract> suitable to implement such navigational architectures. Experiments concerning navigation by dead reckoning are presented, and a differential light compass is introduced  </abstract>::line_number::15
<abstract> to aid robot navigation.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a  </abstract>::line_number::8
<abstract> discrete set containing k &gt; 2 values (i.e., k "classes").  </abstract>::line_number::9
<abstract> The definition is acquired by studying large collections  </abstract>::line_number::10
<abstract> of training examples of the form hx i ; f(x i )i. Existing  </abstract>::line_number::11
<abstract> approaches to this problem include (a) direct application of multiclass algorithms such as the decision-tree  </abstract>::line_number::12
<abstract> algorithms ID3 and CART, (b) application of binary  </abstract>::line_number::13
<abstract> concept learning algorithms to learn individual binary  </abstract>::line_number::14
<abstract> functions for each of the k classes, and (c) application  </abstract>::line_number::15
<abstract> of binary concept learning algorithms with distributed  </abstract>::line_number::16
<abstract> output codes such as those employed by Sejnowski and  </abstract>::line_number::17
<abstract> Rosenberg in the NETtalk system. This paper compares these three approaches to a new technique in  </abstract>::line_number::18
<abstract> which BCH error-correcting codes are employed as a  </abstract>::line_number::19
<abstract> distributed output representation. We show that these  </abstract>::line_number::20
<abstract> output representations improve the performance of ID3  </abstract>::line_number::21
<abstract> on the NETtalk task and of backpropagation on an  </abstract>::line_number::22
<abstract> isolated-letter speech-recognition task. These results  </abstract>::line_number::23
<abstract> demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass  </abstract>::line_number::24
<abstract> problems.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::4
<abstract> A new set of tools for verifying smoothness of surfaces generated by stationary  </abstract>::line_number::5
<abstract> subdivision algorithms is presented. The main challenge here is the verification of  </abstract>::line_number::6
<abstract> injectivity of the characteristic map. The tools are sufficiently versatile and easy  </abstract>::line_number::7
<abstract> to wield to allow, as an application, a full analysis of algorithms generalizing bi-quadratic and bicubic B-spline subdivision. In the case of generalized biquadratic  </abstract>::line_number::8
<abstract> subdivision the analysis yields a hitherto unknown sharp bound strictly less than  </abstract>::line_number::9
<abstract> one on the second largest eigenvalue of any smoothly converging subdivision.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper describes the performance evaluation of six temporal reasoning systems.  </abstract>::line_number::8
<abstract> We show that if you are working with large temporal datasets where information  </abstract>::line_number::9
<abstract> is added incrementally throughout the execution of the program, systems using incompletely connected graphs (i.e., TMM, TimeGraph and TimeGraph-II) seem the  </abstract>::line_number::10
<abstract> best option. While they do not offer the constant query time of systems using fully  </abstract>::line_number::11
<abstract> connected graphs (i.e. the systems based on constraint satisfaction), the savings at  </abstract>::line_number::12
<abstract> assertion time are so substantial that the relatively small performance penalty for  </abstract>::line_number::13
<abstract> queries is a reasonable tradeoff. Of course, these systems do not offer the expressiv  </abstract>::line_number::14
<abstract> ity of the interval-based systems as they only handle point-based relations. Of the  </abstract>::line_number::15
<abstract> three, TimeGraph-II offers a wider range of qualitative relations as it handles point  </abstract>::line_number::16
<abstract> inequality. It does not currently handle metric information, however, as do TMM  </abstract>::line_number::17
<abstract> and TimeGraph. Thus decisions between these three may be more determined by the  </abstract>::line_number::18
<abstract> reasoning capabilities required rather than raw performance.  </abstract>::line_number::19
<abstract> This material is based upon work supported in part by U.S. Air Force-Rome Laboratory research  </abstract>::line_number::20
<abstract> contract no. F30602-91-C-0010.   </abstract>::line_number::21
<abstract>  Abstract. In order to make spoken dialogue systems more sophisticated, designers need to better understand the conventions that people  </abstract>::line_number::2
<abstract> use in structuring their speech and in interacting with their fellow con-versants. In particular, it is crucial to discriminate the basic building  </abstract>::line_number::3
<abstract> blocks of dialogue and how they affect the way people process language. Many researchers have proposed the utterance unit as the  </abstract>::line_number::4
<abstract> primary object of study, but defining exactly what this is has remained a difficult issue. To shed light on this question, we consider  </abstract>::line_number::5
<abstract> grounding behavior in dialogue, and examine co-occurrences between  </abstract>::line_number::6
<abstract> turn-initial grounding acts and utterance unit signals that have been  </abstract>::line_number::7
<abstract> proposed in the literal, namely prosodic boundary tones and pauses.  </abstract>::line_number::8
<abstract> Preliminary results indicate high correlation between grounding and  </abstract>::line_number::9
<abstract> boundary tones, with a secondary correlation for longer pauses. We  </abstract>::line_number::10
<abstract> also consider some of the dialogue processing issues which are impacted by a definition of utterance unit.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::13
<abstract> Our research addresses the general topic of atomic update of shared data  </abstract>::line_number::14
<abstract> structures on large-scale shared-memory multiprocessors. In this paper  </abstract>::line_number::15
<abstract> we consider alternative implementations of the general-purpose single-address atomic primitives fetch and , compare and swap, load linked,  </abstract>::line_number::16
<abstract> and store conditional. These primitives have proven popular on small-scale bus-based machines, but have yet to become widely available on  </abstract>::line_number::17
<abstract> large-scale, distributed shared memory machines. We propose several alternative hardware implementations of these primitives, and then analyze  </abstract>::line_number::18
<abstract> the performance of these implementations for various data sharing patterns. Our results indicate that good overall performance can be obtained  </abstract>::line_number::19
<abstract> by implementing compare and swap in the cache controllers, and by pro  </abstract>::line_number::20
<abstract> viding an additional instruction to load an exclusive copy of a cache line.   </abstract>::line_number::21
<abstract>  Abstract. Maximal word functions occur in data retrieval applications  </abstract>::line_number::4
<abstract> and have connections with ranking problems, which in turn were first  </abstract>::line_number::5
<abstract> investigated in relation to data compression [21]. By the "maximal word  </abstract>::line_number::6
<abstract> function" of a language L , we mean the problem of finding, on  </abstract>::line_number::7
<abstract> input x, the lexicographically largest word belonging to L that is smaller  </abstract>::line_number::8
<abstract> than or equal to x.  </abstract>::line_number::9
<abstract> In this paper we present a parallel algorithm for computing maximal  </abstract>::line_number::10
<abstract> word functions for languages recognized by one-way nondeterministic  </abstract>::line_number::11
<abstract> auxiliary pushdown automata (and hence for the class of context-free  </abstract>::line_number::12
<abstract> languages).  </abstract>::line_number::13
<abstract> This paper is a continuation of a stream of research focusing on the  </abstract>::line_number::14
<abstract> problem of identifying properties others than membership which are  </abstract>::line_number::15
<abstract> easily computable for certain classes of languages. For a survey, see [24].   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Bayesian inference begins with a prior distribution for model parameters that is  </abstract>::line_number::10
<abstract> meant to capture prior beliefs about the relationship being modeled. For multilayer  </abstract>::line_number::11
<abstract> perceptron networks, where the parameters are the connection weights, the prior  </abstract>::line_number::12
<abstract> lacks any direct meaning | what matters is the prior over functions computed  </abstract>::line_number::13
<abstract> by the network that is implied by this prior over weights. In this paper, I show  </abstract>::line_number::14
<abstract> that priors over weights can be defined in such a way that the corresponding  </abstract>::line_number::15
<abstract> priors over functions reach reasonable limits as the number of hidden units in the  </abstract>::line_number::16
<abstract> network goes to infinity. When using such priors, there is thus no need to limit the  </abstract>::line_number::17
<abstract> size of the network in order to avoid "overfitting". The infinite network limit also  </abstract>::line_number::18
<abstract> provides insight into the properties of different priors. A Gaussian prior for hidden-to-output weights results in a Gaussian process prior for functions, which can be  </abstract>::line_number::19
<abstract> smooth, Brownian, or fractional Brownian, depending on the hidden unit activation  </abstract>::line_number::20
<abstract> function and the prior for input-to-hidden weights. Quite different effects can be  </abstract>::line_number::21
<abstract> obtained using priors based on non-Gaussian stable distributions. In networks with  </abstract>::line_number::22
<abstract> more than one hidden layer, a combination of Gaussian and non-Gaussian priors  </abstract>::line_number::23
<abstract> appears most interesting.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We describe a hierarchical, generative model that can be viewed as a non-linear generalization of factor analysis and can be implemented in a neural network. The model uses  </abstract>::line_number::10
<abstract> bottom-up, top-down and lateral connections to perform Bayesian perceptual inference correctly. Once perceptual inference has been performed the connection strengths can be updated  </abstract>::line_number::11
<abstract> using a very simple learning rule that only requires locally available information. We demon  </abstract>::line_number::12
<abstract> strate that the network learns to extract sparse, distributed, hierarchical representations.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We first describe a hierarchical, generative model that can be  </abstract>::line_number::10
<abstract> viewed as a non-linear generalisation of factor analysis and can  </abstract>::line_number::11
<abstract> be implemented in a neural network. The model performs perceptual inference in a probabilistically consistent manner by using  </abstract>::line_number::12
<abstract> top-down, bottom-up and lateral connections. These connections  </abstract>::line_number::13
<abstract> can be learned using simple rules that require only locally available information. We then show how to incorporate lateral connections into the generative model. The model extracts a sparse,  </abstract>::line_number::14
<abstract> distributed, hierarchical representation of depth from simplified  </abstract>::line_number::15
<abstract> random-dot stereograms and the localised disparity detectors in  </abstract>::line_number::16
<abstract> the first hidden layer form a topographic map. When presented  </abstract>::line_number::17
<abstract> with image patches from natural scenes, the model develops topo  </abstract>::line_number::18
<abstract> graphically organised local feature detectors.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Maya is a simulation platform for evaluating the performance of parallel programs on parallel architectures with different memory coherence protocols. Rapid prototyping of different memory protocols  </abstract>::line_number::6
<abstract> supporting varying degrees of coherence is possible and the impact of these protocols on the performance  </abstract>::line_number::7
<abstract> of application programs can be studied. Implementations of existing weak memories along with some  </abstract>::line_number::8
<abstract> new primitives using Maya are presented. The results of running some user applications are summarized  </abstract>::line_number::9
<abstract> and the impact of weak memories on the efficiency of parallel programs is discussed.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Multi-armed bandits may be viewed as  </abstract>::line_number::7
<abstract> decompositionally-structured Markov decision processes (MDP's) with potentially very-large state sets. A particularly elegant  </abstract>::line_number::8
<abstract> methodology for computing optimal policies  </abstract>::line_number::9
<abstract> was developed over twenty ago by Gittins  </abstract>::line_number::10
<abstract> [Gittins & Jones, 1974]. Gittins' approach  </abstract>::line_number::11
<abstract> reduces the problem of finding optimal policies for the original MDP to a sequence of  </abstract>::line_number::12
<abstract> low-dimensional stopping problems whose solutions determine the optimal policy through  </abstract>::line_number::13
<abstract> the so-called "Gittins indices." Katehakis  </abstract>::line_number::14
<abstract> and Veinott [Katehakis & Veinott, 1987] have  </abstract>::line_number::15
<abstract> shown that the Gittins index for a process  </abstract>::line_number::16
<abstract> in state i may be interpreted as a particular  </abstract>::line_number::17
<abstract> component of the maximum-value function  </abstract>::line_number::18
<abstract> associated with the "restart-in-i" process,  </abstract>::line_number::19
<abstract> a simple MDP to which standard solution  </abstract>::line_number::20
<abstract> methods for computing optimal policies, such  </abstract>::line_number::21
<abstract> as successive approximation, apply. This paper explores the problem of learning the Git-tins indices on-line without the aid of a process model; it suggests utilizing process-state-specific Q-learning agents to solve their respective restart-in-state-i subproblems, and  </abstract>::line_number::22
<abstract> includes an example in which the online reinforcement learning approach is applied to  </abstract>::line_number::23
<abstract> a problem of stochastic scheduling|one instance drawn from a wide class of problems  </abstract>::line_number::24
<abstract> that may be formulated as bandit problems.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::16
<abstract> Several researchers have proposed modeling  </abstract>::line_number::17
<abstract> temporally abstract actions in reinforcement  </abstract>::line_number::18
<abstract> learning by the combination of a policy and a termination condition, which we refer to as an option. Value functions over options and models of  </abstract>::line_number::19
<abstract> options can be learned using methods designed  </abstract>::line_number::20
<abstract> for semi-Markov decision processes (SMDPs).  </abstract>::line_number::21
<abstract> However, all these methods require an option to  </abstract>::line_number::22
<abstract> be executed to termination. In this paper we explore methods that learn about an option from  </abstract>::line_number::23
<abstract> small fragments of experience consistent with  </abstract>::line_number::24
<abstract> that option, even if the option itself is not executed. We call these methods intra-option learning methods because they learn from experience  </abstract>::line_number::25
<abstract> within an option. Intra-option methods are sometimes much more efficient than SMDP methods because they can use off-policy temporal-difference mechanisms to learn simultaneously  </abstract>::line_number::26
<abstract> about all the options consistent with an experience, not just the few that were actually executed. In this paper we present intra-option learning methods for learning value functions over options and for learning multi-time models of the  </abstract>::line_number::27
<abstract> consequences of options. We present computational examples in which these new methods  </abstract>::line_number::28
<abstract> learn much faster than SMDP methods and learn  </abstract>::line_number::29
<abstract> effectively when SMDP methods cannot learn at  </abstract>::line_number::30
<abstract> all. We also sketch a convergence proof for intra  </abstract>::line_number::31
<abstract> option value learning.   </abstract>::line_number::32
<abstract>  Abstract  </abstract>::line_number::10
<abstract> Tracking and evaluating the progress of large, complex plans or  </abstract>::line_number::11
<abstract> schedules as they unfold in real time is extremely difficult for humans.  </abstract>::line_number::12
<abstract> In this paper we present a mixed-initiative system for the task of schedule maintenance in a simulated shipping network. A schedule maintenance agent monitors the network, predicting the occurrence of states  </abstract>::line_number::13
<abstract> that may result in reduced throughput and formulating schedule modifications to avoid those states. The goal is to maximize throughput  </abstract>::line_number::14
<abstract> while minimizing disruptions to the original schedule. We present results of experiments in which human subjects attempt to obtain that  </abstract>::line_number::15
<abstract> goal both with and without the aid of the agent. We found that the human and the agent working together are able to achieve better results  </abstract>::line_number::16
<abstract> than either one working alone. In addition to looking at global performance measures such as throughput, we analyze individual schedule  </abstract>::line_number::17
<abstract> modification decisions made by subjects in an attempt to assign credit  </abstract>::line_number::18
<abstract> for the improvements in performance.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Design-to-time is an approach to problem-solving in resource-constrained domains where:  </abstract>::line_number::8
<abstract> multiple solution methods are available for tasks, those solution methods make tradeoffs in  </abstract>::line_number::9
<abstract> solution quality versus time, and satisficing solutions are acceptable. Design-to-time involves  </abstract>::line_number::10
<abstract> designing a solution to a problem that uses all available resources to maximize the solution  </abstract>::line_number::11
<abstract> quality within the available time. This paper defines the design-to-time approach in detail,  </abstract>::line_number::12
<abstract> contrasting it to the anytime algorithm approach, and presents a heuristic algorithm for design-to-time real-time scheduling.  </abstract>::line_number::13
<abstract> Our blackboard architecture that implements the design-to-time approach is discussed and  </abstract>::line_number::14
<abstract> an example problem and solution from the Distributed Vehicle Monitoring Testbed (DVMT) is  </abstract>::line_number::15
<abstract> described in detail. Experimental results, generated using a simulation, show the effects of  </abstract>::line_number::16
<abstract> various parameters on scheduler performance. Finally we discuss future research goals and  </abstract>::line_number::17
<abstract> plans.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::11
<abstract> Design-to-time real-time scheduling is an alternative to the many flexible computation approaches that are based on anytime algorithms.  </abstract>::line_number::12
<abstract> It builds schedules at runtime that dynamically  </abstract>::line_number::13
<abstract> combine solutions to subproblems, taking advantage of the time available to achieve the best  </abstract>::line_number::14
<abstract> results it can. In this paper we look in detail at  </abstract>::line_number::15
<abstract> a few issues related to design-to-time, including where the approximations we rely on come  </abstract>::line_number::16
<abstract> from, how uncertainty affects the scheduling  </abstract>::line_number::17
<abstract> process and the interface between the sched-uler and its invoker.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::3
<abstract> We present a new approach that enables compiler  </abstract>::line_number::4
<abstract> optimization of procedure calls and loop nests containing procedure calls. We introduce two inter-procedural transformations that move loops across procedure boundaries, exposing them to traditional optimizations on loop nests. These transformations are  </abstract>::line_number::5
<abstract> incorporated into a code generation algorithm for a  </abstract>::line_number::6
<abstract> shared-memory multiprocessor. The code generator relies on a machine model to estimate the expected benefits of loop parallelization and parallelism-enhancing  </abstract>::line_number::7
<abstract> transformations. Several transformation strategies are  </abstract>::line_number::8
<abstract> explored and one that minimizes total execution time is  </abstract>::line_number::9
<abstract> selected. Efficient support of this strategy is provided  </abstract>::line_number::10
<abstract> by an existing interprocedural compilation system. We  </abstract>::line_number::11
<abstract> demonstrate the potential of these techniques by applying this code generation strategy to two scientific  </abstract>::line_number::12
<abstract> applications programs.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::12
<abstract> This report outlines the IPUS paradigm, named for Integrated Processing and Understanding of Signals, which permits sophisticated interaction between theory-based problem  </abstract>::line_number::13
<abstract> solving in signal processing and heuristic problem-solving in signal interpretation. The need  </abstract>::line_number::14
<abstract> for such a paradigm arises in signal understanding domains that require the processing of  </abstract>::line_number::15
<abstract> complicated interacting signals under variable signal-to-noise ratios. One such application is  </abstract>::line_number::16
<abstract> sound understanding, in the context of which we report on a testbed experiment illustrating  </abstract>::line_number::17
<abstract> the functionality of key IPUS architecture components.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::22
<abstract> The availability of low-cost computational power is a driving force behind the growing sophistication  </abstract>::line_number::23
<abstract> of CAD software. Tools designed to reduce time-consuming build-test-redesign iterations are essential  </abstract>::line_number::24
<abstract> for increasing engineering quality and productivity. However, automation of the design process poses  </abstract>::line_number::25
<abstract> many difficult computational problems. As more downstream engineering activities are being considered  </abstract>::line_number::26
<abstract> during the design phase, guaranteeing reasonable response times within design systems becomes problematic. Design is an interactive process and speed is a critical factor in systems that enable designers to  </abstract>::line_number::27
<abstract> explore and experiment with alternative ideas during the design phase. Achieving interactivity requires  </abstract>::line_number::28
<abstract> an increasingly sophisticated allocation of computational resources in order to perform realistic design  </abstract>::line_number::29
<abstract> analyses and generate feedback in real time.  </abstract>::line_number::30
<abstract> This paper presents our initial efforts to develop techniques to apply distributed algorithms to the  </abstract>::line_number::31
<abstract> problem of recognizing machining features from solid models. Existing work on recognition of features  </abstract>::line_number::32
<abstract> has focused exclusively on serial computer architectures. Our objective is to show that distributed  </abstract>::line_number::33
<abstract> algorithms can be employed on realistic parts with large numbers of features and many geometric and  </abstract>::line_number::34
<abstract> topological entities to obtain significant improvements in computation time using existing hardware and  </abstract>::line_number::35
<abstract> software tools. Migrating solid modeling applications toward a distributed computing framework enables  </abstract>::line_number::36
<abstract> interconnection of many of the autonomous and geographically diverse software tools used in the modern  </abstract>::line_number::37
<abstract> manufacturing enterprise.  </abstract>::line_number::38
<abstract> This has been implemented on a network of SUN workstations using the ACIS solid modeler and the  </abstract>::line_number::39
<abstract> NIH C++ class library; inter-processor communication is handled with TCP/IP-based network communication tools.   </abstract>::line_number::40
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We recently introduced a new flow control scheme, called send-time control, which is  </abstract>::line_number::5
<abstract> based on a deterministic model of virtual circuits in a computer network. In this scheme,  </abstract>::line_number::6
<abstract> the time at which a packet is sent by a source is computed from estimates of round-trip  </abstract>::line_number::7
<abstract> time, traffic in the network and bottleneck service time. In this paper, we describe a new  </abstract>::line_number::8
<abstract> transport protocol, called DTP, which uses send-time control as its flow control scheme.  </abstract>::line_number::9
<abstract> Preliminary measurements of coast-to-coast connections over the Internet show significant  </abstract>::line_number::10
<abstract> performance improvement over TCP, which is the most commonly used transport protocol  </abstract>::line_number::11
<abstract> in the Internet today.   </abstract>::line_number::12
<abstract>  abstract  </abstract>::line_number::6
<abstract> The notion of invariant subspaces is useful in a number of theoretical and practical applications. In this paper we give an  </abstract>::line_number::7
<abstract> elementary treatment of invariant subspaces that stresses their  </abstract>::line_number::8
<abstract> connection with simple eigenvalues and their eigenvectors.   </abstract>::line_number::9
<abstract>  ABSTRACT  </abstract>::line_number::7
<abstract> As network latency drops below disk latency, access time to a remote disk will begin  </abstract>::line_number::8
<abstract> to approach local disk access time. The performance of I/O may then be improved  </abstract>::line_number::9
<abstract> by spreading disk pages across several remote disk servers and accessing disk pages  </abstract>::line_number::10
<abstract> in parallel. To research this we have prototyped a data page server called a Page  </abstract>::line_number::11
<abstract> File. This persistent data type provides a set of methods to access disk pages stored  </abstract>::line_number::12
<abstract> on a cluster of remote machines acting as disk servers. The goal is to improve the  </abstract>::line_number::13
<abstract> throughput of database management system or other I/O intensive application by  </abstract>::line_number::14
<abstract> accessing pages from remote disks and incurring disk latency in parallel. This report  </abstract>::line_number::15
<abstract> describes the conceptual foundation and the methods of access for our prototype.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Traditional inter-domain routing protocols based on superdomains maintain either "strong"  </abstract>::line_number::10
<abstract> or "weak" ToS and policy constraints for each visible superdomain. With strong constraints,  </abstract>::line_number::11
<abstract> a valid path may not be found even though one exists. With weak constraints, an invalid  </abstract>::line_number::12
<abstract> domain-level path may be treated as a valid path.  </abstract>::line_number::13
<abstract> We present an inter-domain routing protocol based on superdomains, which always finds  </abstract>::line_number::14
<abstract> a valid path if one exists. Both strong and weak constraints are maintained for each visible  </abstract>::line_number::15
<abstract> superdomain. If the strong constraints of the superdomains on a path are satisfied, then the  </abstract>::line_number::16
<abstract> path is valid. If only the weak constraints are satisfied for some superdomains on the path, the  </abstract>::line_number::17
<abstract> source uses a query protocol to obtain a more detailed "internal" view of these superdomains,  </abstract>::line_number::18
<abstract> and searches again for a valid path. Our protocol handles topology changes, including node/link  </abstract>::line_number::19
<abstract> failures that partition superdomains. Evaluation results indicate our protocol scales well to large  </abstract>::line_number::20
<abstract> internetworks.   </abstract>::line_number::21
<abstract>  ABSTRACT  </abstract>::line_number::7
<abstract> In a recent paper, Chang and Paige have shown that the usual perturbation bounds for Cholesky factors can systematically overestimate  </abstract>::line_number::8
<abstract> the errors. In this note we sharpen their results and extend them to  </abstract>::line_number::9
<abstract> the factors of the LU decomposition. The results are based on a new  </abstract>::line_number::10
<abstract> formula for the first order terms of the error in the factors.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper presents a detailed comparison of the relative importance of allowing concurrent writers  </abstract>::line_number::8
<abstract> versus the choice of the underlying consistency model. Our comparison is based on single- and multiple-writer versions of a lazy release consistent (LRC) protocol, and a single-writer sequentially consistent  </abstract>::line_number::9
<abstract> protocol, all implemented in the CVM software distributed shared memory system.  </abstract>::line_number::10
<abstract> We find that in our environment, which we believe to be representative of distributed systems today  </abstract>::line_number::11
<abstract> and in the near future, the consistency model has a much higher impact on overall performance than the  </abstract>::line_number::12
<abstract> choice of whether to allow concurrent writers. The multiple writer protocol performs an average of 9%  </abstract>::line_number::13
<abstract> better than the single writer LRC protocol, but 34% better than the single-writer sequentially consistent  </abstract>::line_number::14
<abstract> protocol. Set against this, MW-LRC required an average of 72% memory overhead, compared to 10%  </abstract>::line_number::15
<abstract> overhead for the single-writer protocols.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We propose a hybrid method for synthesis of hierarchical structured Petri nets. In a top-down manner, we decompose a system into a set of subsystems at each level of abstraction, each  </abstract>::line_number::7
<abstract> of these is specified as a blackbox Petri net that has multiple inputs and outputs. We stipulate  </abstract>::line_number::8
<abstract> that each subsystem satisfies the following I/O constraints: (1) At any instance of time, at  </abstract>::line_number::9
<abstract> most one of the inputs can be activated; and (2) If one input is activated, then the subsystem  </abstract>::line_number::10
<abstract> must consume the input and produce exactly one output within a finite length of time. We  </abstract>::line_number::11
<abstract> give a stepwise refinement procedure which starts from the initial high-level abstraction of the  </abstract>::line_number::12
<abstract> system and expands an internal place of a blackbox Petri net into a more detailed subnet at  </abstract>::line_number::13
<abstract> each step. By enforcing the I/O constraints of each subsystem in each intermediate abstraction,  </abstract>::line_number::14
<abstract> our refinement maintains the sequencing of transitions prescribed by the initial abstraction of  </abstract>::line_number::15
<abstract> the system. Next, for the bottom-up synthesis, we present interconnection rules for sequential,  </abstract>::line_number::16
<abstract> parallel, and loop structures and prove that each rule maintains the I/O constraints. Thus, by  </abstract>::line_number::17
<abstract> incorporating these interconnection rules into our refinement formulation, our approach can be  </abstract>::line_number::18
<abstract> regarded as a hybrid Petri net synthesis technique that employs both top-down and bottom-up  </abstract>::line_number::19
<abstract> methods. The major advantage of the method is that the modeling details can be introduced  </abstract>::line_number::20
<abstract> incrementally and naturally, while the important logical properties of the resulting Petri net are  </abstract>::line_number::21
<abstract> guaranteed.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We propose a new bandwidth allocation scheme for VBR video traffic in ATM networks.  </abstract>::line_number::9
<abstract> The scheme is tailored to MPEG-coded video sources that require stringent and deterministic  </abstract>::line_number::10
<abstract> quality-of-service guarantees. By exploiting the temporal structure of MPEG sources, we show  </abstract>::line_number::11
<abstract> that our scheme results in an effective bandwidth which, in most cases, is less than the source  </abstract>::line_number::12
<abstract> peak rate. The reduction in the bandwidth requirement is achieved without sacrificing any  </abstract>::line_number::13
<abstract> perceived QoS. Efficient procedures are provided for the computation of the effective bandwidth  </abstract>::line_number::14
<abstract> under heterogeneous MPEG sources. The effective bandwidth strongly depends on the arrangement of the multiplexed streams which is a measure of the degree of synchronization between the  </abstract>::line_number::15
<abstract> GOP patterns of different streams. Assuming that all possible arrangements are equi-probable,  </abstract>::line_number::16
<abstract> we derive an expression for the asymptotic tail distribution of the effective bandwidth. From  </abstract>::line_number::17
<abstract> the tail distribution, we compute several performance measures for the call blocking probability  </abstract>::line_number::18
<abstract> when the allocation is made based on the effective bandwidth. In the case of homogeneous  </abstract>::line_number::19
<abstract> sources, we give a closed-form expression for the `best' arrangement that results in the `optimal'  </abstract>::line_number::20
<abstract> effective bandwidth. Numerical examples based on real MPEG traces are used to demonstrate  </abstract>::line_number::21
<abstract> the advantages of our scheme.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The Human-Computer Interaction Laboratory (HCIL) and the Maryland Department of Juvenile Justice (DJJ) have  </abstract>::line_number::10
<abstract> been working together to develop the ProgramFinder, a tool for choosing programs for a troubled youth from drug  </abstract>::line_number::11
<abstract> rehabilitation centers to secure residential facilities. The seemingly straightforward journey of the ProgramFinder  </abstract>::line_number::12
<abstract> from an existing user interface technique to a product design required the development of five different prototypes  </abstract>::line_number::13
<abstract> which involved user interface design, prototype implementation, and selecting search criterion. While HCILs effort  </abstract>::line_number::14
<abstract> focused primarily on design and implementation, DJJs attribute selection process was the most time consuming and  </abstract>::line_number::15
<abstract> difficult task. We also found that a direct link to DJJs workflow was needed in the prototypes to generate the  </abstract>::line_number::16
<abstract> necessary buy-in. This paper analyzes the interaction between the efforts of HCIL and DJJ and the amount of buy-in by DJJ staff and management. Lesson learned are presented for developers.   </abstract>::line_number::17
<abstract>  Abstract: This paper presents an empirical study of several policies for managing the effect  </abstract>::line_number::8
<abstract> of delay jitter on the playout of audio and video in computer-based conferences. The problem  </abstract>::line_number::9
<abstract> addressed is that of managing the fundamental tradeoff between display with low latency and  </abstract>::line_number::10
<abstract> display with few gaps. We describe a particular policy called queue monitoring which  </abstract>::line_number::11
<abstract> observes delay jitter over time and dynamically adjusts display latency in order to support  </abstract>::line_number::12
<abstract> low-latency conferences with an acceptable gap rate. Queue monitoring is evaluated by  </abstract>::line_number::13
<abstract> comparing it with two policies from the literature in a study based on measurements from a  </abstract>::line_number::14
<abstract> computer-based conferencing system. Our results show that queue monitoring performs as  </abstract>::line_number::15
<abstract> well or better than the other policies over the range of observed network loads. More  </abstract>::line_number::16
<abstract> importantly, we show that queue monitoring performs better on those network loads for  </abstract>::line_number::17
<abstract> which the other policies exhibit poor performance.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::3
<abstract> This paper considers the use of lock-free shared objects  </abstract>::line_number::4
<abstract> within hard real-time systems. As the name suggests,  </abstract>::line_number::5
<abstract> lock-free shared objects are distinguished by the fact  </abstract>::line_number::6
<abstract> that they are not locked. As such, they do not give  </abstract>::line_number::7
<abstract> rise to priority inversions, a key advantage over conventional, lock-based object-sharing approaches. Despite this advantage, it is not immediately apparent  </abstract>::line_number::8
<abstract> that lock-free shared objects can be employed if tasks  </abstract>::line_number::9
<abstract> must adhere to strict timing constraints. In particular,  </abstract>::line_number::10
<abstract> lock-free object implementations permit concurrent operations to interfere with each other, and repeated interferences can cause a given operation to take an arbitrarily long time to complete.  </abstract>::line_number::11
<abstract> The main contribution of this paper is to show that  </abstract>::line_number::12
<abstract> such interferences can be bounded by judicious scheduling. This work pertains to periodic, hard real-time  </abstract>::line_number::13
<abstract> tasks that share lock-free objects on a uniprocessor. In  </abstract>::line_number::14
<abstract> the first part of the paper, scheduling conditions are derived for such tasks, for both static and dynamic priority schemes. Based on these conditions, it is formally  </abstract>::line_number::15
<abstract> shown that lock-free object-sharing approaches can be  </abstract>::line_number::16
<abstract> expected to incur much less overhead than approaches  </abstract>::line_number::17
<abstract> based on wait-free objects or lock-based schemes. In  </abstract>::line_number::18
<abstract> the last part of the paper, this conclusion is validated experimentally through work involving a real-time desktop videoconferencing system.   </abstract>::line_number::19
<abstract>  ABSTRACT  </abstract>::line_number::4
<abstract> Sync is a new Java-based framework for developing collaborative applications for wireless mobile  </abstract>::line_number::5
<abstract> systems. Sync is based on objectoriented replication and offers high-level synchronization-aware classes  </abstract>::line_number::6
<abstract> based on existing Java classes. Programmers may also extend the Sync-provided classes to create new  </abstract>::line_number::7
<abstract> replicated classes, either to add functionality or to modify a classs merge policy. Sync supports fully  </abstract>::line_number::8
<abstract> disconnected operation and employs centralized, asynchronous synchronization. Application programmers  </abstract>::line_number::9
<abstract> use the Sync framework to define conflicts and specify conflict resolution on the basis of the applications  </abstract>::line_number::10
<abstract> structure and semantics.  </abstract>::line_number::11
<abstract> We discuss the general needs of wireless mobile applications, and present a high-function example  </abstract>::line_number::12
<abstract> application that would be useful to mobile users, to be used for illustration throughout the paper. Next we  </abstract>::line_number::13
<abstract> discuss related work, and evaluate each work relative to its ability to support the example application. We  </abstract>::line_number::14
<abstract> then present the Sync framework, motivating each feature with its use in the example application.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::12
<abstract> The relation between the orthography and the phonology of a language has  </abstract>::line_number::13
<abstract> traditionally been modelled by hand-crafted rule sets. Machine-learning (ML)  </abstract>::line_number::14
<abstract> approaches offer a means to gather this knowledge automatically. Problems  </abstract>::line_number::15
<abstract> arise when the training material is sparse. Generalising from sparse data  </abstract>::line_number::16
<abstract> is a well-known problem for many ML algorithms. We present experiments  </abstract>::line_number::17
<abstract> in which connectionist, instance-based, and decision-tree learning algorithms  </abstract>::line_number::18
<abstract> are applied to a small corpus of Scottish Gaelic. instance-based learning in the  </abstract>::line_number::19
<abstract> ib1-ig algorithm yields the best generalisation performance, and that most  </abstract>::line_number::20
<abstract> algorithms tested perform tolerably well. Given the availability of a lexicon,  </abstract>::line_number::21
<abstract> even if it is sparse, ML is a valuable and efficient tool for automatic phonetic  </abstract>::line_number::22
<abstract> transcription of written text.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Naming plays a key role in the design of any system that exports services or resources. Object systems  </abstract>::line_number::7
<abstract> may export many different categories of names: instances, components of records, types, etc. Operating  </abstract>::line_number::8
<abstract> systems export the names of files, devices, and services. Integrating an object base with existing operating system facilities can improve accessibility of the  </abstract>::line_number::9
<abstract> object base resources. We consider the benefits and  </abstract>::line_number::10
<abstract> pitfalls of integrating an object base namespace with  </abstract>::line_number::11
<abstract> the Unix namespace. 1   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::12
<abstract> Integrating persistence into an existing programming language is a serious undertaking. Preserving the essence of the existing language, adequately supporting persistence, and maintaining efficiency require low-level support from the compiler and runtime systems. Pervasive,  </abstract>::line_number::13
<abstract> low-level changes were made to a Lisp compiler and runtime system to introduce persistence.  </abstract>::line_number::14
<abstract> The result is an efficient language which is worthy of the name Persistent Lisp. 1   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Many emerging applications (e.g., teleconference, real-time  </abstract>::line_number::7
<abstract> information services, pay per view, distributed interactive  </abstract>::line_number::8
<abstract> simulation, and collaborative work) are based upon a group  </abstract>::line_number::9
<abstract> communications model, i.e., they require packet delivery  </abstract>::line_number::10
<abstract> from one or more authorized senders to a very large number  </abstract>::line_number::11
<abstract> of authorized receivers. As a result, securing group communications (i.e., providing confidentiality, integrity, and authenticity of messages delivered between group members)  </abstract>::line_number::12
<abstract> will become a critical networking issue.  </abstract>::line_number::13
<abstract> In this paper, we present a novel solution to the scalability problem of group/multicast key management. We  </abstract>::line_number::14
<abstract> formalize the notion of a secure group as a triple (U; K; R)  </abstract>::line_number::15
<abstract> where U denotes a set of users, K a set of keys held by the  </abstract>::line_number::16
<abstract> users, and R a user-key relation. We then introduce key  </abstract>::line_number::17
<abstract> graphs to specify secure groups. For a special class of key  </abstract>::line_number::18
<abstract> graphs, we present three strategies for securely distributing rekey messages after a join/leave, and specify protocols  </abstract>::line_number::19
<abstract> for joining and leaving a secure group. The rekeying strategies and join/leave protocols are implemented in a prototype  </abstract>::line_number::20
<abstract> group key server we have built. We present measurement  </abstract>::line_number::21
<abstract> results from experiments and discuss performance comparisons. We show that our group key management service, using any of the three rekeying strategies, is scalable to large  </abstract>::line_number::22
<abstract> groups with frequent joins and leaves. In particular, the  </abstract>::line_number::23
<abstract> average measured processing time per join/leave increases  </abstract>::line_number::24
<abstract> linearly with the logarithm of group size.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::10
<abstract> Planning systems have become an important tool for automating a wide variety  </abstract>::line_number::11
<abstract> of tasks. Control knowledge guides a planner to find solutions quickly and is crucial  </abstract>::line_number::12
<abstract> for efficient planning in most domains. Machine learning techniques enable a planning  </abstract>::line_number::13
<abstract> system to automatically acquire domain-specific search-control knowledge for different  </abstract>::line_number::14
<abstract> applications. Past approaches to learning control information have usually employed  </abstract>::line_number::15
<abstract> explanation-based learning (EBL) to generate control rules. Unfortunately, EBL alone  </abstract>::line_number::16
<abstract> often produces overly complex rules that actually decrease rather than improve overall  </abstract>::line_number::17
<abstract> planning efficiency. This paper presents a novel learning approach for control knowledge  </abstract>::line_number::18
<abstract> acquisition that integrates explanation-based learning with techniques from inductive  </abstract>::line_number::19
<abstract> logic programming. In our learning system Scope, EBL is used to constrain an inductive search for control heuristics that help a planner choose between competing plan  </abstract>::line_number::20
<abstract> refinements. Scope is one of the few systems to address learning control information for newer, partial-order planners. Specifically, this proposal describes how Scope  </abstract>::line_number::21
<abstract> learns domain-specific control rules for the UCPOP planning algorithm. The resulting  </abstract>::line_number::22
<abstract> system is shown to produce significant speedup in two different planning domains, and  </abstract>::line_number::23
<abstract> to be more effective than a pure EBL approach. Future research will be performed  </abstract>::line_number::24
<abstract> in three main areas. First, Scope's learning algorithm will be extended to include  </abstract>::line_number::25
<abstract> additional techniques such as constructive induction and rule utility analysis. Second,  </abstract>::line_number::26
<abstract> Scope will be more thoroughly tested; several real-world planning domains have been  </abstract>::line_number::27
<abstract> identified as possible testbeds, and more in-depth comparisons will be drawn between  </abstract>::line_number::28
<abstract> Scope and other competing approaches. Third, Scope will be implemented in a different planning system in order to test its portability to other planning algorithms. This  </abstract>::line_number::29
<abstract> work should demonstrate that machine-learning techniques can be a powerful tool in  </abstract>::line_number::30
<abstract> the quest for tractable real-world planning.   </abstract>::line_number::31
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We argue that domain models should produce four basic products: identification of reusable software components, definition of software architectures that explain how components can be composed, a demonstration of architecture scalability, and a direct relationship of these results to  </abstract>::line_number::7
<abstract> software generation of target systems.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We define the ripple-carry and the carry-lookahead adder circuits in the  </abstract>::line_number::9
<abstract> powerlist notation and we use the powerlist algebra to prove that these  </abstract>::line_number::10
<abstract> circuits correctly implement addition for natural numbers represented as  </abstract>::line_number::11
<abstract> bit vectors.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Nested loop execution of object-oriented queries retains  </abstract>::line_number::9
<abstract> the promise of maintaining the full generality of the object paradigm, independent of the specifics of any single  </abstract>::line_number::10
<abstract> object model. Thus, from this starting point we have  </abstract>::line_number::11
<abstract> developed an object-oriented query optimizer and execution engine. The methods, developed to date for only  </abstract>::line_number::12
<abstract> acyclic queries, augment nested loops structures with a  </abstract>::line_number::13
<abstract> simple marking mechanism such that unnecessary loop  </abstract>::line_number::14
<abstract> iterations are not repeated. In the case of acyclic queries,  </abstract>::line_number::15
<abstract> the executions are asymptotically optimal. In contrast to  </abstract>::line_number::16
<abstract> optimal query methods based on semijoin reductions our  </abstract>::line_number::17
<abstract> method involves no preprocessing step and thus avoids  </abstract>::line_number::18
<abstract> the extra I/O associated with semijoins and prevents the  </abstract>::line_number::19
<abstract> formal benefits of semijoin reduction from appearing as a  </abstract>::line_number::20
<abstract> practical improvement. Empirical results comparing our  </abstract>::line_number::21
<abstract> query environment with a commercially available product  </abstract>::line_number::22
<abstract> demonstrate significant performance improvement.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::5
<abstract> A common task in automated manufacturing processes is to orient parts prior to  </abstract>::line_number::6
<abstract> assembly. We address sensorless orientation of a polygonal part on a conveyor belt by  </abstract>::line_number::7
<abstract> a sequence of stationary fences across this belt. Since fences can only push against the  </abstract>::line_number::8
<abstract> motion of the belt, it is a challenging problem to compute fence designs which orients  </abstract>::line_number::9
<abstract> a given part. In this paper, we give several polynomial-time, algorithms to compute  </abstract>::line_number::10
<abstract> fence designs which are optimal with respect to various criteria. We address both  </abstract>::line_number::11
<abstract> frictionless and frictional fences. We also compute modular fence designs in which  </abstract>::line_number::12
<abstract> the fence angles are restricted to a discrete set of angles instead of an interval.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::7
<abstract> A bandwidth control mechanism is proposed for ATM  </abstract>::line_number::8
<abstract> networks that can control the usage of bandwidth in the  </abstract>::line_number::9
<abstract> presence of both connection-oriented and connection-less traffic, as well as multiple classes of connectionless  </abstract>::line_number::10
<abstract> traffic. The bandwidth control mechanism operates at  </abstract>::line_number::11
<abstract> three levels. At the topmost level, bandwidth is dynamically regulated between connection-oriented and  </abstract>::line_number::12
<abstract> connectionless traffic based on the utilization of each  </abstract>::line_number::13
<abstract> traffic type. At the next level, bandwidth is controlled  </abstract>::line_number::14
<abstract> between different classes of connectionless traffic, such  </abstract>::line_number::15
<abstract> as real-time traffic, bulk data traffic, and so on. At the  </abstract>::line_number::16
<abstract> lowest level, bandwidth is distributed among flows belonging to the same connectionless traffic class.   </abstract>::line_number::17
<abstract>  Abstract. The demand for computing and computing power is increasing at a rapid pace. With this demand,  </abstract>::line_number::8
<abstract> the ability to develop, enhance and maintain software is a top priority. Educating students to do competent  </abstract>::line_number::9
<abstract> work in software development, enhancement and maintenance has become a complex problem. Software  </abstract>::line_number::10
<abstract> engineering concepts are typically not introduced in beginning computer science courses. Students do not see  </abstract>::line_number::11
<abstract> software engineering until the third or fourth year of the curriculum. We do not believe students can acquire  </abstract>::line_number::12
<abstract> an adequate software engineering foundation with the present approach. We believe an emphasis on software  </abstract>::line_number::13
<abstract> engineering should begin in the very first course and continue throughout the curriculum. We are redesigning  </abstract>::line_number::14
<abstract> our curriculum to reect this. The first course of the new curriculum is complete. This article focuses on two  </abstract>::line_number::15
<abstract> of the laboratory activities we have developed which deal with specific software engineering concepts.   </abstract>::line_number::16
<abstract>  Abstract We introduce a class of networks called isotach networks designed to reduce the  </abstract>::line_number::4
<abstract> cost of concurrency control in asynchronous computations. Isotach networks support several  </abstract>::line_number::5
<abstract> properties important to the correct execution of parallel and distributed computations: atomi-city, causal message delivery, sequential consistency, and memory coherence in systems in  </abstract>::line_number::6
<abstract> which shared data can replicate and migrate. They allow processes to execute atomic actions  </abstract>::line_number::7
<abstract> without locks and to pipeline memory accesses without sacrificing sequential consistency. Iso-tach networks can be implemented in a wide variety of configurations, including NUMA (nonuniform memory access) multiprocessors and distributed as well as parallel systems. Networks  </abstract>::line_number::8
<abstract> that implement isotach time systems are characterized not by their topology, but by the guarantees they make about the relative order in which messages appear to be delivered. These  </abstract>::line_number::9
<abstract> guarantees are expressed in logical time, not physical time. Physical time guarantees would be  </abstract>::line_number::10
<abstract> prohibitively expensive, whereas logical time guarantees can be enforced cheaply, using purely  </abstract>::line_number::11
<abstract> local knowledge, and yet are powerful enough to support efficient techniques for coordinating  </abstract>::line_number::12
<abstract> asynchronously executing processes. Empirical and analytic studies of isotach systems show  </abstract>::line_number::13
<abstract> that they outperform conventional systems under realistic workloads, in some cases by an order  </abstract>::line_number::14
<abstract> of magnitude or more.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Tracing tools are used widely to help analyze, design, and tune  </abstract>::line_number::9
<abstract> both hardware and software systems. This paper describes a tool  </abstract>::line_number::10
<abstract> called Shade which combines efficient instruction-set simulation  </abstract>::line_number::11
<abstract> with a flexible, extensible trace generation capability. Efficiency  </abstract>::line_number::12
<abstract> is achieved by dynamically compiling and caching code to simulate and trace the application program. The user may control the  </abstract>::line_number::13
<abstract> extent of tracing in a variety of ways; arbitrarily detailed application state information may be collected during the simulation, but  </abstract>::line_number::14
<abstract> tracing less translates directly into greater efficiency. Current  </abstract>::line_number::15
<abstract> Shade implementations run on SPARC systems and simulate the  </abstract>::line_number::16
<abstract> SPARC (Versions 8 and 9) and MIPS I instruction sets. This  </abstract>::line_number::17
<abstract> paper describes the capabilities, design, implementation, and performance of Shade, and discusses instruction set emulation in  </abstract>::line_number::18
<abstract> general.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::21
<abstract> In computer systems with large, physically-indexed,  </abstract>::line_number::22
<abstract> direct-mapped caches, a poor mapping from virtual to  </abstract>::line_number::23
<abstract> physical pages causes excessive cache conflict misses.  </abstract>::line_number::24
<abstract> In a previous paper we proposed a simple hardware device, the Cache Miss Lookaside (CML) Buffer, which  </abstract>::line_number::25
<abstract> identifies pages that are suffering from conflict misses.  </abstract>::line_number::26
<abstract> The operating system can use this information to implement a dynamic page mapping policy that resolves  </abstract>::line_number::27
<abstract> conflicts by performing an in-memory copy of one of  </abstract>::line_number::28
<abstract> the conflicting pages, and updating the virtual to physical mappings. In this paper, we propose several dynamic page mapping policies that detect and resolve  </abstract>::line_number::29
<abstract> cache conflicts using hardware available in existing systems, such as a TLB and cache miss counter, to locate  </abstract>::line_number::30
<abstract> possible cache conflicts. We evaluate the simulated  </abstract>::line_number::31
<abstract> performance of a variety of mapping policies, and show  </abstract>::line_number::32
<abstract> that a dynamic page mapping policy using standard  </abstract>::line_number::33
<abstract> hardware can improve upon the performance of a static  </abstract>::line_number::34
<abstract> policy, but is not as effective as special-purpose hardware such as an associative cache or a CML buffer.  </abstract>::line_number::35
<abstract> We also describe the implementation and performance  </abstract>::line_number::36
<abstract> of a software-based dynamic policy on a DEC Alpha  </abstract>::line_number::37
<abstract> workstation running DEC OSF/1.   </abstract>::line_number::38
<abstract>  Abstract  </abstract>::line_number::2
<abstract> We present parallel solutions for direct and fast n-body solvers written in the ZPL  </abstract>::line_number::3
<abstract> language. We describe the direct solver, compare its performance against a sequential  </abstract>::line_number::4
<abstract> C program, and show performance results for two very different parallel machines: the  </abstract>::line_number::5
<abstract> KSR-2 and the Paragon. We also discuss the implementation of the fast solver in ZPL,  </abstract>::line_number::6
<abstract> including factors pertinent to data movement.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A fundamental problem in the synthesis and optimization of concurrent systems is the determination of the separation time between system events. We present a theoretical framework  </abstract>::line_number::7
<abstract> for solving this problem for arbitrary process graphs without conditional behavior and develop an efficient and exact algorithm based on this theoretical foundation. Examples are  </abstract>::line_number::8
<abstract> used to demonstrate the operation and generality of the algorithm.   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::6
<abstract> User-level threads have performance and flexibility advantages over both Unix-like processes  </abstract>::line_number::7
<abstract> and kernel threads. However, the performance of user-level threads may suffer in multipro-grammed environments, or when threads block in the kernel (e.g., for I/O). These problems  </abstract>::line_number::8
<abstract> can be particularly severe in tasks that communicate frequently using IPC (e.g., multithreaded  </abstract>::line_number::9
<abstract> servers), due to interactions between the user-level thread scheduler and the operating system  </abstract>::line_number::10
<abstract> IPC primitives. Efficient IPC typically involves processor handoff that blocks the caller and  </abstract>::line_number::11
<abstract> unblocks a thread in the callee; when combined with user-level threads, this can cause problems  </abstract>::line_number::12
<abstract> for both caller and callee, particularly if the caller thread should subsequently block.  </abstract>::line_number::13
<abstract> In this paper we describe a new user-level thread package, called OThreads, designed to  </abstract>::line_number::14
<abstract> support blocking and efficient IPC for a system based on traditional kernel threads. We discuss  </abstract>::line_number::15
<abstract> the extent to which these problems can be solved at the user level without kernel changes  </abstract>::line_number::16
<abstract> such as scheduler activations. Our conclusion is that problems caused by application-controlled  </abstract>::line_number::17
<abstract> blocking and IPC can be resolved in the user-level thread package, but that problems due  </abstract>::line_number::18
<abstract> to multiprogramming workload and unanticipated blocking such as page faults require kernel  </abstract>::line_number::19
<abstract> changes such as scheduler activations.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We present a new method for accelerating walkthroughs of geometrically complex static  </abstract>::line_number::10
<abstract> scenes. As a preprocessing step, our method constructs a BSP-tree that hierarchically partitions the geometric primitives in the scene. In the course of a walkthrough, images of nodes  </abstract>::line_number::11
<abstract> at various levels of the hierarchy are cached for reuse in subsequent frames. A cached image is applied as a texture map to a single quadrilateral that is drawn instead of the geometry  </abstract>::line_number::12
<abstract> contained in the corresponding node. Visual artifacts are kept under control by using an error metric that quantifies the discrepancy between the appearance of the geometry contained  </abstract>::line_number::13
<abstract> in a node and the cached image. The new method is shown to achieve significant speedups  </abstract>::line_number::14
<abstract> for a walkthrough of a complex outdoor scene, with little or no loss in rendering quality.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Subdivision surfaces provide a curved surface representation that is useful in a number of applications, including modeling surfaces of arbitrary topological type [5] , fitting scattered data [6] , and geometric compression  </abstract>::line_number::7
<abstract> and automatic level-of-detail generation using wavelets [8] . Subdivision surfaces also provide an attractive representation for fast rendering, since they can directly represent complex surfaces of arbitrary topology. This direct  </abstract>::line_number::8
<abstract> representation contrasts with traditional approaches such as trimmed NURBS, in which tesselating trim regions  </abstract>::line_number::9
<abstract> dominates rendering time, and algebraic implicit surfaces, in which rendering requires resultants, root finders, or  </abstract>::line_number::10
<abstract> other computationally expensive techniques.  </abstract>::line_number::11
<abstract> We present a method for subdivision surface triangulation that is fast, uses minimum memory, and is simpler in  </abstract>::line_number::12
<abstract> structure than a naive rendering method based on direct subdivision. These features make the algorithm amenable  </abstract>::line_number::13
<abstract> to implementation on dedicated geometry engine processors, allowing high rendering performance on appropri  </abstract>::line_number::14
<abstract> ately equipped graphics hardware.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::19
<abstract> The principles underlying this report can be summarized as follows:  </abstract>::line_number::20
<abstract> 1. A strong theoretical foundation is vital to computer science.  </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Linear equality and inequality constraints arise naturally in specifying many aspects of user  </abstract>::line_number::10
<abstract> interfaces, such as requiring that one window be to the left of another, requiring that a pane  </abstract>::line_number::11
<abstract> occupy the leftmost 1/3 of a window, or preferring that an object be contained within a rectangle if possible. Current constraint solvers designed for UI applications cannot efficiently  </abstract>::line_number::12
<abstract> handle simultaneous linear equations and inequalities. This is a major limitation. We describe  </abstract>::line_number::13
<abstract> Cassowary|an incremental algorithm based on the dual simplex method that can solve such  </abstract>::line_number::14
<abstract> systems of constraints efficiently.   </abstract>::line_number::15
<abstract>   Abstract. A formula for the error in Chung-Yao interpolation announced earlier is proved (by induction). In the process, a bivariate divided difference identity of independent interest is proved. Also, an inductive proof of an error formula for polynomial interpolation by tensor-products is given. The main tool is a (convenient notation for a) multi-variate divided difference.   </abstract>::line_number::3
<abstract>  ABSTRACT  </abstract>::line_number::2
<abstract> We provide a map fi 7! fi which associates each finite set fi of points in C s with a polynomial  </abstract>::line_number::3
<abstract> space fi from which interpolation to arbitrary data given at the points in fi is possible and uniquely  </abstract>::line_number::4
<abstract> so. Among all polynomial spaces Q from which interpolation at fi is uniquely possible, our fi  </abstract>::line_number::5
<abstract> is of smallest degree. It is also D- and scale-invariant. Our map is monotone, thus providing a  </abstract>::line_number::6
<abstract> Newton form for the resulting interpolant. Our map is also continuous within reason, allowing us to  </abstract>::line_number::7
<abstract> interpret certain cases of coalescence as Hermite interpolation. In fact, our map can be extended to  </abstract>::line_number::8
<abstract> the case where, with each 2 fi, there is associated a polynomial space P , and, for given smooth  </abstract>::line_number::9
<abstract> f , a polynomial q 2 Q is sought for which  </abstract>::line_number::10
<abstract> p(D)(f q)() = 0; all p 2 P ; 2 fi:  </abstract>::line_number::11
<abstract> We obtain fi as the "scaled limit at the origin" (Exp fi ) # of the exponential space Exp fi with  </abstract>::line_number::12
<abstract> frequencies fi, and base our results on a study of the map H 7! H # defined on subspaces H of  </abstract>::line_number::13
<abstract> the space of functions analytic at the origin. This study also allows us to determine the local  </abstract>::line_number::14
<abstract> approximation order from such H and provides an algorithm for the construction of H # from any  </abstract>::line_number::15
<abstract> basis for H.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We present an approach for recovering surface shape from the occluding contour using an active (i.e., moving) observer. It is based on a relation between the geometries of  </abstract>::line_number::8
<abstract> a surface in a scene and its occluding contour: If the viewing direction of the observer  </abstract>::line_number::9
<abstract> is along a principal direction for a surface point whose projection is on the contour,  </abstract>::line_number::10
<abstract> surface shape (i.e., curvature) at the surface point can be recovered from the contour.  </abstract>::line_number::11
<abstract> Unlike previous approaches for recovering shape from the occluding contour, we use an  </abstract>::line_number::12
<abstract> observer that purposefully changes viewpoint in order to achieve a well-defined geometric relationship with respect to a 3D shape prior to its recognition. We show that there  </abstract>::line_number::13
<abstract> is a simple and efficient viewing strategy that allows the observer to align their viewing  </abstract>::line_number::14
<abstract> direction with one of the two principal directions for a point on the surface. This strategy depends on only curvature measurements on the occluding contour and therefore  </abstract>::line_number::15
<abstract> demonstrates that recovering quantitative shape information from the contour does not  </abstract>::line_number::16
<abstract> require knowledge of the velocities or accelerations of the observer. Experimental results  </abstract>::line_number::17
<abstract> demonstrate that our method can be easily implemented and can provide reliable shape  </abstract>::line_number::18
<abstract> information from the occluding contour.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::10
<abstract> This paper presents the Plannett system, which  </abstract>::line_number::11
<abstract> combines artificial neural networks to achieve expert-  </abstract>::line_number::12
<abstract> level accuracy on the difficult scientific task of recognizing volcanos in radar images of the surface of the  </abstract>::line_number::13
<abstract> planet Venus. Plannett uses ANNs that vary along  </abstract>::line_number::14
<abstract> two dimensions: the set of input features used to train  </abstract>::line_number::15
<abstract> and the number of hidden units. The ANNs are combined simply by averaging their output activations.  </abstract>::line_number::16
<abstract> When Plannett is used as the classification module  </abstract>::line_number::17
<abstract> of a three-stage image analysis system called JAR-  </abstract>::line_number::18
<abstract> tool, the end-to-end accuracy (sensitivity and specificity) is as good as that of a human planetary geologist on a four-image test suite. JARtool-Plannett  </abstract>::line_number::19
<abstract> also achieves the best algorithmic accuracy on these  </abstract>::line_number::20
<abstract> images to date.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::11
<abstract> A team of learning machines is a multiset of  </abstract>::line_number::12
<abstract> learning machines. A team is said to successfully learn a concept just in case each member  </abstract>::line_number::13
<abstract> of some nonempty subset, of predetermined  </abstract>::line_number::14
<abstract> size, of the team learns the concept.  </abstract>::line_number::15
<abstract> Team learning of computer programs for  </abstract>::line_number::16
<abstract> computable functions from their graphs has  </abstract>::line_number::17
<abstract> been studied extensively. However, team  </abstract>::line_number::18
<abstract> learning of languages turns out to be a  </abstract>::line_number::19
<abstract> more suitable theoretical model for studying  </abstract>::line_number::20
<abstract> computational limits on multi-agent machine  </abstract>::line_number::21
<abstract> learning. The main reason for this is that  </abstract>::line_number::22
<abstract> language learning can model both learning  </abstract>::line_number::23
<abstract> from positive data and learning from positive  </abstract>::line_number::24
<abstract> and negative data, whereas function learning  </abstract>::line_number::25
<abstract> models only learning from positive and negative data.  </abstract>::line_number::26
<abstract> Some theoretical results about learnability of  </abstract>::line_number::27
<abstract> formal languages by teams of algorithmic machines are surveyed. Some new results about  </abstract>::line_number::28
<abstract> restricted classes of languages are presented.  </abstract>::line_number::29
<abstract> These results are mainly about two issues: redundancy and aggregation. The issue of redundancy deals with the impact of increasing  </abstract>::line_number::30
<abstract> the size of a team and increasing the number  </abstract>::line_number::31
<abstract> of machines required to be successful. The  </abstract>::line_number::32
<abstract> issue of aggregation deals with conditions under which a team may be replaced by a single  </abstract>::line_number::33
<abstract> machine without any loss in learning ability.  </abstract>::line_number::34
<abstract> Scenarios which can be modeled by team  </abstract>::line_number::35
<abstract> learning are also presented.   </abstract>::line_number::36
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We describe in this work a number of central problems of machine learning and  </abstract>::line_number::5
<abstract> show how they can be modeled and solved as mathematical programs of various  </abstract>::line_number::6
<abstract> complexity.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The problem of assigning m points in the n-dimensional real space  </abstract>::line_number::8
<abstract> R n to k clusters is formulated as that of determining k centers in  </abstract>::line_number::9
<abstract> R n such that the sum of distances of each point to the nearest  </abstract>::line_number::10
<abstract> center is minimized. If a polyhedral distance is used, the problem  </abstract>::line_number::11
<abstract> can be formulated as that of minimizing a piecewise-linear concave  </abstract>::line_number::12
<abstract> function on a polyhedral set which is shown to be equivalent to  </abstract>::line_number::13
<abstract> a bilinear program: minimizing a bilinear function on a polyhedral set. A fast finite k-Median Algorithm consisting of solving  </abstract>::line_number::14
<abstract> few linear programs in closed form leads to a stationary point of  </abstract>::line_number::15
<abstract> the bilinear program. Computational testing on a number of real-world databases was carried out. On the Wisconsin Diagnostic  </abstract>::line_number::16
<abstract> Breast Cancer (WDBC) database, k-Median training set correctness was comparable to that of the k-Mean Algorithm, however its  </abstract>::line_number::17
<abstract> testing set correctness was better. Additionally, on the Wisconsin  </abstract>::line_number::18
<abstract> Prognostic Breast Cancer (WPBC) database, distinct and clinically important survival curves were extracted by the k-Median  </abstract>::line_number::19
<abstract> Algorithm, whereas the k-Mean Algorithm failed to obtain such  </abstract>::line_number::20
<abstract> distinct survival curves for the same database.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::8
<abstract> In an effort to push the envelope of system performance, microprocessor designs are continually exploiting higher levels of  </abstract>::line_number::9
<abstract> instruction-level parallelism, resulting in increasing bandwidth demands on the address translation mechanism. Most current microprocessor designs meet this demand with a multi-ported TLB. While  </abstract>::line_number::10
<abstract> this design provides an excellent hit rate at each port, its access latency and area grow very quickly as the number of ports is increased.  </abstract>::line_number::11
<abstract> As bandwidth demands continue to increase, multi-ported designs  </abstract>::line_number::12
<abstract> will soon impact memory access latency.  </abstract>::line_number::13
<abstract> We present four high-bandwidth address translation mechanisms  </abstract>::line_number::14
<abstract> with latency and area characteristics that scale better than a multi-ported TLB design. We extend traditional high-bandwidth memory  </abstract>::line_number::15
<abstract> design techniques to address translation, developing interleaved and  </abstract>::line_number::16
<abstract> multi-level TLB designs. In addition, we introduce two new designs  </abstract>::line_number::17
<abstract> crafted specifically for high-bandwidth address translation. Piggyback ports are introduced as a technique to exploit spatial locality in  </abstract>::line_number::18
<abstract> simultaneous translation requests, allowing accesses to the same virtual memory page to combine their requests at the TLB access port.  </abstract>::line_number::19
<abstract> Pretranslation is introduced as a technique for attaching translations  </abstract>::line_number::20
<abstract> to base register values, making it possible to reuse a single translation many times.  </abstract>::line_number::21
<abstract> We perform extensive simulation-based studies to evaluate our  </abstract>::line_number::22
<abstract> designs. We vary key system parameters, such as processor model,  </abstract>::line_number::23
<abstract> page size, and number of architected registers, to see what effects  </abstract>::line_number::24
<abstract> these changes have on the relative merits of each approach. A number of designs show particular promise. Multi-level TLBs with as  </abstract>::line_number::25
<abstract> few as eight entries in the upper-level TLB nearly achieve the performance of a TLB with unlimited bandwidth. Piggyback ports  </abstract>::line_number::26
<abstract> combined with a lesser-ported TLB structure, e.g., an interleaved or  </abstract>::line_number::27
<abstract> multi-ported TLB, also perform well. Pretranslation over a single-ported TLB performs almost as well as a same-sized multi-level  </abstract>::line_number::28
<abstract> TLB with the added benefit of decreased access latency for physically indexed caches.   </abstract>::line_number::29
<abstract>  Abstract. Constraints of a mathematical program are distributed among parallel processors together with an appropriately constructed augmented Lagrangian for each processor, which contains  </abstract>::line_number::2
<abstract> Lagrangian information on the constraints handled by the other processors. Lagrange multiplier information is then exchanged between processors. Convergence is established under suitable conditions  </abstract>::line_number::3
<abstract> for strongly convex quadratic programs and for general convex programs.   </abstract>::line_number::4
<abstract>  Abstract. The computing time benefits of parallelism in database systems (achieved by using multiple processors to execute a query) must be weighed against communication, startup, and  </abstract>::line_number::4
<abstract> termination overhead costs that increase as a function of the number of processors used. We consider problems of minimizing overhead subject to allocating data among the processors according  </abstract>::line_number::5
<abstract> to specified loads. We present lower bounds for these combinatorial problems and demonstrate how  </abstract>::line_number::6
<abstract> processors may be optimally assigned for some problem classes.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::9
<abstract> This report presents results of a peer review of MQPs conducted within  </abstract>::line_number::10
<abstract> the Computer Science Department during the Summer of 1995 as part of a  </abstract>::line_number::11
<abstract> campus-wide MQP review. The goal of the report is to assess whether the  </abstract>::line_number::12
<abstract> department MQPs are accomplishing their educational goals. The report  </abstract>::line_number::13
<abstract> identifies problems that need to be addressed and trends that need to be  </abstract>::line_number::14
<abstract> continued to make the MQPs a worthwhile learning experience. It reflects  </abstract>::line_number::15
<abstract> data and evaluations for 27 MQPs, involving 43 computer science students,  </abstract>::line_number::16
<abstract> that were completed between the Summer of 1994 and the Spring of 1995.  </abstract>::line_number::17
<abstract> The report also makes comparisons to similar reviews done in 1991 and 1993.  </abstract>::line_number::18
<abstract> Overall, the large majority of the projects are meeting the educational  </abstract>::line_number::19
<abstract> goals of the department as good learning experiences. The reviews indicate  </abstract>::line_number::20
<abstract> the overall quality of the projects is good, about the same as in 1993 and  </abstract>::line_number::21
<abstract> a little better than 1991. The report draws a number of conclusions about  </abstract>::line_number::22
<abstract> the success of the projects based upon the data collected and evaluations  </abstract>::line_number::23
<abstract> done for this review. The report concludes with recommendations for future  </abstract>::line_number::24
<abstract> projects.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::10
<abstract> This article studies the following question: "When is it possible to decide, on the basis of images of point features observed by an imprecisely modeled two-camera stereo  </abstract>::line_number::11
<abstract> vision system, whether or not a prescribed robot positioning task has been accomplished with precision?" It is shown that for a stereo vision system with known epipo-lar geometry, whether or not such a positioning task has been accomplished can be  </abstract>::line_number::12
<abstract> decided with available data, just in case the task function which specifies the task is a  </abstract>::line_number::13
<abstract> projective invariant.   </abstract>::line_number::14
<abstract>  Abstract: High Performance Fortran (HPF) compilers  </abstract>::line_number::12
<abstract> and communication libraries with the standardized Message Passing Interface (MPI) are becoming widely available, easing the development of portable parallel applications on distributed-memory parallel processor systems.  </abstract>::line_number::13
<abstract> The recently developed Annai tool environment supports  </abstract>::line_number::14
<abstract> programming, debugging and tuning of both HPF- and  </abstract>::line_number::15
<abstract> MPI-based applications. Considering code development  </abstract>::line_number::16
<abstract> and subsequent maintenance time to be as important as ultimate performance, we address how sequential Fortran-77  </abstract>::line_number::17
<abstract> versions of the familiar NAS Parallel Benchmark kernels  </abstract>::line_number::18
<abstract> can be expediently parallelized with appropriate tool support. While automatic parallelization of scientific applications written in traditional sequential languages remains  </abstract>::line_number::19
<abstract> largely impractical, Annai provides users with high-level  </abstract>::line_number::20
<abstract> language extensions and integrated program engineering  </abstract>::line_number::21
<abstract> support tools. In this paper, Annai support is demonstrated primarily focusing on the MG (multigrid) kernel,  </abstract>::line_number::22
<abstract> with complementary examples selected from the other four  </abstract>::line_number::23
<abstract> kernels. Respectable performance and good scalability  </abstract>::line_number::24
<abstract> in most cases are obtained with this straightforward par-allelization strategy, even without recourse to platform-specific optimizations or major program transformations.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Explanations play a key role in operationalization-based anomaly detection techniques. In this paper  </abstract>::line_number::6
<abstract> we show that their role is not limited to anomaly detection; they can also be used for guiding automated  </abstract>::line_number::7
<abstract> knowledge base refinement. We introduce a refinement procedure which takes: (i) a small number of  </abstract>::line_number::8
<abstract> refinement rules (rather than test cases), and (ii) explanations constructed in an attempt to reveal the  </abstract>::line_number::9
<abstract> cause (or causes) for inconsistencies detected during  </abstract>::line_number::10
<abstract> the verification process, and returns rule revisions  </abstract>::line_number::11
<abstract> aiming to recover the consistency of the KB-theory.  </abstract>::line_number::12
<abstract> Inconsistencies caused by more than one anomaly  </abstract>::line_number::13
<abstract> are handled at the same time, which improves the  </abstract>::line_number::14
<abstract> efficiency of the refinement process.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::10
<abstract> In this paper, syntactic parsing is discussed in the context of connectionism. A new model - the Confluent  </abstract>::line_number::11
<abstract> Preorder Parser (CPP), is proposed which exemplifies the holistic parsing paradigm. Holistic parsing has the  </abstract>::line_number::12
<abstract> advantage that little assumption has to be made concerning the detailed parsing algorithm, which is often  </abstract>::line_number::13
<abstract> unknown or debatable, especially when human language understanding is concerned. In the CPP, syntactic  </abstract>::line_number::14
<abstract> parsing is achieved by transforming in a oneshot manner, from the connectionist representation of the sentence  </abstract>::line_number::15
<abstract> to the connectionist representation of the preorder traversal of its parse tree, instead of the parse tree itself. As  </abstract>::line_number::16
<abstract> revealed by the simulation experiments, generalization performance is excellent (as high as 90%). Besides, the  </abstract>::line_number::17
<abstract> CPP is also capable of parsing erroneous sentences and resolving syntactic ambiguities. A systematic study is  </abstract>::line_number::18
<abstract> conducted to explore the range of factors which can affect the effectiveness of it. This error-recovery capability  </abstract>::line_number::19
<abstract> is especially useful in natural language processing when incomplete or even ungrammatical sentences are to be  </abstract>::line_number::20
<abstract> dealt with.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Situated cognition (SC) claims that knowledge is mostly context-dependent and that symbolic descriptions elicited prior to direct experience are less important than functional units developed via direct  </abstract>::line_number::7
<abstract> experience with the current problem. If this were true, then we would need to modify the knowledge  </abstract>::line_number::8
<abstract> modeling approaches of KA which assume that re-using old symbolic descriptions are a productivity tool  </abstract>::line_number::9
<abstract> for new applications. There are numerous tools which, if added to conventional knowledge modeling,  </abstract>::line_number::10
<abstract> could be said to handle SC (e.g. machine learning, abduction, verification & validation tools, repertory  </abstract>::line_number::11
<abstract> grids, certain frameworks for decision support systems, expert critiquing systems, and ripple-down-rules).  </abstract>::line_number::12
<abstract> However, we require an experiment to assess the effectiveness of these tools as a response to SC.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::12
<abstract> This paper presents Splice, a batch meta-learning system, designed to learn locally stable concepts in domains with hidden changes  </abstract>::line_number::13
<abstract> in context. The majority of machine learning  </abstract>::line_number::14
<abstract> algorithms assume that target concepts remain stable over time. In many domains this  </abstract>::line_number::15
<abstract> assumption is invalid. For example, financial prediction, medical diagnosis, and network performance are domains in which target concepts may not remain stable. Unstable target concepts are often due to changes  </abstract>::line_number::16
<abstract> in a hidden context. Existing works on learning in the presence of hidden changes in con  </abstract>::line_number::17
<abstract> text use an incremental learning approach.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::17
<abstract> We analyze differences between two  </abstract>::line_number::18
<abstract> information-theoretically motivated approaches to statistical inference and model  </abstract>::line_number::19
<abstract> selection: the Minimum Description Length  </abstract>::line_number::20
<abstract> (MDL) principle, and the Minimum Message  </abstract>::line_number::21
<abstract> Length (MML) principle. Based on this  </abstract>::line_number::22
<abstract> analysis, we present two revised versions of  </abstract>::line_number::23
<abstract> MML: a pointwise estimator which gives  </abstract>::line_number::24
<abstract> the MML-optimal single parameter model,  </abstract>::line_number::25
<abstract> and a volumewise estimator which gives  </abstract>::line_number::26
<abstract> the MML-optimal region in the parameter  </abstract>::line_number::27
<abstract> space. Our empirical results suggest that  </abstract>::line_number::28
<abstract> with small data sets, the MDL approach  </abstract>::line_number::29
<abstract> yields more accurate predictions than the  </abstract>::line_number::30
<abstract> MML estimators. The empirical results  </abstract>::line_number::31
<abstract> also demonstrate that the revised MML  </abstract>::line_number::32
<abstract> estimators introduced here perform better  </abstract>::line_number::33
<abstract> than the original MML estimator suggested  </abstract>::line_number::34
<abstract> by Wallace and Freeman.   </abstract>::line_number::35
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The graph topo-visual formalism has been shown to  </abstract>::line_number::9
<abstract> be well-suited to the task of visualizing complex relations on a set of elements. Unfortunately, most visual  </abstract>::line_number::10
<abstract> formalisms do not scale very well. This observation is  </abstract>::line_number::11
<abstract> particularly true of graphs, which even when hand-drawn  </abstract>::line_number::12
<abstract> by an artist, are seldom meaningful when the number of  </abstract>::line_number::13
<abstract> nodes or links exceeds a very modest threshold typically only a few hundred elements. This severe limitation  </abstract>::line_number::14
<abstract> has prompted many researchers to seek alternative visualization techniques that may eliminate, or, at the very  </abstract>::line_number::15
<abstract> least, raise this threshold.  </abstract>::line_number::16
<abstract> In this paper we analyze these recent efforts, describe  </abstract>::line_number::17
<abstract> an abstract space of presentation emphasis techniques,  </abstract>::line_number::18
<abstract> and locate the current approaches within this space. The  </abstract>::line_number::19
<abstract> contributions of this paper are several: (1) a significant  </abstract>::line_number::20
<abstract> portion of recent work is collected and reviewed; (2) a  </abstract>::line_number::21
<abstract> common set of criteria and a taxonomy of graph views  </abstract>::line_number::22
<abstract> are proposed; these, (3) permit a more direct comparison  </abstract>::line_number::23
<abstract> of previous work; which helps to, (4) identify common  </abstract>::line_number::24
<abstract> shortcomings and limitations; which in turn, (5) suggest  </abstract>::line_number::25
<abstract> future directions.   </abstract>::line_number::26
<abstract>  Abstract. Evolving algebras (EAs) as defined by Yuri Gurevich constitute the basis of a powerful and elegant specification and verification  </abstract>::line_number::6
<abstract> method which has successfully been applied to the design and analysis of  </abstract>::line_number::7
<abstract> various kinds of discrete dynamic systems. Aiming at the development  </abstract>::line_number::8
<abstract> of a comprehensive EA-based specification and design environment, we  </abstract>::line_number::9
<abstract> introduce the concept of an evolving algebra abstract machine (EAM ) as  </abstract>::line_number::10
<abstract> a platform for the systematic development of EA tools; for instance, as  </abstract>::line_number::11
<abstract> required for machine based analysis and execution of EA specifications.  </abstract>::line_number::12
<abstract> We give a formal definition of the EAM ground model in terms of a  </abstract>::line_number::13
<abstract> universal evolving algebra, where we validate the correctness of the relation between evolving algebras (their theoretical foundations) and their  </abstract>::line_number::14
<abstract> EAM representation and interpretation. Our approach covers sequential  </abstract>::line_number::15
<abstract> as well as distributed evolving algebras.   </abstract>::line_number::16
<abstract>  Abstract. We provide concise abstract code for running the Java Virtual Machine (JVM) to execute compiled Java programs, and define a  </abstract>::line_number::7
<abstract> general compilation scheme of Java programs to JVM code. These definitions, together with the definition of an abstract interpreter of Java  </abstract>::line_number::8
<abstract> programs given in our previous work [3], allow us to prove that any  </abstract>::line_number::9
<abstract> compiler that satisfies the conditions stated in this paper compiles Java  </abstract>::line_number::10
<abstract> code correctly. In addition we have validated our JVM and compiler  </abstract>::line_number::11
<abstract> specification through experimentation.  </abstract>::line_number::12
<abstract> The modularity of our definitions for Java, the JVM and the compilation  </abstract>::line_number::13
<abstract> scheme exhibit orthogonal language, machine and compiler components,  </abstract>::line_number::14
<abstract> which fit together and provide the basis for a stepwise and provably correct design-for-reuse. As a by-product we provide a challenging realistic  </abstract>::line_number::15
<abstract> case study for mechanical verification of a compiler correctness proof.   </abstract>::line_number::16
<abstract>  Abstract. We use the steam boiler control specification problem to illustrate how the evolving algebra approach to the specification and the  </abstract>::line_number::10
<abstract> verification of complex systems can be exploited for a reliable and well  </abstract>::line_number::11
<abstract> documented development of executable, but formally inspectable and  </abstract>::line_number::12
<abstract> systematically modifiable code. A hierarchy of stepwise refined abstract  </abstract>::line_number::13
<abstract> machine models is developed, the ground version of which can be checked  </abstract>::line_number::14
<abstract> for whether it faithfully reflects the informally given problem. The sequence of machine models yields various abstract views of the system,  </abstract>::line_number::15
<abstract> making the various design decisions transparent, and leads to a C++  </abstract>::line_number::16
<abstract> program. This program has been demonstrated during the Dagstuhl-Meeting on Methods for Semantics and Specification, in June 1995, to  </abstract>::line_number::17
<abstract> control the Karlsruhe steam boiler simulator satisfactorily.  </abstract>::line_number::18
<abstract> The abstract machines are evolving algebras and thereby have a rigorous  </abstract>::line_number::19
<abstract> semantical foundation, allowing us to formalize and prove, under precisely stated assumptions, some typical sample properties of the system.  </abstract>::line_number::20
<abstract> This provides insight into the structure of the system which supports  </abstract>::line_number::21
<abstract> easily maintainable extensions and modifications of both the abstract  </abstract>::line_number::22
<abstract> specification and the implementation.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Drawing on on our work in the area of Distributed Artificial Intelligence, we propose the rudiments of a view of multiagent reasoning that relates current philosophical  </abstract>::line_number::9
<abstract> intuitions, theoretical foundations, and preliminary implementation. The philosophical  </abstract>::line_number::10
<abstract> position we take is a combination of Daniel Dennett's philosophy of the ladder of per-sonhood (consisting of rationality, intentionality, stance, reciprocity, communication,  </abstract>::line_number::11
<abstract> and consciousness) on one hand, and the utilitarian philosophy of selfish utility maximization on the other hand. The theories we incorporate are logics of knowledge and  </abstract>::line_number::12
<abstract> belief, which in addressing the multiagent issues can be developed based on a recursive  </abstract>::line_number::13
<abstract> version of the Kripke structure, and the related fields of utility, decision and game  </abstract>::line_number::14
<abstract> theories. Our preliminary implementation, the Recursive Modeling Method (RMM),  </abstract>::line_number::15
<abstract> lets an agent coordinate its actions with the actions of other agents, cooperate with  </abstract>::line_number::16
<abstract> them when appropriate, and rationally choose an optimal form of communication with  </abstract>::line_number::17
<abstract> them.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::10
<abstract> Plan recognition is the process of observing another agent's behavior(s) and inferring what, and  </abstract>::line_number::11
<abstract> possibly why, the agent is acting as it is. Plan recognition becomes a very important means of acquiring  </abstract>::line_number::12
<abstract> such information about other agents in situations and domains where explicit communication is either  </abstract>::line_number::13
<abstract> very costly, dangerous, or impossible. Performing plan recognition in a physical domain (i.e. the real  </abstract>::line_number::14
<abstract> world) forces the world's ubiquitous uncertainty upon the observing agent because of the necessity to  </abstract>::line_number::15
<abstract> use real sensors to make the observations. We have developed a multiple resolution, hierarchical plan  </abstract>::line_number::16
<abstract> recognition system to coordinate the motion of two interacting mobile robots. Uncertainty arises in the  </abstract>::line_number::17
<abstract> system from dead reckoning errors that accumulate while the robots are moving, as well as by errors  </abstract>::line_number::18
<abstract> in the computer vision system that is used to detect the other agent's behaviors. Based upon belief  </abstract>::line_number::19
<abstract> networks, the plan recognition system gracefully degrades in performance as the level of uncertainty  </abstract>::line_number::20
<abstract> about observations increase.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We describe a flexible experimental testbed, called MICE, for distributed artificial intelligence  </abstract>::line_number::8
<abstract> research. We argue that the adoption of MICE (or some other standard testbed) by the distributed  </abstract>::line_number::9
<abstract> artificial intelligence community can draw together the community and permit a much greater level  </abstract>::line_number::10
<abstract> of exchange of ideas, formalisms, and techniques. MICE allows an experimenter to specify the  </abstract>::line_number::11
<abstract> constraints and characteristics of an environment in which agents are simulated to act and interact,  </abstract>::line_number::12
<abstract> and does not assume any particular implementation of an agent's reasoning architecture. MICE  </abstract>::line_number::13
<abstract> therefore provides a platform for investigating and evaluating alternative reasoning architectures  </abstract>::line_number::14
<abstract> and coordination mechanisms in many different simulated environments. We outline the design  </abstract>::line_number::15
<abstract> of MICE and illustrate its flexibility by describing simulated environments that model the coordination issues in domains such as predators chasing prey, predators attacking each other, agents  </abstract>::line_number::16
<abstract> fighting a fire, and diverse robots that are working together. In addition, we note that MICE's  </abstract>::line_number::17
<abstract> ability to simulate multi-agent environments makes it an ideal platform for studying reasoning in  </abstract>::line_number::18
<abstract> dynamic worlds; we can associate functionality to arbitrary objects in order to trigger changes in  </abstract>::line_number::19
<abstract> the environment. We conclude by discussing the status of MICE and how we are using MICE in  </abstract>::line_number::20
<abstract> our current research.   </abstract>::line_number::21
<abstract>  ABSTRACT  </abstract>::line_number::4
<abstract> In this paper, a method is introduced for incorporating perfectly registered MRI boundary information into  </abstract>::line_number::5
<abstract> a penalized likelihood emission reconstruction scheme.  </abstract>::line_number::6
<abstract> The boundary curve is modeled as a periodic spline  </abstract>::line_number::7
<abstract> whose coefficients are estimated from the MRI image.  </abstract>::line_number::8
<abstract> The resulting boundary estimate is mapped to a spatially variant set of Gibbs weights. When incorporated into a quadratic roughness penalty, these weights  </abstract>::line_number::9
<abstract> improve emission reconstruction bias/variance performance by preventing smoothing across the estimated  </abstract>::line_number::10
<abstract> boundary.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::10
<abstract> Plan recognition is the process of observing another agent's behavior(s) and inferring what, and  </abstract>::line_number::11
<abstract> possibly why, the agent is acting as it is. Plan recognition becomes a very important means of acquiring  </abstract>::line_number::12
<abstract> such information about other agents in situations and domains where explicit communication is either  </abstract>::line_number::13
<abstract> very costly, dangerous, or impossible. Performing plan recognition in a physical domain (i.e. the real  </abstract>::line_number::14
<abstract> world) forces the world's ubiquitous uncertainty upon the observing agent because of the necessity to  </abstract>::line_number::15
<abstract> use real sensors to make the observations. We have developed a multiple resolution, hierarchical plan  </abstract>::line_number::16
<abstract> recognition system to coordinate the motion of two interacting mobile robots. Uncertainty arises in the  </abstract>::line_number::17
<abstract> system from dead reckoning errors that accumulate while the robots are moving, as well as by errors  </abstract>::line_number::18
<abstract> in the computer vision system that is used to detect the other agent's behaviors. Based upon belief  </abstract>::line_number::19
<abstract> networks, the plan recognition system gracefully degrades in performance as the level of uncertainty  </abstract>::line_number::20
<abstract> about observations increase.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Efficient path computation necessary for route guidance has been identified as one of the key requirements  </abstract>::line_number::10
<abstract> for Intelligent Transportation Systems (ITS) applications. While the current ITS literature has focused on  </abstract>::line_number::11
<abstract> the application of search algorithms (typically, heuristic A* algorithms) to provide for compute-on-demand  </abstract>::line_number::12
<abstract> path finding, we propose an encoded path view approach that precomputes optimal paths. Advantages of  </abstract>::line_number::13
<abstract> our approach include (1) route search is efficient and less dependent on system load, (2) alternative paths  </abstract>::line_number::14
<abstract> are materialized in addition to the optimal paths, simplifying the process of global optimization, (3) the  </abstract>::line_number::15
<abstract> storage overhead is manageable and less than for the full enumeration of all possible paths. In this paper,  </abstract>::line_number::16
<abstract> we present algorithms for incrementally updating the encoded path view structure in response to weight  </abstract>::line_number::17
<abstract> changes on the traffic links of the underlying network. Despite non-optimal paths also being materialized, our  </abstract>::line_number::18
<abstract> algorithms are designed to operate on cyclic planar graphs | given that ITS maps typically correspond to  </abstract>::line_number::19
<abstract> highly interconnected grid structures. In this paper, we show that while our approach does not encode all  </abstract>::line_number::20
<abstract> paths, it omits some non-optimal paths to resolve cycle ambivalence and will recover them once they become  </abstract>::line_number::21
<abstract> optimal. Proofs of correctness and of complexity are also given. We demonstrate the potential of our approach  </abstract>::line_number::22
<abstract> by presenting experimental results of evaluating our approach both on randomly generated as well as on real  </abstract>::line_number::23
<abstract> city map data. Our experiments furthermore compare the proposed approach against more conventional path  </abstract>::line_number::24
<abstract> searching algorithms, which correspond to the state-of-the-art for route guidance in ITS.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Efficient path query processing necessary for route guidance has been identified as one of the key requirements  </abstract>::line_number::7
<abstract> for Intelligent Transportation Systems (ITS) applications.  </abstract>::line_number::8
<abstract> While precomputing the view of all shortest paths provides  </abstract>::line_number::9
<abstract> the most efficient path retrieval, the view maintenance and  </abstract>::line_number::10
<abstract> storage costs become unrealistic for large ITS networks. Based  </abstract>::line_number::11
<abstract> on ITS road type classification, we propose a hierarchical  </abstract>::line_number::12
<abstract> path view approach, in which the path view maintenance  </abstract>::line_number::13
<abstract> and storage costs are dramatically reduced at the cost of  </abstract>::line_number::14
<abstract> negligible loss of path optimality. Comparing with the traditional ITS path finding approaches that use A or hierarchical A , our hierarchical approach is superior in three  </abstract>::line_number::15
<abstract> areas: 1) path search is more efficient, 2) the connecting  </abstract>::line_number::16
<abstract> point from the low-level roads to the high-level roads and  </abstract>::line_number::17
<abstract> vice versa are dynamically determined based on the most  </abstract>::line_number::18
<abstract> recent traffic, 3) within one region, the high-level traffic can  </abstract>::line_number::19
<abstract> be dynamically rerouted through the low-level roads. In  </abstract>::line_number::20
<abstract> this paper, we conduct experiments to gain insight into the  </abstract>::line_number::21
<abstract> performance of our proposed algorithms and model, as well  </abstract>::line_number::22
<abstract> as to contrast the difference in computational resource requirements between the hierarchical path view and the A   </abstract>::line_number::23
<abstract> algorithms.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::11
<abstract> Efficient path query processing is a key requirement for advanced  </abstract>::line_number::12
<abstract> database applications including GIS (Geographic Information Systems) and ITS (Intelligent Transportation Systems). We study the  </abstract>::line_number::13
<abstract> problem in the context of automobile navigation systems where a  </abstract>::line_number::14
<abstract> large number of path requests can be submitted over the transportation network within a short period of time. To guarantee efficient re-sponsefor path queries, we employ a path view materialization strategy for precomputing the best paths. We tackle the following three  </abstract>::line_number::15
<abstract> issues: (1) memory-resident solutions quickly exceed current computer storage capacity for networks of thousands of nodes, (2) disk-based solutions have been found inefficient to meet the stringent  </abstract>::line_number::16
<abstract> performance requirements, and (3) path views become too costly  </abstract>::line_number::17
<abstract> to update for large graphs. We propose the HEP V (Hierarchical  </abstract>::line_number::18
<abstract> Encoded Path View) approach that addresses these problems while  </abstract>::line_number::19
<abstract> guaranteeing the optimality of path retrieval. Our experimental results reveal that HEP V is more efficient than previously known  </abstract>::line_number::20
<abstract> path finding approaches.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We examine a standard factory scheduling  </abstract>::line_number::10
<abstract> problem with stochastic processing and setup  </abstract>::line_number::11
<abstract> times, minimizing the expectation of the  </abstract>::line_number::12
<abstract> weighted number of tardy jobs. Because  </abstract>::line_number::13
<abstract> the costs of operators in the schedule are  </abstract>::line_number::14
<abstract> stochastic and sequence dependent, standard  </abstract>::line_number::15
<abstract> dynamic programming algorithms such as  </abstract>::line_number::16
<abstract> A* may fail to find the optimal schedule.  </abstract>::line_number::17
<abstract> The SDA* (Stochastic Dominance A*) algorithm remedies this difficulty by relaxing the  </abstract>::line_number::18
<abstract> pruning condition. We present an improved  </abstract>::line_number::19
<abstract> state-space search formulation for these problems and discuss the conditions under which  </abstract>::line_number::20
<abstract> stochastic scheduling problems can be solved  </abstract>::line_number::21
<abstract> optimally using SDA*. In empirical testing  </abstract>::line_number::22
<abstract> on randomly generated problems, we found  </abstract>::line_number::23
<abstract> that in 70%, the expected cost of the optimal stochastic solution is lower than that of  </abstract>::line_number::24
<abstract> the solution derived using a deterministic ap  </abstract>::line_number::25
<abstract> proximation, with comparable search effort.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Concept hierarchies organize data and concepts in hierarchical forms or in certain partial order, which  </abstract>::line_number::8
<abstract> helps expressing knowledge and data relationships in databases in concise, high level terms, and thus, plays  </abstract>::line_number::9
<abstract> an important role in knowledge discovery processes. Concept hierarchies could be provided by knowledge  </abstract>::line_number::10
<abstract> engineers, domain experts or users, or embedded in some data relations. However, it is sometimes desirable to automatically generate some concept hierarchies or adjust some given hierarchies for particular  </abstract>::line_number::11
<abstract> learning tasks. In this paper, the issues of dynamic generation and refinement of concept hierarchies are  </abstract>::line_number::12
<abstract> studied. The study leads to some algorithms for automatic generation of concept hierarchies for numerical attributes based on data distributions and for dynamic refinement of a given or generated concept  </abstract>::line_number::13
<abstract> hierarchy based on a learning request, the relevant set of data and database statistics. These algorithms  </abstract>::line_number::14
<abstract> have been implemented in the DBLearn knowledge discovery system and tested against large relational  </abstract>::line_number::15
<abstract> databases. The experimental results show that the algorithms are efficient and effective for knowledge  </abstract>::line_number::16
<abstract> discovery in large databases.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::7
<abstract> When autonomous agents attempt to coordinate action, it is often necessary that they reach  </abstract>::line_number::8
<abstract> some kind of consensus. Reaching consensus  </abstract>::line_number::9
<abstract> has traditionally been dealt with in the Distributed Artificial Intelligence literature via negotiation. Another alternative is to have agents  </abstract>::line_number::10
<abstract> use a voting mechanism; each agent expresses  </abstract>::line_number::11
<abstract> its preferences, and a group choice mechanism  </abstract>::line_number::12
<abstract> is used to select the result. Some choice mechanisms are better than others, and ideally we  </abstract>::line_number::13
<abstract> would like one that cannot be manipulated by  </abstract>::line_number::14
<abstract> untruthful agents.  </abstract>::line_number::15
<abstract> Coordination of actions by a group of agents  </abstract>::line_number::16
<abstract> corresponds to a group planning process. We  </abstract>::line_number::17
<abstract> here introduce a new multi-agent planning  </abstract>::line_number::18
<abstract> technique, that makes use of a dynamic, iterative search procedure. Through a process of  </abstract>::line_number::19
<abstract> group constraint aggregation, agents incrementally construct a plan that brings the group to  </abstract>::line_number::20
<abstract> a state maximizing social welfare. At each step,  </abstract>::line_number::21
<abstract> agents vote about the next joint action in the  </abstract>::line_number::22
<abstract> group plan (i.e., what the next transition state  </abstract>::line_number::23
<abstract> will be in the emerging plan). Using this technique agents need not fully reveal their preferences, and the set of alternative final states  </abstract>::line_number::24
<abstract> need not be generated in advance of a vote.  </abstract>::line_number::25
<abstract> With a minor variation, the entire procedure  </abstract>::line_number::26
<abstract> can be made resistant to untruthful agents.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Formal technical review (FTR) is an essential component of all modern software quality assessment, assurance,  </abstract>::line_number::9
<abstract> and improvement techniques, and is acknowledged to be  </abstract>::line_number::10
<abstract> the most cost-effective form of quality improvement when  </abstract>::line_number::11
<abstract> practiced effectively. However, traditional FTR methods  </abstract>::line_number::12
<abstract> such as inspection are very difficult to adopt in organizations: they introduce substantial new up-front costs,  </abstract>::line_number::13
<abstract> training, overhead, and group process obstacles. Sustained commitment from high-level management along  </abstract>::line_number::14
<abstract> with substantial resources is often necessary for successful  </abstract>::line_number::15
<abstract> technology transfer of FTR.  </abstract>::line_number::16
<abstract> Since 1991, we have been designing and evaluating  </abstract>::line_number::17
<abstract> a series of versions of a system called CSRS: an instrumented, computer-supported cooperative work environment for formal technical review. The current version of  </abstract>::line_number::18
<abstract> CSRS includes an FTR method definition language, which  </abstract>::line_number::19
<abstract> allows organizations to design their own FTR method,  </abstract>::line_number::20
<abstract> and to evolve it over time. This paper describes how our  </abstract>::line_number::21
<abstract> approach to computer supported FTR can address some  </abstract>::line_number::22
<abstract> of the issues in technology transfer of FTR.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::12
<abstract> Current collaborative learning systems focus on maximizing shared information.  </abstract>::line_number::13
<abstract> However, meaningful learning is not simply information sharing but also knowledge  </abstract>::line_number::14
<abstract> construction. CLARE is a computer-supported learning environment that facilitates  </abstract>::line_number::15
<abstract> meaningful learning through collaborative knowledge construction. It provides a semiformal representation language called RESRA and an explicit process model called  </abstract>::line_number::16
<abstract> SECAI. Experimental evaluation through 300 hours of classroom usage indicates that  </abstract>::line_number::17
<abstract> CLARE does support meaningful learning. It also shows that a major bottleneck to  </abstract>::line_number::18
<abstract> computer-mediated knowledge construction is summarization. Lessons learned through  </abstract>::line_number::19
<abstract> the design and evaluation of CLARE provide new insights into both collaborative learning  </abstract>::line_number::20
<abstract> systems and collaborative learning theories.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The algebraic structure of combinatory differential fields is constructed to provide a semantics for computations in analysis. In this setting programs, approximations, limits and operations of analysis are represented  </abstract>::line_number::8
<abstract> as algebraic terms. Analytic algorithms can be derived by algebraic methods. The main tool in this construction are combinatory models which are inner algebras of Engeler graph models. As an universal domain  </abstract>::line_number::9
<abstract> of denotational semantics the lattice structure of the graph models allows to give a striking simple semantics  </abstract>::line_number::10
<abstract> for computations with approximations. As models of combinatory algebra they provide all essential computational constructs, including recursion. Combinatory models are constructed as extensions of first order  </abstract>::line_number::11
<abstract> theories. The classical first order theory to describe analysis is the theory of differential fields. It turns out  </abstract>::line_number::12
<abstract> that two types of computational constructs, namely composition and piecewise definition of functions, are  </abstract>::line_number::13
<abstract> preferably introduced as extensions of the differential fields theory. Combinatory differential fields are then  </abstract>::line_number::14
<abstract> the combinatory models of these enriched differential fields. We show for basic algorithms of computational  </abstract>::line_number::15
<abstract> analysis how their combinatory counterparts are derived in the algebraic setting. We illustrate how these  </abstract>::line_number::16
<abstract> algorithms are suitable to be implemented in a computer algebra environment like mathematica.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper attempts to exemplify the advantages of perceptually grounded semantics with respect to traditional formalist approaches in elucidating the nature of the  </abstract>::line_number::7
<abstract> controversial notion of linguistic polysemy, or multiplicity of meaning. It is also suggested how some aspects of language typically associated with compositionality could  </abstract>::line_number::8
<abstract> be modeled, without there being a strictly "compositional semantics".  </abstract>::line_number::9
<abstract> This is done through a series of experiments, using modifications of Terry Regier's  </abstract>::line_number::10
<abstract> connectionist system for learning spatial relations [Regier, 1992] which constitutes a  </abstract>::line_number::11
<abstract> part of the L 0 project concerned with associating descriptions in an arbitrary language  </abstract>::line_number::12
<abstract> with an analog environment, (sequences of) pictures of simple 2-dimensional scenes.  </abstract>::line_number::13
<abstract> The emphasis is above all on the English preposition `over', famous for its poly-semy, and analyzed in detail by [Brugman, 1981] and [Lakoff, 1987], but some modeling has been also done of the meaning of `under', as well as some rudimentary  </abstract>::line_number::14
<abstract> semantics for simple verbs such as `be', `go' and `fly' that combine with the two  </abstract>::line_number::15
<abstract> prepositions.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The paper considers the problem of computing a maximal independent set  </abstract>::line_number::10
<abstract> in a hypergraph (see [3] and [7]). We present an efficient deterministic NC  </abstract>::line_number::11
<abstract> algorithm for finding a maximal independent set in a hypergraph of dimension  </abstract>::line_number::12
<abstract> 3: the algorithm runs in time O(log 4 n) time on n + m processors of an  </abstract>::line_number::13
<abstract> EREW PRAM and is optimal up to a polylogarithmic factor. Our algorithm  </abstract>::line_number::14
<abstract> adapts the technique of Goldberg and Spencer ([5]) for finding a maximal  </abstract>::line_number::15
<abstract> independent set in a graph (or hypergraph of dimension 2). It is the first  </abstract>::line_number::16
<abstract> efficient NC algorithm for finding a maximal independent set in a hypergraph  </abstract>::line_number::17
<abstract> of dimension greater than 2.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::13
<abstract> We present algorithms for the randomized simulation of a shared memory machine  </abstract>::line_number::14
<abstract> (PRAM) on a Distributed Memory Machine (DMM). In a PRAM, memory conflicts  </abstract>::line_number::15
<abstract> occur only through concurrent access to the same cell, whereas the memory of a  </abstract>::line_number::16
<abstract> DMM is divided into modules, one for each processor, and concurrent accesses to  </abstract>::line_number::17
<abstract> the same module create a conflict. The delay of a simulation is the time needed to  </abstract>::line_number::18
<abstract> simulate a parallel memory access of the PRAM. Any general simulation of an m  </abstract>::line_number::19
<abstract> processor PRAM on a n processor DMM will necessarily have delay at least m=n. A  </abstract>::line_number::20
<abstract> randomized simulation is called time-processor optimal if the delay is O(m=n) with  </abstract>::line_number::21
<abstract> high probability. Using a novel simulation scheme based on hashing we obtain a  </abstract>::line_number::22
<abstract> time-processor optimal simulation with delay O(loglog(n)log (n)). The best previous  </abstract>::line_number::23
<abstract> simulations use a simpler scheme based on hashing and have much larger delay:  </abstract>::line_number::24
<abstract> fi(log(n)= loglog(n)) for the simulation of an n processor PRAM on an n processor  </abstract>::line_number::25
<abstract> DMM, and fi(log(n)) in the case where the simulation is time-processor optimal.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We present a compositional model of paper transportation in a photocopier that is meant to  </abstract>::line_number::6
<abstract> support different problem solving tasks like simulation and diagnosis, and to be applicable to  </abstract>::line_number::7
<abstract> a variety of configurations. Therefore, we try to avoid making hard-wired implicit assumptions  </abstract>::line_number::8
<abstract> about design principles and possible scenarios. In order to simplify our analysis, the model  </abstract>::line_number::9
<abstract> abstracts away from the physical forces and reasons only about velocities. Nonetheless, it  </abstract>::line_number::10
<abstract> succeeds in determining essential features of the motion of the sheet of paper like buckling  </abstract>::line_number::11
<abstract> and tearing. The framework provided is quite generic and can be used as a starting point for  </abstract>::line_number::12
<abstract> developing models of other transportation domains.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We study the problem of sorting on a parallel computer with limited communication  </abstract>::line_number::6
<abstract> bandwidth. By using the recently proposed PRAM(m) model, where p processors  </abstract>::line_number::7
<abstract> communicate through a small, globally shared memory consisting of m bits, we focus  </abstract>::line_number::8
<abstract> on the trade-off between the amount of local computation and the amount of inter-processor communication required for parallel sorting algorithms. We prove a lower  </abstract>::line_number::9
<abstract> bound of ( n log m  </abstract>::line_number::10
<abstract> m ) on the time to sort n numbers in an exclusive-read variant of  </abstract>::line_number::11
<abstract> the PRAM(m) model. We show that Leighton's Columnsort can be used to give  </abstract>::line_number::12
<abstract> an asymptotically matching upper bound in the case where m grows as a fractional  </abstract>::line_number::13
<abstract> power of n. The bounds are of a surprising form, in that they have little dependence  </abstract>::line_number::14
<abstract> on the parameter p. This implies that attempting to distribute the workload across  </abstract>::line_number::15
<abstract> more processors while holding the problem size and the size of the shared memory  </abstract>::line_number::16
<abstract> fixed will not improve the optimal running time of sorting in this model. We also  </abstract>::line_number::17
<abstract> show that both the upper and the lower bound can be adapted to bridging models  </abstract>::line_number::18
<abstract> that address the issue of limited communication bandwidth: the LogP model and  </abstract>::line_number::19
<abstract> the BSP model. The lower bounds provide convincing evidence that efficient parallel  </abstract>::line_number::20
<abstract> algorithms for sorting rely strongly on high communication bandwidth.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The burstiness of variable bit rate traffic makes it difficult to both efficiently utilize network resources and provide end-to-end network performance guarantees to the traffic sources.  </abstract>::line_number::8
<abstract> Generally, smoothing or shaping traffic sources at the entrance of the network reduces their  </abstract>::line_number::9
<abstract> burstiness to allow higher utilization within the network. However, this buffering introduces  </abstract>::line_number::10
<abstract> an additional delay so that, in effect, lossless smoothing trades queueing delay inside the  </abstract>::line_number::11
<abstract> network for smoothing delay at the network edge. In this paper, we consider the net effect  </abstract>::line_number::12
<abstract> of smoothing on end-to-end performance guarantees where a no-loss, no-delay-violation deterministic guarantee is provided with the D-BIND traffic model. We analytically quantify  </abstract>::line_number::13
<abstract> these tradeoffs and provide a set of general rules for determining under which conditions  </abstract>::line_number::14
<abstract> smoothing provides a net gain. We also empirically investigate these tradeoffs using traces  </abstract>::line_number::15
<abstract> of MPEG compressed video.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> A result of Roquette [3] states that if D is an absolutely irreducible representation  </abstract>::line_number::9
<abstract> of a p-group G over the field of complex numbers, then D can be realized in K((g) j  </abstract>::line_number::10
<abstract> g 2 G), where is the character of D and K = Q or K = Q(i) according to whether  </abstract>::line_number::11
<abstract> p 6= 2 or p = 2. Based on Baum and Clausen's [1] algorithm for computing the  </abstract>::line_number::12
<abstract> irreducible representations of supersolvable groups, we give an elementary proof of a  </abstract>::line_number::13
<abstract> theorem which, among other well-known facts on representations of p-groups, implies  </abstract>::line_number::14
<abstract> Roquette's result.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::13
<abstract> For slotted networks carrying full multi-media traffic to work successfully, it is essential that connection setup and management is done well under all traffic conditions.  </abstract>::line_number::14
<abstract> Major challenges remain with the current state of the technology, however, particularly on how one copes with traffic bursts. Existing reservation-based networks do not  </abstract>::line_number::15
<abstract> allow the user to dynamically adjust his bandwidth requirements on demand. In this  </abstract>::line_number::16
<abstract> paper we propose a new scheme, called the reservoir scheme, which allows dynamic  </abstract>::line_number::17
<abstract> and distributed resource allocation. The basic idea behind the scheme is to reserve  </abstract>::line_number::18
<abstract> bandwidth with a guaranteed bit rate for each virtual circuit. The user is allowed to  </abstract>::line_number::19
<abstract> decentrally allocate additional bandwidth from an Available Bit Rate (ABR) reservoir to satisfy dynamic changes of Variable Bit Rate (VBR) traffic. The duration and  </abstract>::line_number::20
<abstract> bandwidth of this dynamic access are negotiated in the call setup phase and do not  </abstract>::line_number::21
<abstract> require any renegotiation with the service provider so that this solution overcomes the  </abstract>::line_number::22
<abstract> rigidity of current static bandwidth reservation schemes. The additional management  </abstract>::line_number::23
<abstract> requirements are low compared to other dynamic bandwidth reservation schemes. We  </abstract>::line_number::24
<abstract> also describe an analytic model and simulation which we used to determine whether  </abstract>::line_number::25
<abstract> it would be practical to apply the proposed scheme in a slotted network.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::12
<abstract> We determine the computational complexity of deciding whether m polynomials in n variables have relatively prime leading terms with respect to some  </abstract>::line_number::13
<abstract> term order. This problem is NP-complete in general, but solvable in polynomial time for m fixed and for nm fixed. Our new algorithm for the latter case  </abstract>::line_number::14
<abstract> determines a candidate set of leading terms by solving a maximum matching  </abstract>::line_number::15
<abstract> problem. This reduces the problem to linear programming.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Technological progress has made providing numerous new services to large number  </abstract>::line_number::8
<abstract> of users possible. Concurrently, we also experience an increased interest in real-time  </abstract>::line_number::9
<abstract> and interactive applications, e. g. teleseminaring, video conferencing and application  </abstract>::line_number::10
<abstract> sharing, in particular, because of the worldwide and decentralized character of today's  </abstract>::line_number::11
<abstract> research and development organizations.  </abstract>::line_number::12
<abstract> The International Computer Science Institute (ICSI) is a participant of the first  </abstract>::line_number::13
<abstract> transatlantic ATM link which is an integral part of the Multimedia Applications  </abstract>::line_number::14
<abstract> on Intercontinental Highways (MAY) Project. Additionally, ICSI is attached to the  </abstract>::line_number::15
<abstract> Bay Area Gigabit Network (BAGNet) providing ATM connectivity at the best-effort  </abstract>::line_number::16
<abstract> basis. Both projects provide platforms to identify the key research and development  </abstract>::line_number::17
<abstract> topics in cooperative real-time communication.  </abstract>::line_number::18
<abstract> The technical report gives a brief introduction to the ATM infrastructure at ICSI and  </abstract>::line_number::19
<abstract> addresses challenging management issues of multimedia applications in such global  </abstract>::line_number::20
<abstract> area ATM networks. We explore three management areas: performance, configuration,  </abstract>::line_number::21
<abstract> and fault management with respect to the user's point of view. Finally, we introduce  </abstract>::line_number::22
<abstract> a management platform and tools we have been developing which help the user to  </abstract>::line_number::23
<abstract> better predict the quality of service provided and to recover from faults occurred in  </abstract>::line_number::24
<abstract> the system or during a transmission.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::7
<abstract> At the International Computer Science Institute (ICSI), there is an ongoing effort  </abstract>::line_number::8
<abstract> to gain experience on ATM and multi-media applications. ICSI is participating in  </abstract>::line_number::9
<abstract> two ATM pilots called Bay Area Gigabit Network (BAGNet) and Multimedia Applications on Intercontinental Highway (MAY). Beside these wide-area trial ICSI's  </abstract>::line_number::10
<abstract> ATM network is used for local multi-media experiments. The ATM environment at  </abstract>::line_number::11
<abstract> ICSI is heterogeneous. Both, local and long distance traffic is based on permanent  </abstract>::line_number::12
<abstract> virtual connections. The management of this environment has often been cumbersome and time-consuming for a number of reasons: The ATM devices have to be  </abstract>::line_number::13
<abstract> accessed separately in an unintegrated manner. Different vendor-specific tools with  </abstract>::line_number::14
<abstract> different user interfaces are used. Configuration data is stored unstructured, redundant and not centralized. Users cannot setup or verify a connection without knowing  </abstract>::line_number::15
<abstract> device-specific details. Hence, the need for a software tool arose that can minimize the  </abstract>::line_number::16
<abstract> administrative work spent on connection management. This technical report contains  </abstract>::line_number::17
<abstract> my master's thesis which is about the design and implementation of TOMCAD a  </abstract>::line_number::18
<abstract> tool for monitoring and configuration of ATM devices. Being a web-based software  </abstract>::line_number::19
<abstract> tool it can support local and wide-area connectivity and provide access for local and  </abstract>::line_number::20
<abstract> remote users.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We consider the problem of scheduling permanent jobs on related machines in an  </abstract>::line_number::8
<abstract> on-line fashion. We design a new algorithm that achieves the competitive ratio of 3 +  </abstract>::line_number::9
<abstract> p  </abstract>::line_number::10
<abstract> 8 5:828 for the deterministic version, and 3:31= ln 2:155 4:311 for its randomized  </abstract>::line_number::11
<abstract> variant, improving the previous competitive ratios of 8 and 2e 5:436. We also prove  </abstract>::line_number::12
<abstract> lower bounds of 2:4380 on the competitive ratio of deterministic algorithms and 1:8372  </abstract>::line_number::13
<abstract> on the competitive ratio of randomized algorithms for this problem.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We have introduced concurrency into the framework of Sandewall. The resulting formalism is capable of reasoning about interdependent as well  </abstract>::line_number::8
<abstract> as independent concurrent actions. Following  </abstract>::line_number::9
<abstract> Sandewall's systematical method, we have then  </abstract>::line_number::10
<abstract> applied the entailment criterion PCM to selecting  </abstract>::line_number::11
<abstract> intended models of common sense theories where  </abstract>::line_number::12
<abstract> concurrent actions are allowed, and proved that  </abstract>::line_number::13
<abstract> the criterion leads to only intended models for a  </abstract>::line_number::14
<abstract> subset of such theories.   </abstract>::line_number::15
<abstract>  Abstract. We use simulated soccer to study multiagent learning. Each  </abstract>::line_number::8
<abstract> team's players (agents) share action set and policy but may behave differently due to position-dependent inputs. All agents making up a team  </abstract>::line_number::9
<abstract> are rewarded or punished collectively in case of goals. We conduct simulations with varying team sizes, and compare two learning algorithms:  </abstract>::line_number::10
<abstract> TD-Q learning with linear neural networks (TD-Q) and Probabilistic  </abstract>::line_number::11
<abstract> Incremental Program Evolution (PIPE). TD-Q is based on evaluation  </abstract>::line_number::12
<abstract> functions (EFs) mapping input/action pairs to expected reward, while  </abstract>::line_number::13
<abstract> PIPE searches policy space directly. PIPE uses an adaptive probability  </abstract>::line_number::14
<abstract> distribution to synthesize programs that calculate action probabilities  </abstract>::line_number::15
<abstract> from current inputs. Our results show that TD-Q has difficulties to learn  </abstract>::line_number::16
<abstract> appropriate shared EFs. PIPE, however, does not depend on EFs and  </abstract>::line_number::17
<abstract> finds good policies faster and more reliably.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::13
<abstract> Two key issues for induction algorithms are the accuracy of the learned hypothesis and the computational  </abstract>::line_number::14
<abstract> resources consumed in inducing that hypothesis. One  </abstract>::line_number::15
<abstract> of the most promising ways to improve performance  </abstract>::line_number::16
<abstract> along both dimensions is to make use of additional  </abstract>::line_number::17
<abstract> knowledge. Multi-strategy learning algorithms tackle  </abstract>::line_number::18
<abstract> this problem by employing several strategies for handling different kinds of knowledge in different ways.  </abstract>::line_number::19
<abstract> However, integrating knowledge into an induction algorithm can be difficult when the new knowledge differs significantly from the knowledge the algorithm  </abstract>::line_number::20
<abstract> already uses. In many cases the algorithm must be  </abstract>::line_number::21
<abstract> rewritten.  </abstract>::line_number::22
<abstract> This paper presents KII, a Knowledge Integration  </abstract>::line_number::23
<abstract> framework for Induction, that provides a uniform  </abstract>::line_number::24
<abstract> mechanism for integrating knowledge into induction.  </abstract>::line_number::25
<abstract> In theory, arbitrary knowledge can be integrated with  </abstract>::line_number::26
<abstract> this mechanism, but in practice the knowledge representation language determines both the knowledge  </abstract>::line_number::27
<abstract> that can be integrated, and the costs of integration  </abstract>::line_number::28
<abstract> and induction. By instantiating KII with various set  </abstract>::line_number::29
<abstract> representations, algorithms can be generated at different trade-off points along these dimensions.  </abstract>::line_number::30
<abstract> One instantiation of KII, called RS-KII, is presented  </abstract>::line_number::31
<abstract> that can implement hybrid induction algorithms, depending on which knowledge it utilizes. RS-KII is  </abstract>::line_number::32
<abstract> demonstrated to implement AQ-11 (Michalski 1978),  </abstract>::line_number::33
<abstract> as well as a hybrid algorithm that utilizes a domain  </abstract>::line_number::34
<abstract> theory and noisy examples. Other algorithms are also  </abstract>::line_number::35
<abstract> possible.   </abstract>::line_number::36
<abstract>  Abstract: A Hybrid Intelligent Architecture that aims to exploit the complementary features of  </abstract>::line_number::6
<abstract> expert systems and connectionist architecture, is proposed to revise input characterization and initial  </abstract>::line_number::7
<abstract> domain knowledge. HIA has two building blocks, a Rule-Based module and a Connectionist Architecture  </abstract>::line_number::8
<abstract> module. A specific format for the rule-based description of the initial theory acquired from the application  </abstract>::line_number::9
<abstract> domain enables its mapping into a uniform, three layer network. Continuous inputs are discretized into  </abstract>::line_number::10
<abstract> input vectors using a new coarse coding scheme. An extension of the Backpropagation Algorithm allows  </abstract>::line_number::11
<abstract> refinement of the discretization functions. A successful application to the control of dams on the Colorado  </abstract>::line_number::12
<abstract> river near Austin, is described.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Genetic Programming is applied to the task of  </abstract>::line_number::8
<abstract> evolving general iterative sorting algorithms. A  </abstract>::line_number::9
<abstract> connection between size and generality was discovered. Adding inverse size to the fitness measure along with correctness not only decreases  </abstract>::line_number::10
<abstract> the size of the resulting evolved algorithms, but  </abstract>::line_number::11
<abstract> also dramatically increases their generality and  </abstract>::line_number::12
<abstract> thus the effectiveness of the evolution process. In  </abstract>::line_number::13
<abstract> addition, a variety of differing problem formulations are investigated and the relative probability  </abstract>::line_number::14
<abstract> of success for each is reported. An example of an  </abstract>::line_number::15
<abstract> evolved sort from each problem formulation is  </abstract>::line_number::16
<abstract> presented, and an initial attempt is made to  </abstract>::line_number::17
<abstract> understand the variations in difficulty resulting  </abstract>::line_number::18
<abstract> from these differing problem formulations.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper outlines a methodology for  </abstract>::line_number::8
<abstract> analyzing the representational support  </abstract>::line_number::9
<abstract> for knowledge-based decision-modeling  </abstract>::line_number::10
<abstract> in a broad domain. A relevant set of inference  </abstract>::line_number::11
<abstract> patterns and knowledge types are identified.  </abstract>::line_number::12
<abstract> By comparing the analysis results to existing representations, some insights are gained  </abstract>::line_number::13
<abstract> into a design approach for integrating categorical and uncertain knowledge in a context  </abstract>::line_number::14
<abstract> sensitive manner.   </abstract>::line_number::15
<abstract>  A simple real-time garbage collection algorithm is presented which does not copy, thereby avoiding  </abstract>::line_number::7
<abstract> some of the problems caused by the asynchronous motion of objects. This in-place "treadmill"  </abstract>::line_number::8
<abstract> garbage collection scheme has approximately the same complexity as other nonmoving garbage  </abstract>::line_number::9
<abstract> collectors, thus making it usable in a high-level language implementation where some pointers  </abstract>::line_number::10
<abstract> cannot be traced. The treadmill is currently being used in a Lisp system built in Ada.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Zero temperature Gibbs learning is considered for a connected committee machine  </abstract>::line_number::9
<abstract> with K hidden units. For large K, the scale of the learning curve strongly depends  </abstract>::line_number::10
<abstract> on the target rule. When learning a perceptron, the sample size P needed for optimal  </abstract>::line_number::11
<abstract> generalization scales so that N t P t KN, where N is the dimension of the input.  </abstract>::line_number::12
<abstract> This even holds for a noisy perceptron rule if a new input is classified by the majority  </abstract>::line_number::13
<abstract> vote of all students in the version space. When learning a committee machine with M  </abstract>::line_number::14
<abstract> hidden units, 1 t M t K, optimal generalization requires  </abstract>::line_number::15
<abstract> p   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper describes an efficient optimistic concurrency control  </abstract>::line_number::9
<abstract> scheme for use in distributed database systems in which objects are  </abstract>::line_number::10
<abstract> cached and manipulated at client machines while persistent storage  </abstract>::line_number::11
<abstract> and transactional support are provided by servers. The scheme  </abstract>::line_number::12
<abstract> provides both serializability and external consistency for committed  </abstract>::line_number::13
<abstract> transactions; it uses loosely synchronized clocks to achieve global  </abstract>::line_number::14
<abstract> serialization. It stores only a single version of each object, and  </abstract>::line_number::15
<abstract> avoids maintaining any concurrency control information on a per-  </abstract>::line_number::16
<abstract> object basis; instead, it tracks recent invalidations on a per-client  </abstract>::line_number::17
<abstract> basis, an approach that has low in-memory space overhead and no  </abstract>::line_number::18
<abstract> per-object disk overhead. In addition to its low space overheads,  </abstract>::line_number::19
<abstract> the scheme also performs well. The paper presents a simulation  </abstract>::line_number::20
<abstract> study that compares the scheme to adaptive callback locking, the  </abstract>::line_number::21
<abstract> best concurrency control scheme for client-server object-oriented  </abstract>::line_number::22
<abstract> database systems studied to date. The study shows that our  </abstract>::line_number::23
<abstract> scheme outperforms adaptive callback locking for low to moderate  </abstract>::line_number::24
<abstract> contention workloads, and scales better with the number of clients.  </abstract>::line_number::25
<abstract> For high contention workloads, optimism can result in a high abort  </abstract>::line_number::26
<abstract> rate; the scheme presented here is a first step toward a hybrid scheme  </abstract>::line_number::27
<abstract> that we expect to perform well across the full range of workloads.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::7
<abstract> A non-greedy approach for constructing globally optimal  </abstract>::line_number::8
<abstract> multivariate decision trees with fixed structure is proposed. Previous greedy tree construction algorithms are  </abstract>::line_number::9
<abstract> locally optimal in that they optimize some splitting criterion at each decision node, typically one node at a time.  </abstract>::line_number::10
<abstract> In contrast, global tree optimization explicitly considers  </abstract>::line_number::11
<abstract> all decisions in the tree concurrently. An iterative linear  </abstract>::line_number::12
<abstract> programming algorithm is used to minimize the classification error of the entire tree. Global tree optimization  </abstract>::line_number::13
<abstract> can be used both to construct decision trees initially and  </abstract>::line_number::14
<abstract> to update existing decision trees. Encouraging computational experience is reported.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::12
<abstract> Generating language that reflects the temporal organization of represented knowledge requires a language generation model that integrates contemporary theories of tense and aspect, temporal representations, and methods  </abstract>::line_number::13
<abstract> to plan text. This paper presents a model  </abstract>::line_number::14
<abstract> that produces complex sentences that reflect  </abstract>::line_number::15
<abstract> temporal relations present in underlying temporal concepts. The main result of this work  </abstract>::line_number::16
<abstract> is the successful application of constrained linguistic theories of tense and aspect to a generator which produces meaningful event combinations and selects appropriate connecting words  </abstract>::line_number::17
<abstract> that relate them.   </abstract>::line_number::18
<abstract>  Abstract. In this paper we present one aspect of our research on machine translation (MT):  </abstract>::line_number::7
<abstract> capturing the grammatical and computational relation between (i) the interlingua (IL) as defined  </abstract>::line_number::8
<abstract> declaratively in the lexicon and (ii) the IL as defined procedurally by way of algorithms that  </abstract>::line_number::9
<abstract> compose and decompose pivot IL forms. We begin by examining the interlinguas in the lexicons of  </abstract>::line_number::10
<abstract> a variety of current IL-based approaches to MT. This brief survey makes it clear that no consensus  </abstract>::line_number::11
<abstract> exists among MT researchers on the level of representation for defining the IL. In the section that  </abstract>::line_number::12
<abstract> follows, we explore the consequences of this missing formal framework for MT system builders who  </abstract>::line_number::13
<abstract> develop their own lexical-IL entries. The lack of software tools to support rapid IL respecification  </abstract>::line_number::14
<abstract> and testing greatly hampers their ability to modify representations to handle new data and new  </abstract>::line_number::15
<abstract> domains. Our view is that IL-based MT research needs both (a) the formal framework to specify  </abstract>::line_number::16
<abstract> possible IL grammars and (b) the software support tools to implement and test these grammars.  </abstract>::line_number::17
<abstract> With respect to (a), we propose adopting a lexicalized grammar approach, tapping research  </abstract>::line_number::18
<abstract> results from the study of tree grammars for natural language syntax. With respect to (b), we  </abstract>::line_number::19
<abstract> sketch the design and functional specifications for parts of ILustrate, the set of software tools  </abstract>::line_number::20
<abstract> that we need to implement and test the various IL formalisms that meet the requirements of a  </abstract>::line_number::21
<abstract> lexicalized grammar. In this way, we begin to address a basic issue in MT research, how to define  </abstract>::line_number::22
<abstract> and test an interlingua as a computational language | without building a full MT system for  </abstract>::line_number::23
<abstract> each possible IL formalism that might be proposed.   </abstract>::line_number::24
<abstract>  Abstract. This paper presents and evaluates two algorithms for incrementally constructing Radial  </abstract>::line_number::6
<abstract> Basis Function Networks, a class of neural networks which looks more suitable for adtaptive control  </abstract>::line_number::7
<abstract> applications than the more popular backpropagation networks. The first algorithm has been derived  </abstract>::line_number::8
<abstract> by a previous method developed by Fritzke, while the second one has been inspired by the CART  </abstract>::line_number::9
<abstract> algorithm developed by Breiman for generation regression trees. Both algorithms proved to work  </abstract>::line_number::10
<abstract> well on a number of tests and exhibit comparable performances. An evaluation on the standard case  </abstract>::line_number::11
<abstract> study of the Mackey-Glass temporal series is reported.   </abstract>::line_number::12
<abstract>  Abstract. The application of Machine Learning techniques to multimedia and multimodal systems,  </abstract>::line_number::4
<abstract> resp., seems to be a promising approach in order to enhance the systems' capabilities. Especially  </abstract>::line_number::5
<abstract> in multimodal systems which support human-computer interaction (HCI) via several input/output  </abstract>::line_number::6
<abstract> channels in parallel, intelligent mechanisms are needed in order to process the user's inputs and to  </abstract>::line_number::7
<abstract> select the best output modality.  </abstract>::line_number::8
<abstract> In this paper, we will deal with a multi-agent system which introduces some kind of haptic feedback  </abstract>::line_number::9
<abstract> to the user interface. The main task of the system is to predict the next user action in order to launch  </abstract>::line_number::10
<abstract> the haptic feedback selectively and to adapt this capability over time to both, the user's behavior  </abstract>::line_number::11
<abstract> and the application's user interface structure. Therefore, a statistical interaction model is generated  </abstract>::line_number::12
<abstract> and managed based on stochastic classification methods.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::10
<abstract> The problem of scheduling two classes of real-time traffic with correlated time constraints  </abstract>::line_number::11
<abstract> is considered. Three scheduling disciplines are studied: a priority discipline which gives strict  </abstract>::line_number::12
<abstract> priority to one class of traffic, a threshold-based scheme in which priority is given to one class  </abstract>::line_number::13
<abstract> of traffic when the minimum laxity of its queued packets falls below some threshold, and a  </abstract>::line_number::14
<abstract> "balancing" scheme which assigns priority on the basis of the differences in minimum laxities in  </abstract>::line_number::15
<abstract> the two classes of traffic. Analytic results are obtained by using a discrete time model to obtain  </abstract>::line_number::16
<abstract> the state occupancy probabilities for the system. Here, the state is defined using the laxities of  </abstract>::line_number::17
<abstract> the queued real time packets. Parameters are defined to study the tradeoff in the performance  </abstract>::line_number::18
<abstract> of the two classes of traffic. Results are obtained to demonstrate how the balancing scheme  </abstract>::line_number::19
<abstract> permits us to achieve significant improvement in the performance of one class of traffic with  </abstract>::line_number::20
<abstract> only minimal effect on the performance of other class. A video application is suggested for this  </abstract>::line_number::21
<abstract> work.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Real-Time reliable multicast over a best-effort service network remains a challenging research problem. Most  </abstract>::line_number::10
<abstract> protocols for reliable multicast use repair techniques that result in significant and variable delay, which can lead to  </abstract>::line_number::11
<abstract> missed deadlines in real-time scenarios. This paper presents a repair technique that combines forward error correction  </abstract>::line_number::12
<abstract> (FEC) with automatic repeat request (ARQ). The novel aspect of the technique is its ability to reduce delay in reliable  </abstract>::line_number::13
<abstract> multicast delivery by sending repairs proactively (i.e., before they are required). The technique requires minimal  </abstract>::line_number::14
<abstract> state at senders and receivers, and no additional active router functionality beyond what is required by the current  </abstract>::line_number::15
<abstract> multicast service model. Furthermore, the technique uses only end-to-end mechanisms, where all data and repairs are  </abstract>::line_number::16
<abstract> transmitted by the data-originating source, leaving receivers free from any burden of sending repairs. We simulate  </abstract>::line_number::17
<abstract> a simple round-based version of a protocol embodying this technique to show its effectiveness in preventing repair  </abstract>::line_number::18
<abstract> request implosion, reducing the expected time of reliable delivery of data, and keeping bandwidth usage for repairs  </abstract>::line_number::19
<abstract> low. We show how a protocol using the technique can be adapted to provide delivery that is reliable before a real-time  </abstract>::line_number::20
<abstract> deadline with probabilities extremely close to one. Finally, we develop several variations of the protocol that use the  </abstract>::line_number::21
<abstract> technique in various fashions for high rate data streaming applications, and present results from additional simulations  </abstract>::line_number::22
<abstract> that examine performance in a variety of Internet-like heterogeneous networks.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Techniques for avoiding the high memory overheads found on  </abstract>::line_number::6
<abstract> many modern shared-memory multiprocessors are of increasing  </abstract>::line_number::7
<abstract> importance in the development of high-performance multiprocessor protocol implementations. One such technique is processor-cache affinity scheduling, which can significantly lower packet  </abstract>::line_number::8
<abstract> latency and substantially increase protocol processing throughput  </abstract>::line_number::9
<abstract> [20]. In this paper, we evaluate several aspects of the effectiveness of affinity-based scheduling in multiprocessor network  </abstract>::line_number::10
<abstract> protocol processing, under packet-level and connection-level par-allelization approaches. Specifically, we evaluate the performance  </abstract>::line_number::11
<abstract> of the scheduling technique 1) when a large number of streams are  </abstract>::line_number::12
<abstract> concurrently supported, 2) when processing includes copying of  </abstract>::line_number::13
<abstract> uncached packet data, 3) as applied to send-side protocol processing, and 4) in the presence of stream burstiness and source locality, two well-known properties of network traffic. We find that  </abstract>::line_number::14
<abstract> affinity-based scheduling performs well under these conditions,  </abstract>::line_number::15
<abstract> emphasizing its robustness and general effectiveness in multiprocessor network processing. In addition, we explore a technique  </abstract>::line_number::16
<abstract> which improves the caching behavior and available packet-level  </abstract>::line_number::17
<abstract> concurrency under connection-level parallelism, and find performance improves dramatically.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The loss probability of a queueing system provides, in many cases, insufficient information for performance evaluation, for example, of data link layer protocols and applications with forward  </abstract>::line_number::7
<abstract> error correction.  </abstract>::line_number::8
<abstract> This paper evaluates and characterizes the correlation between packet losses for two queueing systems in discrete time  </abstract>::line_number::9
<abstract> that are motivated by BISDN applications. The first, a two-class discrete-time queueing system, approximates the output  </abstract>::line_number::10
<abstract> queue of an ATM switch. The queue serves periodic foreground  </abstract>::line_number::11
<abstract> traffic and random background traffic. The background traffic  </abstract>::line_number::12
<abstract> is modeled as i.i.d. batches of arbitrary distribution. It is shown  </abstract>::line_number::13
<abstract> that the conditional loss probability (CLP) is independent of the  </abstract>::line_number::14
<abstract> buffer size if the buffer size is at least as large as the period of  </abstract>::line_number::15
<abstract> the foreground traffic. Example calculations indicate that losses  </abstract>::line_number::16
<abstract> occur essentially randomly as long as the foreground traffic uses  </abstract>::line_number::17
<abstract> less than 10% of the channel capacity.  </abstract>::line_number::18
<abstract> The second analysis derives the CLP seen by a selected  </abstract>::line_number::19
<abstract> stream in a slotted finite-buffer system with a superposition of  </abstract>::line_number::20
<abstract> interrupted Poisson sources. Here, the total number of arrivals  </abstract>::line_number::21
<abstract> may be correlated from slot to slot. Traffic correlation is seen  </abstract>::line_number::22
<abstract> to have a strong influence on loss correlation, while buffer size  </abstract>::line_number::23
<abstract> is seen to have virtually none.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::8
<abstract> VBR compressed video is known to exhibit significant, multiple-time-scale bit rate variability. In this paper, we consider the transmission of stored video from a server to a client across a  </abstract>::line_number::9
<abstract> high speed network, and explore how the client buffer space can be used most effectively toward  </abstract>::line_number::10
<abstract> reducing the variability of the transmitted bit rate.  </abstract>::line_number::11
<abstract> We present two basic results. First, we show how to achieve the greatest possible reduction in  </abstract>::line_number::12
<abstract> rate variability when sending stored video to a client with given buffer size. We formally establish  </abstract>::line_number::13
<abstract> the optimality of our optimal smoothing approach, and illustrate its performance over a set of  </abstract>::line_number::14
<abstract> long MPEG-1 encoded video traces. Second, we evaluate the impact of optimal smoothing on the  </abstract>::line_number::15
<abstract> network resources needed for video transport, under two network service models: Deterministic  </abstract>::line_number::16
<abstract> Guaranteed service [1, 11] and Renegotiated CBR (RCBR) service [9, 8]. Under both models, we  </abstract>::line_number::17
<abstract> find the impact of optimal smoothing to be dramatic.   </abstract>::line_number::18
<abstract>  Abstract. Domain or background knowledge is often needed in order  </abstract>::line_number::6
<abstract> to solve difficult problems of learning medical diagnostic rules. Earlier  </abstract>::line_number::7
<abstract> experiments have demonstrated the utility of background knowledge  </abstract>::line_number::8
<abstract> when learning rules for early diagnosis of rheumatic diseases. A particular form of background knowledge comprising typical co-occurrences  </abstract>::line_number::9
<abstract> of several groups of attributes was provided by a medical expert. This  </abstract>::line_number::10
<abstract> paper explores the possibility to automate the process of acquiring background knowledge of this kind. A method based on function decomposition is proposed that identifies typical co-occurrences for a given set  </abstract>::line_number::11
<abstract> of attributes. The method is evaluated by comparing the typical co-occurrences it identifies, as well as their contribution to the performance  </abstract>::line_number::12
<abstract> of machine learning algorithms, to the ones provided by a medical expert.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Massively parallel processors have begun using commodity operating systems that support demand-paged  </abstract>::line_number::10
<abstract> virtual memory. To evaluate the utility of virtual  </abstract>::line_number::11
<abstract> memory, we measured the behavior of seven shared-memory parallel application programs on a simulated  </abstract>::line_number::12
<abstract> distributed-shared-memory machine. Our results (i)  </abstract>::line_number::13
<abstract> confirm the importance of gang CPU scheduling, (ii)  </abstract>::line_number::14
<abstract> show that a page-faulting processor should spin rather  </abstract>::line_number::15
<abstract> than invoke a parallel context switch, (iii) show that  </abstract>::line_number::16
<abstract> our parallel programs frequently touch most of their  </abstract>::line_number::17
<abstract> data, and (iv) indicate that memory, not just CPUs,  </abstract>::line_number::18
<abstract> must be "gang scheduled". Overall, our experiments  </abstract>::line_number::19
<abstract> demonstrate that demand paging has limited value  </abstract>::line_number::20
<abstract> on current parallel machines because of the applications' synchronization and memory reference patterns  </abstract>::line_number::21
<abstract> and the machines' high page-fault and parallel-context-switch overheads.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::4
<abstract> This paper describes how a runtime support library can be used as compiler runtime  </abstract>::line_number::5
<abstract> support in irregular applications. The CHAOS runtime support library carries out  </abstract>::line_number::6
<abstract> optimizations designed to reduce communication costs by performing software caching,  </abstract>::line_number::7
<abstract> communication coalescing and inspector/executor preprocessing. CHAOS also supplies  </abstract>::line_number::8
<abstract> special purpose routines to support specific types of irregular reduction and runtime  </abstract>::line_number::9
<abstract> support for partitioning data and work between processors. A number of adaptive  </abstract>::line_number::10
<abstract> irregular codes have been parallelized using the CHAOS library and performance results  </abstract>::line_number::11
<abstract> from these codes are also presented in this paper.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper presents methods that make it possible to efficiently support irregular problems using data  </abstract>::line_number::8
<abstract> parallel languages. The approach involves the use of a portable, compiler-independent, runtime support  </abstract>::line_number::9
<abstract> library called CHAOS. The CHAOS runtime support library contains procedures that  </abstract>::line_number::10
<abstract> * support static and dynamic distributed array partitioning,  </abstract>::line_number::11
<abstract> * partition loop iterations and indirection arrays,  </abstract>::line_number::12
<abstract> * remap arrays from one distribution to another, and  </abstract>::line_number::13
<abstract> * carry out index translation, buffer allocation and communication schedule generation.  </abstract>::line_number::14
<abstract> The CHAOS runtime procedures are used by a prototype Fortran 90D compiler as runtime support for irregular problems. This paper also presents performance results of compiler-generated and  </abstract>::line_number::15
<abstract> hand-parallelized versions of two stripped down applications codes. The first code is derived from  </abstract>::line_number::16
<abstract> an unstructured mesh computational fluid dynamics flow solver and the second is derived from the  </abstract>::line_number::17
<abstract> molecular dynamics code CHARMM.  </abstract>::line_number::18
<abstract> A method is described that makes it possible to emulate irregular distributions in HPF by reordering elements of data arrays and renumbering indirection arrays. The results suggest that an HPF  </abstract>::line_number::19
<abstract> compiler could use reordering and renumbering extrinsic functions to obtain performance comparable  </abstract>::line_number::20
<abstract> to that achieved by a compiler for a language (such as Fortran 90D) that directly supports irregular  </abstract>::line_number::21
<abstract> distributions.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A number of methods are presented for highly efficient calculation  </abstract>::line_number::7
<abstract> of substrate current transport. A three-dimensionalGreen's Function  </abstract>::line_number::8
<abstract> based substrate representation, in combination with the use of the  </abstract>::line_number::9
<abstract> Fast Fourier Transform, significantly speeds up the computation of  </abstract>::line_number::10
<abstract> sensitivities with respect to all parameters associated with a given  </abstract>::line_number::11
<abstract> architecture. Substrate sensitivity analysis is used in a number of  </abstract>::line_number::12
<abstract> physical optimization tools, such as placement and trend analysis for  </abstract>::line_number::13
<abstract> the estimation of the impact of technology migration and/or layout  </abstract>::line_number::14
<abstract> re-design.   </abstract>::line_number::15
<abstract>  Abstract. Interpretation of models induced by artificial neural networks is often a difficult task. In this paper we focus on a relatively  </abstract>::line_number::5
<abstract> novel neural network architecture and learning algorithm, bp-som, that  </abstract>::line_number::6
<abstract> offers possibilities to overcome this difficulty. It is shown that networks  </abstract>::line_number::7
<abstract> trained with bp-som show interesting regularities, in that hidden-unit  </abstract>::line_number::8
<abstract> activations become restricted to discrete values, and that the som part  </abstract>::line_number::9
<abstract> can be exploited for automatic rule extraction.   </abstract>::line_number::10
<abstract>  ABSTRACT  </abstract>::line_number::7
<abstract> This paper presents the overall structure of PAPIA2, a pyramid  </abstract>::line_number::8
<abstract> system belonging to the family of massive parallel machines. It embeds  </abstract>::line_number::9
<abstract> the topology of the quad-pyramid into a highly regular, fault tolerant,  </abstract>::line_number::10
<abstract> eight-connected proces sor array by means of specially reconfigurable  </abstract>::line_number::11
<abstract> near-neighbor interconnections. The system comes with a fully-fledged  </abstract>::line_number::12
<abstract> software environment designed to optimize the use of machine resources.  </abstract>::line_number::13
<abstract> The highly interactive graphic tools help in understanding the machine's  </abstract>::line_number::14
<abstract> capabilities, provide a valuable testbed for the machine instruction set,  </abstract>::line_number::15
<abstract> and offer a suitable context for monitoring program execution.   </abstract>::line_number::16
<abstract>  The paper presents an application of simulated annealing, tabu search and an adapted  </abstract>::line_number::32
<abstract> genetic algorithm to a real world instance of the timetable problem. The computational  </abstract>::line_number::33
<abstract> results obtained are compared and discussed.   </abstract>::line_number::34
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The concept of a fitness formula as a property of an organism is proposed. In  </abstract>::line_number::10
<abstract> artificial life simulations with organisms living in an environment, the fitness formula  </abstract>::line_number::11
<abstract> can be interpreted as the ability of organisms to extract energy from potential food  </abstract>::line_number::12
<abstract> sources distributed in the environment. In simulations where the goal of the genetic  </abstract>::line_number::13
<abstract> algorithm is that of developing systems which exhibit a certain type of behavior in a  </abstract>::line_number::14
<abstract> particular environment, the fitness formula becomes an independent variable which can  </abstract>::line_number::15
<abstract> be manipulated in order to obtain the desired behavior. The fitness formula can be  </abstract>::line_number::16
<abstract> viewed as an evolvable trait of organisms, and therefore not fixed and decided by the  </abstract>::line_number::17
<abstract> researcher. Simulations with fixed and evolvable fitness formulae show that the fitness  </abstract>::line_number::18
<abstract> formula, the sensory apparatus, and the behavior of organisms may co-evolve and be  </abstract>::line_number::19
<abstract> co-adapted.   </abstract>::line_number::20
<abstract>  Abstract: The learning web was presented [Norrie and Gaines, 1995] at EdMedia95  </abstract>::line_number::5
<abstract> as a systemic approach to the modeling and support of knowledge processes in a  </abstract>::line_number::6
<abstract> learning society. This article addresses the rationale for, and systemic foundations of,  </abstract>::line_number::7
<abstract> the learning web, its implications for restructuring the higher education system, and  </abstract>::line_number::8
<abstract> the role of information technology in supporting that restructuring. Two associated  </abstract>::line_number::9
<abstract> articles report on the implementation of some of the technologies necessary to  </abstract>::line_number::10
<abstract> support the learning web [Gaines and Shaw, 1996], and some preliminary experience  </abstract>::line_number::11
<abstract> in applying them in undergraduate education [Shaw and Gaines, 1996].   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper advocates the idea that the physical modularity (file structure) of application components supported by conventional OS environments can be elevated to the level of logical modularity, which in turn  </abstract>::line_number::7
<abstract> can directly support application development in an  </abstract>::line_number::8
<abstract> object-oriented manner. We demonstrate this idea  </abstract>::line_number::9
<abstract> through a system-wide server that manages the manipulation of such components effectively. The server  </abstract>::line_number::10
<abstract> is designed to be a fundamental operating system service responsible for binding and mapping component  </abstract>::line_number::11
<abstract> instances into client address spaces.  </abstract>::line_number::12
<abstract> We show how this model solves some longstanding  </abstract>::line_number::13
<abstract> problems with the management of application components in existing application development environments. We demonstrate that this model's effectiveness derives from its support for the cornerstones of  </abstract>::line_number::14
<abstract> OO programming: classes and their instances, encapsulation, and several forms of inheritance.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In this paper we introduce a general method for Bayesian computing in richly-parameterized  </abstract>::line_number::6
<abstract> models, Structured Markov Chain Monte Carlo (SMCMC), that is based on a blocked hybrid of the  </abstract>::line_number::7
<abstract> Gibbs sampling and Metropolis-Hastings algorithms. SMCMC speeds algorithm convergence by  </abstract>::line_number::8
<abstract> using the structure that is present in the problem to suggest an appropriate Metropolis-Hastings  </abstract>::line_number::9
<abstract> candidate distribution. While the approach is easiest to describe for hierarchical normal linear  </abstract>::line_number::10
<abstract> models, we show its extension to both non-normal and nonlinear cases to be straightforward.  </abstract>::line_number::11
<abstract> After describing the method in detail we compare its performance (both in terms of runtime and  </abstract>::line_number::12
<abstract> autocorrelation in the samples produced) to several other existing methods, including the traditional  </abstract>::line_number::13
<abstract> single-site updating Gibbs sampler available in the popular BUGS software package. Our results  </abstract>::line_number::14
<abstract> suggest significant improvements in convergence for many problems using SMCMC, as well as  </abstract>::line_number::15
<abstract> broad applicability of the method, including previously intractable hierarchical nonlinear model  </abstract>::line_number::16
<abstract> settings.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Most of the solutions proposed to support real-time (i.e. guaranteed performance) communication services in packet-switching networks adopt a connection-oriented and reservation-oriented approach. In such an approach, resource allocation  </abstract>::line_number::9
<abstract> and route selection decisions are made before the start of the communication on the basis of resource availability and real-time network load at that time, and are usually kept for the duration of the communication. This rather static resource  </abstract>::line_number::10
<abstract> management approach has certain limitations: it does not take into account (a) the dynamics of the communicating clients;  </abstract>::line_number::11
<abstract> (b) the dynamics of the network state; and (c) the tradeoff between quality of service and network availability, thus affecting  </abstract>::line_number::12
<abstract> the availability and flexibility of the real-time network services. Availability is the ability of the network to accommodate  </abstract>::line_number::13
<abstract> as many real-time clients as possible, while flexibility is the ability to adapt the real-time services to changing network state  </abstract>::line_number::14
<abstract> and client demands. In this paper, we present the Dynamic Connection Management (DCM) scheme, which addresses these  </abstract>::line_number::15
<abstract> issues by providing the network with the capability to dynamically modify the performance parameters and the routes of  </abstract>::line_number::16
<abstract> any existing real-time connection. With these capabilities, DCM can be used to increase the availability and flexibility of  </abstract>::line_number::17
<abstract> the guaranteed performance service offered to the clients.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::13
<abstract> We examine the estimation of selectivities for range and spatial join queries in real spatial  </abstract>::line_number::14
<abstract> databases. As we have shown earlier [FK94a], real point sets: (a) violate consistently the  </abstract>::line_number::15
<abstract> "uniformity" and "independence" assumptions, (b) can often be described as "fractals", with  </abstract>::line_number::16
<abstract> non-integer (fractal) dimension. In this paper we show that, among the infinite family of fractal  </abstract>::line_number::17
<abstract> dimensions, the so called "Correlation Dimension" D 2 is the one that we need to predict the  </abstract>::line_number::18
<abstract> selectivity of spatial join.  </abstract>::line_number::19
<abstract> The main contribution is that, for all the real and synthetic point-sets we tried, the average  </abstract>::line_number::20
<abstract> number of neighbors for a given point of the point-set follows a power law, with D 2 as the exponent. This immediately solves the selectivity estimation for spatial joins, as well as for "biased"  </abstract>::line_number::21
<abstract> range queries (i.e., queries whose centers prefer areas of high point density).  </abstract>::line_number::22
<abstract> We present the formulas to estimate the selectivity for the biased queries, including an integration constant (K `shape 0 ) for each query shape. Finally, we show results on real and synthetic  </abstract>::line_number::23
<abstract> point sets, where our formulas achieve very low relative errors (typically about 10%, versus  </abstract>::line_number::24
<abstract> 40%-100% of the uniform assumption).   </abstract>::line_number::25
<abstract> A bstract  </abstract>::line_number::10
<abstract> Graphical techniques for modeling the dependencies of random variables have been explored in a variety  </abstract>::line_number::11
<abstract> of different areas including statistics, statistical physics, artificial intelligence, speech recognition, image  </abstract>::line_number::12
<abstract> processing, and genetics. Formalisms for manipulating these models have been developed relatively  </abstract>::line_number::13
<abstract> independently in these research communities. In this paper we explore hidden Markov models (HMMs)  </abstract>::line_number::14
<abstract> and related structures within the general framework of probabilistic independence networks (PINs). The  </abstract>::line_number::15
<abstract> paper contains a self-contained review of the basic principles of PINs. It is shown that the well-known  </abstract>::line_number::16
<abstract> forward-backward (F-B) and Viterbi algorithms for HMMs are special cases of more general inference  </abstract>::line_number::17
<abstract> algorithms for arbitrary PINs. Furthermore, the existence of inference and estimation algorithms for  </abstract>::line_number::18
<abstract> more general graphical models provides a set of analysis tools for HMM practitioners who wish to explore  </abstract>::line_number::19
<abstract> a richer class of HMM structures. Examples of relatively complex models to handle sensor fusion and  </abstract>::line_number::20
<abstract> coarticulation in speech recognition are introduced and treated within the graphical model framework  </abstract>::line_number::21
<abstract> to illustrate the advantages of the general approach.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Three dimensional visualisation has become a  </abstract>::line_number::5
<abstract> widespread scheme for helping users to access  </abstract>::line_number::6
<abstract> and manage large information network. In this  </abstract>::line_number::7
<abstract> report, various techniques for displaying depth  </abstract>::line_number::8
<abstract> information are reviewed, with an emphasis on  </abstract>::line_number::9
<abstract> stereoscopic displays. Input devices used to interact with a 3-D space are also examined. Issues in 3-D network visualisation are elicited from  </abstract>::line_number::10
<abstract> three viewpoints: psychological, task-related and  </abstract>::line_number::11
<abstract> implementational. Consideration of these issues  </abstract>::line_number::12
<abstract> leads to the design of a preliminary experimental  </abstract>::line_number::13
<abstract> programme for evaluating various network visu-alisation techniques.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Networks can be considered as approximation schemes. Multilayer networks of the  </abstract>::line_number::10
<abstract> backpropagation type can approximate arbitrarily well continuous functions (Cybenko,  </abstract>::line_number::11
<abstract> 1989; Funahashi, 1989; Stinchcombe and White, 1989). We prove that networks derived from regularization theory and including Radial Basis Functions (Poggio and  </abstract>::line_number::12
<abstract> Girosi, 1989), have a similar property. From the point of view of approximation theory, however, the property of approximating continuous functions arbitrarily well is not  </abstract>::line_number::13
<abstract> sufficient for characterizing good approximation schemes. More critical is the property  </abstract>::line_number::14
<abstract> of best approximation. The main result of this paper is that multilayer networks, of the  </abstract>::line_number::15
<abstract> type used in backpropagation, are not best approximation. For regularization networks  </abstract>::line_number::16
<abstract> (in particular Radial Basis Function networks) we prove existence and uniqueness of  </abstract>::line_number::17
<abstract> best approximation.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Programmers using imperative languages have a number of well-established debugging tools available to them; functional programmers have few, if any, tools available.  </abstract>::line_number::9
<abstract> Many of the tools and techniques developed for debugging functional programs are  </abstract>::line_number::10
<abstract> based on those for imperative programming and lack a theoretical basis relevant to  </abstract>::line_number::11
<abstract> functional programming. In addition, the techniques used are typically very time-consuming. A theoretical foundation on which to base the study of errors and debugging in functional programming is presented in this report. Using this theoretical  </abstract>::line_number::12
<abstract> foundation, a set of program transformation schemes has been developed which facilitate the location of the type of error which results in an evaluation-time error message  </abstract>::line_number::13
<abstract> and the termination of evaluation. A brief description of the practical experience ob  </abstract>::line_number::14
<abstract> tained using the tool is also presented.   </abstract>::line_number::15
<abstract>  ABSTRACT  </abstract>::line_number::12
<abstract> Communication in real-time systems has to be predictable, because unpredictable delays in  </abstract>::line_number::13
<abstract> the delivery of messages can adversely affect the execution of tasks dependent on these messages.  </abstract>::line_number::14
<abstract> In this paper, we develop a scheme for providing predictable inter-process communication in  </abstract>::line_number::15
<abstract> real-time systems with (partially connected) point-to-point interconnection networks, which  </abstract>::line_number::16
<abstract> provides guarantees on the maximum delivery time for messages. This scheme is based on the  </abstract>::line_number::17
<abstract> concept of a real-time channel, a unidirectional connection between source and destination. A  </abstract>::line_number::18
<abstract> real-time channel has parameters which describe the performance requirements of the source-destination communication, e.g., from a sensor station to a control site. Once such a channel  </abstract>::line_number::19
<abstract> is established, the communications subsystem guarantees that these performance requirements  </abstract>::line_number::20
<abstract> will be met. In this paper, we concentrate on methods to compute guarantees for the delivery time of messages belonging to real-time channels. We also address problems associated  </abstract>::line_number::21
<abstract> with allocating buffers for these messages and develop a scheme which preserves delivery time  </abstract>::line_number::22
<abstract> guarantees.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::4
<abstract> This paper describes the SEQUOIA 2000 project  </abstract>::line_number::5
<abstract> and its implementation efforts during the first three years.  </abstract>::line_number::6
<abstract> Included are the objectives we had, how we chose to  </abstract>::line_number::7
<abstract> address them and some of the lessons we learned from  </abstract>::line_number::8
<abstract> this endeavor.   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Designers of embedded systems are facing ever tighter  </abstract>::line_number::6
<abstract> constraints on design time, but computer aided design tools  </abstract>::line_number::7
<abstract> for embedded systems have not kept pace with these trends.  </abstract>::line_number::8
<abstract> The Chinook co-synthesis system addresses the automation of the most time-consuming and error-prone tasks in  </abstract>::line_number::9
<abstract> embedded controller design, namely: the synthesis of interface hardware and software needed to integrate system  </abstract>::line_number::10
<abstract> components; the migration of functions between processors  </abstract>::line_number::11
<abstract> or custom logic; and the co-simulation of the design before,  </abstract>::line_number::12
<abstract> during, and after synthesis. This paper describes the principal elements of Chinook and discuss its application to a  </abstract>::line_number::13
<abstract> variety of embedded designs.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We present in this paper a comparison of the dispersion properties for several finite-difference approximations of the acoustic wave equation. We investigate the compact and  </abstract>::line_number::5
<abstract> staggered schemes of fourth order accuracy in space and of second order or fourth order accuracy in time. We derive the computational cost of the simulation implied by a precision  </abstract>::line_number::6
<abstract> criterion on the numerical simulation (maximum allowed error in phase or group velocity).  </abstract>::line_number::7
<abstract> We conclude that for moderate accuracy the staggered scheme of second order in time is more  </abstract>::line_number::8
<abstract> efficient, whereas for very precise simulation the compact scheme of fourth order in time is  </abstract>::line_number::9
<abstract> a better choice. The comparison increasingly favors the lower order staggered scheme as the  </abstract>::line_number::10
<abstract> dimension increases. In three dimensional simulation, the cost of extremely precise simulation with any of the schemes is very large, whereas for simulation of moderate precision the  </abstract>::line_number::11
<abstract> staggered scheme is the least expensive.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::2
<abstract> We describe Fortran M, message-passing extensions to Fortran 77 that provide  </abstract>::line_number::3
<abstract> deterministic execution and information hiding while preserving desirable properties of  </abstract>::line_number::4
<abstract> message passing.   </abstract>::line_number::5
<abstract>  Abstract  </abstract>::line_number::3
<abstract> Two trust-region interior-point algorithms for the solution of minimization problems  </abstract>::line_number::4
<abstract> with simple bounds are presented. The algorithms scale the local model in a way proposed  </abstract>::line_number::5
<abstract> by Coleman and Li [1], but they are new otherwise. The first algorithm is more usual in  </abstract>::line_number::6
<abstract> that the trust region and the local quadratic model are consistently scaled. The second  </abstract>::line_number::7
<abstract> algorithm proposed here uses an unscaled trust region. A first-order convergence result for  </abstract>::line_number::8
<abstract> these algorithms is given and dogleg and conjugate-gradient algorithms to compute trial  </abstract>::line_number::9
<abstract> steps are introduced. Some numerical examples that show the advantages of the the second  </abstract>::line_number::10
<abstract> algorithm are presented.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We analyze a space-time domain decomposition iteration, for a model advection  </abstract>::line_number::10
<abstract> diffusion equation in one and two dimensions. The asymptotic convergence rate is  </abstract>::line_number::11
<abstract> superlinear, and it is governed by the diffusion of the error across the overlap between  </abstract>::line_number::12
<abstract> subdomains. Hence, it depends on both the size of this overlap and the diffusion  </abstract>::line_number::13
<abstract> coefficient in the equation. However, it is independent of the number of subdomains.  </abstract>::line_number::14
<abstract> The convergence rate for the heat equation in a large time window is initially linear and  </abstract>::line_number::15
<abstract> it deteriorates as the number of subdomains increases. The duration of the transient  </abstract>::line_number::16
<abstract> linear regime is proportional to the length of the time window. For advection dominated  </abstract>::line_number::17
<abstract> problems, the convergence rate is initially linear and it improves as the the ratio of  </abstract>::line_number::18
<abstract> advection to diffusion increases. Moreover, it is independent of the size of the time  </abstract>::line_number::19
<abstract> window and of the number of subdomains. In two space dimensions, the iteration  </abstract>::line_number::20
<abstract> possesses the smoothing property: high modes of the error are damped much faster  </abstract>::line_number::21
<abstract> then low modes. This is a result of the natural smoothing property of the heat equation.  </abstract>::line_number::22
<abstract> Numerical calculations illustrate our analysis.   </abstract>::line_number::23
<abstract>  ABSTRACT  </abstract>::line_number::7
<abstract> This paper discusses a method for training multilayer  </abstract>::line_number::8
<abstract> perceptron networks called DMP2 (Dynamic Multilayer  </abstract>::line_number::9
<abstract> Perceptron 2). The method is based upon a divide and conquer  </abstract>::line_number::10
<abstract> approach which builds networks in the form of binary trees,  </abstract>::line_number::11
<abstract> dynamically allocating nodes and layers as needed. The focus  </abstract>::line_number::12
<abstract> of this paper is on the effects of using multiple node types  </abstract>::line_number::13
<abstract> within the DMP framework. Simulation results show that  </abstract>::line_number::14
<abstract> DMP2 performs favorably in comparison with other learning  </abstract>::line_number::15
<abstract> algorithms, and that using multiple node types can be  </abstract>::line_number::16
<abstract> beneficial to network performance.   </abstract>::line_number::17
<abstract>  Abstract. This paper presents an inductive learning system called the Genetic Instance-Based  </abstract>::line_number::7
<abstract> Learning (GIBL) system. This system combines instance-based learning approaches with  </abstract>::line_number::8
<abstract> evolutionary computation in order to achieve high accuracy in the presence of irrelevant or  </abstract>::line_number::9
<abstract> redundant attributes. Evolutionary computation is used to find a set of attribute weights that  </abstract>::line_number::10
<abstract> yields a high estimate of classification accuracy. Results of experiments on 16 data sets are  </abstract>::line_number::11
<abstract> shown, and are compared with a non-weighted version of the instance-based learning system.  </abstract>::line_number::12
<abstract> The results indicate that the generalization accuracy of GIBL is somewhat higher than that of the  </abstract>::line_number::13
<abstract> non-weighted system on regular data, and is significantly higher on data with irrelevant or  </abstract>::line_number::14
<abstract> redundant attributes.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::2
<abstract> The goal of incremental cryptography is to design cryptographic algorithms with the property that having applied  </abstract>::line_number::3
<abstract> the algorithm to a document, it is possible to quickly update  </abstract>::line_number::4
<abstract> the result of the algorithm for a modified document, rather  </abstract>::line_number::5
<abstract> than having to re-compute it from scratch. In settings where  </abstract>::line_number::6
<abstract> cryptographic algorithms such as encryption or signatures  </abstract>::line_number::7
<abstract> are frequently applied to changing documents, dramatic efficiency improvements can be achieved. One such setting is  </abstract>::line_number::8
<abstract> the use of authentication tags for virus protection.  </abstract>::line_number::9
<abstract> We consider documents that can be modified by powerful (and realistic) document modification operations such as  </abstract>::line_number::10
<abstract> insertion and deletion of character-strings (or equivalently  </abstract>::line_number::11
<abstract> cut and paste of text). We provide efficient incremental  </abstract>::line_number::12
<abstract> signature and message authentication schemes supporting  </abstract>::line_number::13
<abstract> the above document modification operations. They meet a  </abstract>::line_number::14
<abstract> strong notion of tamper-proof security which is appropriate  </abstract>::line_number::15
<abstract> for the virus protection setting. We initiate a study of incremental encryption, providing definitions as well as solutions.  </abstract>::line_number::16
<abstract> Finally, we raise the novel issue of "privacy" of incremental  </abstract>::line_number::17
<abstract> authentication schemes.   </abstract>::line_number::18
<abstract>  Abstract | The purpose of this note is to present a new sampling technique and to demonstrate  </abstract>::line_number::4
<abstract> some of its properties. The new technique consists of picking two elements at random, and deterministically generating (from them) a long sequence of pairwise independent elements. The  </abstract>::line_number::5
<abstract> sequence is guarantees to intersect, with high probability, any set of non-negligible density.   </abstract>::line_number::6
<abstract>  Abstract  </abstract>::line_number::3
<abstract> A fundamental Lemma of Yao states that computational weak-unpredictability  </abstract>::line_number::4
<abstract> of functions gets amplified if the results of several independent instances are XOR  </abstract>::line_number::5
<abstract> together. We survey two known proofs of Yao's Lemma and present a third alternative proof. The third proof proceeds by first proving that a function constructed  </abstract>::line_number::6
<abstract> by concatenating the values of the function on several independent instances is much  </abstract>::line_number::7
<abstract> more unpredictable, with respect to specified complexity bounds, than the original  </abstract>::line_number::8
<abstract> function. This statement turns out to be easier to prove than the XOR-Lemma.  </abstract>::line_number::9
<abstract> Using a result of Goldreich and Levin and some elementary observation, we derive  </abstract>::line_number::10
<abstract> the XOR-Lemma.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::2
<abstract> We present a new specification for distributed data services that trade-off immediate consistency guarantees  </abstract>::line_number::3
<abstract> for improved system availability and efficiency, while  </abstract>::line_number::4
<abstract> ensuring the long-term consistency of the data. An  </abstract>::line_number::5
<abstract> eventually-serializable data service maintains the operations requested in a partial order that gravitates over  </abstract>::line_number::6
<abstract> time towards a total order. It provides clear and unambiguous guarantees about the immediate and long-term  </abstract>::line_number::7
<abstract> behavior of the system. To demonstrate its utility, we  </abstract>::line_number::8
<abstract> present an algorithm, based on one of Ladin, Liskov,  </abstract>::line_number::9
<abstract> Shrira, and Ghemawat [12], that implements this specification. Our algorithm provides the interface of the  </abstract>::line_number::10
<abstract> abstract service, and generalizes their algorithm by allowing general operations and greater flexibility in specifying consistency requirements. We also describe how  </abstract>::line_number::11
<abstract> to use this specification as a building block for applications such as directory services.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Current secure multiparty protocols have the following deficiency. The public transcript of the communication can be used as an involuntary commitment of the parties to their inputs and outputs. Thus  </abstract>::line_number::5
<abstract> parties can be later coerced by some authority to reveal their private data. Previous work that has  </abstract>::line_number::6
<abstract> pointed this interesting problem out contained only partial treatment.  </abstract>::line_number::7
<abstract> In this work we present the first general and rigorous treatment of the coercion problem in secure computation. First we present a general definition of protocols that provide resilience to coercion. Our  </abstract>::line_number::8
<abstract> definition constitutes a natural extension of the general paradigm used for defining secure multiparty  </abstract>::line_number::9
<abstract> protocols. Next we show that if trapdoor permutations exist then any function can be incoercibly  </abstract>::line_number::10
<abstract> computed (i.e., computed by a protocol that provides resilience to coercion) in the presence of com-putationally bounded adversaries and only public communication channels. This holds as long as less  </abstract>::line_number::11
<abstract> than half the parties are coerced (or corrupted). In particular, ours are the first incoercible protocols  </abstract>::line_number::12
<abstract> without physical assumptions. Also, our protocols constitute an alternative solution to the recently  </abstract>::line_number::13
<abstract> solved adaptive security problem.  </abstract>::line_number::14
<abstract> Our techniques are quite surprising and include non-standard use of deniable encryptions.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::3
<abstract> The notion of "proactive security" of basic primitives and cryptosystems that are distributed  </abstract>::line_number::4
<abstract> amongst various servers, was introduced in order to tolerate a very strong "mobile adversary." This  </abstract>::line_number::5
<abstract> adversary may corrupt all participants throughout the lifetime of the system in a non-monotonic  </abstract>::line_number::6
<abstract> fashion (i.e. recoveries are possible) but the adversary is unable to corrupt too many participants  </abstract>::line_number::7
<abstract> during any short time period [OstrovskyYung]. The notion assures increased security and availability  </abstract>::line_number::8
<abstract> of the cryptographic primitive.  </abstract>::line_number::9
<abstract> We present a proactive RSA system in which a threshold of servers applies the RSA signature  </abstract>::line_number::10
<abstract> (or decryption) function in a distributed manner; RSA is perhaps the most important trapdoor  </abstract>::line_number::11
<abstract> function in use. Employing new combinatorial and elementary number theoretic techniques, our  </abstract>::line_number::12
<abstract> protocol enables the dynamic updating of the servers (which hold the RSA key distributively);  </abstract>::line_number::13
<abstract> it is secure even when a linear number of the servers are corrupted during any time period (linear  </abstract>::line_number::14
<abstract> redundancy); it efficiently "self-maintains" the security of the function and its messages (ciphertexts  </abstract>::line_number::15
<abstract> or signatures); and it enables continuous availability, namely, correct function application using the  </abstract>::line_number::16
<abstract> shared key is possible at any time.  </abstract>::line_number::17
<abstract> We present an efficient way in which l servers can share an RSA private function so that, given  </abstract>::line_number::18
<abstract> 0 &lt; &lt; t &lt; 1:  </abstract>::line_number::19
<abstract> * Proactive (Dynamic) Robustness: A gateway G can combine information from any set of lt  </abstract>::line_number::20
<abstract> (honest) servers to deduce the RSA signature for any authorized message at any period.  </abstract>::line_number::21
<abstract> * Proactive Security (against mobile adversary): Our protocol is secure against a polynomial  </abstract>::line_number::22
<abstract> time adversary who controls the gateway G and time-variant sets of up to minfl(1 t ); lg  </abstract>::line_number::23
<abstract> servers, and can obtain the shares of up to l servers (including those that it corrupts).  </abstract>::line_number::24
<abstract> * Uniform Boundedness: The share-size is always bounded by the size of an RSA private key  </abstract>::line_number::25
<abstract> (i.e., logarithmically in N ).  </abstract>::line_number::26
<abstract> We also present special practical instances based on designs; some of these instances were recently  </abstract>::line_number::27
<abstract> implemented as part of a highly secure application testbed at Sandia National Laboratories.  </abstract>::line_number::28
<abstract> A major technical difficulty in "proactivizing" RSA was the fact that the servers have to update  </abstract>::line_number::29
<abstract> the "distributed representation" of an RSA key, while not learning the order of the group from  </abstract>::line_number::30
<abstract> which keys are drawn (in order not to compromise the RSA security).   </abstract>::line_number::31
<abstract>  Abstract  </abstract>::line_number::16
<abstract> A unified, comprehensive presentation of simulation techniques for verification of concurrent systems is given, in terms of a simple untimed automaton model. In particular,  </abstract>::line_number::17
<abstract> (1) refinements, (2) forward and backward simulations, (3) hybrid forward-backward  </abstract>::line_number::18
<abstract> and backward-forward simulations, and (4) history and prophecy relations are defined.  </abstract>::line_number::19
<abstract> History and prophecy relations are abstract versions of the history and prophecy variables of Abadi and Lamport, as well as the auxiliary variables of Owicki and Gries.  </abstract>::line_number::20
<abstract> Relationships between the different types of simulations, as well as soundness and  </abstract>::line_number::21
<abstract> completeness results, are stated and proved. Finally, it is shown how invariants can be  </abstract>::line_number::22
<abstract> incorporated into all the simulations.  </abstract>::line_number::23
<abstract> Even though many results are presented here for the first time, this paper can  </abstract>::line_number::24
<abstract> also be read as a survey (in a simple setting) of the research literature on simulation  </abstract>::line_number::25
<abstract> techniques.  </abstract>::line_number::26
<abstract> The development for untimed automata is designed to support a similar development for timed automata. In Part II of this paper, it is shown how the results of this  </abstract>::line_number::27
<abstract> paper can be carried over to the setting of timed automata.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Previous efforts at facial expression recognition have  </abstract>::line_number::8
<abstract> been based on the Facial Action Coding System (FACS), a  </abstract>::line_number::9
<abstract> representation developed in order to allow human psychologists to code expression from static facial mugshots. In  </abstract>::line_number::10
<abstract> this paper we develop new, more accurate representations  </abstract>::line_number::11
<abstract> for facial expression by building a video database of facial  </abstract>::line_number::12
<abstract> expressions and then probabilistically characterizing the  </abstract>::line_number::13
<abstract> facial muscle activation associated with each expression  </abstract>::line_number::14
<abstract> using a detailed physical model of the skin and muscles.  </abstract>::line_number::15
<abstract> This produces a muscle-based representation of facial motion, which is then used to recognize facial expressions in  </abstract>::line_number::16
<abstract> two different ways. The first method uses the physics-based  </abstract>::line_number::17
<abstract> model directly, by recognizing expressions through comparison of estimated muscle activations. The second method  </abstract>::line_number::18
<abstract> uses the physics-based model to generate spatio-temporal  </abstract>::line_number::19
<abstract> motion-energy templates of the whole face for each different  </abstract>::line_number::20
<abstract> expression. These simple, biologically-plausible motion  </abstract>::line_number::21
<abstract> energy templates are then used for recognition. Both  </abstract>::line_number::22
<abstract> methods show substantially greater accuracy at expression  </abstract>::line_number::23
<abstract> recognition than has been previously achieved.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A thesaurus is a book containing synonyms in a  </abstract>::line_number::7
<abstract> given language; it provides similarity links when  </abstract>::line_number::8
<abstract> trying to retrieve articles or stories about a particular topic. A "visual thesaurus" works with  </abstract>::line_number::9
<abstract> pictures, not words. It aids in recognizing visually similar events, "visual synonyms," including  </abstract>::line_number::10
<abstract> both spatial and motion similarity. This paper  </abstract>::line_number::11
<abstract> describes a method for building such a tool, and  </abstract>::line_number::12
<abstract> recent research results in the MIT Media Lab  </abstract>::line_number::13
<abstract> which contribute toward this goal. The heart  </abstract>::line_number::14
<abstract> of the method is a learning system which gathers information by interacting with a user of a  </abstract>::line_number::15
<abstract> database. The learning system is also capable of  </abstract>::line_number::16
<abstract> incorporating audio and other perceptual information, ultimately constructing a representation  </abstract>::line_number::17
<abstract> of common sense knowledge.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We propose a person identification technique that  </abstract>::line_number::8
<abstract> can recognize and verify people from unconstrained  </abstract>::line_number::9
<abstract> video and audio. We do not expect fully frontal face  </abstract>::line_number::10
<abstract> image or clean speech as our input. Our recognition algorithm can detect and compensate for pose variation  </abstract>::line_number::11
<abstract> and changes in the auditory background and also select the most reliable video frame and audio clip to use  </abstract>::line_number::12
<abstract> for recognition. We also use 3D depth information of  </abstract>::line_number::13
<abstract> a human head to detect the presence of an actual person as opposed to an image of that person. Our system achieves 100% recognition and verification rates  </abstract>::line_number::14
<abstract> on natural real-time input with 26 registered clients.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::3
<abstract> Query optimizers generate plans to retrieve data specified by queries. Query optimization  </abstract>::line_number::4
<abstract> for object databases (i.e., object-oriented and object-relational databases) is an immature field,  </abstract>::line_number::5
<abstract> and stands to benefit from adaptation of techniques that have proved useful for relations. One  </abstract>::line_number::6
<abstract> technique uses query-to-query transformations to rewrite queries into queries that are potentially  </abstract>::line_number::7
<abstract> more amenable to plan generation. For transformations to be useful, they must preserve the  </abstract>::line_number::8
<abstract> semantics of the queries they rewrite (correctness) and usually result in queries that generate  </abstract>::line_number::9
<abstract> better plans (effectiveness). Object databases complicate the expression of correct and effective  </abstract>::line_number::10
<abstract> transformations.  </abstract>::line_number::11
<abstract> Transformation correctness is problematic even for relational queries. Especially error-prone  </abstract>::line_number::12
<abstract> are transformations that rewrite complex nested queries (queries containing other queries) or  </abstract>::line_number::13
<abstract> queries that return duplicates. Objects make correctness more difficult because object queries  </abstract>::line_number::14
<abstract> can be far more complex than relational queries.  </abstract>::line_number::15
<abstract> The effectiveness of a relational transformation typically depends on the syntax of a query  </abstract>::line_number::16
<abstract> rather than the semantics of of its data or functions. On the other hand, the lack of uniformity  </abstract>::line_number::17
<abstract> in data functions and collections in an object query makes effectiveness more subtle. The effectiveness of a transformation for object queries may depend on the semantics of data functions,  </abstract>::line_number::18
<abstract> and may vary from object to object in a collection. Therefore, optimizers may have to perform  </abstract>::line_number::19
<abstract> sophisticated reasoning and apply transformations on a per object basis to ensure that they are  </abstract>::line_number::20
<abstract> used only when appropriate.  </abstract>::line_number::21
<abstract> This thesis considers the correctness and effectiveness of optimizer transformations. To  </abstract>::line_number::22
<abstract> address correctness, we propose a formally specified query algebra and two-tiered language  </abstract>::line_number::23
<abstract> (COKO-KOLA) for expressing transformations that can be verified with a theorem prover. To  </abstract>::line_number::24
<abstract> address effectiveness, we propose semantic and dynamic extensions to the traditional optimizer  </abstract>::line_number::25
<abstract> architecture. The high-level contribution of the thesis is the observation that the choice of  </abstract>::line_number::26
<abstract> query representation impacts the quality of the optimizer. Specifically, a combinator-based  </abstract>::line_number::27
<abstract> (variable-free) query representation simplifies the query manipulations that are required to make  </abstract>::line_number::28
<abstract> transformations correct and effective.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Shape recognition is a challenging task when images contain overlapping, noisy, occluded, partial shapes.  </abstract>::line_number::9
<abstract> This paper addresses the task of matching input shapes with model shapes described in terms of features  </abstract>::line_number::10
<abstract> such as line segments and angles. The quality of matching is gauged using a measure derived from attributed  </abstract>::line_number::11
<abstract> shape grammars. We apply genetic algorithms to the partial shape-matching task. Preliminary results, using  </abstract>::line_number::12
<abstract> model shapes with 6 to 70 features each, are extremely encouraging.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper presents some of the underlying principles of description logics (also known  </abstract>::line_number::8
<abstract> as terminological logics or kl-one-style languages), grounding them in the lattice of terms  </abstract>::line_number::9
<abstract> organized by the so-called "subsumption" relationship. A survey of the increasingly varied uses  </abstract>::line_number::10
<abstract> of description logics, including industrial applications, is presented by considering their role in  </abstract>::line_number::11
<abstract> a number of different operations that one can apply to a knowledge base, including languages  </abstract>::line_number::12
<abstract> for queries, answers, updates, rules, and constraints. Finally, we discuss some of the complexity  </abstract>::line_number::13
<abstract> results related to the logics of descriptions, and survey a spectrum of responses to the many  </abstract>::line_number::14
<abstract> intractability proofs.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Given a permutation P of f1; : : : ; kg and T of f1; : : : ; ng, the pattern matching problem for per  </abstract>::line_number::9
<abstract> mutations is to determine whether there is a length k subsequence of T whose elements are ordered  </abstract>::line_number::10
<abstract> in the same way as the elements of P . We present an O(kn 4 ) time and O(kn 3 ) space algorithm  </abstract>::line_number::11
<abstract> for finding a match of P into T or determining that no match exists, given that P is separable, i.e.  </abstract>::line_number::12
<abstract> contains neither (2, 4, 1, 3) nor (3, 1, 4, 2) as a subpattern.   </abstract>::line_number::13
<abstract>  ABSTRACT  </abstract>::line_number::7
<abstract> Simplicial depth is a way to measure how deep a point is among a set of points. Efficient  </abstract>::line_number::8
<abstract> algorithms to compute it are important to the usefulness of its applications, such as in  </abstract>::line_number::9
<abstract> multivariate analysis in statistics. A straightforward method takes O(n d+1 ) time when the  </abstract>::line_number::10
<abstract> points are in d-dimensional space. We discuss an algorithm that takes O(n 2 ) time when the  </abstract>::line_number::11
<abstract> points are in three-dimensional space, and we generalize it to four-dimensional space with  </abstract>::line_number::12
<abstract> a time complexity of O(n 4 ). For spaces higher than four-dimensional, there are no known  </abstract>::line_number::13
<abstract> algorithms faster than the straightforward method.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper presents an efficient algorithm for constructing Bayesian belief networks from databases. The  </abstract>::line_number::7
<abstract> algorithm takes a database and an attributes ordering (i.e., the causal attributes of an attribute should appear earlier  </abstract>::line_number::8
<abstract> in the order) as input and constructs a belief network structure as output. The construction process is based on the  </abstract>::line_number::9
<abstract> computation of mutual information of attribute pairs. Given a data set which is large enough and has a DAG-Isomorphic probability distribution, this algorithm guarantees that the perfect map [1] of the underlying dependency  </abstract>::line_number::10
<abstract> model is generated, and at the same time, enjoys the time complexity of O N( ) 2 on conditional independence (CI)  </abstract>::line_number::11
<abstract> tests. To evaluate this algorithm, we present the experimental results on three versions of the well-known ALARM  </abstract>::line_number::12
<abstract> network database, which has 37 attributes and 10,000 records. The correctness proof and the analysis of  </abstract>::line_number::13
<abstract> computational complexity are also presented. We also discuss the features of our work and relate it to previous  </abstract>::line_number::14
<abstract> works.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Large-scale parallel machines are incorporating increasingly sophisticated architectural support for user-level messaging and global memory access. We provide a systematic  </abstract>::line_number::5
<abstract> evaluation of a broad spectrum of current design alternatives  </abstract>::line_number::6
<abstract> based on our implementations of a global address language  </abstract>::line_number::7
<abstract> on the Thinking Machines CM-5, Intel Paragon, Meiko CS-2, Cray T3D, and Berkeley NOW. This evaluation includes  </abstract>::line_number::8
<abstract> a range of compilation strategies that make varying use of  </abstract>::line_number::9
<abstract> the network processor; each is optimized for the target architecture and the particular strategy. We analyze a family  </abstract>::line_number::10
<abstract> of interacting issues that determine the performance tradeoffs in each implementation, quantify the resulting latency,  </abstract>::line_number::11
<abstract> overhead, and bandwidth of the global access operations,  </abstract>::line_number::12
<abstract> and demonstrate the effects on application performance.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::5
<abstract> A novel algorithm, named SeqMapII, of technology  </abstract>::line_number::6
<abstract> mapping with retiming for optimal clock period for K-LUT based FPGAs was recently proposed by Pan and  </abstract>::line_number::7
<abstract> Liu [13]. The time complexity of their algorithm, however, is O(K 3 n 4 log(Kn 2 ) log n) for sequential circuits  </abstract>::line_number::8
<abstract> with n gates, which is too high for medium and large  </abstract>::line_number::9
<abstract> size designs in practice. In this paper, we present  </abstract>::line_number::10
<abstract> three strategies to improve the performance of the approach in [13]: 1) efficient label update with single  </abstract>::line_number::11
<abstract> K-cut computation based on the monotone property  </abstract>::line_number::12
<abstract> of labels that we showed for sequential circuits, 2) a  </abstract>::line_number::13
<abstract> novel approach for the K-cut computation on partial  </abstract>::line_number::14
<abstract> flow networks, which are much smaller in practice, 3)  </abstract>::line_number::15
<abstract> SCC (strongly connected component) partition to further speedup the algorithm. In practice, our algorithm  </abstract>::line_number::16
<abstract> works in O(K 2 n 3 log n) time and O(Kn) space according to our experimental results. It is 2fi10 4 times faster  </abstract>::line_number::17
<abstract> than SeqMapII-opt for computing optimal solutions and  </abstract>::line_number::18
<abstract> 2 times faster than SeqMapII-heu which uses very small  </abstract>::line_number::19
<abstract> expanded circuits as a heuristic.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::13
<abstract> An extended visual cryptography scheme, EVCS for short, for an access structure  </abstract>::line_number::14
<abstract> ( Qual ; Forb ) on a set of n participants, is a technique to encode n images in such a  </abstract>::line_number::15
<abstract> way that when we stack together the transparencies associated to participants in any  </abstract>::line_number::16
<abstract> set X 2 Qual we get the secret message with no trace of the original images, but any  </abstract>::line_number::17
<abstract> X 2 Forb has no information on the shared image. Moreover, after the original images  </abstract>::line_number::18
<abstract> are encoded they are still meaningful, that is, any user will recognize the image on his  </abstract>::line_number::19
<abstract> transparency.  </abstract>::line_number::20
<abstract> The main contributions of this paper are the following:  </abstract>::line_number::21
<abstract> * A trade-off between the contrast of the reconstructed image and the contrast of the  </abstract>::line_number::22
<abstract> image on each transparency for (k; k)-threshold EVCS (in a (k; k)-threshold EVCS  </abstract>::line_number::23
<abstract> the image is visible if and only if k transparencies are stacked together). This yields  </abstract>::line_number::24
<abstract> a necessary and sufficient condition for the existence of (k; k)-threshold EVCS for  </abstract>::line_number::25
<abstract> the values of such contrasts. In case a scheme exists we explicitly construct it.  </abstract>::line_number::26
<abstract> * A general technique to implement extended visual cryptography schemes, which  </abstract>::line_number::27
<abstract> uses hypergraph colourings. This technique yields (k; k)-threshold EVCS which  </abstract>::line_number::28
<abstract> are optimal with respect to the pixel expansion. Finally, we discuss some applications of this technique to various interesting classes of access structures by using  </abstract>::line_number::29
<abstract> relevant results from the theory of hypergraph colourings.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The FAA Aging Aircraft Research Program is  </abstract>::line_number::10
<abstract> supporting the development of a robotic mobile  </abstract>::line_number::11
<abstract> nondestructive inspection (NDI) instrument  </abstract>::line_number::12
<abstract> deployment tool at Carnegie Mellon University  </abstract>::line_number::13
<abstract> (CMU) with the active participation of USAir. The  </abstract>::line_number::14
<abstract> program has spawned several new relationships  </abstract>::line_number::15
<abstract> and entities: an alliance with an ARPA-funded  </abstract>::line_number::16
<abstract> research program at CMU having the capability to  </abstract>::line_number::17
<abstract> add 3D-stereoscopic enhanced visual inspection  </abstract>::line_number::18
<abstract> capability, a start-up company organized to  </abstract>::line_number::19
<abstract> commercialize the combined technologies, and  </abstract>::line_number::20
<abstract> State of Pennsylvania funding to foster this  </abstract>::line_number::21
<abstract> commercialization. As a result of these activities  </abstract>::line_number::22
<abstract> and connections the civilian sector appears to be  </abstract>::line_number::23
<abstract> ahead of the military sector in important aspects of  </abstract>::line_number::24
<abstract> automation for deployment of aircraft inspection  </abstract>::line_number::25
<abstract> equipment. A partnership between the university  </abstract>::line_number::26
<abstract> researchers, the airline operator, the start-up  </abstract>::line_number::27
<abstract> company, and the state government is thus  </abstract>::line_number::28
<abstract> emerging as the likely agent for transfer of the  </abstract>::line_number::29
<abstract> civilian-developed technology to the military sector.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper describes automatic document categorization based on large text hierarchy. We  </abstract>::line_number::7
<abstract> handle the large number of features and training examples by taking into account hierarchical  </abstract>::line_number::8
<abstract> structure of examples and using feature selection for large text data. We experimentally evaluate  </abstract>::line_number::9
<abstract> feature subset selection on real-world text data collected from the existing Web hierarchy named  </abstract>::line_number::10
<abstract> Yahoo. In our learning experiments naive Bayesian classifier was used on text data using feature-vector document representation that includes word sequences (n-grams) instead of just single words  </abstract>::line_number::11
<abstract> (unigrams). Experimental evaluation on real-world data collected form the Web shows that our  </abstract>::line_number::12
<abstract> approach gives promising results and can potentially be used for document categorization on the  </abstract>::line_number::13
<abstract> Web. Additionally the best result on our data is achieved for relatively small feature subset, while for  </abstract>::line_number::14
<abstract> larger subset the performance substantially drops. The best performance among six tested feature  </abstract>::line_number::15
<abstract> scoring measure was achieved by the feature scoring measure called Odds ratio that is known from  </abstract>::line_number::16
<abstract> information retrieval.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Region Inference is a technique for inferring lifetimes of values in strict, higher-order programming languages such as Standard ML. The purpose of this paper is to show how ideas  </abstract>::line_number::5
<abstract> from Milner's polymorphic type discipline can serve as a basis for region inference, even in the  </abstract>::line_number::6
<abstract> presence of a limited form of polymorphic recursion.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Access to shared data is provided today by distributed file systems and  </abstract>::line_number::10
<abstract> databases. In this paper, we explore certain usage and technological trends that  </abstract>::line_number::11
<abstract> will radically change the way shared data is used in the future. The usage trends  </abstract>::line_number::12
<abstract> include the growing need to access shared data from anywhere, increasing scale,  </abstract>::line_number::13
<abstract> and the increasing importance of efficient search. The technology trends include  </abstract>::line_number::14
<abstract> the advent of portable machines, the availability of software and hardware for  </abstract>::line_number::15
<abstract> using diverse types of data, and the growing diversity of network speeds and  </abstract>::line_number::16
<abstract> capabilities. These trends induce fundamental research problems in the areas of  </abstract>::line_number::17
<abstract> adaptive system behavior, secure remote execution and extensibility.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In this paper we show that application-aware adaptation, a  </abstract>::line_number::6
<abstract> collaborative partnership between the operating system and  </abstract>::line_number::7
<abstract> applications, offers the most general and effective approach  </abstract>::line_number::8
<abstract> to mobile information access. We describe the design of  </abstract>::line_number::9
<abstract> Odyssey, a prototype implementing this approach, and show  </abstract>::line_number::10
<abstract> how it supports concurrent execution of diverse mobile applications. We identify agility as a key attribute of adaptive systems, and describe how to quantify and measure it.  </abstract>::line_number::11
<abstract> We present the results of our evaluation of Odyssey, indicating performance improvements up to a factor of 5 on a  </abstract>::line_number::12
<abstract> benchmark of three applications concurrently using remote  </abstract>::line_number::13
<abstract> services over a network with highly variable bandwidth.   </abstract>::line_number::14
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> We present recent advances from our efforts in increasing coverage, robustness, generality and speed of JANUS, CMU's  </abstract>::line_number::7
<abstract> speech-to-speech translation system. JANUS is a speaker-independent system which translates spoken utterances in  </abstract>::line_number::8
<abstract> English and also in German into one of German, English or  </abstract>::line_number::9
<abstract> Japanese. The system has been designed around the task  </abstract>::line_number::10
<abstract> of conference registration (CR). It has initially been built  </abstract>::line_number::11
<abstract> based on a speech database of 12 read dialogs, encompassing a vocabulary of around 500 words. We have since been  </abstract>::line_number::12
<abstract> expanding the system along several dimensions to improve  </abstract>::line_number::13
<abstract> speed, robustness and coverage and to move toward spontaneous input.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::5
<abstract> AURORA is a vision-based system designed to warn a vehicle driver of possible impending roadway departure accidents. It employs a downward looking color video camera with a wide angle  </abstract>::line_number::6
<abstract> lens, a digitizer, and a portable Sun Sparc workstation. Using a binormalized adjustable template  </abstract>::line_number::7
<abstract> correlation algorithm, it reliably detects lane markers on structured roads at 60 Hz. A time-to-lane-crossing (TLC) measurement is calculated for each image based on the estimation of vehicles lateral position and velocity. This measurement is used to trigger an alarm when the TLC falls below  </abstract>::line_number::8
<abstract> a preset threshold. Promising results have been achieved under a variety of weather and lighting  </abstract>::line_number::9
<abstract> conditions, on many road types.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Binary manipulators are powered by actuators  </abstract>::line_number::6
<abstract> which have only two stable states. Therefore, they  </abstract>::line_number::7
<abstract> can reach only a discrete (but possibly large) number  </abstract>::line_number::8
<abstract> of locations. Compared to a manipulator built with  </abstract>::line_number::9
<abstract> continuous actuators, a binary manipulator provides  </abstract>::line_number::10
<abstract> reasonable performance, and is relatively inexpensive  </abstract>::line_number::11
<abstract> (up to an order of magnitude cheaper). The number  </abstract>::line_number::12
<abstract> of states of a binary manipulator grows exponentially  </abstract>::line_number::13
<abstract> with the number of actuators. This makes the calculation of its inverse kinematics quite difficult. This  </abstract>::line_number::14
<abstract> paper presents a combinatorial method for computing  </abstract>::line_number::15
<abstract> the inverse kinematics of a binary manipulator that  </abstract>::line_number::16
<abstract> reduces the search space to a manageable size. It also  </abstract>::line_number::17
<abstract> creates extremely smooth motions that follow a specified trajectory very accurately (in both position and  </abstract>::line_number::18
<abstract> orientation), despite the discrete nature of binary actuation.   </abstract>::line_number::19
<abstract>  Abstract. This paper presents an overview of a parallelizing compiler  </abstract>::line_number::6
<abstract> to automatically generate efficient code for large-scale parallel architectures from sequential input programs. This research focuses on loop-level  </abstract>::line_number::7
<abstract> parallelism in dense matrix computations. We illustrate the basic techniques the compiler uses by describing the entire compilation process for  </abstract>::line_number::8
<abstract> a simple example.  </abstract>::line_number::9
<abstract> Our compiler is organized into three major phases: analyzing array references, allocating the computation and data to the processors to optimize  </abstract>::line_number::10
<abstract> parallelism and locality, and generating code.  </abstract>::line_number::11
<abstract> An optimizing compiler for scalable parallel machines requires more sophisticated program analysis than the traditional data dependence analysis. Our compiler uses a precise data-flow analysis technique to identify  </abstract>::line_number::12
<abstract> the producer of the value read by each instance of a read access. In order to allocate the computation and data to the processors, the compiler  </abstract>::line_number::13
<abstract> first transforms the program to expose loop-level parallelism in the computation. It then finds a decomposition of the computation and data  </abstract>::line_number::14
<abstract> such that parallelism is exploited and the communication overhead is  </abstract>::line_number::15
<abstract> minimized. The compiler will trade off extra degrees of parallelism to  </abstract>::line_number::16
<abstract> reduce or eliminate communication. Finally, the compiler generates code  </abstract>::line_number::17
<abstract> to manage the multiple address spaces and to communicate data across  </abstract>::line_number::18
<abstract> processors.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::6
<abstract> CC ++ is Compositional C ++ , a parallel object-oriented notation  </abstract>::line_number::7
<abstract> that consists of C ++ with six extensions. The goals of the CC ++  </abstract>::line_number::8
<abstract> project are to provide a theory, notation and tools for developing reliable scalable concurrent program libraries, and to provide a framework  </abstract>::line_number::9
<abstract> for unifying:  </abstract>::line_number::10
<abstract> 1. distributed reactive systems, batch-oriented numeric and sym  </abstract>::line_number::11
<abstract> bolic applications, and user-interface systems,  </abstract>::line_number::12
<abstract> 2. declarative programs and object-oriented imperative programs,  </abstract>::line_number::13
<abstract> and  </abstract>::line_number::14
<abstract> 3. deterministic and nondeterministic programs.  </abstract>::line_number::15
<abstract> This paper is a brief description of the motivation for CC ++ , the  </abstract>::line_number::16
<abstract> extensions to C ++ , a few examples of CC ++ programs with reasoning  </abstract>::line_number::17
<abstract> about their correctness, and an evaluation of CC ++ in the context of  </abstract>::line_number::18
<abstract> other research on concurrent computation. A short description of  </abstract>::line_number::19
<abstract> C ++ is provided.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::6
<abstract> In this paper we introduce a new approach for parallel, distributed simulation of modular, hierarchical  </abstract>::line_number::7
<abstract> DEVS and DEVS-based combined discrete/continuous  </abstract>::line_number::8
<abstract> multiformalism models. The algorithm combines  </abstract>::line_number::9
<abstract> conservative and optimistic distributed simulation  </abstract>::line_number::10
<abstract> strategies and is able to optimally exploit lookahead  </abstract>::line_number::11
<abstract> capabilities of the model. The object oriented implementation in C++ is intended to serve as a powerful  </abstract>::line_number::12
<abstract> simulator in the STIMS modeling and simulation environment.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The communication latency is a major issue that must be dealt with in parallel  </abstract>::line_number::7
<abstract> computing. The parallel computation model therefore must provide the ability to tolerate  </abstract>::line_number::8
<abstract> such latencies. Communication using blocking receives is the commonly used mechanism  </abstract>::line_number::9
<abstract> in parallel programming today. Message driven execution is an alternate mechanism  </abstract>::line_number::10
<abstract> which does not use receive style statements at all. The message driven execution style  </abstract>::line_number::11
<abstract> promotes the overlap of computation and communication: Programs written in this style  </abstract>::line_number::12
<abstract> exhibit increased latency tolerance. However, they are often difficult to develop and  </abstract>::line_number::13
<abstract> debug. We present a coordination language called Dagger to alleviate this problem. The  </abstract>::line_number::14
<abstract> language has a mechanism which is called expect, that replaces the receive statement.  </abstract>::line_number::15
<abstract> It has been implemented in the Charm parallel programming system, and runs programs  </abstract>::line_number::16
<abstract> portably on a variety of parallel machines.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The advent and acceptance of massively parallel  </abstract>::line_number::7
<abstract> machines has made it increasingly important to have  </abstract>::line_number::8
<abstract> tools to analyze the performance of programs running on these machines. Current day performance  </abstract>::line_number::9
<abstract> tools suffer from two drawbacks: they are not scalable  </abstract>::line_number::10
<abstract> and they lose specific information about the user program in their attempt for generality. In this paper,  </abstract>::line_number::11
<abstract> we present Projections, a scalable performance tool,  </abstract>::line_number::12
<abstract> for Charm that can provide program-specific information to help the users better understand the behavior  </abstract>::line_number::13
<abstract> of their programs.   </abstract>::line_number::14
<abstract>  Abstract One of the main hurdles to improved CLIR effectiveness is resolving ambiguity associated with translation.  </abstract>::line_number::15
<abstract> Availability of resources is also a problem. First we present a  </abstract>::line_number::16
<abstract> technique based on co-occurrence statistics from unlinked corpora which can be used to reduce the ambiguity associated with  </abstract>::line_number::17
<abstract> phrasal and term translation. We then combine this method  </abstract>::line_number::18
<abstract> with other techniques for reducing ambiguity and achieve more  </abstract>::line_number::19
<abstract> than 90% monolingual effectiveness. Finally, we compare the  </abstract>::line_number::20
<abstract> co-occurrence method with parallel corpus and machine translation techniques and show that good retrieval effectiveness can  </abstract>::line_number::21
<abstract> be achieved without complex resources.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::5
<abstract> The retrieval of images based on their visual similarity  </abstract>::line_number::6
<abstract> to an example image is an important and fascinating area of  </abstract>::line_number::7
<abstract> research. Here, a method to characterize visual appearance  </abstract>::line_number::8
<abstract> for determining global similarity in images is described.  </abstract>::line_number::9
<abstract> Images are filtered with Gaussian derivatives and geometric features are computed from the filtered images.  </abstract>::line_number::10
<abstract> The geometric features used here are curvature and phase.  </abstract>::line_number::11
<abstract> Two images may be said to be similar if they have similar distributions of such features. Global similarity may,  </abstract>::line_number::12
<abstract> therefore, be deduced by comparing histograms of these  </abstract>::line_number::13
<abstract> features. This allows for rapid retrieval and examples from  </abstract>::line_number::14
<abstract> collection of gray-level and trademark images are shown.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We describe randomized algorithms for efficiently maintaining a binary space partition of continuously moving, possibly  </abstract>::line_number::5
<abstract> intersecting, line segments in the plane, and of continuously  </abstract>::line_number::6
<abstract> moving but disjoint triangles in space. Our two-dimensional  </abstract>::line_number::7
<abstract> BSP has depth O(log n) and size O(n log n + k) and can be  </abstract>::line_number::8
<abstract> constructed in expected O(n log 2 n + k log n) time, where k  </abstract>::line_number::9
<abstract> is the number of intersecting pairs. We can detect combinatorial changes to our BSP caused by the motion of the segments, and we can update our BSP in expected O(log n) time  </abstract>::line_number::10
<abstract> per change. Our three-dimensional BSP has depth O(log n),  </abstract>::line_number::11
<abstract> size O(n log 2 n+k 0 ), construction time O(n log 3 n+k 0 log n),  </abstract>::line_number::12
<abstract> and update time O(log 2 n) (all expected), where k 0 is the  </abstract>::line_number::13
<abstract> number of intersections between pairs of edges in the xy-projection of the triangles. Under reasonable assumptions  </abstract>::line_number::14
<abstract> about the motion of the segments or triangles, the expected  </abstract>::line_number::15
<abstract> number of number of combinatorial changes to either BSP is  </abstract>::line_number::16
<abstract> O(mn s (n)), where m is the number of moving objects and  </abstract>::line_number::17
<abstract> s (n) is the maximum length of an (n; s) Davenport-Schinzel  </abstract>::line_number::18
<abstract> sequence for some constant s.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> The straight skeleton of a polygon is a variant of the medial axis, introduced by  </abstract>::line_number::6
<abstract> Aichholzer et al., defined by a shrinking process in which each edge of the polygon  </abstract>::line_number::7
<abstract> moves inward at a fixed rate. We construct the straight skeleton of an n-gon with r  </abstract>::line_number::8
<abstract> reflex vertices in time O(n 1+" + n 8=11+" r 9=11+" ), for any fixed " &gt; 0, improving the  </abstract>::line_number::9
<abstract> previous best upper bound of O(nr log n). Our algorithm simulates the sequence of  </abstract>::line_number::10
<abstract> collisions between edges and vertices during the shrinking process, using a technique of  </abstract>::line_number::11
<abstract> Eppstein for maintaining extrema of binary functions to reduce the problem of finding  </abstract>::line_number::12
<abstract> successive interactions to two dynamic range query problems: (1) maintain a changing  </abstract>::line_number::13
<abstract> set of triangles in IR 3 and answer queries asking which triangle would be first hit by  </abstract>::line_number::14
<abstract> a query ray, and (2) maintain a changing set of rays in IR 3 and answer queries asking  </abstract>::line_number::15
<abstract> for the lowest intersection of any ray with a query triangle. We also exploit a novel  </abstract>::line_number::16
<abstract> characterization of the straight skeleton as a lower envelope of triangles in IR 3 . The same  </abstract>::line_number::17
<abstract> time bounds apply to constructing non-self-intersecting offset curves with mitered or  </abstract>::line_number::18
<abstract> beveled corners, and similar methods extend to other problems of simulating collisions  </abstract>::line_number::19
<abstract> and other pairwise interactions among sets of moving objects.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::17
<abstract> Since uncalibrated images permit only projective reconstruction, metric information requires either  </abstract>::line_number::18
<abstract> camera or scene calibration. We propose a stratified approach to projective reconstruction, in which  </abstract>::line_number::19
<abstract> gradual increase in domain information for scene calibration leads to gradual increase in 3D information.  </abstract>::line_number::20
<abstract> Our scheme includes the following steps: (1) Register the images with respect to a reference plane; this  </abstract>::line_number::21
<abstract> can be done using limited scene information, e.g., the knowledge that two pairs of lines on the plane are  </abstract>::line_number::22
<abstract> parallel. We show that this calibration is sufficient for ordinal reconstruction sorting the points by their  </abstract>::line_number::23
<abstract> height over the reference plane. (2) If available, use the relative height of two additional out-of-plane  </abstract>::line_number::24
<abstract> points to compute the height of the remaining points up to constant scaling. Our scheme is based on the  </abstract>::line_number::25
<abstract> dual epipolar geometry in the reference frame, which we develop below. We show good results with five  </abstract>::line_number::26
<abstract> sequences of real images, using mostly scene calibration that can be inferred directly from the images  </abstract>::line_number::27
<abstract> themselves.   </abstract>::line_number::28
<abstract>  Abstract: Clustering is often used for discovering structure in data. Clustering systems  </abstract>::line_number::11
<abstract> differ in the objective function used to evaluate clustering quality and the control strategy  </abstract>::line_number::12
<abstract> used to search the space of clusterings. Ideally, the search strategy should consistently  </abstract>::line_number::13
<abstract> construct clusterings of high quality, but be computationally inexpensive as well. In general,  </abstract>::line_number::14
<abstract> we cannot have it both ways, but we can partition the search so that a system inexpensively  </abstract>::line_number::15
<abstract> constructs a `tentative' clustering for initial examination, followed by iterative optimization,  </abstract>::line_number::16
<abstract> which continues to search in background for improved clusterings. Given this motivation, we  </abstract>::line_number::17
<abstract> evaluate an inexpensive strategy for creating initial clusterings, coupled with several control  </abstract>::line_number::18
<abstract> strategies for iterative optimization, each of which repeatedly modifies an initial clustering  </abstract>::line_number::19
<abstract> in search of a better one. One of these methods appears novel as an iterative optimization  </abstract>::line_number::20
<abstract> strategy in clustering contexts. Once a clustering has been constructed it is judged by  </abstract>::line_number::21
<abstract> analysts often according to task-specific criteria. Several authors have abstracted these  </abstract>::line_number::22
<abstract> criteria and posited a generic performance task akin to pattern completion, where the error  </abstract>::line_number::23
<abstract> rate over completed patterns is used to `externally' judge clustering utility. Given this  </abstract>::line_number::24
<abstract> performance task we adapt resampling-based pruning strategies used by supervised learning  </abstract>::line_number::25
<abstract> systems to the task of simplifying hierarchical clusterings, thus promising to ease post-clustering analysis. Finally, we propose a number of objective functions, based on attribute-selection measures for decision-tree induction, that might perform well on the error rate and  </abstract>::line_number::26
<abstract> simplicity dimensions.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::13
<abstract> We consider the problem of indexing general database  </abstract>::line_number::14
<abstract> workloads (combinations of data sets and sets of potential queries). We define a framework for measuring the  </abstract>::line_number::15
<abstract> efficiency of an indexing scheme for a workload based on  </abstract>::line_number::16
<abstract> two characterizations: storage redundancy (how many  </abstract>::line_number::17
<abstract> times each item in the data set is stored), and access  </abstract>::line_number::18
<abstract> overhead (how many times more blocks than necessary  </abstract>::line_number::19
<abstract> does a query retrieve). Using this framework we present  </abstract>::line_number::20
<abstract> some initial results, showing upper and lower bounds  </abstract>::line_number::21
<abstract> and trade-offs between them in the case of multi-dimensional range queries and set queries.   </abstract>::line_number::22
<abstract>  The World-Wide Web is changing the nature of software development to a distributive  </abstract>::line_number::14
<abstract> plug & play process. This requires a new way of managing software by so-called intelligent  </abstract>::line_number::15
<abstract> software brokers. The aim of the European IBROW3 project is to develop an intelligent  </abstract>::line_number::16
<abstract> brokering service that enables third party knowledge-component reuse through the  </abstract>::line_number::17
<abstract> World-Wide Web. Suppliers provide libraries of knowledge components adhering to some  </abstract>::line_number::18
<abstract> standard, and customers can consult these libraries -- through intelligent brokers -- to  </abstract>::line_number::19
<abstract> configure a knowledge system suited to their needs by selection and adaptation. IBROW3  </abstract>::line_number::20
<abstract> integrates research on heterogeneous databases, interoperability and web technology with  </abstract>::line_number::21
<abstract> knowledge-system technology and ontologies. The aim is to develop a broker that can handle  </abstract>::line_number::22
<abstract> web requests for classes of knowledge system (e.g. diagnostic systems) by accessing  </abstract>::line_number::23
<abstract> libraries of reusable problem-solving methods on the Web, and selecting, adapting and  </abstract>::line_number::24
<abstract> configuring these methods in accordance with the domain at hand.   </abstract>::line_number::25
<abstract> The aim of this paper is to give a general overview of the project and to presents its main  </abstract>::line_number::26
<abstract> ideas and approach. IBROW3 has started on January 1, 1998 and thus we can only present  </abstract>::line_number::27
<abstract> preliminary results.    </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::11
<abstract> A diagonal of a planar, simple polygon P is an open line segment that connects  </abstract>::line_number::12
<abstract> two non-adjacent vertices and lies in the relative interior of P . We present a linear  </abstract>::line_number::13
<abstract> time algorithm for finding a shortest diagonal (in the L 2 norm) of a simple polygon,  </abstract>::line_number::14
<abstract> improving the previous best result by a factor of log n. Our result provides an interesting  </abstract>::line_number::15
<abstract> contrast to a known (n log n) lower bound for finding a closest pair of vertices in a  </abstract>::line_number::16
<abstract> simple polygon|observe that a shortest diagonal is defined by a closest pair of vertices  </abstract>::line_number::17
<abstract> satisfying an additional visibility constraint.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We present a randomized linear-time algorithm for finding a minimum spanning tree in a connected  </abstract>::line_number::6
<abstract> graph with edge weights. The algorithm is a modification of one proposed by Karger and uses random  </abstract>::line_number::7
<abstract> sampling in combination with a recently discovered linear-time algorithm for verifying a minimum spanning tree. Our computational model is a unit-cost random-access machine with the restriction that the  </abstract>::line_number::8
<abstract> only operations allowed on edge weights are binary comparisons.   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::3
<abstract> Consider the following Markov chain, whose states  </abstract>::line_number::4
<abstract> are all domino tilings of a 2n fi 2n chessboard: starting from some arbitrary tiling, pick a 2 fi 2 window  </abstract>::line_number::5
<abstract> uniformly at random. If the four squares appearing in  </abstract>::line_number::6
<abstract> this window are covered by two parallel dominoes, rotate the dominoes in place. Repeat many times. This  </abstract>::line_number::7
<abstract> process is used in practice to generate a random tiling,  </abstract>::line_number::8
<abstract> and is a key tool in the study of the combinatorics of  </abstract>::line_number::9
<abstract> tilings and the behavior of dimer systems in statistical physics. Analogous Markov chains are used to  </abstract>::line_number::10
<abstract> randomly generate other structures on various two-dimensional lattices. This paper presents techniques  </abstract>::line_number::11
<abstract> which prove for the first time that, in many interesting cases, a small number of random moves suffice to  </abstract>::line_number::12
<abstract> obtain a uniform distribution.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::10
<abstract> This paper describes an experimental study of constraint-based network design. We used a  </abstract>::line_number::11
<abstract> novel network design tool, implemented in Java, to design representative networks joining  </abstract>::line_number::12
<abstract> major U.S. cities. The cost of three topologies: Best Star, Minimum Spanning Tree (MST),  </abstract>::line_number::13
<abstract> and Delaunay Triangulation, are compared, with and without localized traffic constraints.  </abstract>::line_number::14
<abstract> The best star network gives near optimal result when the traffic is only constrained by source  </abstract>::line_number::15
<abstract> and sink capacity of switches (flat traffic constraints). With localized traffic constraints, the  </abstract>::line_number::16
<abstract> most cost effective network has a structure similar to the MST. The cheapest network has a  </abstract>::line_number::17
<abstract> tree structure when there are only flat traffic constraints, but can have cycles when localized  </abstract>::line_number::18
<abstract> traffic constraints are present.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We empirically analyze and compare two simple, deterministic policies for scheduling dynamically evolving tree-structured computations on parallel architectures that are rings of identical  </abstract>::line_number::8
<abstract> processing elements (PEs). Our computations have each task either halt or spawn two independent children; they abstract, for instance, computations generated by multigrid methods. Our  </abstract>::line_number::9
<abstract> simpler policy, called koso, has each PE keep one child of a spawning task and pass the other  </abstract>::line_number::10
<abstract> to its clockwise neighbor in the ring; our more sophisticated policy, called koso ? , operates similarly, but allows child-passing only from a more heavily loaded PE to a more lightly loaded one.  </abstract>::line_number::11
<abstract> Both policies execute waiting tasks in increasing order of their depths in the evolving task-tree.  </abstract>::line_number::12
<abstract> Based on partial (mathematical) analyses of our policies' behaviors, we conjectured that both  </abstract>::line_number::13
<abstract> yield good parallel speedup on large classes of the computations we study, but that policy  </abstract>::line_number::14
<abstract> koso ? outperforms policy koso in many important situations. Not having been able to verify  </abstract>::line_number::15
<abstract> these conjectures analytically, we study them in this paper via a suite of carefully designed and  </abstract>::line_number::16
<abstract> analyzed experiments. Our experiments largely substantiate both of our conjectures. We find  </abstract>::line_number::17
<abstract> that both policies give close to optimal parallel speedup on large classes of computations, and  </abstract>::line_number::18
<abstract> that koso ? outperforms koso on these computations, except on very small processor rings.  </abstract>::line_number::19
<abstract> We believe that our methodology of experimental design and analysis will prove useful in other  </abstract>::line_number::20
<abstract> such studies.   </abstract>::line_number::21
<abstract>  Abstract| In this paper, we use a genetic algorithm to evolve a set of classification rules with  </abstract>::line_number::3
<abstract> real-valued attributes. We show how real-valued  </abstract>::line_number::4
<abstract> attribute ranges can be encoded with real-valued  </abstract>::line_number::5
<abstract> genes and present a new uniform method for representing don't cares in the rules. We view supervised classification as an optimization problem,  </abstract>::line_number::6
<abstract> and evolve rule sets that maximize the number of  </abstract>::line_number::7
<abstract> correct classifications of input instances. We use a  </abstract>::line_number::8
<abstract> variant of the Pitt approach to genetic-based machine learning system with a novel conflict resolution mechanism between competing rules within  </abstract>::line_number::9
<abstract> the same rule set. Experimental results demonstrate the effectiveness of our proposed approach  </abstract>::line_number::10
<abstract> on a benchmark wine classifier system.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Today's high-performance RISC microprocessors have been  </abstract>::line_number::7
<abstract> highly tuned for integer and floating point application performance. These architectures have paid less attention to  </abstract>::line_number::8
<abstract> operating system requirements. At the same time, new operating system designs often have overlooked modern architectural trends which may unavoidably change the relative  </abstract>::line_number::9
<abstract> cost of certain primitive operations. The result is that operating system performance is well below application code  </abstract>::line_number::10
<abstract> performance on contemporary RISCs.  </abstract>::line_number::11
<abstract> This paper examines recent directions in computer architecture and operating systems, and the implications of  </abstract>::line_number::12
<abstract> changes in each domain for the other. The requirements of  </abstract>::line_number::13
<abstract> three components of operating system design are discussed  </abstract>::line_number::14
<abstract> in detail: interprocess communication, virtual memory, and  </abstract>::line_number::15
<abstract> thread management. For each component, we relate operating system functional and performance needs to the mechanisms available on commercial RISC architectures such as  </abstract>::line_number::16
<abstract> the MIPS R2000 and R3000, Sun SPARC, IBM RS6000,  </abstract>::line_number::17
<abstract> Motorola 88000, and Intel i860.  </abstract>::line_number::18
<abstract> Our analysis reveals a number of specific reasons why  </abstract>::line_number::19
<abstract> the performance of operating system primitives on RISCs  </abstract>::line_number::20
<abstract> has not scaled with integer performance. In addition,  </abstract>::line_number::21
<abstract> we identify areas in which architectures could better (and  </abstract>::line_number::22
<abstract> cost-effectively) accommodate operating system needs, and  </abstract>::line_number::23
<abstract> areas in which operating system design could accommodate certain necessary characteristics of cost-effective high-performance microprocessors.   </abstract>::line_number::24
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> Many important and useful applications for software agents  </abstract>::line_number::7
<abstract> require multiple agents on a network that communicate with  </abstract>::line_number::8
<abstract> each other. Such agents must find each other and perform a  </abstract>::line_number::9
<abstract> useful joint computation without having to know about every  </abstract>::line_number::10
<abstract> other such agent on the network. This paper describes a  </abstract>::line_number::11
<abstract> matchmaker  </abstract>::line_number::12
<abstract> system, designed to find people with similar interests and introduce them to each other. The matchmaker is  </abstract>::line_number::13
<abstract> designed to introduce   </abstract>::line_number::14
<abstract> everyone  </abstract>::line_number::15
<abstract> , unlike conventional Internet  </abstract>::line_number::16
<abstract> media which only allow those who take the time to   </abstract>::line_number::17
<abstract> speak  </abstract>::line_number::18
<abstract> public to be known.  </abstract>::line_number::19
<abstract> The paper details how the agents that make it up the match-making system can function in a decentralized fashion, yet  </abstract>::line_number::20
<abstract> can group themselves into clusters which reflect their users  </abstract>::line_number::21
<abstract> interests; these clusters are then used to make introductions or  </abstract>::line_number::22
<abstract> allow users to send messages to others who share their inter  </abstract>::line_number::23
<abstract> ests. The algorithm uses   </abstract>::line_number::24
<abstract> referrals  </abstract>::line_number::25
<abstract> from one agent to another  </abstract>::line_number::26
<abstract> in the same fashion that word-of-mouth is used when people  </abstract>::line_number::27
<abstract> are looking for an expert. A prototype of the system has been  </abstract>::line_number::28
<abstract> implemented, and results of its use are presented.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We describe the design and implementation of a compiler  </abstract>::line_number::7
<abstract> that automatically translates ordinary programs written in  </abstract>::line_number::8
<abstract> a subset of ML into code that generates native code at run  </abstract>::line_number::9
<abstract> time. Run-time code generation can make use of values and  </abstract>::line_number::10
<abstract> invariants that cannot be exploited at compile time, yielding  </abstract>::line_number::11
<abstract> code that is often superior to statically optimal code. But  </abstract>::line_number::12
<abstract> the cost of optimizing and generating code at run time can  </abstract>::line_number::13
<abstract> be prohibitive. We demonstrate how compile-time specialization can reduce the cost of run-time code generation by  </abstract>::line_number::14
<abstract> an order of magnitude without greatly affecting code quality.  </abstract>::line_number::15
<abstract> Several benchmark programs are examined, which exhibit an  </abstract>::line_number::16
<abstract> average cost of only six cycles per instruction generated at  </abstract>::line_number::17
<abstract> run time.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::20
<abstract> This paper provides a tutorial introduction to visual servo control of robotic manipulators.  </abstract>::line_number::21
<abstract> Since the topic spans many disciplines our goal is limited to providing a basic conceptual framework. We begin by reviewing the prerequisite topics from robotics and computer vision, including  </abstract>::line_number::22
<abstract> a brief review of coordinate transformations, velocity representation, and a description of the  </abstract>::line_number::23
<abstract> geometric aspects of the image formation process. We then present a taxonomy of visual servo  </abstract>::line_number::24
<abstract> control systems. The two major classes of systems, position-based and image-based systems, are  </abstract>::line_number::25
<abstract> then discussed. Since any visual servo system must be capable of tracking image features in a  </abstract>::line_number::26
<abstract> sequence of images, we include an overview of feature-based and correlation-based methods for  </abstract>::line_number::27
<abstract> tracking. We conclude the tutorial with a number of observations on the current directions of  </abstract>::line_number::28
<abstract> the research field of visual servo control.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We have implemented a parallel version of the Bellman-Ford algorithm for the single-source shortest paths  </abstract>::line_number::9
<abstract> problem. Our software has been developed on the CM-5 using C with CMMD communication primitives.  </abstract>::line_number::10
<abstract> We have empirically compared the efficiency of our implementation with a sequential implementation of  </abstract>::line_number::11
<abstract> the Bellman-Ford-Moore algorithm developed by Cherkassky, Goldberg and Radzik. We have performed  </abstract>::line_number::12
<abstract> our experiments using fifty randomly generated graphs with vertex counts in the range between 2 10 and  </abstract>::line_number::13
<abstract> 2 15 and edge counts in the range between 2 11 and 2 21 . In our experiments, the parallel implementation  </abstract>::line_number::14
<abstract> becomes faster than the sequential implementation when the average degree of the input graphs exceeds  </abstract>::line_number::15
<abstract> 2 5 or 2 6 . For the dense graphs in our test suite, we obtain speedups of up to 3.3 on 32 processors and up  </abstract>::line_number::16
<abstract> to 8.3 on 128 processors.  </abstract>::line_number::17
<abstract> In the implementation we discuss in this paper, several design decisions were taken in view of the limited  </abstract>::line_number::18
<abstract> time we had to complete a working version of our software. For example, instead of performing any kind  </abstract>::line_number::19
<abstract> of dynamic load balancing, we try to keep the computation load balanced by applying a straightforward  </abstract>::line_number::20
<abstract> data distribution scheme at the beginning of the computation. Moreover, in the code that runs on  </abstract>::line_number::21
<abstract> each processor, we avoid any sophisticated data structures and only use linear arrays. We are currently  </abstract>::line_number::22
<abstract> experimenting with alternative implementations that may lead to improved speedups, particularly on the  </abstract>::line_number::23
<abstract> denser graphs of our test suite.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The use of graphs to represent independence structure in multivariate probability  </abstract>::line_number::9
<abstract> models has been pursued in a relatively independent fashion across a wide variety of  </abstract>::line_number::10
<abstract> research disciplines since the beginning of this century. This paper provides a brief  </abstract>::line_number::11
<abstract> overview of the current status of such research with particular attention to recent developments which have served to unify such seemingly disparate topics as probabilistic  </abstract>::line_number::12
<abstract> expert systems, statistical physics, image analysis, genetics, decoding of error-correcting  </abstract>::line_number::13
<abstract> codes, Kalman filters, and speech recognition with Markov models.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The paper presents the general theory of designing multidimensional Quadrature Mirror Filters (QMF),  </abstract>::line_number::7
<abstract> for use in sub-band coding (SBC) systems, using the McClellan transform [1]. It was recently shown that  </abstract>::line_number::8
<abstract> McClellan transform could be used to generate 2-D diamond shape QMF filters [2]. In this paper we will  </abstract>::line_number::9
<abstract> formalize the proofs of the diamond shape case, and generalize it to other shapes, sampling rasters and  </abstract>::line_number::10
<abstract> dimensions.  </abstract>::line_number::11
<abstract> Moreover we show that we do not really need the 1-D QMF filters: it is also possible and even more  </abstract>::line_number::12
<abstract> convenient to design QMF filter banks by performing transformations on a class of real valued polynomials.  </abstract>::line_number::13
<abstract> Examples are given of two dimensional diamond and fan-shape filters and three dimensional tetrad filters  </abstract>::line_number::14
<abstract> designed using this transformation technique.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We are developing design principles applying tangible interfaces to storytelling. This paper describes an underlying  </abstract>::line_number::9
<abstract> philosophy and three resultant designs for computer-mediated toys, exploring how the merging of physical objects  </abstract>::line_number::10
<abstract> with computer technology can enhance childrens storytelling. Each prototype aims to develop a specific set of both  </abstract>::line_number::11
<abstract> oral and written storytelling skills, as well as collaboration, sharing, and the notion of revision. By creating  </abstract>::line_number::12
<abstract> narratives, children learn about culture and identity, and develop a sense of self. In addition, narrative can be used as  </abstract>::line_number::13
<abstract> a gateway to draw girls into technology. The use of multi-sensory interfaces allows for richer interaction.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::2
<abstract> This paper presents our work towards achieving a model based approach to three dimensional  </abstract>::line_number::3
<abstract> morphing. It describes the initial algorithms and ideas that we envisioned, the final algorithm we  </abstract>::line_number::4
<abstract> developed and implemented, the environment we worked in, our visualization techniques, and future  </abstract>::line_number::5
<abstract> work planned on the subject.    </abstract>::line_number::6
<abstract>  Abstract  </abstract>::line_number::14
<abstract> Despite the emergence of high speed LANs, the communication performance available to applications on workstation clusters still falls short of that available on MPPs.  </abstract>::line_number::15
<abstract> A new generation of efficient messaging layers is needed to take advantage of the hardware performance and to deliver it to the application level. Communication software  </abstract>::line_number::16
<abstract> is the key element in bridging the communication performance gap separating MPPs  </abstract>::line_number::17
<abstract> and workstation clusters.  </abstract>::line_number::18
<abstract> MPI-FM is a high performance implementation of MPI for networks of workstations connected with a Myrinet network, built on top of the Fast Messages (FM) library.  </abstract>::line_number::19
<abstract> Based on the FM version 1.1 released in Fall 1995, MPI-FM achieves a minimum one-way latency of 19 s and a peak bandwidth of 17.3 MByte/s with common MPI send  </abstract>::line_number::20
<abstract> and receive function calls. A direct comparison using published performance figures  </abstract>::line_number::21
<abstract> shows that MPI-FM running on SPARCstation 20 workstations connected with a relatively inexpensive Myrinet network outperforms the MPI implementations available  </abstract>::line_number::22
<abstract> on the IBM SP2 and the Cray T3D, both in latency and in bandwidth, for messages  </abstract>::line_number::23
<abstract> up to 2 KByte in size.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Multiple lightweight processes or threads have multiple stacks, and a thread context switch moves  </abstract>::line_number::8
<abstract> execution from one stack to another. On the SPARC 1 architecture, parts of a thread's stack can be  </abstract>::line_number::9
<abstract> cached in register windows while the thread is running. The cached data must be flushed to memory  </abstract>::line_number::10
<abstract> when the thread is suspended. Doing the flushing both efficiently and correctly can be tricky. This  </abstract>::line_number::11
<abstract> document discusses the implementation of a non-preemptive user-space threads package under SunOS 2 .   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A recognition strategy consisting of a mixture of indexing on invariants and search, allows objects to be recog-nised up to a Euclidean ambiguity with an uncalibrated  </abstract>::line_number::7
<abstract> camera. The approach works by using projective invariants to determine all the possible projectively equivalent  </abstract>::line_number::8
<abstract> models for a particular imaged object; then a system of  </abstract>::line_number::9
<abstract> global consistency constraints is used to determine which of  </abstract>::line_number::10
<abstract> these projectively equivalent, but Euclidean distinct, models corresponds to the objects viewed. These constraints  </abstract>::line_number::11
<abstract> follow from properties of the imaging geometry. In particular, a recognition hypothesis is equivalent to an assertion about, among other things, viewing conditions and geometric relationships between objects, and these assertions  </abstract>::line_number::12
<abstract> must be consistent for hypotheses to be correct. The approach is demonstrated to work on images of real scenes  </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper describes several key trends in technology that will inuence the design of file systems for the next decade. It first outlines the basic trends to hardware performance that underlie  </abstract>::line_number::7
<abstract> file system design. These trends affect both user demands on file systems and trade-offs in their  </abstract>::line_number::8
<abstract> design. It then considers how technologies will drive more demanding file system workloads that  </abstract>::line_number::9
<abstract> will require scalable file systems. Next, it outlines how opportunities raised by these low-level  </abstract>::line_number::10
<abstract> technology trends impact specific aspects of the xFS file systems serverless design [Dahlin  </abstract>::line_number::11
<abstract> et al., 1994b, Anderson et al., 1996]. Finally, to put xFSs serverless approach in context, it discusses other technology trends that affect file systems but that are not explicitly addressed in the  </abstract>::line_number::12
<abstract> serverless design.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We advocate the use of Common Lisp as a powerful glue for  </abstract>::line_number::5
<abstract> building scientific computing environments. Naturally one  </abstract>::line_number::6
<abstract> then has to address mixing pre-existing (non Lisp) code into  </abstract>::line_number::7
<abstract> this system. We provide a specific example as an elaborate  </abstract>::line_number::8
<abstract> FORTRAN system written by David Bailey for arbitrary-precision floating-point numeric calculation. We discuss the  </abstract>::line_number::9
<abstract> advantages and disadvantages of wholesale importing into  </abstract>::line_number::10
<abstract> Lisp. A major advantage is being able to use state-of-the  </abstract>::line_number::11
<abstract> art packaged software sooner, while overcoming the disadvantages caused by FORTRAN's traditional batch orientation and weak storage model. In this paper we emphasize in  </abstract>::line_number::12
<abstract> particular how effective use of imported systems may require  </abstract>::line_number::13
<abstract> one to address the contrast between the functional (Lisp-like) versus state-transition-based (Fortran-like) approaches  </abstract>::line_number::14
<abstract> to dealing with compound objects. While our example is  </abstract>::line_number::15
<abstract> high-precision floats, other highly useful packages including those for simulation, PDE solutions, signal processing,  </abstract>::line_number::16
<abstract> statistical computation, etc. may also benefit by similar  </abstract>::line_number::17
<abstract> consideration.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::15
<abstract> In this paper, we study the tradeoffs involved in choosing the bit allocation in a  </abstract>::line_number::16
<abstract> multiresolution remote image retrieval system. Such a system uses a multiresolution  </abstract>::line_number::17
<abstract> image coding scheme so that a user accessing the database will first see a coarse  </abstract>::line_number::18
<abstract> version of the images and will be able to accept or discard a given image faster,  </abstract>::line_number::19
<abstract> without needing to receive all the image data. We formalize the problem of choosing  </abstract>::line_number::20
<abstract> the bit allocation (e.g., in the two resolution case, how many bits should be given  </abstract>::line_number::21
<abstract> to the coarse image and the additional information, respectively?) so that the  </abstract>::line_number::22
<abstract> overall delay in the query is minimized. We provide analytical methods to find the  </abstract>::line_number::23
<abstract> optimal solution under different configurations and show how a good choice of the  </abstract>::line_number::24
<abstract> bit allocation results in a significant reduction of the overall delay in the query (by  </abstract>::line_number::25
<abstract> up to a factor of two in some cases).   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::0
<abstract> TCP is a reliable transport protocol tuned to perform well  </abstract>::line_number::1
<abstract> in traditional networks made up of wired links with stationary hosts. Networks with wireless links and mobile  </abstract>::line_number::2
<abstract> hosts violate many of the assumptions made by TCP, causing degraded performance. In this paper, we describe a  </abstract>::line_number::3
<abstract> simple protocol that improves TCP performance by modifying network-layer software only at a basestation without  </abstract>::line_number::4
<abstract> violating end-to-end TCP semantics. The main idea is to  </abstract>::line_number::5
<abstract> cache packets at the basestation and perform local  </abstract>::line_number::6
<abstract> retransmissions. Simulations of this protocol show that it  </abstract>::line_number::7
<abstract> is significantly more robust in the presence of multiple  </abstract>::line_number::8
<abstract> packet losses in a single transmission window as compared to TCP. This enables our protocol to tolerate at least  </abstract>::line_number::9
<abstract> 10 times as high an error rate without any performance  </abstract>::line_number::10
<abstract> degradation.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Several researchers have proposed algorithms for basic block reordering. We call these branch alignment algorithms. The primary  </abstract>::line_number::8
<abstract> emphasis of these algorithms has been on improving instruction  </abstract>::line_number::9
<abstract> cache locality, and the few studies concerned with branch prediction reported small or minimal improvements. As wide-issue architectures become increasingly popular the importance of reducing  </abstract>::line_number::10
<abstract> branch costs will increase, and branch alignment is one mechanism  </abstract>::line_number::11
<abstract> which can effectively reduce these costs.  </abstract>::line_number::12
<abstract> In this paper, we propose an improved branch alignment algorithm that takes into consideration the architectural cost model and  </abstract>::line_number::13
<abstract> the branch prediction architecture when performing the basic block  </abstract>::line_number::14
<abstract> reordering. We show that branch alignment algorithms can improve  </abstract>::line_number::15
<abstract> a broad range of static and dynamic branch prediction architectures.  </abstract>::line_number::16
<abstract> We also show that a programs performance can be improved by approximately 5% even when using recently proposed, highly accurate  </abstract>::line_number::17
<abstract> branch prediction architectures. The programs are compiled by any  </abstract>::line_number::18
<abstract> existing compiler and then transformed via binary transformations.  </abstract>::line_number::19
<abstract> When implementing these algorithms on a Alpha AXP 21604 up to  </abstract>::line_number::20
<abstract> a 16% reduction in total execution time is achieved.   </abstract>::line_number::21
<abstract>  Abstract: This paper presents empirical data on the behavior of large dataflow programs on  </abstract>::line_number::9
<abstract> a distributed memory multiprocessor. The programs, written in the dataflow language Id90, are  </abstract>::line_number::10
<abstract> compiled via a Threaded Abstract Machine (TAM) for the CM-5. TAM refines dataflow execution  </abstract>::line_number::11
<abstract> models by addressing critical constraints that modern parallel architectures place on the compilation  </abstract>::line_number::12
<abstract> of general-purpose parallel programming languages. It exposes synchronization, scheduling, and  </abstract>::line_number::13
<abstract> network access so that the compiler can optimize against the cost of these operations.  </abstract>::line_number::14
<abstract> The data presented in this paper evaluates the TAM approach in compiling dataflow languages  </abstract>::line_number::15
<abstract> on stock hardware. We present data on the instruction mix, speedup, scheduling behavior, and  </abstract>::line_number::16
<abstract> locality of large ID90 programs. It is shown that the TAM scheduling hierarchy is able to tolerate  </abstract>::line_number::17
<abstract> long communication latencies, especially when some degree of I-structure locality is present. We investigate how frame allocation strategies, k-bounded loops, and I-structure caching and distribution  </abstract>::line_number::18
<abstract> together affect the overall efficiency. Finally we document some scheduling anomalies.   </abstract>::line_number::19
<abstract>  1.0 Abstract  </abstract>::line_number::6
<abstract> Distributed systems in use today depend heavily on network communications between clients and servers. In this report, we describe the  </abstract>::line_number::7
<abstract> design and implementation of the network architecture (hardware, software and protocols) of the RAID-II system. RAID-II is a high speed network file server connected to an UltraNetwork. In order to support high  </abstract>::line_number::8
<abstract> bandwidth network transfers with the RAID-II server, we partitioned the  </abstract>::line_number::9
<abstract> networking software among the various processors in the system. Measurements of the system show that the RAID-II server can sustain 21MB/  </abstract>::line_number::10
<abstract> s of data bandwidth to the Ultranet.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::7
<abstract> As the difference in speed between processor and memory system continues to increase, it is becoming crucial to develop  </abstract>::line_number::8
<abstract> and refine techniques that enhance the effectiveness of cache  </abstract>::line_number::9
<abstract> hierarchies. Two such techniques are data prefetching and  </abstract>::line_number::10
<abstract> data forwarding. With prefetching, a processor hides the latency of cache misses by requesting the data before it actually  </abstract>::line_number::11
<abstract> needs it. With forwarding, a producer processor hides the  </abstract>::line_number::12
<abstract> latency of communication-induced cache misses in the consumer processors by sending the data to the caches of the  </abstract>::line_number::13
<abstract> latter. These two techniques are complementary approaches  </abstract>::line_number::14
<abstract> to hiding the latency of communication-induced misses.  </abstract>::line_number::15
<abstract> This paper compares the effectiveness of data forwarding  </abstract>::line_number::16
<abstract> and data prefetching to hide communication-induced misses.  </abstract>::line_number::17
<abstract> Although both techniques require comparable hardware support, forwarding usually has a lower instruction overhead. We  </abstract>::line_number::18
<abstract> evaluate prefetching and forwarding algorithms in a paralleliz-ing compiler using execution-driven simulations of a shared-memory multiprocessor. Both data forwarding and prefetch-ing reduce the execution time of applications significantly (30-40% on average). Forwarding performs better on average,  </abstract>::line_number::19
<abstract> while prefetching is more robust to changes in cache and memory parameters. Finally, we propose two ways of integrating  </abstract>::line_number::20
<abstract> the two techniques. The integration of the two techniques reduces the execution time even more (43-48% on average) and  </abstract>::line_number::21
<abstract> is very robust.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Optimizing on-chip primary data caches for parallel scientific applications is challenging because different applications  </abstract>::line_number::7
<abstract> exhibit different behavior. Indeed, while some applications  </abstract>::line_number::8
<abstract> exhibit good spatial locality, others have accesses with long  </abstract>::line_number::9
<abstract> strides that prevent the effective use of cache lines. Finally,  </abstract>::line_number::10
<abstract> other applications cannot exploit long lines because they exhibit false sharing. To help processors execute these three  </abstract>::line_number::11
<abstract> types of applications efficiently, we introduce the Pool Buffer,  </abstract>::line_number::12
<abstract> a small direct-mapped cache accessed in parallel with the primary cache. The function of the pool buffer is to fetch long  </abstract>::line_number::13
<abstract> sectors of relatively short cache lines from memory on a miss,  </abstract>::line_number::14
<abstract> while only letting into the cache the lines that the processor  </abstract>::line_number::15
<abstract> actually references. The pool buffer can also perform sequential prefetching of sectors.  </abstract>::line_number::16
<abstract> An evaluation of the pool buffer based on simulations of  </abstract>::line_number::17
<abstract> five 32-processor Perfect Club codes yields encouraging results. Adding a pool buffer of one-quarter the size of the  </abstract>::line_number::18
<abstract> cache causes a small increase in area while usually achieving  </abstract>::line_number::19
<abstract> large reductions in execution time. For example, for a range  </abstract>::line_number::20
<abstract> of caches with 32-byte lines, the execution time decreases by  </abstract>::line_number::21
<abstract> an average of about 20%. We also show that small 1-Kbyte  </abstract>::line_number::22
<abstract> buffers are often large enough to get most of the potential  </abstract>::line_number::23
<abstract> benefits. Finally, caches with pool buffers are more effective  </abstract>::line_number::24
<abstract> than caches with long lines and no pool buffer.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A new generation of sensor rich, massively distributed  </abstract>::line_number::7
<abstract> autonomous systems is being developed that has  </abstract>::line_number::8
<abstract> the potential for unprecedented performance, such  </abstract>::line_number::9
<abstract> as smart buildings, reconfigurable factories, adaptive  </abstract>::line_number::10
<abstract> traffic systems and remote earth ecosystem monitoring. To achieve high performance these massive systems will need to accurately model themselves and  </abstract>::line_number::11
<abstract> their environment from sensor information. Accomplishing this on a grand scale requires automating the  </abstract>::line_number::12
<abstract> art of large-scale modeling. This paper presents a  </abstract>::line_number::13
<abstract> formalization of decompositional, model-based learning  </abstract>::line_number::14
<abstract> (DML), a method developed by observing a modeler's  </abstract>::line_number::15
<abstract> expertise at decomposing large scale model estimation  </abstract>::line_number::16
<abstract> tasks. The method exploits a striking analogy between  </abstract>::line_number::17
<abstract> learning and consistency-based diagnosis. Moriarty,  </abstract>::line_number::18
<abstract> an implementation of DML, has been applied to thermal modeling of a smart building, demonstrating a  </abstract>::line_number::19
<abstract> significant improvement in learning rate.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::8
<abstract> In image segmentation problems, there is usually a vast amount of filter  </abstract>::line_number::9
<abstract> operations available, a subset of which has to be selected and instantiated  </abstract>::line_number::10
<abstract> in order to obtain a satisfactory segmentation procedure for a particular domain. In supervised segmentation, a mapping from features, such as filter  </abstract>::line_number::11
<abstract> outputs for individual pixels, to classes is induced automatically. However,  </abstract>::line_number::12
<abstract> since the sample size required for supervised learning grows exponentially  </abstract>::line_number::13
<abstract> in the number of features it is not feasible to learn a segmentation procedure  </abstract>::line_number::14
<abstract> from a large amount of possible filters. But we argue that automatic model  </abstract>::line_number::15
<abstract> selection methods are able to select a region model in terms of some filters.  </abstract>::line_number::16
<abstract> We propose a wrapper algorithm that performs this task. We present results  </abstract>::line_number::17
<abstract> on artificial textured images (Brodatz) and report on our experiences with  </abstract>::line_number::18
<abstract> x-ray images.   </abstract>::line_number::19
<abstract>  Abstract. In this work it will be shown, how the comparison of recursive program schemata (RPS) can be reduced to an only slightly modified  </abstract>::line_number::8
<abstract> type of the search for maximal isomorphic subgraphs by interpreting the  </abstract>::line_number::9
<abstract> RPS as directed, cyclic, labelled graphs. The quality of the mapping of  </abstract>::line_number::10
<abstract> two RPS can be used as a quantitative measure for similarity of RPS  </abstract>::line_number::11
<abstract> among each other. The simultaneously calculated graph morphism can  </abstract>::line_number::12
<abstract> serve as a basis for the detection of analogies between the RPS. A special  </abstract>::line_number::13
<abstract> neural net, developed for the solution of general graph-matching problems, realizes the search for a sensible and as comprising as possible  </abstract>::line_number::14
<abstract> mapping between two RPS. It is shown, which special properties of RPS  </abstract>::line_number::15
<abstract> have to be accounted for in the modeling and how these can be incorporated into the algorithms when using a special neural approach for the  </abstract>::line_number::16
<abstract> solution.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Kinetic simulation of plasmas in which equilibrium occurs over ion timescales poses  </abstract>::line_number::8
<abstract> a computational challenge due to the disparate timescales of the electron plasma frequency (~ 10 9 ), the ion plasma frequency (~ 10 7 ), ion transit frequency (~ 10 6 ), and  </abstract>::line_number::9
<abstract> the ionization frequency (~ 10 7 ). Hybrid electrostatic PIC algorithms are presented  </abstract>::line_number::10
<abstract> in which the electrons reach thermodynamic equilibrium with the ions each time step.  </abstract>::line_number::11
<abstract> There are two different approximations for the electrons. First, the nonlinear Boltzmann relationship for the electrons can be applied to the bulk of a plasma. Second,  </abstract>::line_number::12
<abstract> there is a truncated Maxwellian which is used in sheaths; this approximation truncates  </abstract>::line_number::13
<abstract> the electron distribution at the wall potential. The error associated with neglecting  </abstract>::line_number::14
<abstract> this second approximation in the sheath is small. The collision cross section, (E), can  </abstract>::line_number::15
<abstract> be a tabulated or fitted function; the method is implemented with He cross sections.  </abstract>::line_number::16
<abstract> These approximations neglect effects faster than ion time-scales, decreasing the computer time used by over an order of magnitude; however, they increase the complexity  </abstract>::line_number::17
<abstract> of the boundary conditions and the simulation is no longer self-consistent. Theoretical  </abstract>::line_number::18
<abstract> ramifications of these approximations are examined, and results are compared with full   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Experiments have shown[1],[2] that ion acoustic solitons tunnel through the space charge sheath  </abstract>::line_number::6
<abstract> in front of a grid without time delay. They are absorbed resonantly when the spatial width of the  </abstract>::line_number::7
<abstract> wave is close to the characteristic gradient scale length of the sheath. The reflection and transmission  </abstract>::line_number::8
<abstract> coefficients found in these experiments have compared well with theory in the long wavelength limit[3].  </abstract>::line_number::9
<abstract> However, to achieve this comparison, two parameters were added that were not in the original theory.  </abstract>::line_number::10
<abstract> These parameters allow for the absorption of wave energy by the space charge sheath. The goal of our  </abstract>::line_number::11
<abstract> numerical simulations, designed to reproduce the experimental results, is to uncover the mechanism of  </abstract>::line_number::12
<abstract> this energy loss and large speed of propagation through the sheath.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This survey paper describes the current approaches on the update-in-place analysis  </abstract>::line_number::9
<abstract> for sets. Pure functional languages do not allow mutations, destructive updates, or selective updates so that straightforward implementations of functional language compilers  </abstract>::line_number::10
<abstract> may induce large amounts of copying to preserve program semantics. The unnecessary  </abstract>::line_number::11
<abstract> copying of data can increase both the execution time and the memory requirements of  </abstract>::line_number::12
<abstract> an application. Introducing sets to functional languages as a primitive data constructor posts a new problem of update-in-place analysis in functional languages. Moreover, most of the compiler optimization techniques depend on the side-effects and the  </abstract>::line_number::13
<abstract> update-in-place analysis serves as the premise of applying such optimization techniques.  </abstract>::line_number::14
<abstract> Among other compiler optimization techniques, finite differencing captures common yet  </abstract>::line_number::15
<abstract> distinctive program constructions of costly repeated calculations and transforms them  </abstract>::line_number::16
<abstract> into more efficient incremental program constructions. This dissertation is an attempt  </abstract>::line_number::17
<abstract> to explore the update-in-place analysis for sets in functional languages in order to apply finite differencing to compiling pure functional languages. In this survey paper,  </abstract>::line_number::18
<abstract> we will describe the approaches of update-in-place analysis and the finite differencing  </abstract>::line_number::19
<abstract> techniques.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::8
<abstract> A search for charginos and neutralinos, predicted by supersymmetric theories, has been  </abstract>::line_number::9
<abstract> performed using a data sample of 2.6 pb 1 at a centre-of-mass energy of p s =130 GeV and  </abstract>::line_number::10
<abstract> 2.6 pb 1 at 136 GeV collected with the OPAL detector at LEP during November 1995. No  </abstract>::line_number::11
<abstract> candidate events were observed. The 95% C.L. lower limit on the lightest chargino mass  </abstract>::line_number::12
<abstract> in the Minimal Supersymmetric Standard Model is 65.4 GeV if the universal scalar mass  </abstract>::line_number::13
<abstract> m 0 is greater than 1 TeV, and 58.7 GeV for the smallest m 0 compatible with slepton and  </abstract>::line_number::14
<abstract> sneutrino mass limits obtained at centre-of-mass energies near the Z peak. These limits  </abstract>::line_number::15
<abstract> were obtained under the conditions that the lightest chargino is heavier than the lightest  </abstract>::line_number::16
<abstract> neutralino by more than 10 GeV and tan fi is larger than 1.5. The results of a model  </abstract>::line_number::17
<abstract> independent search for charginos and neutralinos are also given.   </abstract>::line_number::18
<abstract>  We first describe the general goals of system administration explaining the  </abstract>::line_number::2
<abstract> relationship to monitoring, diagnosing, and repairing (MDR). Then, we describe the  </abstract>::line_number::3
<abstract> functional and environmental concerns for a MDR system, and use these concerns to  </abstract>::line_number::4
<abstract> explain how previous approaches have failed to fully address the problem. Next, we  </abstract>::line_number::5
<abstract> describe the major pieces of our approach, and identify the research questions  </abstract>::line_number::6
<abstract> associated with each piece. Finally we present a method for testing the system when  </abstract>::line_number::7
<abstract> it is created.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We use the two time influence functional method of the path integral approach in  </abstract>::line_number::10
<abstract> order to reduce the dimension of the coupled-channels equations for heavy-ion reactions  </abstract>::line_number::11
<abstract> based on the no-Coriolis approximation. Our method is superior to other methods in that  </abstract>::line_number::12
<abstract> it easily enables us to study the cases where the initial spin of the colliding particle is not  </abstract>::line_number::13
<abstract> zero. It can also be easily applied to the cases where there is a spin-orbit force, and where  </abstract>::line_number::14
<abstract> the internal degrees of freedom are not necessarily collective coordinates. It also clarifies  </abstract>::line_number::15
<abstract> the underlying assumption of the approximation.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We argue that the specification of an object's functional behavior and the timing constraints imposed  </abstract>::line_number::10
<abstract> on it may be separated. Specifically, we describe  </abstract>::line_number::11
<abstract> RTsynchronizer, a high-level programming language  </abstract>::line_number::12
<abstract> construct for specifying real-time constraints between  </abstract>::line_number::13
<abstract> objects in a distributed concurrent system. During program execution, RTsynchronizers affect the  </abstract>::line_number::14
<abstract> scheduling of distributed objects to enforce real-time  </abstract>::line_number::15
<abstract> relations between events. Objects in our system are  </abstract>::line_number::16
<abstract> defined in terms of the actor model extended with  </abstract>::line_number::17
<abstract> timing assumptions. Separation of the functional  </abstract>::line_number::18
<abstract> behaviors of actors and the timing constraints on  </abstract>::line_number::19
<abstract> patterns of actor invocation provides at least three  </abstract>::line_number::20
<abstract> important advantages. First, it simplifies code development by separating design concerns. Second,  </abstract>::line_number::21
<abstract> multiple timing constraints can be independently  </abstract>::line_number::22
<abstract> specified and composed. And finally, a specification  </abstract>::line_number::23
<abstract> of timing constraints can be reused even if the  </abstract>::line_number::24
<abstract> representation of the functional behavior of actors has  </abstract>::line_number::25
<abstract> changed, and conversely.  </abstract>::line_number::26
<abstract> A number of examples are given to illustrate the  </abstract>::line_number::27
<abstract> use of RTsynchronizers. These examples illustrate  </abstract>::line_number::28
<abstract> how real-time constraints for periodic events, simultaneous events, exception handling, and producer-consumer may be specified.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::11
<abstract> Concurrent systems maintain a distributed state and thus require coordination and synchronization between  </abstract>::line_number::12
<abstract> components to ensure consistency. To provide a coherent design approach to concurrent systems, recent work  </abstract>::line_number::13
<abstract> has employed an object-based methodology which emphasizes interactions through well-defined interfaces. The  </abstract>::line_number::14
<abstract> Actor model has provided formal reasoning about distributed object systems. Nonetheless, due to the complex  </abstract>::line_number::15
<abstract> interactions among components and the high volume of observable information produced, understanding and  </abstract>::line_number::16
<abstract> reasoning about concurrent algorithms in terms of simple interactions is a difficult task. Coordination patterns,  </abstract>::line_number::17
<abstract> which abstract over simple interactions, are not biased by low-level event orderings and are the appropriate  </abstract>::line_number::18
<abstract> mechanism for reasoning about concurrent algorithms. We outline a methodology for visualizing coordination  </abstract>::line_number::19
<abstract> patterns in concurrent algorithms which emphasizes observable interactions and causal connections between  </abstract>::line_number::20
<abstract> objects. We introduce visualizers as a linguistic mechanism for mapping coordination patterns to visualization.  </abstract>::line_number::21
<abstract> Visualizers are specified separately from algorithm code and thus respect code integrity. Moreover, visualizers  </abstract>::line_number::22
<abstract> may be implemented strictly in terms of object interfaces and thus preserve object encapsulation.   </abstract>::line_number::23
<abstract>  Abstract| This paper presents a system for billing users  </abstract>::line_number::3
<abstract> for their TCP traffic. This is achieved by postponing the  </abstract>::line_number::4
<abstract> establishment of connections while the user is contacted,  </abstract>::line_number::5
<abstract> verifying in a secure way that they are prepared to pay. By  </abstract>::line_number::6
<abstract> presenting the user with cost and price information, the system can be used for cost recovery and to encourage efficient  </abstract>::line_number::7
<abstract> use of network resources. The system requires no changes to  </abstract>::line_number::8
<abstract> existing protocols or applications and can be used to recover  </abstract>::line_number::9
<abstract> costs between cooperating sites. Statistics collected from a  </abstract>::line_number::10
<abstract> four day trace of traffic between the University of Califor-nia, Berkeley and the rest of the Internet demonstrate that  </abstract>::line_number::11
<abstract> such a billing system is practical and introduces acceptable  </abstract>::line_number::12
<abstract> latency. An implementation based on the BayBridge prototype router is described. Our study also indicates that  </abstract>::line_number::13
<abstract> pricing schemes may be used to control network congestion  </abstract>::line_number::14
<abstract> either by rescheduling time-insensitive traffic to a less expensive time of the day, or by smoothing packet transfers to  </abstract>::line_number::15
<abstract> reduce traffic peaks.   </abstract>::line_number::16
<abstract>  Abstract   </abstract>::line_number::11
<abstract> Learning to predict rare events from sequences of events  </abstract>::line_number::12
<abstract> with categorical features is an important, real-world,  </abstract>::line_number::13
<abstract> problem that existing statistical and machine learning  </abstract>::line_number::14
<abstract> methods are not well suited to solve. This paper describes  </abstract>::line_number::15
<abstract> timeweaver, a genetic algorithm based machine learning  </abstract>::line_number::16
<abstract> system that predicts rare events by identifying predictive  </abstract>::line_number::17
<abstract> temporal and sequential patterns. Timeweaver is applied to  </abstract>::line_number::18
<abstract> the task of predicting telecommunication equipment failures  </abstract>::line_number::19
<abstract> from 110,000 alarm messages and is shown to outperform  </abstract>::line_number::20
<abstract> existing learning methods.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Object recognition, which involves the classification of objects into one of many a priori known object types, and determining object characteristics such as pose, is a difficult  </abstract>::line_number::8
<abstract> problem. A wide range of approaches have been proposed and applied to this problem with  </abstract>::line_number::9
<abstract> limited success. This paper presents a brief comparative study of methods from three different paradigms for object recognition: Bayesian, Neural Network and Expert Systems.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Rules extracted from trained feedforward networks  </abstract>::line_number::8
<abstract> can be used for explanation, validation, and cross-referencing of network output decisions. This paper  </abstract>::line_number::9
<abstract> introduces a rule evaluation and ordering mechanism  </abstract>::line_number::10
<abstract> that orders rules extracted from feedforward networks  </abstract>::line_number::11
<abstract> based on three performance measures. Detailed experiments using three rule extraction techniques as applied  </abstract>::line_number::12
<abstract> to the Wisconsin breast cancer database, illustrate the  </abstract>::line_number::13
<abstract> power of the proposed methods. Moreover, a method  </abstract>::line_number::14
<abstract> of integrating the output decisions of both the extracted  </abstract>::line_number::15
<abstract> rule-based system and the corresponding trained network is proposed. The integrated system provides further improvements.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This note provides information for using the Fortran program [Friedman (1996b)] that imple  </abstract>::line_number::8
<abstract> ments the recursive covering approach to local learning described in Friedman (1996a).   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::4
<abstract> The properties of Rayleigh fading channels are derived and their  </abstract>::line_number::5
<abstract> effects on various QAM signal constellations are explored. A simplified  </abstract>::line_number::6
<abstract> channel model for an urban radio environment is justified in order  </abstract>::line_number::7
<abstract> to simplify the analysis of error performance for the constellations.  </abstract>::line_number::8
<abstract> Finally, arguments are made for extending the results to more general  </abstract>::line_number::9
<abstract> channel models.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Asymptotic tracking is studied for systems in which the relative degree is not well defined,  </abstract>::line_number::6
<abstract> meaning that the control law derived from exact input-output linearization has singularities in  </abstract>::line_number::7
<abstract> the state space. We propose a tracking control law which switches between approximate tracking  </abstract>::line_number::8
<abstract> [1] close to the singularities, and exact tracking away from the singularities, and we study the  </abstract>::line_number::9
<abstract> applicability of this law based on the behavior of the system's zero dynamics at the switching  </abstract>::line_number::10
<abstract> boundary. As in [1], the ball and beam example is used to motivate the study.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A case study of the use of simulation as a tool  </abstract>::line_number::7
<abstract> for design and validation of hybrid systems is presented. We use the Intelligent Vehicle Highway Systems (IVHS) architecture of [1], a system that involves  </abstract>::line_number::8
<abstract> both continuous state and discrete event controllers as  </abstract>::line_number::9
<abstract> our example of a hierarchical hybrid system. We point  </abstract>::line_number::10
<abstract> out that even though analytical methods do not exist  </abstract>::line_number::11
<abstract> for verification of hybrid control system, a simulation  </abstract>::line_number::12
<abstract> tool can be useful to (in)validate that the the hybrid  </abstract>::line_number::13
<abstract> system operates properly.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Using linguistic variables to describe the behavior of a  </abstract>::line_number::8
<abstract> hybrid system, which consists of a discrete event system and a continuous system, could make the design  </abstract>::line_number::9
<abstract> of the controller and verification of the system perform  </abstract>::line_number::10
<abstract> on an unified framework. In this paper, we show the  </abstract>::line_number::11
<abstract> construction of a fuzzy linguistic model from a given  </abstract>::line_number::12
<abstract> mathematical model of a physical system. By considering the state-space realization of the model, the system  </abstract>::line_number::13
<abstract> construction problem can be transformed into a function approximation problem. We propose to use projection theorem in obtaining an optimal fuzzy system  </abstract>::line_number::14
<abstract> which is the best approximation of a given nonlinear  </abstract>::line_number::15
<abstract> function in L 2 (U ) space. We show that the existence  </abstract>::line_number::16
<abstract> and uniqueness of the optimal solution is assured when  </abstract>::line_number::17
<abstract> the Fuzzy Basis Functions(FBFs) are linearly independent. We demonstrate that the dependence of the basis  </abstract>::line_number::18
<abstract> functions can be examined by checking the condition of  </abstract>::line_number::19
<abstract> the Gram determinant associated to the FBFs. Finally,  </abstract>::line_number::20
<abstract> a method is proposed in converting the optimal coefficients into fuzzy sets to obtain a fuzzy linguistic model.   </abstract>::line_number::21
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> In a new collaborative project involving the University of California, Berkeley, NASA Ames Research  </abstract>::line_number::7
<abstract> Center, and Honeywell Systems Research Center, we  </abstract>::line_number::8
<abstract> have begun the study of hierarchical, hybrid control  </abstract>::line_number::9
<abstract> systems in the framework of air traffic management  </abstract>::line_number::10
<abstract> systems (ATMS). The need for a new ATMS arises  </abstract>::line_number::11
<abstract> from the overcrowding of large urban airports and  </abstract>::line_number::12
<abstract> the need to more efficiently land and take off larger  </abstract>::line_number::13
<abstract> numbers of aircraft, without building new runways.  </abstract>::line_number::14
<abstract> Technological advances that make a more advanced  </abstract>::line_number::15
<abstract> air traffic control system a reality include the availability of relatively inexpensive and fast real time  </abstract>::line_number::16
<abstract> computers (both on board the aircraft and in the control tower) and global positioning systems. The usefulness of these technological advances is currently  </abstract>::line_number::17
<abstract> limited by today's air traffic control system, which  </abstract>::line_number::18
<abstract> involves the use of "freeways" in the Terminal Radar  </abstract>::line_number::19
<abstract> Approach Control (TRACON) region around urban  </abstract>::line_number::20
<abstract> airports. These freeways are set approach patterns  </abstract>::line_number::21
<abstract> to runways which do not allow for the possibility of  </abstract>::line_number::22
<abstract> so-called "free flight" by an aircraft to its destination.  </abstract>::line_number::23
<abstract> Limiting the aircraft trajectories in this manner results in the addition of both planned and unplanned  </abstract>::line_number::24
<abstract> delays to air travel.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We propose a hierarchical control architecture for dealing with faults and adverse environmental conditions on an Automated Highway System (AHS). Our design extends  </abstract>::line_number::8
<abstract> a previous control architecture that works under normal conditions of operation. The  </abstract>::line_number::9
<abstract> faults that are considered in our design are classified according to the capabilities remaining on the vehicle or roadside after the fault has occurred. Information about these  </abstract>::line_number::10
<abstract> capabilities is used by supervisors in each of the layers of the architecture to select appropriate control strategies. We outline the extended control strategies that are needed  </abstract>::line_number::11
<abstract> by these supervisors and, in certain cases, give examples of their detailed operation.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The aim of this paper is to explore intrinsic geometric methods of recovering the three  </abstract>::line_number::9
<abstract> dimensional motion of a moving camera from a sequence of images. Generic similarities between  </abstract>::line_number::10
<abstract> the discrete approach and the differential approach are revealed through a parallel development  </abstract>::line_number::11
<abstract> of their analogous motion estimation theories.  </abstract>::line_number::12
<abstract> We begin with a brief review of the (discrete) essential matrix approach, showing how to  </abstract>::line_number::13
<abstract> recover the 3D displacement from image correspondences. The space of normalized essential  </abstract>::line_number::14
<abstract> matrices is characterized geometrically: the unit tangent bundle of the rotation group is a  </abstract>::line_number::15
<abstract> double covering of the space of normalized essential matrices. This characterization naturally  </abstract>::line_number::16
<abstract> explains the geometry of the possible number of 3D displacements which can be obtained from  </abstract>::line_number::17
<abstract> the essential matrix.  </abstract>::line_number::18
<abstract> Second, a differential version of the essential matrix constraint previously explored by [19, 20]  </abstract>::line_number::19
<abstract> is introduced. We then present the precise characterization of the space of differential essential  </abstract>::line_number::20
<abstract> matrices, which gives rise to a novel eigenvector-decomposition-based 3D velocity estimation  </abstract>::line_number::21
<abstract> algorithm from the optical flow measurements. This algorithm gives a unique solution to the  </abstract>::line_number::22
<abstract> motion estimation problem and serves as a differential counterpart of the SVD-based 3D displacement estimation algorithm from the discrete case.  </abstract>::line_number::23
<abstract> Finally, simulation results are presented evaluating the performance of our algorithm in terms  </abstract>::line_number::24
<abstract> of bias and sensitivity of the estimates with respect to the noise in optical flow measurements.  </abstract>::line_number::25
<abstract> The presented unifying theory of the motion estimation using discrete and differential version of the Longuet-Higgins (essential) constraint can be extended to the case of uncalibrated  </abstract>::line_number::26
<abstract> cameras.   </abstract>::line_number::27
<abstract>  ABSTRACT  </abstract>::line_number::10
<abstract> Air Traffic Management Systems (ATMS) of the future will feature Free Flight, in which aircraft choose  </abstract>::line_number::11
<abstract> their own routes, altitude, and speed, and automated conflict resolution methods in which aircraft  </abstract>::line_number::12
<abstract> will coordinate to resolve conflicts. The resulting distributed control architecture is a hybrid system, with  </abstract>::line_number::13
<abstract> mixed discrete event and continuous time dynamics.  </abstract>::line_number::14
<abstract> SmartATMS is an object oriented modeling and simulation facility which accounts for these hybrid issues  </abstract>::line_number::15
<abstract> and will serve as a uniform modeling framework for  </abstract>::line_number::16
<abstract> the design and evaluation of various ATMS concepts.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> MineSet TM , Silicon Graphics' interactive system for  </abstract>::line_number::9
<abstract> data mining, integrates three powerful technologies:  </abstract>::line_number::10
<abstract> database access, analytical data mining, and data visualization. It supports the knowledge discovery process from data access and preparation through iterative analysis and visualization to deployment. Mine-Set is based on a client-server architecture that scales  </abstract>::line_number::11
<abstract> to large databases. The database access component  </abstract>::line_number::12
<abstract> provides a rich set of operators that can be used to  </abstract>::line_number::13
<abstract> preprocess and transform the stored data into forms  </abstract>::line_number::14
<abstract> appropriate for visualization and analytical mining.  </abstract>::line_number::15
<abstract> The 3D visualization capabilities allow direct data visualization for exploratory analysis, including tools  </abstract>::line_number::16
<abstract> for displaying high-dimensional data containing geographical and hierarchical information. The analytical mining algorithms help identify potentially interesting models of the data, which can be viewed using  </abstract>::line_number::17
<abstract> visualization tools specialized for the learned models.  </abstract>::line_number::18
<abstract> Third party vendors can interface to the MineSet tools  </abstract>::line_number::19
<abstract> for model deployment and for integration with other  </abstract>::line_number::20
<abstract> packages.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We present a user interface paradigm for  </abstract>::line_number::7
<abstract> database management systems that is motivated  </abstract>::line_number::8
<abstract> by scientific visualization applications. Our  </abstract>::line_number::9
<abstract> graphical user interface includes a "boxes and arrows" notation for database access and a flight  </abstract>::line_number::10
<abstract> simulator model of movement through information space. We also provide means to specify a  </abstract>::line_number::11
<abstract> hierarchy of abstracts of data of different types  </abstract>::line_number::12
<abstract> and resolutions, so that a "zoom" capability can  </abstract>::line_number::13
<abstract> be supported. The underlying DBMS support for  </abstract>::line_number::14
<abstract> this system is described and includes the compilation of query plans into megaplans, new algorithms for data buffering, and provisions for  </abstract>::line_number::15
<abstract> a guaranteed rate of data delivery. The current state of the Tioga implementation is also described.   </abstract>::line_number::16
<abstract>  ABSTRACT  </abstract>::line_number::8
<abstract> In this paper we present a prototype system for  </abstract>::line_number::9
<abstract> the management of earth science data which is  </abstract>::line_number::10
<abstract> novel in that it takes a DBMS centric view of the  </abstract>::line_number::11
<abstract> the task. Our prototype -- called "BigSur" -- is  </abstract>::line_number::12
<abstract> shown in the context of its use by two geographically distributed scientific groups with demanding data storage and processing requirements.  </abstract>::line_number::13
<abstract> BigSur currently stores 1 Terabyte of data, about  </abstract>::line_number::14
<abstract> one thousandth of the volume EOSDIS must  </abstract>::line_number::15
<abstract> store. We claim that the design principles  </abstract>::line_number::16
<abstract> embodied in BigSur provide sufficient exibility  </abstract>::line_number::17
<abstract> to achieve the difficult scientific and technical  </abstract>::line_number::18
<abstract> objectives of Mission to Planet Earth.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The increasing size and complexity of many software  </abstract>::line_number::9
<abstract> systems demand a greater emphasis on capturing and  </abstract>::line_number::10
<abstract> maintaining knowledge at many different levels within  </abstract>::line_number::11
<abstract> the software development process. This knowledge includes descriptions of the hardware and software components and their behavior, external and internal design specifications, and support for system testing.  </abstract>::line_number::12
<abstract> The knowledge-based software engineering (KBSE) research paradigm is concerned with systems that use  </abstract>::line_number::13
<abstract> formally represented knowledge, with associated inference procedures, to support the various subactivi-ties of software development. As they grow in scale,  </abstract>::line_number::14
<abstract> KBSE systems must balance expressivity and inferential power with the real demands of knowledge base  </abstract>::line_number::15
<abstract> construction, maintenance, performance and comprehensibility. Description Logics (DL's) possess several  </abstract>::line_number::16
<abstract> features a terminological orientation, a formal semantics and efficient reasoning procedures which offer an effective tradeoff of these factors. We discuss  </abstract>::line_number::17
<abstract> three KBSE systems in which DL's capture some of  </abstract>::line_number::18
<abstract> the requisite knowledge needed to support design, coding and testing activities. We close with a discussion  </abstract>::line_number::19
<abstract> of the benefits of DL's and ways to address some of  </abstract>::line_number::20
<abstract> their limitations.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> People can differentiate spoken languages  </abstract>::line_number::8
<abstract> without understanding them, and, in some  </abstract>::line_number::9
<abstract> sense, this differentiation can only be done  </abstract>::line_number::10
<abstract> without understanding the language. When  </abstract>::line_number::11
<abstract> we consider a multi-lingual person trying to  </abstract>::line_number::12
<abstract> understand an utterance spoken in one of the  </abstract>::line_number::13
<abstract> languages with which they are familiar, they  </abstract>::line_number::14
<abstract> will first decide which language this utterance  </abstract>::line_number::15
<abstract> belongs to, before trying to interpret it.  </abstract>::line_number::16
<abstract> The language identification task is one  </abstract>::line_number::17
<abstract> example of high-level feature abstraction from  </abstract>::line_number::18
<abstract> raw speech. Speech samples are classified  </abstract>::line_number::19
<abstract> into categories according to what language  </abstract>::line_number::20
<abstract> was spoken. We conjecture that this classification can be performed reliably and in real  </abstract>::line_number::21
<abstract> time. To be successful, such a system should  </abstract>::line_number::22
<abstract> be speaker-independent as well as context-independent. A large amount of training is  </abstract>::line_number::23
<abstract> required to achieve a satisfactory level of performance.  </abstract>::line_number::24
<abstract> We present a continuation of previous  </abstract>::line_number::25
<abstract> work (Kwasny et al., 1992) which introduces  </abstract>::line_number::26
<abstract> two important improvements to the system:  </abstract>::line_number::27
<abstract> (1) replacement of the non-recurrent, feed-forward network with a recurrent one, which  </abstract>::line_number::28
<abstract> is smaller, but still classifies correctly; (2)  </abstract>::line_number::29
<abstract> development of a frontend processor on a  </abstract>::line_number::30
<abstract> Nextfi workstation to facilitate sample  </abstract>::line_number::31
<abstract> recording and data acquisition. This is important for large-scale data acquisition, training,  </abstract>::line_number::32
<abstract> and testing of the network.   </abstract>::line_number::33
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We consider the problem of maximum a posteriori (MAP) restoration of multicolor images  </abstract>::line_number::6
<abstract> where each pixel has been degraded by independent arbitrary noise. We assume that the  </abstract>::line_number::7
<abstract> prior distribution is given by a Markov random field with only pairwise site interactions.  </abstract>::line_number::8
<abstract> Two classes of site interactions are considered: two-valued site interactions, which form a  </abstract>::line_number::9
<abstract> generalized Potts model; and linear site interactions. We give efficient algorithms based on  </abstract>::line_number::10
<abstract> graph cuts for both classes. The MAP estimate for a generalized Potts model can be computed by solving a multiway minimum cut problem on a graph. While this graph problem is  </abstract>::line_number::11
<abstract> computationally intractable, there are fast algorithms for computing provably good approximations. The MAP estimate with linear site interactions can be computed exactly by solving  </abstract>::line_number::12
<abstract> a minimum cut problem on a graph. This can be performed in nearly linear time.   </abstract>::line_number::13
<abstract>  Abstract: This paper presents several patterns for distributing business information systems that are structured according to a layered architecture. 2 Each distribution pattern cuts the architecture into different client and server components. All  </abstract>::line_number::21
<abstract> the patterns presented give an answer to the same question: How do I distribute a  </abstract>::line_number::22
<abstract> business information system? However, the consequences of applying the patterns  </abstract>::line_number::23
<abstract> are very different with regards to the forces influencing distributed systems design.   </abstract>::line_number::24
<abstract>  Intent  </abstract>::line_number::7
<abstract> Define the interface for a hierarchy of classes while deferring the implementation to subclasses.  </abstract>::line_number::8
<abstract> Abstract Class lets subclasses redefine the implementation of an interface while preserving the  </abstract>::line_number::9
<abstract> polymorphism of those classes.  </abstract>::line_number::10
<abstract> Also Known As  </abstract>::line_number::11
<abstract> Liskov Substitution Principle [LW93], Design by Contract [Meyer91], Base Class [Auer95] ,  </abstract>::line_number::12
<abstract> Template Class [Woolf97]   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::13
<abstract> Query caching can play a vital role in heterogeneous, multi-database environments. Answers to a query that are available in cache  </abstract>::line_number::14
<abstract> at the local client can be returned to the user  </abstract>::line_number::15
<abstract> quickly, while the rest of the query is evaluated. The use of caches can optimize query  </abstract>::line_number::16
<abstract> evaluation. By caching certain sensitive data  </abstract>::line_number::17
<abstract> locally, caches can be used to answer the parts  </abstract>::line_number::18
<abstract> of queries that involve the sensitive data, so it  </abstract>::line_number::19
<abstract> need not be shipped across the network. Most  </abstract>::line_number::20
<abstract> prior cache schemes have been tuple-based or  </abstract>::line_number::21
<abstract> page-based. It is unclear, however, how these  </abstract>::line_number::22
<abstract> might be adapted for multi-databases. We explore a more flexible semantic query caching  </abstract>::line_number::23
<abstract> (SQC) approach. In SQC, caches are the answer sets of previous queries, labeled by the  </abstract>::line_number::24
<abstract> query expressions that produced them. We  </abstract>::line_number::25
<abstract> promote developing the technology, based on  </abstract>::line_number::26
<abstract> logic, to manipulate semantic caches, to determine when and how caches can be used to answer subsequent queries, and to optimize via  </abstract>::line_number::27
<abstract> cache use.   </abstract>::line_number::28
<abstract>  Abstract. This paper develops a new I/O automaton model called the  </abstract>::line_number::4
<abstract> Clock General Timed Automaton (Clock GTA) model. The Clock GTA  </abstract>::line_number::5
<abstract> is based on the General Timed Automaton (GTA) of Lynch and Vaan-  </abstract>::line_number::6
<abstract> drager. The Clock GTA provides a systematic way of describing timing-  </abstract>::line_number::7
<abstract> based systems in which there is a notion of "normal" timing behavior,  </abstract>::line_number::8
<abstract> but that do not necessarily always exhibit this "normal" behavior. It can  </abstract>::line_number::9
<abstract> be used for practical time performance analysis based on the stabilization  </abstract>::line_number::10
<abstract> of the physical system.  </abstract>::line_number::11
<abstract> We use the Clock GTA automaton to model, verify and analyze the  </abstract>::line_number::12
<abstract> paxos algorithm. The paxos algorithm is an efficient and highly fault-  </abstract>::line_number::13
<abstract> tolerant algorithm, devised by Lamport, for reaching consensus in a distributed system. Although it appears to be practical, it is not widely  </abstract>::line_number::14
<abstract> known or understood. This paper contains a new presentation of the  </abstract>::line_number::15
<abstract> paxos algorithm, based on a formal decomposition into several interacting components. It also contains a correctness proof and a time performance and fault-tolerance analysis.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::3
<abstract> Consider an n-vertex, m-edge, undirected graph with maximum flow value v. We give a method to find augmenting  </abstract>::line_number::4
<abstract> paths in such a graph in amortized sub-linear (O(n  </abstract>::line_number::5
<abstract> p  </abstract>::line_number::6
<abstract> v)) time  </abstract>::line_number::7
<abstract> per path. This lets us improve the time bound of the classic augmenting path algorithm to O(m + nv 3=2 ) on simple  </abstract>::line_number::8
<abstract> graphs. The addition of a blocking flow subroutine gives a  </abstract>::line_number::9
<abstract> simple, deterministic O(nm 2=3 v 1=6 )-time algorithm. We also  </abstract>::line_number::10
<abstract> use our technique to improve known randomized algorithms,  </abstract>::line_number::11
<abstract> giving O(m+nv 5=4 )-time and O(m+n 11=9 v)-time algorithms  </abstract>::line_number::12
<abstract> for capacitated undirected graphs. For simple graphs, in  </abstract>::line_number::13
<abstract> which v n, the last bound is O(n 2:2 ), improving on the best  </abstract>::line_number::14
<abstract> previous bound of O(n 2:5 ), which is also the best known time  </abstract>::line_number::15
<abstract> bound for bipartite matching.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We consider a system of distributed processors that  </abstract>::line_number::5
<abstract> communicate by passing messages and that have inexact information about time. Specifically, a processor knows that a single message is delayed by at most  </abstract>::line_number::6
<abstract> time d and the time between any two of its consecutive steps is at least c 1 and at most c 2 ; it has no  </abstract>::line_number::7
<abstract> other way of estimating elapsed time. This simple  </abstract>::line_number::8
<abstract> model is very close to traditional models used in distributed computing theory, and has been studied by  </abstract>::line_number::9
<abstract> Attiya and Lynch [2, 1] among others. We extend  </abstract>::line_number::10
<abstract> the model by making a realistic assumption about  </abstract>::line_number::11
<abstract> how the delay of messages is affected by the rate at  </abstract>::line_number::12
<abstract> which they are sent. We define a model of message  </abstract>::line_number::13
<abstract> links with bounded capacity, which are guaranteed to  </abstract>::line_number::14
<abstract> deliver messages at only a given rate. If a processor sends messages at a greater rate, they may incur  </abstract>::line_number::15
<abstract> greater delay.  </abstract>::line_number::16
<abstract> We quantify the effect of this bounded capacity on  </abstract>::line_number::17
<abstract> the time necessary to detect processor failures. We  </abstract>::line_number::18
<abstract> consider a system of two processors connected by a  </abstract>::line_number::19
<abstract> bi-directional message link of (integral) capacity .  </abstract>::line_number::20
<abstract> First we give two very simple protocols that guarantee any stopping failure will be detected within  </abstract>::line_number::21
<abstract> time 2Cd + d and C 2 d= + Cd + d respectively,  </abstract>::line_number::22
<abstract> where C = c 2 =c 1 . The main result is an almost-matching lower bound of 2Cd+d= or C 2 d=+Cd+d,  </abstract>::line_number::23
<abstract> whichever is less. If the link is uni-directional, our result specializes to give a matching upper and lower  </abstract>::line_number::24
<abstract> bound of C 2 d= + Cd + d.   </abstract>::line_number::25
<abstract>  Abstract. We present a new micropayment scheme based on the use of  </abstract>::line_number::5
<abstract> "electronic lottery tickets." This scheme is exceptionally efficient since  </abstract>::line_number::6
<abstract> the bank handles only winning tickets, instead of handling each micro  </abstract>::line_number::7
<abstract> payment.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::4
<abstract> SOLAR is a portable high-performance library for out-of-core dense  </abstract>::line_number::5
<abstract> matrix computations. It combines portability with high performance  </abstract>::line_number::6
<abstract> by using existing high-performance in-core subroutine libraries and  </abstract>::line_number::7
<abstract> by using an optimized matrix input-output library. SOLAR works on  </abstract>::line_number::8
<abstract> parallel computers, workstations, and personal computers. It supports  </abstract>::line_number::9
<abstract> in-core computations on both shared-memory and distributed-memory  </abstract>::line_number::10
<abstract> machines, and its matrix input-output library supports both conventional I/O interfaces and parallel I/O interfaces. This paper discusses  </abstract>::line_number::11
<abstract> the overall design of SOLAR, its interfaces, and the design of several  </abstract>::line_number::12
<abstract> important subroutines. Experimental results show that SOLAR can  </abstract>::line_number::13
<abstract> factor on a single workstation an out-of-core positive-definite symmetric matrix at a rate exceeding 215 Mflops, and an out-of-core general  </abstract>::line_number::14
<abstract> matrix at a rate exceeding 195 Mflops. Less than 16% of the running  </abstract>::line_number::15
<abstract> time is spent on I/O in these computations. These results indicate  </abstract>::line_number::16
<abstract> that SOLAR's portability does not compromise its performance. We  </abstract>::line_number::17
<abstract> expect that the combination of portability, modularity, and the use of  </abstract>::line_number::18
<abstract> a high-level I/O interface will make the library an important platform  </abstract>::line_number::19
<abstract> for research on out-of-core algorithms and on parallel I/O.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We have implemented a prototype compiler called porch that transforms C programs into C programs supporting portable checkpoints. Portable checkpoints capture the state of a computation in  </abstract>::line_number::7
<abstract> a machine-independent format that allows the transfer of computations across binary incompatible machines. We introduce source-to-source compilation techniques for generating code to save and  </abstract>::line_number::8
<abstract> recover from such portable checkpoints automatically. These techniques instrument a program with code that maps the state of a computation into a machine-independent representation and vice versa.  </abstract>::line_number::9
<abstract> In particular, the following problems are addressed: (1) providing  </abstract>::line_number::10
<abstract> stack environment portability, (2) enabling conversion of complex  </abstract>::line_number::11
<abstract> data types, and (3) rendering pointers portable. Experimental results show that the overhead of checkpointing is reasonably small,  </abstract>::line_number::12
<abstract> even if data representation conversion is required for portability.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We propose a new method for estimation in linear models. The "lasso"  </abstract>::line_number::7
<abstract> minimizes the residual sum of squares subject to the sum of the absolute  </abstract>::line_number::8
<abstract> value of the coefficients being less than a constant. Because of the nature  </abstract>::line_number::9
<abstract> of this constraint it tends to produce some coefficients that are exactly zero  </abstract>::line_number::10
<abstract> and hence gives interpretable models. Our simulation studies suggest that  </abstract>::line_number::11
<abstract> the lasso enjoys some of the favourable properties of both subset selection  </abstract>::line_number::12
<abstract> and ridge regression. It produces interpretable models like subset selection  </abstract>::line_number::13
<abstract> and exhibits the stability of ridge regression. There is also an interesting  </abstract>::line_number::14
<abstract> relationship with recent work in adaptive function estimation by Donoho  </abstract>::line_number::15
<abstract> and Johnstone. The lasso idea is quite general and can be applied in a  </abstract>::line_number::16
<abstract> variety of statistical models: extensions to generalized regression models  </abstract>::line_number::17
<abstract> and tree-based models are briefly described.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::7
<abstract> A new method for extracting planar polygonal rooftops in monocular aerial imagery is proposed. Through bottom-up and top-down construction of perceptual groups, polygons in a  </abstract>::line_number::8
<abstract> single aerial image can be robustly extracted.  </abstract>::line_number::9
<abstract> Orthogonal corners and lines are extracted and  </abstract>::line_number::10
<abstract> hierarchically related using perceptual grouping techniques. Top-down feature verification is  </abstract>::line_number::11
<abstract> used so that features, and links between the features, are verified with local information in the  </abstract>::line_number::12
<abstract> image and weighed in a graph structure according to the underlying support for each feature.  </abstract>::line_number::13
<abstract> Cycles in the graph correspond to possible  </abstract>::line_number::14
<abstract> building rooftop hypotheses. Virtual features  </abstract>::line_number::15
<abstract> are hypothesized for the perceptual completion  </abstract>::line_number::16
<abstract> of partial rooftops. Extraction of the "best"  </abstract>::line_number::17
<abstract> grouping of features into a building rooftop hypothesis is posed as a graph search problem.  </abstract>::line_number::18
<abstract> The maximally weighted, independent set of cycles in the graph is extracted as the final set of  </abstract>::line_number::19
<abstract> roof boundaries.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We describe a novel approach for image matching  </abstract>::line_number::9
<abstract> based on deformable intensity surfaces. In this  </abstract>::line_number::10
<abstract> approach, the intensity surface of the image  </abstract>::line_number::11
<abstract> is modeled as a deformable 3D mesh in the  </abstract>::line_number::12
<abstract> (x; ; I(x; )) space. Each surface point has 3  </abstract>::line_number::13
<abstract> degrees of freedom, thus capturing fine surface  </abstract>::line_number::14
<abstract> changes. A set of representative deformations  </abstract>::line_number::15
<abstract> within a class of objects (e.g. faces) are statistically learned through a Principal Components Analysis, thus providing a priori knowledge  </abstract>::line_number::16
<abstract> about object-specific deformations. We demonstrate the power of the approach by examples  </abstract>::line_number::17
<abstract> such as image matching and interpolation of  </abstract>::line_number::18
<abstract> missing data. Moreover this approach dramatically reduces the computational cost of solving  </abstract>::line_number::19
<abstract> the governing equation for the physically based  </abstract>::line_number::20
<abstract> system by approximately three orders of magni  </abstract>::line_number::21
<abstract> tude.  </abstract>::line_number::22
<abstract>  </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::5
<abstract> This paper presents a glove-free method for tracking  </abstract>::line_number::6
<abstract> hand movements using a set of 3-D models. In this  </abstract>::line_number::7
<abstract> approach, the hand is represented by five cylindrical  </abstract>::line_number::8
<abstract> models which are fit to the third phalangeal segments  </abstract>::line_number::9
<abstract> of the fingers. Six 3-D motion parameters for each  </abstract>::line_number::10
<abstract> model are calculated that correspond to the movement  </abstract>::line_number::11
<abstract> of the fingertips in the image plane. Trajectories of  </abstract>::line_number::12
<abstract> the moving models are then established to show the 3-D nature of hand motion.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Multi-chip module (MCM) packaging techniques present several new technical challenges, notably substrate testing. We formulate MCM substrate testing as a problem of connectivity verification in trees via k-probes, and present a linear-time algorithm which computes a minimum  </abstract>::line_number::7
<abstract> set of probes achieving complete open fault coverage. Since actual substrate testing also involves  </abstract>::line_number::8
<abstract> scheduling probe operations, we formulate efficient probe scheduling as a special type of metric  </abstract>::line_number::9
<abstract> traveling salesman optimization and give a provably-good heuristic. Empirical results using both  </abstract>::line_number::10
<abstract> random and industry benchmarks demonstrate reductions in testing costs of up to 21% over previous methods. We conclude with generalizations to alternate probe technologies and several open  </abstract>::line_number::11
<abstract> problems.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::4
<abstract> With fast switching speeds and large interconnect trees (MCMs), the  </abstract>::line_number::5
<abstract> resistance and inductance of interconnect has a dominant impact on  </abstract>::line_number::6
<abstract> logic gate delay. In this paper, we propose a new P model for distributed RC and RLC interconnects to estimate the driving point admittance at the output of a CMOS gate. Using this model we are able to  </abstract>::line_number::7
<abstract> compute the gate delay efficiently, within 25% of SPICE-computed delays. Our parameters depend only on total interconnect tree resistance  </abstract>::line_number::8
<abstract> and capacitance at the output of the gate. Previous effective load capacitance methods [7, 9], applicable only for distributed RC interconnects, are based on P model parameters obtained via a recursive admittance moment computation. Our model should be useful for iterative  </abstract>::line_number::9
<abstract> optimization of performance-driven routing or for estimation of gate  </abstract>::line_number::10
<abstract> delay and rise times in high-level synthesis.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::5
<abstract> With submicron technologies, gate delays are dominated by gate  </abstract>::line_number::6
<abstract> load delays rather than intrinsic gate delays. While the common approach for computing gate load delay (or total gate delay) is through  </abstract>::line_number::7
<abstract> delay tables (or k-factor equations), there are important methodology problems associated with the delay table approach. In this paper, we propose a gate driver model with a Thevenin equivalent circuit consisting of a ramp voltage source whose slew time is obtained  </abstract>::line_number::8
<abstract> from the gate slew tables, and a driver resistance in series with the  </abstract>::line_number::9
<abstract> gate load. We then develop analytical gate delay formulas using this  </abstract>::line_number::10
<abstract> Thevenin driver model and modeling the load with various gate load  </abstract>::line_number::11
<abstract> models under both rising and falling ramp input.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Increasingly popular reuse-based design paradigms create a pressing need for authorship enforcement techniques that protect the intellectual property rights of designers. We develop the first intellectual property protection protocols for embedding design watermarks at the physical design level. We demonstrate that these protocols are transparent with respect to existing industrial tools and  </abstract>::line_number::6
<abstract> design flows, and that they can embed watermarks into real-world  </abstract>::line_number::7
<abstract> industrial designs with very low implementation overhead (as measured by such standard metrics as wirelength, layout area, number  </abstract>::line_number::8
<abstract> of vias, routing congestion and CPU time). On several industrial  </abstract>::line_number::9
<abstract> test cases, we obtain extremely strong, tamper-resistant proofs of  </abstract>::line_number::10
<abstract> authorship for placement and routing solutions.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::16
<abstract> This paper presents general algorithms for concurrency control in  </abstract>::line_number::17
<abstract> tree-based access methods as well as a recovery protocol and a  </abstract>::line_number::18
<abstract> mechanism for ensuring repeatable read. The algorithms are developed in the context of the Generalized Search Tree (GiST) data  </abstract>::line_number::19
<abstract> structure, an index structure supporting an extensible set of queries  </abstract>::line_number::20
<abstract> and data types. Although developed in a GiST context, the algorithms are generally applicable to many tree-based access methods.  </abstract>::line_number::21
<abstract> The concurrency control protocol is based on an extension of the  </abstract>::line_number::22
<abstract> link technique originally developed for B-trees, and completely  </abstract>::line_number::23
<abstract> avoids holding node locks during I/Os. Repeatable read isolation is  </abstract>::line_number::24
<abstract> achieved with a novel combination of predicate locks and two-phase  </abstract>::line_number::25
<abstract> locking of data records. To our knowledge, this is the first time that  </abstract>::line_number::26
<abstract> isolation issues have been addressed outside the context of B-trees.  </abstract>::line_number::27
<abstract> A discussion of the fundamental structural differences between B-trees and more general tree structures like GiSTs explains why the  </abstract>::line_number::28
<abstract> algorithms developed here deviate from their B-tree counterparts.  </abstract>::line_number::29
<abstract> An implementation of GiSTs emulating B-trees in DB2/Common  </abstract>::line_number::30
<abstract> Server is underway.   </abstract>::line_number::31
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The problem we address is how to quickly estimate by simulation the loss in a  </abstract>::line_number::8
<abstract> buffer with multiclass on-off Markov fluid sources. We generate the Markov fluids  </abstract>::line_number::9
<abstract> with the altered rate matrices given in [11], instead of the originals, to speed up  </abstract>::line_number::10
<abstract> the simulation. Likelihood ratios are used to recover an estimate of the loss for the  </abstract>::line_number::11
<abstract> original traffic parameters.   </abstract>::line_number::12
<abstract>  Abstract. We present a new diagnostic algorithm, based on backward-propagation, for localising design  </abstract>::line_number::7
<abstract> errors in combinational logic circuits. Three hypotheses are considered, that cover all single gate replacement and insertion errors. Diagnosis-oriented test patterns are generated in order to rapidly reduce the  </abstract>::line_number::8
<abstract> suspected area where the error lies. The originality of our method is the use of patterns which do not  </abstract>::line_number::9
<abstract> detect the error, in addition to detecting patterns. A theorem shows that, in favourable cases, only two  </abstract>::line_number::10
<abstract> patterns suffice to get a correction. We have implemented the test generation and diagnosis algorithms.  </abstract>::line_number::11
<abstract> Results obtained on benchmarks show that the error is always found, after the application of a small  </abstract>::line_number::12
<abstract> number of test patterns, with an execution time proportional to the circuit size.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Don't care information has proven to be useful in logic minimization.  </abstract>::line_number::5
<abstract> Here, the use of don't care information in network collapsing for mapping  </abstract>::line_number::6
<abstract> to LUT-based FPGAs is explored. Results are shown which indicate that  </abstract>::line_number::7
<abstract> this approach does not result in appreciable improvements in network size.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::3
<abstract> The simulation preorder on state transition systems is widely accepted as a  </abstract>::line_number::4
<abstract> useful notion of refinement, both in its own right and as an efficiently checkable sufficient condition for trace containment. For composite systems, due to  </abstract>::line_number::5
<abstract> the exponential explosion of the state space, there is a need for decomposing a  </abstract>::line_number::6
<abstract> simulation check of the form P s Q into simpler simulation checks on the components of P and Q. We present an assume-guarantee rule that enables such a  </abstract>::line_number::7
<abstract> decomposition. To the best of our knowledge, this is the first assume-guarantee  </abstract>::line_number::8
<abstract> rule that applies to a refinement relation different from trace containment. Our  </abstract>::line_number::9
<abstract> rule is circular, and its soundness proof requires induction on trace-trees. The  </abstract>::line_number::10
<abstract> proof is constructive: given simulation relations that witness the simulation  </abstract>::line_number::11
<abstract> preorder between components, we provide a procedure for constructing a witness relation for P s Q. We also extend our assume-guarantee rule to account  </abstract>::line_number::12
<abstract> for fairness assumptions on transition systems.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::10
<abstract> In this paper we develop a simple analytic characterization of the steady state throughput, as a function of loss rate and round trip time for a bulk transfer TCP flow, i.e., a flow with an unlimited amount  </abstract>::line_number::11
<abstract> of data to send. Unlike the models in [6, 7, 10], our model captures not only the behavior of TCP's fast  </abstract>::line_number::12
<abstract> retransmit mechanism (which is also considered in [6, 7, 10]) but also the effect of TCP's timeout mechanism on throughput. Our measurements suggest that this latter behavior is important from a modeling  </abstract>::line_number::13
<abstract> perspective, as almost all of our TCP traces contained more timeout events than fast retransmit events.  </abstract>::line_number::14
<abstract> Our measurements demonstrate that our model is able to more accurately predict TCP throughput and is  </abstract>::line_number::15
<abstract> accurate over a wider range of loss rates.  </abstract>::line_number::16
<abstract> This material is based upon work supported by the National Science Foundation under grants NCR-95-08274, NCR-95-23807  </abstract>::line_number::17
<abstract> and CDA-95-02639. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors  </abstract>::line_number::18
<abstract> and do not necessarily reflect the views of the National Science Foundation.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::15
<abstract> In the past few years there has been an increasing interest in workflow applications as a  </abstract>::line_number::16
<abstract> way of supporting complex business processes in modern corporations. Given the nature  </abstract>::line_number::17
<abstract> of the environment and the technology involved, workflow applications are inherently  </abstract>::line_number::18
<abstract> distributed and pose many interesting challenges to the system designer. In most cases, a  </abstract>::line_number::19
<abstract> client/server architecture is used in which knowledge about the processes being executed is  </abstract>::line_number::20
<abstract> centralized in one node to facilitate monitoring, auditing, and to simplify synchronization.  </abstract>::line_number::21
<abstract> In this paper, we explore a novel distributed architecture, Exotica/FMQM, for workflow  </abstract>::line_number::22
<abstract> systems in which the need for such a centralized database is eliminated. Instead, we use  </abstract>::line_number::23
<abstract> persistent messages as the means to store the information relevant to the execution of a  </abstract>::line_number::24
<abstract> business process. Our approach is to completely distribute the execution of a process so  </abstract>::line_number::25
<abstract> individual nodes are independent. The advantages of this approach are increased resilience  </abstract>::line_number::26
<abstract> to failures and greater scalability and flexibility of the system configuration.   </abstract>::line_number::27
<abstract>  ABSTRACT  </abstract>::line_number::35
<abstract> The problem of source  </abstract>::line_number::36
<abstract> identification involves correctly  </abstract>::line_number::37
<abstract> classifying an incoming signal into  </abstract>::line_number::38
<abstract> a category that identifies the  </abstract>::line_number::39
<abstract> signal's source.  </abstract>::line_number::40
<abstract> The problem is difficult because  </abstract>::line_number::41
<abstract> information is not provided  </abstract>::line_number::42
<abstract> distinguishing characteristics and  </abstract>::line_number::43
<abstract> because successive signals from the  </abstract>::line_number::44
<abstract> same source differ. The source  </abstract>::line_number::45
<abstract> identification problem can be made  </abstract>::line_number::46
<abstract> more difficult by dynamically  </abstract>::line_number::47
<abstract> changing the repertoire of sources  </abstract>::line_number::48
<abstract> while the problem is being solved.  </abstract>::line_number::49
<abstract> We used genetic programming to  </abstract>::line_number::50
<abstract> evolve both the topology and the  </abstract>::line_number::51
<abstract> sizing (numerical values) for each  </abstract>::line_number::52
<abstract> component of an analog electrical  </abstract>::line_number::53
<abstract> circuit that can correctly classify an  </abstract>::line_number::54
<abstract> incoming analog electrical signal  </abstract>::line_number::55
<abstract> into three categories. Then, the  </abstract>::line_number::56
<abstract> repertoire of sources was  </abstract>::line_number::57
<abstract> dynamically changed by adding a  </abstract>::line_number::58
<abstract> new source during the run. The  </abstract>::line_number::59
<abstract> paper describe show the  </abstract>::line_number::60
<abstract> enabled genetic programming to  </abstract>::line_number::61
<abstract> adapt, during the run, to the  </abstract>::line_number::62
<abstract> changed environment. Specifically,  </abstract>::line_number::63
<abstract> a three-way source identification  </abstract>::line_number::64
<abstract> circuit was evolved and then  </abstract>::line_number::65
<abstract> adapted into a four-way classifier,  </abstract>::line_number::66
<abstract> during the run, thereby successfully  </abstract>::line_number::67
<abstract> handling the additional new source.   </abstract>::line_number::68
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Network throughput can be increased by allowing mul-tipath, adaptive routing. Adaptive routing allows more  </abstract>::line_number::9
<abstract> freedom in the paths taken by messages, spreading load  </abstract>::line_number::10
<abstract> over physical channels more evenly. The flexibility of  </abstract>::line_number::11
<abstract> adaptive routing introduces new possibilities of deadlock. Previous deadlock avoidance schemes in k-ary n-cubes require an exponential number of virtual channels  </abstract>::line_number::12
<abstract> [17]. We describe a family of deadlock-free routing algorithms, called planar-adaptive routing algorithms which  </abstract>::line_number::13
<abstract> require only a constant number of virtual channels, independent of network size and dimension. Planar-adaptive  </abstract>::line_number::14
<abstract> routing algorithms reduce the complexity of deadlock  </abstract>::line_number::15
<abstract> prevention by reducing the number of choices at each  </abstract>::line_number::16
<abstract> routing step. In the fault-free case, planar-adaptive  </abstract>::line_number::17
<abstract> networks are guaranteed to be deadlock-free. In the  </abstract>::line_number::18
<abstract> presence of network faults, the planar-adaptive router  </abstract>::line_number::19
<abstract> can be extended with misrouting to produce a working network which remains provably deadlock free and  </abstract>::line_number::20
<abstract> is provably livelock free. In addition, planar adaptive  </abstract>::line_number::21
<abstract> networks can simultaneously support both in-order and  </abstract>::line_number::22
<abstract> adaptive, out-of-order packet delivery.  </abstract>::line_number::23
<abstract> Planar-adaptive routing is of practical significance. It  </abstract>::line_number::24
<abstract> provides the simplest known support for deadlock-free  </abstract>::line_number::25
<abstract> adaptive routing in k-ary n-cubes of more than two  </abstract>::line_number::26
<abstract> dimensions (with k &gt; 2). Restricting adaptivity reduces the hardware complexity, improving router speed  </abstract>::line_number::27
<abstract> or allowing additional performance-enhancing network  </abstract>::line_number::28
<abstract> features. The structure of planar-adaptive routers is  </abstract>::line_number::29
<abstract> amenable to efficient implementation.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::17
<abstract> Information retrieval differs significantly from function approximation in that the goal is for the system to achieve the same ranking  </abstract>::line_number::18
<abstract> function of documents relative to queries as the user: the outputs of  </abstract>::line_number::19
<abstract> the system relative to one another must be in the proper order. We  </abstract>::line_number::20
<abstract> hypothesize that a particular rank-order statistic, Guttman's point  </abstract>::line_number::21
<abstract> alienation, is the proper objective function for such a system, and  </abstract>::line_number::22
<abstract> demonstrate its efficacy by using it to find the optimal combination  </abstract>::line_number::23
<abstract> of retrieval experts. In application to a commercial retrieval system,  </abstract>::line_number::24
<abstract> the combination performs 47% better than any single expert.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::10
<abstract> By implementing agents and environments using a domain-independent, extensible simulation substrate, described in this  </abstract>::line_number::11
<abstract> paper, agents will have clean interfaces to  </abstract>::line_number::12
<abstract> their environments. These makes it easier  </abstract>::line_number::13
<abstract> for agents to be plugged into other environments that have been similarly defined. If  </abstract>::line_number::14
<abstract> agents can interact with multiple environments, their behaviors and the associated  </abstract>::line_number::15
<abstract> experimental results will be more general  </abstract>::line_number::16
<abstract> and interesting.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Network bandwidth has always been a key issue for multimedia protocols. Many potential users of networked multimedia protocols will continue to have low bandwidth network  </abstract>::line_number::9
<abstract> connections for some time: copper wire ISDN, infra-red, cellular modems, etc.. Compression provides potential relief for users of slow networks by increasing effective bandwidth.  </abstract>::line_number::10
<abstract> HBX introduces a new technique, based on arithmetic coding and statistical modeling, for  </abstract>::line_number::11
<abstract> compressing structured data. Applied to the X networked graphics protocol, this technique  </abstract>::line_number::12
<abstract> yields 4.5:1 compression across a representative set of traces, performing twice as well as the  </abstract>::line_number::13
<abstract> popular LZW-based Xremote compression protocol. HBX's coding techniques are generally  </abstract>::line_number::14
<abstract> applicable to the graphics and imaging subset of multimedia protocols. Future work will  </abstract>::line_number::15
<abstract> determine whether HBX's coding techniques can be applied to audio and video streams as  </abstract>::line_number::16
<abstract> well.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Several existing volume rendering algorithms operate by factoring the viewing transformation into a 3D shear parallel to the data  </abstract>::line_number::9
<abstract> slices, a projection to form an intermediate but distorted image,  </abstract>::line_number::10
<abstract> and a 2D warp to form an undistorted final image. We extend  </abstract>::line_number::11
<abstract> this class of algorithms in three ways. First, we describe a new  </abstract>::line_number::12
<abstract> object-order rendering algorithm based on the factorization that is  </abstract>::line_number::13
<abstract> significantly faster than published algorithms with minimal loss  </abstract>::line_number::14
<abstract> of image quality. Shear-warp factorizations have the property that  </abstract>::line_number::15
<abstract> rows of voxels in the volume are aligned with rows of pixels in the  </abstract>::line_number::16
<abstract> intermediate image. We use this fact to construct a scanline-based  </abstract>::line_number::17
<abstract> algorithm that traverses the volume and the intermediate image in  </abstract>::line_number::18
<abstract> synchrony, taking advantage of the spatial coherence present in  </abstract>::line_number::19
<abstract> both. We use spatial data structures based on run-length encoding  </abstract>::line_number::20
<abstract> for both the volume and the intermediate image. Our implementation running on an SGI Indigo workstation renders a 256 3 voxel  </abstract>::line_number::21
<abstract> medical data set in one second. Our second extension is a shear-warp factorization for perspective viewing transformations, and  </abstract>::line_number::22
<abstract> we show how our rendering algorithm can support this extension.  </abstract>::line_number::23
<abstract> Third, we introduce a data structure for encoding spatial coherence  </abstract>::line_number::24
<abstract> in unclassified volumes (i.e. scalar fields with no precomputed  </abstract>::line_number::25
<abstract> opacity). When combined with our shear-warp rendering algorithm this data structure allows us to classify and render a 256 3  </abstract>::line_number::26
<abstract> voxel volume in three seconds. The method extends to support  </abstract>::line_number::27
<abstract> mixed volumes and geometry and is parallelizable.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::3
<abstract> This paper presents a progressive refinement algorithm for  </abstract>::line_number::4
<abstract> volume rendering which uses a pyramidal volume representation. Besides storing average values, the pyramid stores  </abstract>::line_number::5
<abstract> estimated error, so an oct-tree can be fit to the pyramid  </abstract>::line_number::6
<abstract> given a user-supplied precision. This oct-tree is then drawn  </abstract>::line_number::7
<abstract> using a set of splats, or footprints, each scaled to match the  </abstract>::line_number::8
<abstract> size of the projection of a cell. The splats themselves are approximated with RGBA Gouraud-shaded polygons, so that  </abstract>::line_number::9
<abstract> they can be drawn efficiently on modern graphics workstations. The result is a real-time rendering algorithm suitable  </abstract>::line_number::10
<abstract> for interactive applications.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::3
<abstract> The Xremote protocol is a compressed transformation of the X Window System protocol,  </abstract>::line_number::4
<abstract> designed to efficiently implement X connections across relatively slow serial lines. Using an  </abstract>::line_number::5
<abstract> Xremote simulator and 11 traces of X sessions, we found that Xremote's overall compression  </abstract>::line_number::6
<abstract> ratio is 2.4:1. This figure varies widely depending on the trace. A study of compression  </abstract>::line_number::7
<abstract> ratio as a function of message type shows text based messages commonly achieving 3:1  </abstract>::line_number::8
<abstract> compression, while geometric messages usually achieve only 1.6:1 compression. By examining bandwidth requirements and compression performance as a function of time, we see  </abstract>::line_number::9
<abstract> that Xremote performs adequately for some applications which are text based or which use  </abstract>::line_number::10
<abstract> small geometric datasets, except at application startup where more bandwidth is required.  </abstract>::line_number::11
<abstract> Further work is required to adequately support the initialization stage of X applications and  </abstract>::line_number::12
<abstract> medium to large geometric databases.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::5
<abstract> This paper presents a method for modeling the surface  </abstract>::line_number::6
<abstract> of an object from a sequence of range maps. Our method  </abstract>::line_number::7
<abstract> is based on a volumetric approach that produces a compact  </abstract>::line_number::8
<abstract> surface without boundary. It provides robustness through  </abstract>::line_number::9
<abstract> the use of interval analysis techniques and computational  </abstract>::line_number::10
<abstract> efficiency through hierarchical processing using octrees.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::5
<abstract> The aim of this paper is to identify and to characterize the features that render one class  </abstract>::line_number::6
<abstract> of the Constraint Satisfaction Problem (CSP) computationally more efficient. Our approach  </abstract>::line_number::7
<abstract> is to search for a causal structure not only in the topology of the subsets of variables upon  </abstract>::line_number::8
<abstract> which the constraints are specified, but also in the nature of the constraints. Basically, there  </abstract>::line_number::9
<abstract> should exist an ordering of variables in the system such that an assignment of the variables  </abstract>::line_number::10
<abstract> can be reached without backtracking. First, an approach of a causal structure is formulated,  </abstract>::line_number::11
<abstract> and second, an efficient procedure is provided (i) for deciding if such an ordering of variables  </abstract>::line_number::12
<abstract> exists and, (ii) for identifying such an ordering whenever possible.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We have proposed an extension to the definition of general integer linear programs (ILP) to accept dis-equality constraints explicitly. A new class of logical  </abstract>::line_number::7
<abstract> variables is introduced to transform the extended ILP in general form to standard  </abstract>::line_number::8
<abstract> form. Branch and Bound algorithm is modified to solve this new class of ILP.   </abstract>::line_number::9
<abstract>  Abstract. The current vehicle-highway system has reached a plateau in its ability  </abstract>::line_number::6
<abstract> to meet the demand for moving goods and people. We sketch an architecture for  </abstract>::line_number::7
<abstract> an automated highway system or AHS. The architecture can be realized by several  </abstract>::line_number::8
<abstract> designs that differ in terms of performance and sophistication. We describe one design  </abstract>::line_number::9
<abstract> that could triple capacity and reduce travel time; guarantee collision-free operation  </abstract>::line_number::10
<abstract> in the absence of malfunctions; limit performance degradation in the case of faults;  </abstract>::line_number::11
<abstract> and reduce emissions by half. We summarize evidence suggesting that the design can  </abstract>::line_number::12
<abstract> be implemented. We indicate how the design can be adapted to different urban and  </abstract>::line_number::13
<abstract> rural scenarios and how a standard land use model can show the impact of AHS on  </abstract>::line_number::14
<abstract> urban density. We conclude with a critique of AHS.   </abstract>::line_number::15
<abstract>  ABSTRACT  </abstract>::line_number::11
<abstract> In this paper we present an implementation of an MPEG1 encoder on the Intel Touchstone Delta and Intel  </abstract>::line_number::12
<abstract> Paragon parallel computers. We describe the unique aspects of mapping the algorithm onto the parallel  </abstract>::line_number::13
<abstract> machines and present several versions of the algorithms. We will show that I/O contention can be a bottleneck  </abstract>::line_number::14
<abstract> relative to performance. We will also describe how the Touchstone Delta and Paragon can be used to compress  </abstract>::line_number::15
<abstract> video sequences faster than real-time.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper presents an approach to describing  </abstract>::line_number::9
<abstract> group behavior using simple local interactions  </abstract>::line_number::10
<abstract> among individuals. We propose that for a given  </abstract>::line_number::11
<abstract> domain a set of basic interactions can be defined  </abstract>::line_number::12
<abstract> which describes a large variety of group behaviors.  </abstract>::line_number::13
<abstract> The methodology we present allows for simplified  </abstract>::line_number::14
<abstract> qualitative analysis of group behavior through the  </abstract>::line_number::15
<abstract> use of shared goals, kin recognition, and minimal  </abstract>::line_number::16
<abstract> communication. We also demonstrate how these  </abstract>::line_number::17
<abstract> basic interactions can be simply combined into  </abstract>::line_number::18
<abstract> more complex compound group behaviors.  </abstract>::line_number::19
<abstract> To validate our approach we implemented an array of basic group behaviors in the domain of spatial interactions among homogeneous agents. We  </abstract>::line_number::20
<abstract> describe some of the experimental results from two  </abstract>::line_number::21
<abstract> distinct domains: a software environment, and a  </abstract>::line_number::22
<abstract> collection of 20 mobile robots. We also describe  </abstract>::line_number::23
<abstract> a compound behavior involving a combination of  </abstract>::line_number::24
<abstract> the basic interactions. Finally, we compare the  </abstract>::line_number::25
<abstract> performance of homogeneous groups to those of  </abstract>::line_number::26
<abstract> dominance hierarchies on the same set of basic behaviors.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::10
<abstract> In this paper we describe the implementation of several  </abstract>::line_number::11
<abstract> graphical programming paradigms (Model View Controller,  </abstract>::line_number::12
<abstract> Fudgets, and Functional Animations) using the GUI library  </abstract>::line_number::13
<abstract> TkGofer. This library relies on a combination of monads  </abstract>::line_number::14
<abstract> and multiple-parameter type classes to provide an abstract,  </abstract>::line_number::15
<abstract> type safe interface to Tcl/Tk. We show how choosing the  </abstract>::line_number::16
<abstract> right abstractions makes the given implementations surprisingly concise and easy to understand.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::5
<abstract> This paper outlines various recent approaches to solving word problems.  </abstract>::line_number::6
<abstract> Term orderings are used to define a terminating rewrite relation. When confluent, that relation defines unique normal forms that can be used to decide word  </abstract>::line_number::7
<abstract> problems. Some results obtained by these methods are summarized.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We demonstrate that the geometric separator algorithm of Miller, Teng, Thurston, and Vavasis finds a  </abstract>::line_number::6
<abstract> 3=4-separator of size 1:84  </abstract>::line_number::7
<abstract> p  </abstract>::line_number::8
<abstract> n for every n node planar  </abstract>::line_number::9
<abstract> graph. Our bound is derived from an analysis of disk  </abstract>::line_number::10
<abstract> packings on the sphere.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We examine the practical synergy between symbolic and statistical language processing in a generator  </abstract>::line_number::8
<abstract> called Nitrogen. The analysis provides insight into the kinds of linguistic decisions that bigram frequency  </abstract>::line_number::9
<abstract> statistics can make, and how it improves scalability. We also discuss the limits of bigram statistical  </abstract>::line_number::10
<abstract> knowledge. We focus on specific examples of Nitrogen's output.   </abstract>::line_number::11
<abstract>  Abstract: We exhibit a set of functions coded in  </abstract>::line_number::7
<abstract> Haskell that can be used as building blocks to construct  </abstract>::line_number::8
<abstract> a variety of interpreters for Lisp-like languages. The  </abstract>::line_number::9
<abstract> building blocks are joined merely through functional  </abstract>::line_number::10
<abstract> composition. Each building block contributes code to  </abstract>::line_number::11
<abstract> support a specific feature, such as numbers, continuations, functions calls, or nondeterminism. The result of  </abstract>::line_number::12
<abstract> composing some number of building blocks is a parser,  </abstract>::line_number::13
<abstract> an interpreter, and a printer that support exactly the  </abstract>::line_number::14
<abstract> expression forms and data types needed for the combined set of features, and no more.  </abstract>::line_number::15
<abstract> The data structures are organized as pseudomonads,  </abstract>::line_number::16
<abstract> a generalization of monads that allows composition.  </abstract>::line_number::17
<abstract> Functional composition of the building blocks implies  </abstract>::line_number::18
<abstract> type composition of the relevant pseudomonads.  </abstract>::line_number::19
<abstract> Our intent was that the Haskell type resolution system ought to be able to deduce the approprate data  </abstract>::line_number::20
<abstract> types automatically. Unfortunately there is a deficiency  </abstract>::line_number::21
<abstract> in current Haskell implementations related to recursive  </abstract>::line_number::22
<abstract> data types: circularity must be reflected statically in the  </abstract>::line_number::23
<abstract> type definitions.  </abstract>::line_number::24
<abstract> We circumvent this restriction by applying a purpose-built program simplifier that performs partial evaluation  </abstract>::line_number::25
<abstract> and a certain amount of program algebra. We construct  </abstract>::line_number::26
<abstract> a wide variety of interpreters in the style of Wadler by  </abstract>::line_number::27
<abstract> starting with the building blocks and a page of boiler-plate code, writing three lines of code (one to specify the  </abstract>::line_number::28
<abstract> building blocks and two to (redundantly) specify type  </abstract>::line_number::29
<abstract> compositions), and then applying the simplifier. The  </abstract>::line_number::30
<abstract> resulting code is acceptable Haskell code.  </abstract>::line_number::31
<abstract> We have tested a dozen different interpreters with  </abstract>::line_number::32
<abstract> various combinations of features. In this paper we discuss the overall code structuring strategy, exhibit several building blocks, briefly describe the partial evaluator, and present a number of automatically generated  </abstract>::line_number::33
<abstract> interpreters.   </abstract>::line_number::34
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> A restoration algorithm for estimating lossy compressed  </abstract>::line_number::7
<abstract> images that are corrupted by data-dependent Poisson noise  </abstract>::line_number::8
<abstract> is presented. The algorithm is based on modeling the image  </abstract>::line_number::9
<abstract> as a Markov random field (MRF) that penalizes the blocking artifact. The effectiveness of the proposed algorithm is  </abstract>::line_number::10
<abstract> illustrated using synthetic and real images.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The paper presents the general theory of designing  </abstract>::line_number::7
<abstract> multidimensional Quadrature Mirror Filters (QMF),  </abstract>::line_number::8
<abstract> for use in sub-band coding (SBC) systems, using the  </abstract>::line_number::9
<abstract> McClellan transform [1]. It was recently shown that  </abstract>::line_number::10
<abstract> McClellan transform could be used to generate 2-D  </abstract>::line_number::11
<abstract> diamond shape QMF filters [2]. In this paper we will  </abstract>::line_number::12
<abstract> formalize the proofs of the diamond shape case, and  </abstract>::line_number::13
<abstract> generalize it to other shapes, sampling rasters and  </abstract>::line_number::14
<abstract> dimensions. Examples are given of two dimensional  </abstract>::line_number::15
<abstract> diamond shape filters and three dimensional tetrad  </abstract>::line_number::16
<abstract> filters designed using the technique.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::12
<abstract> Multiple description coding (MDC) is source coding for multiple channels  </abstract>::line_number::13
<abstract> such that a decoder which receives an arbitrary subset of the channels may produce a useful reconstruction. Orchard et al. [1] proposed a transform coding  </abstract>::line_number::14
<abstract> method for MDC of pairs of independent Gaussian random variables. This paper provides a general framework which extends multiple description transform  </abstract>::line_number::15
<abstract> coding (MDTC) to any number of variables and expands the set of transforms  </abstract>::line_number::16
<abstract> which are considered. Analysis of the general case is provided, which can be  </abstract>::line_number::17
<abstract> used to numerically design optimal MDTC systems. The case of two variables  </abstract>::line_number::18
<abstract> sent over two channels is analytically optimized in the most general setting  </abstract>::line_number::19
<abstract> where channel failures need not have equal probability or be independent. It  </abstract>::line_number::20
<abstract> is shown that when channel failures are equally probable and independent, the  </abstract>::line_number::21
<abstract> transforms used in [1] are in the optimal set, but many other choices are possible. A cascade structure is presented which facilitates low-complexity design,  </abstract>::line_number::22
<abstract> coding, and decoding for a system with a large number of variables.   </abstract>::line_number::23
<abstract>  Abstract|Coefficient quantization has peculiar qualitative  </abstract>::line_number::6
<abstract> effects on representations of vectors in R N with respect to  </abstract>::line_number::7
<abstract> overcomplete sets of vectors. These effects are investigated  </abstract>::line_number::8
<abstract> in two settings: frame expansions (representations obtained  </abstract>::line_number::9
<abstract> by forming inner products with each element of the set)  </abstract>::line_number::10
<abstract> and matching pursuit expansions (approximations obtained  </abstract>::line_number::11
<abstract> by greedily forming linear combinations). In both cases,  </abstract>::line_number::12
<abstract> based on the concept of consistency, it is shown that traditional linear reconstruction methods are suboptimal, and  </abstract>::line_number::13
<abstract> better consistent reconstruction algorithms are given. The  </abstract>::line_number::14
<abstract> proposed consistent reconstruction algorithms were in each  </abstract>::line_number::15
<abstract> case implemented, and experimental results are included.  </abstract>::line_number::16
<abstract> For frame expansions, results are proven to bound distortion as a function of frame redundancy r and quantization  </abstract>::line_number::17
<abstract> step size for linear, consistent, and optimal reconstruction  </abstract>::line_number::18
<abstract> methods. Taken together, these suggest that optimal reconstruction methods will yield O(1=r 2 ) MSE, and that consistency is sufficient to insure this asymptotic behavior. A  </abstract>::line_number::19
<abstract> result on the asymptotic tightness of random frames is also  </abstract>::line_number::20
<abstract> proven.  </abstract>::line_number::21
<abstract> Applicability of quantized matching pursuit to lossy vector compression is explored. Experiments demonstrate the  </abstract>::line_number::22
<abstract> likelihood that a linear reconstruction is inconsistent, the  </abstract>::line_number::23
<abstract> MSE reduction obtained with a nonlinear (consistent) reconstruction algorithm, and generally competitive performance  </abstract>::line_number::24
<abstract> at low bit rates.   </abstract>::line_number::25
<abstract>  Abstract. The paper adresses proof planning as a specific AI planning. It describes some peculiarities of proof planning and discusses  </abstract>::line_number::2
<abstract> some possible cross-fertilization of planning and proof planning.   </abstract>::line_number::3
<abstract>  Abstract  </abstract>::line_number::2
<abstract> Applications of learning to autonomous  </abstract>::line_number::3
<abstract> agents (simulated or real) have often been  </abstract>::line_number::4
<abstract> restricted to learning a mapping from perceived state of the world to the next action  </abstract>::line_number::5
<abstract> to take. Often this is couched in terms of  </abstract>::line_number::6
<abstract> learning from no previous knowledge. This  </abstract>::line_number::7
<abstract> general case for real autonomous robots is  </abstract>::line_number::8
<abstract> very difficult. In any case, when building a  </abstract>::line_number::9
<abstract> real robot there is usually a lot of a priori  </abstract>::line_number::10
<abstract> knowledge (e.g., from the engineering that  </abstract>::line_number::11
<abstract> went into its design) which doesn't need to  </abstract>::line_number::12
<abstract> be learned. We describe the behavior-based  </abstract>::line_number::13
<abstract> approach to autonomous robots, and then examine four classes of learning problems associated with such robots.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::13
<abstract> Predictions of lifetimes of dynamically allocated objects can be used  </abstract>::line_number::14
<abstract> to improve time and space efficiency of dynamic memory management in computer programs. Barrett and Zorn [1993] used a simple  </abstract>::line_number::15
<abstract> lifetime predictor and demonstrated this improvement on a variety  </abstract>::line_number::16
<abstract> of computer programs. In this paper, we use decision trees to do  </abstract>::line_number::17
<abstract> lifetime prediction on the same programs and show significantly  </abstract>::line_number::18
<abstract> better prediction. Our method also has the advantage that during  </abstract>::line_number::19
<abstract> training we can use a large number of features and let the decision  </abstract>::line_number::20
<abstract> tree automatically choose the relevant subset.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We describe a software package for computing and manipulating the subdivision of a sphere  </abstract>::line_number::8
<abstract> by a collection of (not necessarily great) circles and for computing the boundary surface of the  </abstract>::line_number::9
<abstract> union of spheres. We present problems that arise in the implementation of the software and the  </abstract>::line_number::10
<abstract> solutions that we have found for them. At the core of the paper is a novel perturbation scheme to  </abstract>::line_number::11
<abstract> overcome degeneracies and precision problems in computing spherical arrangements while using  </abstract>::line_number::12
<abstract> floating point arithmetic. The scheme is relatively simple, it balances between the efficiency  </abstract>::line_number::13
<abstract> of computation and the magnitude of the perturbation, and it performs well in practice. We  </abstract>::line_number::14
<abstract> report and discuss experimental results. Our package is a major component in a larger package  </abstract>::line_number::15
<abstract> aimed to support geometric queries on molecular models; it is currently employed by chemists  </abstract>::line_number::16
<abstract> working in `rational drug design.' The spherical subdivisions are used to construct a geometric  </abstract>::line_number::17
<abstract> model of a molecule where each sphere represents an atom. We also give an overview of the  </abstract>::line_number::18
<abstract> molecular modeling package and detail additional features and implementation issues.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::3
<abstract> It is obvious to anyone familiar with the rules of the game of chess  </abstract>::line_number::4
<abstract> that a king on an empty board can reach every square. It is true, but  </abstract>::line_number::5
<abstract> not obvious, that a knight can reach every square. Why is the first  </abstract>::line_number::6
<abstract> fact obvious but the second fact not? This paper presents an analytic  </abstract>::line_number::7
<abstract> theory of a class of obviousness judgments of this type. Whether or  </abstract>::line_number::8
<abstract> not the specifics of this analysis are correct, it seems that the study of  </abstract>::line_number::9
<abstract> obviousness judgments can be used to construct integrated theories of  </abstract>::line_number::10
<abstract> linguistics, knowledge representation, and inference.   </abstract>::line_number::11
<abstract>  Abstract: We identify a new polynomial time decidable fragment of first order  </abstract>::line_number::3
<abstract> logic and present a general method for using polynomial time inference procedures  </abstract>::line_number::4
<abstract> in knowledge representation systems. Our results indicate that a non-standard  </abstract>::line_number::5
<abstract> "taxonomic" syntax is essential in constructing natural and powerful polynomial  </abstract>::line_number::6
<abstract> time inference procedures. The central role of taxonomic syntax in our polynomial time inference procedures provides technical support for the often expressed  </abstract>::line_number::7
<abstract> intuition that knowledge is better represented in terms of taxonomic relationships  </abstract>::line_number::8
<abstract> than classical first order formulas. To use our procedures in a knowledge representation system we define a "Socratic proof system" which is complete for first  </abstract>::line_number::9
<abstract> order inference and which can be used as a semi-automated interface to a first  </abstract>::line_number::10
<abstract> order knowledge base.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We have developed a new Bayesian framework for visual object  </abstract>::line_number::9
<abstract> recognition which is based on the insight that images of objects can be  </abstract>::line_number::10
<abstract> modeled as a conjunction of local features. This framework can be used  </abstract>::line_number::11
<abstract> to both derive an object recognition algorithm and an algorithm for  </abstract>::line_number::12
<abstract> learning the features themselves. The overall approach, called complex  </abstract>::line_number::13
<abstract> feature recognition or CFR, is unique for several reasons: it is broadly  </abstract>::line_number::14
<abstract> applicable to a wide range of object types, it makes constructing object  </abstract>::line_number::15
<abstract> models easy, it is capable of identifying either the class or the identity  </abstract>::line_number::16
<abstract> of an object, and it is computationally efficient requiring time proportional to the size of the image.  </abstract>::line_number::17
<abstract> Instead of a single simple feature such as an edge, CFR uses a large  </abstract>::line_number::18
<abstract> set of complex features that are learned from experience with model  </abstract>::line_number::19
<abstract> objects. The response of a single complex feature contains much more  </abstract>::line_number::20
<abstract> class information than does a single edge. This significantly reduces the  </abstract>::line_number::21
<abstract> number of possible correspondences between the model and the image.  </abstract>::line_number::22
<abstract> In addition, CFR takes advantage of a type of image processing called  </abstract>::line_number::23
<abstract> oriented energy. Oriented energy is used to efficiently pre-process the  </abstract>::line_number::24
<abstract> image to eliminate some of the difficulties associated with changes in  </abstract>::line_number::25
<abstract> lighting and pose.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The maximization of diversity of neuronal response properties has been recently suggested  </abstract>::line_number::8
<abstract> as an organizing principle for the formation of such prominent features of the functional  </abstract>::line_number::9
<abstract> architecture of the brain as the cortical columns and the associated patchy projection patterns  </abstract>::line_number::10
<abstract> (Malach, 1994). We report a computational study of two aspects of this hypothesis. First, we  </abstract>::line_number::11
<abstract> show that maximal diversity is attained when the ratio of dendritic and axonal arbor sizes is  </abstract>::line_number::12
<abstract> equal to one, as it has been found in many cortical areas and across species (Lund et al., 1993;  </abstract>::line_number::13
<abstract> Malach, 1994). Second, we show that maximization of diversity leads to better performance in  </abstract>::line_number::14
<abstract> two case studies: in systems of receptive fields implementing steerable/shiftable filters, and in  </abstract>::line_number::15
<abstract> matching spatially distributed signals, a problem that arises in visual tasks such as stereopsis,  </abstract>::line_number::16
<abstract> motion processing, and recognition.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::14
<abstract> Several early game-playing computer programs used forward pruning (i.e., the practice of  </abstract>::line_number::15
<abstract> deliberately ignoring nodes that are believed unlikely to affect a game tree's minimax value),  </abstract>::line_number::16
<abstract> but this technique did not seem to result in good decision-making. The poor performance of  </abstract>::line_number::17
<abstract> forward pruning presents a major puzzle for AI research on game playing, because some version  </abstract>::line_number::18
<abstract> of forward pruning seems to be "what people do," and the best chess-playing programs still do  </abstract>::line_number::19
<abstract> not play as well as the best humans.  </abstract>::line_number::20
<abstract> As a step toward deeper understanding of how forward pruning affects quality of play, in  </abstract>::line_number::21
<abstract> this paper we set up a model of forward pruning on two abstract classes of binary game trees,  </abstract>::line_number::22
<abstract> and we use this model to investigate how forward pruning affects the accuracy of the minimax  </abstract>::line_number::23
<abstract> values returned. The primary result of our study is that forward pruning does better when there  </abstract>::line_number::24
<abstract> is a high correlation among the minimax values of sibling nodes in a game tree.  </abstract>::line_number::25
<abstract> This result suggests that forward pruning may possibly be a useful decision-making technique  </abstract>::line_number::26
<abstract> in certain kinds of games. In particular, we believe that bridge may be such a game.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Model-Based Optimization (MBO) is a paradigm in which an objective function is used to express  </abstract>::line_number::8
<abstract> both geometric and photometric constraints on features of interest. A parametric model of a feature  </abstract>::line_number::9
<abstract> (such as a road, a building, or coastline) is extracted from one or more images by adjusting the model's  </abstract>::line_number::10
<abstract> state variables until a minimum value of the objective function is obtained. The optimization procedure  </abstract>::line_number::11
<abstract> yields a description that simultaneously satisfies (or nearly satisfies) all constraints, and, as a result, is  </abstract>::line_number::12
<abstract> likely to be a good model of the feature.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We describe the design principles and functionality  </abstract>::line_number::7
<abstract> of a visual query language called SeeQL that represents data retrieval and analysis operations as a data-flow graph. A query is viewed as a sequence of relational algebra and other data transformation operations applied to database tables. The language is well-suited for large-scale scientific database applications,  </abstract>::line_number::8
<abstract> where data analysis is a major component and the typical queries or data retrieval patterns are unrestricted.  </abstract>::line_number::9
<abstract> The language provides a flexible yet easy-to-use environment for database access and data analysis for  </abstract>::line_number::10
<abstract> non-programmer research scientists. We have implemented this language in a system being used in a long-term data-intensive highway pavement research project  </abstract>::line_number::11
<abstract> (MnRoad) conducted by the Minnesota Department of  </abstract>::line_number::12
<abstract> Transportation.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We describe an integrated problem solving architecture named INBANCA in  </abstract>::line_number::10
<abstract> which Bayesian networks and case-based reasoning (CBR) work cooperatively on  </abstract>::line_number::11
<abstract> multiagent planning tasks. This includes two-team dynamic tasks, and this paper  </abstract>::line_number::12
<abstract> concentrates on simulated soccer as an example. Bayesian networks are used to characterize action selection whereas a case-based approach is used to determine how to  </abstract>::line_number::13
<abstract> implement actions. This paper has two contributions. First, we survey integrations  </abstract>::line_number::14
<abstract> of case-based and Bayesian approaches from the perspective of a popular CBR task  </abstract>::line_number::15
<abstract> decomposition framework, thus explaining what types of integrations have been attempted. This allows us to explain the unique aspects of our proposed integration.  </abstract>::line_number::16
<abstract> Second, we demonstrate how Bayesian nets can be used to provide environmental  </abstract>::line_number::17
<abstract> context, and thus feature selection information, for the case-based reasoner.   </abstract>::line_number::18
<abstract>  Abstract.  </abstract>::line_number::3
<abstract> A quorum system is a collection of sets (quorums) every two of which intersect. Quorum systems  </abstract>::line_number::4
<abstract> have been used for many applications in the area of distributed systems, including mutual exclusion,  </abstract>::line_number::5
<abstract> data replication and dissemination of information  </abstract>::line_number::6
<abstract> Given a strategy to pick quorums, the load L(S) is the minimal access probability of the busiest  </abstract>::line_number::7
<abstract> element, minimizing over the strategies. The capacity Cap(S) is the highest quorum accesses rate  </abstract>::line_number::8
<abstract> that S can handle, so Cap(S) = 1=L(S).  </abstract>::line_number::9
<abstract> The availability of a quorum system S is the probability that at least one quorum survives,  </abstract>::line_number::10
<abstract> assuming that each element fails independently with probability p. A tradeoff between L(S) and the  </abstract>::line_number::11
<abstract> availability of S is shown.  </abstract>::line_number::12
<abstract> We present four novel constructions of quorum system, all featuring optimal or near optimal  </abstract>::line_number::13
<abstract> load, and high availability. The best construction, based on paths in a grid, has a load of O(1=  </abstract>::line_number::14
<abstract> p  </abstract>::line_number::15
<abstract> and a failure probability of exp((  </abstract>::line_number::16
<abstract> p  </abstract>::line_number::17
<abstract> n)) when the elements fail with probability p &lt; 1  </abstract>::line_number::18
<abstract> 2 . Moreover,  </abstract>::line_number::19
<abstract> even in the presence of faults, with exponentially high probability the load of this system is still  </abstract>::line_number::20
<abstract> O(1=  </abstract>::line_number::21
<abstract> n). The analysis of this scheme is based on Percolation Theory.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::4
<abstract> A data breakpoint associates debugging actions with  </abstract>::line_number::5
<abstract> programmer-specified conditions on the memory state  </abstract>::line_number::6
<abstract> of an executing program. Data breakpoints provide  </abstract>::line_number::7
<abstract> a means for discovering program bugs that are tedious or impossible to isolate using control breakpoints  </abstract>::line_number::8
<abstract> alone. In practice, programmers rarely use data break-points, because they are either unimplemented or prohibitively slow in available debugging software. In this  </abstract>::line_number::9
<abstract> paper, we present the design and implementation of a  </abstract>::line_number::10
<abstract> practical data breakpoint facility.  </abstract>::line_number::11
<abstract> A data breakpoint facility must monitor all memory  </abstract>::line_number::12
<abstract> updates performed by the program being debugged.  </abstract>::line_number::13
<abstract> We implemented and evaluated two complementary  </abstract>::line_number::14
<abstract> techniques for reducing the overhead of monitoring  </abstract>::line_number::15
<abstract> memory updates. First, we checked write instructions  </abstract>::line_number::16
<abstract> by inserting checking code directly into the program  </abstract>::line_number::17
<abstract> being debugged. The checks use a segmented bitmap  </abstract>::line_number::18
<abstract> data structure that minimizes address lookup complexity. Second, we developed data flow algorithms  </abstract>::line_number::19
<abstract> that eliminate checks on some classes of write instructions but may increase the complexity of the remaining  </abstract>::line_number::20
<abstract> checks.  </abstract>::line_number::21
<abstract> We evaluated these techniques on the Sparc using  </abstract>::line_number::22
<abstract> the spec benchmarks. Checking each write instruc   </abstract>::line_number::23
<abstract>  tion using a segmented bitmap achieved an average  </abstract>::line_number::28
<abstract> overhead of 42%. This overhead is independent of the  </abstract>::line_number::29
<abstract> number of breakpoints in use. Data flow analysis eliminated an average of 79% of the dynamic write checks.  </abstract>::line_number::30
<abstract> For scientific programs such the nas kernels, analysis  </abstract>::line_number::31
<abstract> reduced write checks by a factor of ten or more. On the  </abstract>::line_number::32
<abstract> Sparc these optimizations reduced the average overhead to 25%.   </abstract>::line_number::33
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> The adaptation of existing general-purpose speech recognition and language understanding systems can greatly  </abstract>::line_number::7
<abstract> reduce the cost of developing applications. However, the  </abstract>::line_number::8
<abstract> components must have appropriate characteristics for this  </abstract>::line_number::9
<abstract> to be possible.  </abstract>::line_number::10
<abstract> Work is in progress to adapt two task-independent  </abstract>::line_number::11
<abstract> components, the AURIX speech recognizer and the CLARE  </abstract>::line_number::12
<abstract> language processor to create a system allowing spoken  </abstract>::line_number::13
<abstract> queries of the PC-based Autoroute route planning package.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::7
<abstract> A simple and general method is described that can combine different  </abstract>::line_number::8
<abstract> knowledge sources to reorder N-best lists of hypotheses produced by a  </abstract>::line_number::9
<abstract> speech recognizer. The method is automatically trainable, acquiring information from both positive and negative examples. Experiments are  </abstract>::line_number::10
<abstract> described in which it was tested on a 1000-utterance sample of unseen  </abstract>::line_number::11
<abstract> ATIS data.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::9
<abstract> While plan recognition research has been applied to a  </abstract>::line_number::10
<abstract> wide variety of problems, it has largely made identical assumptions about the number of agents participating in the plan, the observability of the plan execution process, and the scale of the domain. We describe a method for plan recognition in a real-world  </abstract>::line_number::11
<abstract> domain involving large numbers of agents performing  </abstract>::line_number::12
<abstract> spatial maneuvers in concert under conditions of limited observability. These assumptions differ radically  </abstract>::line_number::13
<abstract> from those traditionally made in plan recognition and  </abstract>::line_number::14
<abstract> produce a problem which combines aspects of the fields  </abstract>::line_number::15
<abstract> of plan recognition, pattern recognition, and object  </abstract>::line_number::16
<abstract> tracking. We describe our initial solution which borrows and builds upon research from each of these areas,  </abstract>::line_number::17
<abstract> employing a pattern-directed approach to recognize individual movements and generalizing these to produce  </abstract>::line_number::18
<abstract> inferences of large-scale behavior.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::10
<abstract> Reactive controllers has been widely used in mobile robots since they are able to achieve successful performance in real-time. However, the configuration of a reactive controller depends  </abstract>::line_number::11
<abstract> highly on the operating conditions of the robot and the environment; thus, a reactive controller  </abstract>::line_number::12
<abstract> configured for one class of environments may not perform adequately in another. This paper  </abstract>::line_number::13
<abstract> presents a formulation of learning adaptive reactive controllers. Adaptive reactive controllers  </abstract>::line_number::14
<abstract> inherit all the advantages of traditional reactive controllers, but in addition they are able to adjust themselves to the current operating conditions of the robot and the environment in order to  </abstract>::line_number::15
<abstract> improve task performance. Furthermore, learning adaptive reactive controllers can learn when  </abstract>::line_number::16
<abstract> and how to adapt the reactive controller so as to achieve effective performance under different  </abstract>::line_number::17
<abstract> conditions. The paper presents an algorithm for a learning adaptive reactive controller that  </abstract>::line_number::18
<abstract> combines ideas from case-based reasoning and reinforcement learning to construct a mapping  </abstract>::line_number::19
<abstract> between the operating conditions of a controller and the appropriate controller configuration;  </abstract>::line_number::20
<abstract> this mapping is in turn used to adapt the controller configuration dynamically. As a case  </abstract>::line_number::21
<abstract> study, the algorithm is implemented in a robotic navigation system that controls a Denning  </abstract>::line_number::22
<abstract> MRV-III mobile robot. The system is extensively evaluated using statistical methods to verify  </abstract>::line_number::23
<abstract> its learning performance and to understand the relevance of different design parameters on the  </abstract>::line_number::24
<abstract> performance of the system.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::8
<abstract> In this paper we develop a framework for comparing  </abstract>::line_number::9
<abstract> ontologies, and place a number of the more  </abstract>::line_number::10
<abstract> prominent ontologies into it. We have selected 10  </abstract>::line_number::11
<abstract> specific projects for this study, including general  </abstract>::line_number::12
<abstract> ontologies, domain specific ones, and one knowledge  </abstract>::line_number::13
<abstract> representation system. The comparison framework  </abstract>::line_number::14
<abstract> includes general characteristics such as the purpose of  </abstract>::line_number::15
<abstract> an ontology, its coverage (general or domain-specific), its size, and the formalism used. It also  </abstract>::line_number::16
<abstract> includes the design process used in creating an  </abstract>::line_number::17
<abstract> ontology and the methods used to evaluate it.  </abstract>::line_number::18
<abstract> Characteristics that describe the content of an  </abstract>::line_number::19
<abstract> ontology include taxonomic organization, types of  </abstract>::line_number::20
<abstract> concepts covered, top-level divisions, internal  </abstract>::line_number::21
<abstract> structure of concepts, representation of part-whole  </abstract>::line_number::22
<abstract> relations, and the presence and nature of additional  </abstract>::line_number::23
<abstract> axioms. Finally we consider what experiments or  </abstract>::line_number::24
<abstract> applications have used the ontologies. Knowledge  </abstract>::line_number::25
<abstract> sharing and reuse will require a common framework  </abstract>::line_number::26
<abstract> to support interoperability of independently created  </abstract>::line_number::27
<abstract> ontologies. Our study shows there is great diversity  </abstract>::line_number::28
<abstract> in the way ontologies are designed and the way they  </abstract>::line_number::29
<abstract> represent the world. By identifying the similarities  </abstract>::line_number::30
<abstract> and differences among existing ontologies, we clarify  </abstract>::line_number::31
<abstract> the range of alternatives in creating a standard  </abstract>::line_number::32
<abstract> framework for ontology design.   </abstract>::line_number::33
<abstract>  Summary  </abstract>::line_number::15
<abstract> Markov chain Monte Carlo (MCMC) is used for evaluating expectations of functions of interest  </abstract>::line_number::16
<abstract> under a target distribution . This is done by calculating averages over the sample path of a  </abstract>::line_number::17
<abstract> Markov chain having as its stationary distribution. For computational efficiency, the Markov  </abstract>::line_number::18
<abstract> chain should be rapidly mixing. This can sometimes be achieved only by careful design of the  </abstract>::line_number::19
<abstract> transition kernel of the chain, on the basis of a detailed preliminary exploratory analysis of . An  </abstract>::line_number::20
<abstract> alternative approach might be to allow the transition kernel to adapt whenever new features of   </abstract>::line_number::21
<abstract> are encountered during the MCMC run. However, if such adaptation occurs infinitely often, the  </abstract>::line_number::22
<abstract> stationary distribution of the chain may be disturbed. We describe a framework, based on the  </abstract>::line_number::23
<abstract> concept of Markov chain regeneration, which allows adaptation to occur infinitely often, but which  </abstract>::line_number::24
<abstract> does not disturb the stationary distribution of the chain or the consistency of sample-path averages.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Many connectionist approaches to musical expectancy and music composition let the  </abstract>::line_number::6
<abstract> question of What next? overshadow the equally important question of When next?. One cannot  </abstract>::line_number::7
<abstract> escape the latter question, one of temporal structure, when considering the perception of musical  </abstract>::line_number::8
<abstract> meter. We view the perception of metrical structure as a dynamic process where the temporal  </abstract>::line_number::9
<abstract> organization of external musical events synchronizes, or entrains, a listeners internal processing  </abstract>::line_number::10
<abstract> mechanisms. This article introduces a novel connectionist unit, based upon a mathematical model  </abstract>::line_number::11
<abstract> of entrainment, capable of phase and frequency-locking to periodic components of incoming  </abstract>::line_number::12
<abstract> rhythmic patterns. Networks of these units can self-organize temporally structured responses to  </abstract>::line_number::13
<abstract> rhythmic patterns. The resulting network behavior embodies the perception of metrical structure.  </abstract>::line_number::14
<abstract> The article concludes with a discussion of the implications of our approach for theories of metrical  </abstract>::line_number::15
<abstract> structure and musical expectancy.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Advanced display technologies have made the virtual exploration of relatively complex models feasible  </abstract>::line_number::10
<abstract> in many applications. Unfortunately, only a few human interfaces allow natural interaction with the  </abstract>::line_number::11
<abstract> environment. Moreover, in surgical applications, such realistic interaction requires real-time rendering  </abstract>::line_number::12
<abstract> of volumetric data - placing an overwhelming performance burden on the system. We report on a  </abstract>::line_number::13
<abstract> collaboration of an interdisciplinary group developing a virtual reality system that provides intuitive  </abstract>::line_number::14
<abstract> interaction with volume data by employing real-time volume rendering and force feedback (haptic)  </abstract>::line_number::15
<abstract> sensations. We describe our rendering methods and the haptic devices and explain its utility of this  </abstract>::line_number::16
<abstract> system in the real-world application of Endoscopic Sinus Surgery (ESS) simulation.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Grouping people into clusters based on the items they have purchased allows accurate recommendations of new items for purchase:  </abstract>::line_number::6
<abstract> if you and I have liked many of the same movies, then I will probably enjoy other movies that you like. Recommending items based  </abstract>::line_number::7
<abstract> on similarity of interest (a.k.a. collaborative filtering) is attractive  </abstract>::line_number::8
<abstract> for many domains: books, CDs, movies, etc., but does not always  </abstract>::line_number::9
<abstract> work well. Because data are always sparse any given person has  </abstract>::line_number::10
<abstract> seen only a small fraction of all movies much more accurate predictions can be made by grouping people into clusters with similar  </abstract>::line_number::11
<abstract> movies and grouping movies into clusters which tend to be liked by  </abstract>::line_number::12
<abstract> the same people. Finding optimal clusters is tricky because the movie  </abstract>::line_number::13
<abstract> groups should be used to help determine the people groups and visa  </abstract>::line_number::14
<abstract> versa. We present a formal statistical model of collaborative filtering,  </abstract>::line_number::15
<abstract> and compare different algorithms for estimating the model parameters  </abstract>::line_number::16
<abstract> including variations of K-means clustering and Gibbs Sampling. This  </abstract>::line_number::17
<abstract> formal model is easily extended to handle clustering of objects with  </abstract>::line_number::18
<abstract> multiple attributes.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Model predictive control strategies generally focus on controlling plant outputs to setpoints; in  </abstract>::line_number::6
<abstract> industry, however, a more desirable goal is maximizing a plants profitability. In principle, this can be  </abstract>::line_number::7
<abstract> done by creating a plant model and maximizing profit with respect to the market prices of the plants  </abstract>::line_number::8
<abstract> inputs and outputs, but in practice, such centralized approaches often cannot effectively be applied at  </abstract>::line_number::9
<abstract> the operations time scale due to the size and complexity of the problem. One solution is to use  </abstract>::line_number::10
<abstract> decentralized optimization at the unit operations level by tearing process streams and coordinating the  </abstract>::line_number::11
<abstract> resulting pieces. Such optimization, however, requires that unit inputs and outputs be priced. We show  </abstract>::line_number::12
<abstract> that a traditional Lagrangean-based approach to this pricing fails for simple systems. Instead, we define  </abstract>::line_number::13
<abstract> slack resources over the torn process streams and price them using auctions. Unlike Lagrange  </abstract>::line_number::14
<abstract> multipliers, slack resource prices contain useful information and can be used to make decisions  </abstract>::line_number::15
<abstract> regarding capital improvements, thus providing a strong tie between the operations and management  </abstract>::line_number::16
<abstract> layers in chemical plants.   </abstract>::line_number::17
<abstract>  ABSTRACT  </abstract>::line_number::8
<abstract> Current input device taxonomies and other frameworks typically emphasize  </abstract>::line_number::9
<abstract> the mechanical structure of input devices. We suggest that selecting an  </abstract>::line_number::10
<abstract> appropriate input device for an interactive task requires looking beyond the  </abstract>::line_number::11
<abstract> physical structure of devices to the deeper perceptual structure of the task, the  </abstract>::line_number::12
<abstract> device, and the interrelationship between the perceptual structure of the task and  </abstract>::line_number::13
<abstract> the control properties of the device. We affirm that perception is key to  </abstract>::line_number::14
<abstract> understanding performance of multidimensional input devices on  </abstract>::line_number::15
<abstract> multidimensional tasks. We have therefore extended the theory of processing of  </abstract>::line_number::16
<abstract> perceptual structure to graphical interactive tasks and to the control structure of  </abstract>::line_number::17
<abstract> input devices. This allows us to predict task and device combinations that lead to  </abstract>::line_number::18
<abstract> better performance and hypothesize that performance is improved when the  </abstract>::line_number::19
<abstract> perceptual structure of the task matches the control structure of the device. We  </abstract>::line_number::20
<abstract> conducted an experiment in which subjects performed two tasks with different  </abstract>::line_number::21
<abstract> perceptual structures, using two input devices with correspondingly different  </abstract>::line_number::22
<abstract> control structures, a three-dimensional tracker and a mouse. We analyzed both  </abstract>::line_number::23
<abstract> speed and accuracy, as well as the trajectories generated by subjects as they used  </abstract>::line_number::24
<abstract> the unconstrained three-dimensional tracker to perform each task. The results  </abstract>::line_number::25
<abstract> support our hypothesis and confirm the importance of matching the perceptual  </abstract>::line_number::26
<abstract> structure of the task and the control structure of the input device.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Large-scale, distributed hypermedia information systems allow fast, structured access to very large, dynamic information bases. The highly perceptual nature of a virtual reality interface has the power to take users both inside information and inside its  </abstract>::line_number::8
<abstract> structure. Combining the two takes us a step towards cyberspace, William Gibson's  </abstract>::line_number::9
<abstract> vision of a virtual model of all the world's interconnected data. This paper reviews  </abstract>::line_number::10
<abstract> current work on the boundary of virtual reality and hypermedia.   </abstract>::line_number::11
<abstract>  ABSTRACT INTRODUCTION  </abstract>::line_number::12
<abstract> We describe the design and implementation of a prototype When we think of the use of head-mounted displays and 3D  </abstract>::line_number::13
<abstract> heads-up window system intended for use in a 3D environ- interaction devices to present virtual worlds, it is often in  </abstract>::line_number::14
<abstract> ment. Our system includes a see-through head-mounted terms of environments populated solely by 3D objects.  </abstract>::line_number::15
<abstract> display that runs a full X server whose image is overlaid on There are many situations, however, in which 2D text and  </abstract>::line_number::16
<abstract> the user's view of the physical world. The user's head is graphics of the sort supported by current window systems  </abstract>::line_number::17
<abstract> tracked so that the display indexes into a large X bitmap, can be useful components of these environments. This is  </abstract>::line_number::18
<abstract> effectively placing the user inside a display space that is especially true in the case of the many applications that run  </abstract>::line_number::19
<abstract> mapped onto part of a surrounding virtual sphere. By under an industry standard window system such as X [13].  </abstract>::line_number::20
<abstract> tracking the user's body, and interpreting head motion rela- While we might imagine porting or enhancing a significant  </abstract>::line_number::21
<abstract> tive to it, we create a portable information surround that X application to take advantage of the 3D capabilities of a  </abstract>::line_number::22
<abstract> envelopes the user as they move about. virtual world, the effort and cost may not be worth the  </abstract>::line_number::23
<abstract> return, especially if the application is inherently 2D.  </abstract>::line_number::24
<abstract> We support three kinds of windows implemented on top of Therefore, we have been exploring how we can incorporate  </abstract>::line_number::25
<abstract> the X server: windows fixed to the head-mounted display, an existing 2D window system within a 3D virtual world.  </abstract>::line_number::26
<abstract> windows fixed to the information surround, and windows  </abstract>::line_number::27
<abstract> fixed to locations and objects in the 3D world. Objects can We are building an experimental system that supports a full  </abstract>::line_number::28
<abstract> also be tracked, allowing windows to move with them. To X11 server on a see-through head-mounted display. Our  </abstract>::line_number::29
<abstract> demonstrate the utility of this model, we describe a small display overlays a selected portion of the X bitmap on the  </abstract>::line_number::30
<abstract> hypermedia system that allows links to be made between user's view of the world, creating an X-based augmented  </abstract>::line_number::31
<abstract> windows and windows to be attached to objects. Thus, our reality. Depending on the situation and application, the  </abstract>::line_number::32
<abstract> hypermedia system can forge links between any combina- user may wish to treat a window as a stand-alone entity or  </abstract>::line_number::33
<abstract> tion of physical objects and virtual windows. to take advantage of the potential relationships that can be  </abstract>::line_number::34
<abstract> made between it and the visible physical world. To make  </abstract>::line_number::35
<abstract> this possible, we have developed facilities that allow X KEYWORDS: augmented reality, virtual reality, virtual  </abstract>::line_number::36
<abstract> windows to be situated in a variety of ways relative to the worlds, head-mounted displays, portable computers, mobile  </abstract>::line_number::37
<abstract> user and the 3D world. computing, window systems, X11, hypertext/hypermedia.  </abstract>::line_number::38
<abstract> In this paper we first present related work and provide an  </abstract>::line_number::39
<abstract> overview of our system. Next, we describe the different  </abstract>::line_number::40
<abstract> kinds of windows that we support, and show how these  </abstract>::line_number::41
<abstract> windows can be used to advantage by a simple hypermedia  </abstract>::line_number::42
<abstract> system. Finally, we explain the underlying system architec-   </abstract>::line_number::43
<abstract>  Abstract  </abstract>::line_number::4
<abstract> This paper defines a set of type inference rules for resolving overloading introduced by type classes. Programs including type classes  </abstract>::line_number::5
<abstract> are transformed into ones which may be typed by the Hindley-Milner inference rules. In contrast to other work on type classes, the  </abstract>::line_number::6
<abstract> rules presented here relate directly to user programs. An innovative  </abstract>::line_number::7
<abstract> aspect of this work is the use of second-order lambda calculus to  </abstract>::line_number::8
<abstract> record type information in the program.   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Existing complexity measures from contemporary learning theory cannot be conveniently applied to specific learning problems (e.g., training sets). Moreover, they are typically non-generic,  </abstract>::line_number::9
<abstract> i.e., they necessitate making assumptions about the way in which the learner will operate. The lack  </abstract>::line_number::10
<abstract> of a satisfactory, generic complexity measure for learning problems poses difficulties for researchers  </abstract>::line_number::11
<abstract> in various areas; the present paper puts forward an idea which may help to alleviate these. It  </abstract>::line_number::12
<abstract> shows that supervised learning problems fall into two, generic, complexity classes only one of which  </abstract>::line_number::13
<abstract> is associated with computational tractability. By determining which class a particular problem  </abstract>::line_number::14
<abstract> belongs to, we can thus effectively evaluate its degree of generic difficulty.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Let V and W be n-dimensional vector spaces over GF (2). A mapping  </abstract>::line_number::9
<abstract> Q : V ! W is called crooked if it satisfies the following three properties:  </abstract>::line_number::10
<abstract> Q(0) = 0;  </abstract>::line_number::11
<abstract> Q(x) + Q() + Q() + Q(x + + ) 6= 0 for any three distinct x; ; ;  </abstract>::line_number::12
<abstract> Q(x) + Q() + Q() + Q(x + a) + Q( + a) + Q( + a) 6= 0 if a 6= 0 (x; ;   </abstract>::line_number::13
<abstract> arbitrary).  </abstract>::line_number::14
<abstract> We show that every crooked function gives rise to a distance regular graph  </abstract>::line_number::15
<abstract> of diameter 3 having = 0 and = 2 which is a cover of the complete  </abstract>::line_number::16
<abstract> graph. Our approach is a generalization of a recent construction found by  </abstract>::line_number::17
<abstract> de Caen, Mathon, and Moorhouse. We study graph-theoretical properties of  </abstract>::line_number::18
<abstract> the resulting graphs, including their automorphisms. Also we demonstrate a  </abstract>::line_number::19
<abstract> connection between crooked functions and bent functions.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The use of music as a means to automate the sculpting and movement of graphical objects is investigated. An interactive environment for producing musically-controlled  </abstract>::line_number::8
<abstract> computer animations is presented. The graphical objects studied are based on Todd's  </abstract>::line_number::9
<abstract> and Latham's work in evolutionary art. The environment permits the creation of kernel objects using an interactive toolset. In addition to a basic set of morphological  </abstract>::line_number::10
<abstract> definitions, each object incorporates a script, which is an instance of programming  </abstract>::line_number::11
<abstract> language code and data definitions. Scripts permit the run-time computation of object characteristics, and when done in a temporal setting, allow complex animation  </abstract>::line_number::12
<abstract> control. The script language has a number of functions that can access MIDI information, as read into the system via a MIDI file. The practical consequence of this  </abstract>::line_number::13
<abstract> is that animations are controllable with music data, in which music determines the  </abstract>::line_number::14
<abstract> movement and morphology of animated objects. The tight integration of music and  </abstract>::line_number::15
<abstract> animation in an interactive production environment such as this one has a number  </abstract>::line_number::16
<abstract> of pragmatic consequences, ranging from the ability to automatically synchronize  </abstract>::line_number::17
<abstract> complex activities to music, to the use of music as a creative source for graphical  </abstract>::line_number::18
<abstract> sculptoring and animation.   </abstract>::line_number::19
<abstract>  Abstract: It is shown that if a formula is constructed from noisy 2-input NAND gates,  </abstract>::line_number::12
<abstract> with each gate failing independently with probability ", then reliable computation can or  </abstract>::line_number::13
<abstract> cannot take place according as " is less than or greater than " 0 = (3   </abstract>::line_number::14
<abstract> p   </abstract>::line_number::15
<abstract>  Summary  </abstract>::line_number::7
<abstract> This article presents a software-only solution to the synchronization problem for uniprocessors.  </abstract>::line_number::8
<abstract> The idea is to execute atomic sequences without any hardware protection, and in the rare case  </abstract>::line_number::9
<abstract> of pre-emption, to roll the sequence forward to the end, thereby preserving atomicity. One of  </abstract>::line_number::10
<abstract> the proposed implementations protects atomic sequences without any memory-accesses. This  </abstract>::line_number::11
<abstract> is significant as it enables execution at CPU-speeds, rather than memory-speeds. The benefit of  </abstract>::line_number::12
<abstract> this method increases with the frequency at which atomic sequences are executed. It therefore  </abstract>::line_number::13
<abstract> encourages the building of systems with fine-grained synchronization. This has the additional  </abstract>::line_number::14
<abstract> advantage of reducing average latency. Experiments demonstrate that this technique has the  </abstract>::line_number::15
<abstract> potential to outperform even the best hardware mechanisms. The main contribution of this article  </abstract>::line_number::16
<abstract> is to discuss operating-system related issues of rollforward and to demonstrate its practicality,  </abstract>::line_number::17
<abstract> both in terms of flexibility and performance.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Conventional software radios take advantage of vastly improved A/D converters and DSP hardware. Our  </abstract>::line_number::6
<abstract> approach, which we refer to as virtual radios, also depends upon high performance A/D converters. However,  </abstract>::line_number::7
<abstract> rather than use DSPs, we have chosen to ride the curve of rapidly improving workstation hardware. We use  </abstract>::line_number::8
<abstract> wideband digitization and then perform all of the digital signal processing in user space on a general purpose  </abstract>::line_number::9
<abstract> workstation. This approach allows us to experiment with new approaches to signal processing that exploit the  </abstract>::line_number::10
<abstract> hardware and software resources of the workstation. Furthermore, it allows us to experiment with different  </abstract>::line_number::11
<abstract> ways of structuring systems in which the radio component of communication devices are integrated with  </abstract>::line_number::12
<abstract> higher-level applications.  </abstract>::line_number::13
<abstract> This paper describes the design and performance of an environment we have constructed that facilitates building virtual radios and of two applications built using that environment. The environment consists of an I/O  </abstract>::line_number::14
<abstract> subsystem that provides high bandwidth low latency user-level access to digitized signals and a programming  </abstract>::line_number::15
<abstract> environment that provides an infrastructure for building applications. The applications, which exemplify  </abstract>::line_number::16
<abstract> some of the benefits of virtual radios, are a software cellular receiver and a novel wireless network interface.   </abstract>::line_number::17
<abstract>  Abstract. Myrinet is a new type of local-area network (LAN) based on the  </abstract>::line_number::9
<abstract> technology used for packet communication and switching within "massively-parallel processors" (MPPs). Think of Myrinet as an MPP message-passing  </abstract>::line_number::10
<abstract> network that can span campus dimensions, rather than as a wide-area  </abstract>::line_number::11
<abstract> telecommunications network that is operating in close quarters. The  </abstract>::line_number::12
<abstract> technical steps toward making Myrinet a reality included the development  </abstract>::line_number::13
<abstract> of (1) robust, 25m communication channels with flow control, packet  </abstract>::line_number::14
<abstract> framing, and error control; (2) self-initializing, low-latency, cut-through  </abstract>::line_number::15
<abstract> switches; (3) host interfaces that can map the network, select routes, and  </abstract>::line_number::16
<abstract> translate from network addresses to routes, as well as handle packet traffic;  </abstract>::line_number::17
<abstract> and (4) streamlined host software that allows direct communication  </abstract>::line_number::18
<abstract> between user processes and the network.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::9
<abstract> This paper argues that the CPU/memory data path is a potential throughput bottleneck in  </abstract>::line_number::10
<abstract> workstations connected to high-speed networks, and considers the implications for the design  </abstract>::line_number::11
<abstract> of the I/O subsystem.   </abstract>::line_number::12
<abstract>  ABSTRACT  </abstract>::line_number::7
<abstract> A new virtual memory architecture for the Sun implementation of the UNIX  </abstract>::line_number::8
<abstract> operating system is described. Our goals included unifying and simplifying the concepts  </abstract>::line_number::9
<abstract> the system used to manage memory, as well as providing an implementation that fit well  </abstract>::line_number::10
<abstract> with the rest of the system. We discuss an architecture suitable for environments that  </abstract>::line_number::11
<abstract> (potentially) consist of systems of heterogeneous hardware and software architectures.  </abstract>::line_number::12
<abstract> The result is a page-based system in which the fundamental notion is that of mapping  </abstract>::line_number::13
<abstract> process addresses to files.   </abstract>::line_number::14
<abstract>  Abstract:  </abstract>::line_number::6
<abstract> Modern operating systems provide a rich set of interfaces for mapping, sharing, and protecting memory. Different  </abstract>::line_number::7
<abstract> memory management unit (MMU) architectures provide different mechanisms for managing memory translations.  </abstract>::line_number::8
<abstract> Since the same OS usually runs on different MMU architectures, a software hardware address translation (hat)  </abstract>::line_number::9
<abstract> layer that abstracts the MMU architecture is normally implemented between MMU hardware and the virtual memory system of the OS. In this paper, we study the impact of the OS and the MMU on the structure and performance  </abstract>::line_number::10
<abstract> of the hat layer. In particular, we concentrate on the role of the hat layer on the scalability of system performance  </abstract>::line_number::11
<abstract> on symmetric multiprocessors with 2-12 CPUs. The results show that, unlike single-user applications, multi-user  </abstract>::line_number::12
<abstract> applications require very careful multi-threading of the hat layer to achieve system performance that scales with  </abstract>::line_number::13
<abstract> the number of CPUs. In addition, multi-threading the hat can result in better performance in lesser amounts of  </abstract>::line_number::14
<abstract> physical memory.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The correspondence problem in computer vision is basically a matching task between two or more sets of features. In this paper, we introduce a vectorized image  </abstract>::line_number::9
<abstract> representation, which is a feature-based representation  </abstract>::line_number::10
<abstract> where correspondence has been established with respect  </abstract>::line_number::11
<abstract> to a reference image. The representation consists of two  </abstract>::line_number::12
<abstract> image measurements made at the feature points: shape  </abstract>::line_number::13
<abstract> and texture. Feature geometry, or shape, is represented  </abstract>::line_number::14
<abstract> using the (x; ) locations of features relative to the some  </abstract>::line_number::15
<abstract> standard reference shape. Image grey levels, or texture,  </abstract>::line_number::16
<abstract> are represented by mapping image grey levels onto the  </abstract>::line_number::17
<abstract> standard reference shape. Computing this representation  </abstract>::line_number::18
<abstract> is essentially a correspondence task, and in this paper  </abstract>::line_number::19
<abstract> we explore an automatic technique for "vectorizing" face  </abstract>::line_number::20
<abstract> images. Our face vectorizer alternates back and forth  </abstract>::line_number::21
<abstract> between computation steps for shape and texture, and a  </abstract>::line_number::22
<abstract> key idea is to structure the two computations so that each  </abstract>::line_number::23
<abstract> one uses the output of the other. In addition to describing the vectorizer, an application to the problem of facial  </abstract>::line_number::24
<abstract> feature detection will be presented.   </abstract>::line_number::25
<abstract>  ABSTRACT  </abstract>::line_number::1
<abstract> Multipol is a library of distributed data structures designed for irregular applications, including those with asynchronous communication patterns. In this paper,  </abstract>::line_number::2
<abstract> we describe the Multipol runtime layer, which provides an efficient and portable abstraction underlying the data structures. It contains a thread system to express  </abstract>::line_number::3
<abstract> computations with varying degrees of parallelism and to support multiple threads  </abstract>::line_number::4
<abstract> per processor for hiding communication latency. To simplify programming in a mul-tithreaded environment, Multipol threads are small, finite-length computations that  </abstract>::line_number::5
<abstract> are executed atomically. Rather than enforcing a single scheduling policy on threads,  </abstract>::line_number::6
<abstract> users may write their own schedulers or choose one of the schedulers provided by  </abstract>::line_number::7
<abstract> Multipol. The system is designed for distributed memory architectures and performs  </abstract>::line_number::8
<abstract> communication optimizations such as message aggregation to improve efficiency on  </abstract>::line_number::9
<abstract> machines with high communication startup overhead. The runtime system currently  </abstract>::line_number::10
<abstract> runs on the Thinking Machines CM5, Intel Paragon, and IBM SP1, and is being  </abstract>::line_number::11
<abstract> ported to a network of workstations. Multipol applications include an event-driven  </abstract>::line_number::12
<abstract> timing simulator [1], an eigenvalue solver [2], and a program that solves the phylogeny  </abstract>::line_number::13
<abstract> problem [3].   </abstract>::line_number::14
<abstract>  1. Abstract  </abstract>::line_number::3
<abstract> Interval arithmetic is an automated attempt to give guaranteed upper and lower bounds of a numerical  </abstract>::line_number::4
<abstract> computation in the face of uncertainly in the input data and floating point roundoff during the calculation.  </abstract>::line_number::5
<abstract> While a simple interval equivalent of a rational function can be readily synthesized, the bounds from this  </abstract>::line_number::6
<abstract> construction may be too pessimistically large to be useful. This paper surveys a variety of techniques for  </abstract>::line_number::7
<abstract> refining the interval bounds. An appendix identifies issues with realizing floating point based interval  </abstract>::line_number::8
<abstract> arithmetic on current IEEE 754 compliant processors.   </abstract>::line_number::9
<abstract>  Abstract  </abstract>::line_number::11
<abstract> We present an approach for creating realistic synthetic views of existing architectural  </abstract>::line_number::12
<abstract> scenes from a sparse set of still photographs. Our approach, which combines both geometry-based and image-based modeling and rendering techniques, has two components. The first  </abstract>::line_number::13
<abstract> component is an easy-to-use photogrammetric modeling system which facilitates the recovery of a basic geometric model of the photographed scene. The modeling system is effective  </abstract>::line_number::14
<abstract> and robust because it exploits the constraints that are characteristic of architectural scenes.  </abstract>::line_number::15
<abstract> The second component is a model-based stereo algorithm, which recovers how the real scene  </abstract>::line_number::16
<abstract> deviates from the basic model. By making use of the model, our stereo approach can robustly  </abstract>::line_number::17
<abstract> recover accurate depth from image pairs with large baselines. Consequently, our approach  </abstract>::line_number::18
<abstract> can model large architectural environments with far fewer photographs than current image-based modeling approaches. As an intermediate result, we present view-dependent texture  </abstract>::line_number::19
<abstract> mapping, a method of better simulating geometric detail on basic models. Our approach  </abstract>::line_number::20
<abstract> can recover models for use in either geometry-based or image-based rendering systems. We  </abstract>::line_number::21
<abstract> present results that demonstrate our approach's abilty to create realistic renderings of architectural scenes from viewpoints far from the original photographs.  </abstract>::line_number::22
<abstract> Keywords: Image-based modeling, image-based rendering, interactive modeling systems,  </abstract>::line_number::23
<abstract> photogrammetry, reconstruction, view-dependent texture mapping, view interpolation, model-based stereo   </abstract>::line_number::24
<abstract>  Abstract. Object-Relational and Object-Oriented DBMSs allow  </abstract>::line_number::5
<abstract> users to invoke time-consuming (expensive) methods in their  </abstract>::line_number::6
<abstract> queries. When queries containing these expensive methods are run  </abstract>::line_number::7
<abstract> on data with duplicate values, time is wasted redundantly computing methods on the same value. This problem has been studied in  </abstract>::line_number::8
<abstract> the context of programming languages, where memoization is the  </abstract>::line_number::9
<abstract> standard solution. In the database literature, sorting has been proposed to deal with this problem. We compare these approachesalong  </abstract>::line_number::10
<abstract> with a third solution, a variant of unary hybrid hashing which we call  </abstract>::line_number::11
<abstract> Hybrid Cache. We demonstrate that Hybrid Cache always dominates memoization, and significantly outperforms sorting in many  </abstract>::line_number::12
<abstract> instances. This provides new insights into the tradeoff between hashing and sorting for unary operations. Additionally, our Hybrid Cache  </abstract>::line_number::13
<abstract> algorithm includes some new optimizations for unary hybrid hashing, which can be used for other applications such as grouping and  </abstract>::line_number::14
<abstract> duplicate elimination. We conclude with a discussion of techniques  </abstract>::line_number::15
<abstract> for caching multiple expensive methods in a single query, and raise  </abstract>::line_number::16
<abstract> some new optimization problems in choosing caching techniques.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper describes a practical path planner for  </abstract>::line_number::7
<abstract> nonholonomic robots in environments with obstacles.  </abstract>::line_number::8
<abstract> The planner is based on building a one-dimensional,  </abstract>::line_number::9
<abstract> maximal clearance skeleton through the configuration  </abstract>::line_number::10
<abstract> space of the robot. However rather than using the Eu-clidean metric to determine clearance, a special metric  </abstract>::line_number::11
<abstract> which captures information about the nonholonomy of  </abstract>::line_number::12
<abstract> the robot is used. The robot navigates from start to  </abstract>::line_number::13
<abstract> goal states by loosely following the skeleton; the resulting paths taken by the robot are of low "complexity."  </abstract>::line_number::14
<abstract> We describe how much of the computation can be done  </abstract>::line_number::15
<abstract> off-line once and for all for a given robot, making for  </abstract>::line_number::16
<abstract> an efficient planner. The focus is on path planning  </abstract>::line_number::17
<abstract> for mobile robots, particularly the planar two-axle car,  </abstract>::line_number::18
<abstract> but the underlying ideas are quite general and may be  </abstract>::line_number::19
<abstract> applied to planners for other nonholonomic robots.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::4
<abstract> The relative slowdown of DRAMs with respect to  </abstract>::line_number::5
<abstract> processor speeds and the widespread use of SMP  </abstract>::line_number::6
<abstract> machines have bolstered the reliance on processor caches  </abstract>::line_number::7
<abstract> to provide good performance. As a result, optimizing  </abstract>::line_number::8
<abstract> machines and software for caches have recently received  </abstract>::line_number::9
<abstract> more attention. In addition, with the popularity of  </abstract>::line_number::10
<abstract> extensible computing, which includes the object oriented  </abstract>::line_number::11
<abstract> programming style, shared libraries, and Java based  </abstract>::line_number::12
<abstract> computing, creating effective compilers has become  </abstract>::line_number::13
<abstract> more challenging, with an increased reliance on more  </abstract>::line_number::14
<abstract> dynamic techniques, such as profiling and runtime code  </abstract>::line_number::15
<abstract> generation. This paper proposes a dynamic optimization  </abstract>::line_number::16
<abstract> method called cache windowing to reduce conflict misses  </abstract>::line_number::17
<abstract> in L1 instruction caches. Using a combination of  </abstract>::line_number::18
<abstract> hardware and software support, cache windowing  </abstract>::line_number::19
<abstract> integrates a RollCache (a direct-mapped cache enhanced  </abstract>::line_number::20
<abstract> to support dynamic cache configuration) and a software  </abstract>::line_number::21
<abstract> implemented FIFO caching policy. Together, both allow  </abstract>::line_number::22
<abstract> a program to reposition procedures, dynamically and  </abstract>::line_number::23
<abstract> efficiently, to eliminate cache conflicts. Experiments  </abstract>::line_number::24
<abstract> show that this type of caching scheme can achieve miss  </abstract>::line_number::25
<abstract> rates competitive to a 2-way set associative cache for  </abstract>::line_number::26
<abstract> various programs. Currently, a high software overhead  </abstract>::line_number::27
<abstract> exists to support a software caching policy, though  </abstract>::line_number::28
<abstract> different compiler optimizations, such as inlining, may  </abstract>::line_number::29
<abstract> help to reduce this. Such a system provides a more robust  </abstract>::line_number::30
<abstract> runtime architecture that, potentially, may adapt better to  </abstract>::line_number::31
<abstract> a wider variety of environments.   </abstract>::line_number::32
<abstract>  Abstract  </abstract>::line_number::14
<abstract> The problem of belief changehow an agent should revise her beliefs upon learning new  </abstract>::line_number::15
<abstract> informationhas been an active area of research in both philosophy and artificial intelligence.  </abstract>::line_number::16
<abstract> Many approaches to belief change have been proposed in the literature. Our goal is not to  </abstract>::line_number::17
<abstract> introduce yet another approach, but to examine carefully the rationale underlying the approaches  </abstract>::line_number::18
<abstract> already taken in the literature, and to highlight what we view as methodological problems in the  </abstract>::line_number::19
<abstract> literature. The main message is that to study belief change carefully, we must be quite explicit  </abstract>::line_number::20
<abstract> about the ontology or scenario underlying the belief change process. This is something that  </abstract>::line_number::21
<abstract> has been missing in previous work, with its focus on postulates. Our analysis shows that we  </abstract>::line_number::22
<abstract> must pay particular attention to two issues which have often been taken for granted: The first  </abstract>::line_number::23
<abstract> is how we model the agent's epistemic state. (Do we use a set of beliefs, or a richer structure,  </abstract>::line_number::24
<abstract> such as an ordering on worlds? And if we use a set of beliefs, in what language are these  </abstract>::line_number::25
<abstract> beliefs are expressed?) The second is the status of observations. (Are observations known to  </abstract>::line_number::26
<abstract> be true, or just believed? In the latter case, how firm is the belief?) For example, we argue that  </abstract>::line_number::27
<abstract> even postulates that have been called beyond controversy are unreasonable when the agent's  </abstract>::line_number::28
<abstract> beliefs include beliefs about her own epistemic state as well as the external world. Issues of the  </abstract>::line_number::29
<abstract> status of observations arise particularly when we consider iterated belief revision, and we must  </abstract>::line_number::30
<abstract> confront the possibility of revising by ' and then by :'.   </abstract>::line_number::31
<abstract>  Abstract  </abstract>::line_number::19
<abstract> Conditional logics play an important role in recent attempts  </abstract>::line_number::20
<abstract> to investigate default reasoning. This paper investigates first-order conditional logic. We show that, as for first-order  </abstract>::line_number::21
<abstract> probabilistic logic, it is important not to confound statistical conditionals over the domain (such as most birds fly),  </abstract>::line_number::22
<abstract> and subjective conditionals over possible worlds (such as I  </abstract>::line_number::23
<abstract> believe that Tweety is unlikely to fly). We then address  </abstract>::line_number::24
<abstract> the issue of ascribing semantics to first-order conditional  </abstract>::line_number::25
<abstract> logic. As in the propositional case, there are many possible semantics. To study the problem in a coherent way, we  </abstract>::line_number::26
<abstract> use plausibility structures. These provide us with a general  </abstract>::line_number::27
<abstract> framework in which many of the standard approaches can be  </abstract>::line_number::28
<abstract> embedded. We show that while these standard approaches  </abstract>::line_number::29
<abstract> are all the same at the propositional level, they are significantly different in the context of a first-order language. We  </abstract>::line_number::30
<abstract> show that plausibilities provide the most natural extension of  </abstract>::line_number::31
<abstract> conditional logic to the first-order case: We provide a sound  </abstract>::line_number::32
<abstract> and complete axiomatization that contains only the KLM  </abstract>::line_number::33
<abstract> properties and standard axioms of first-order modal logic.  </abstract>::line_number::34
<abstract> We show that most of the other approaches have additional  </abstract>::line_number::35
<abstract> properties, which result in an inappropriate treatment of an  </abstract>::line_number::36
<abstract> infinitary version of the lottery paradox.   </abstract>::line_number::37
<abstract>  Abstract  </abstract>::line_number::4
<abstract> A simple and efficient algorithm for finding the closest points between two convex polyhedra is described  </abstract>::line_number::5
<abstract> here. Data from numerous experiments tested on a  </abstract>::line_number::6
<abstract> broad set of convex polyhedra on &lt; 3 show that the  </abstract>::line_number::7
<abstract> running time is roughly constant for finding closest  </abstract>::line_number::8
<abstract> points when nearest points are approximately known  </abstract>::line_number::9
<abstract> and is linear in total number of vertices if no special  </abstract>::line_number::10
<abstract> initialization is done. This algorithm can be used for  </abstract>::line_number::11
<abstract> collision detection, computation of the distance between two polyhedra in three-dimensional space, and  </abstract>::line_number::12
<abstract> other robotics problems. It forms the heart of the  </abstract>::line_number::13
<abstract> motion planning algorithm of [1].   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::10
<abstract> Multi-threaded programming is difficult and error prone. It  </abstract>::line_number::11
<abstract> is easy to make a mistake in synchronization that produces a  </abstract>::line_number::12
<abstract> data race, yet it can be extremely hard to locate this mistake  </abstract>::line_number::13
<abstract> during debugging. This paper describes a new tool, called  </abstract>::line_number::14
<abstract> Eraser, for dynamically detecting data races in lock-based  </abstract>::line_number::15
<abstract> multi-threaded programs. Eraser uses binary rewriting techniques to monitor every shared memory reference and verify  </abstract>::line_number::16
<abstract> that consistent locking behavior is observed. We present several case studies, including undergraduate coursework and a  </abstract>::line_number::17
<abstract> multi-threaded Web search engine, that demonstrate the effectiveness of this approach.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::21
<abstract> We report the performance of NOW-Sort, a collection of sorting implementations on a Network of Workstations (NOW).  </abstract>::line_number::22
<abstract> We find that parallel sorting on a NOW is competitive to sorting on the large-scale SMPs that have traditionally held the  </abstract>::line_number::23
<abstract> performance records. On a 64-node cluster, we sort 6.0 GB  </abstract>::line_number::24
<abstract> in just under one minute, while a 32-node cluster finishes the  </abstract>::line_number::25
<abstract> Datamation benchmark in 2.41 seconds.  </abstract>::line_number::26
<abstract> Our implementations can be applied to a variety of disk,  </abstract>::line_number::27
<abstract> memory, and processor configurations; we highlight salient  </abstract>::line_number::28
<abstract> issues for tuning each component of the system. We evaluate the use of commodity operating systems and hardware for  </abstract>::line_number::29
<abstract> parallel sorting. We find existing OS primitives for memory  </abstract>::line_number::30
<abstract> management and file access adequate. Due to aggregate communication and disk bandwidth requirements, the bottleneck  </abstract>::line_number::31
<abstract> of our system is the workstation I/O bus.   </abstract>::line_number::32
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We present an implementation of a Fast Fourier Transform on Vector Intelligent RAM architecture. The algorithm computes the Discrete  </abstract>::line_number::8
<abstract> Fourier Transform in O(N log N) time, is self-sorting (no bit-reversed copy  </abstract>::line_number::9
<abstract> phase is required), and has a minimum vector length of  </abstract>::line_number::10
<abstract> p  </abstract>::line_number::11
<abstract> N=2, where N is  </abstract>::line_number::12
<abstract> the number of data points in the transform. An N-element scratch space  </abstract>::line_number::13
<abstract> is required. The performance of this algorithm on VIRAM is analyzed  </abstract>::line_number::14
<abstract> against two variants of the Stockham [12] algorithm.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper examines the plausibility of using a network of  </abstract>::line_number::8
<abstract> workstations (NOW) for a mixture of parallel and sequential  </abstract>::line_number::9
<abstract> jobs. Through simulations, our study examines issues that arise  </abstract>::line_number::10
<abstract> when combining these two workloads on a single platform. Starting from a dedicated NOW just for parallel programs, we incrementally relax uniprogramming restrictions until we have a  </abstract>::line_number::11
<abstract> multi-programmed, multi-user NOW for both interactive sequential users and parallel programs. We show that a number of issues  </abstract>::line_number::12
<abstract> associated with the distributed NOW environment (e.g., daemon  </abstract>::line_number::13
<abstract> activity, coscheduling skew) can have a small but noticeable effect on parallel program performance. We also find that efficient  </abstract>::line_number::14
<abstract> migration to idle workstations is necessary to maintain acceptable parallel application performance. Furthermore, we present a  </abstract>::line_number::15
<abstract> methodology for deriving an optimal delay time for recruiting idle  </abstract>::line_number::16
<abstract> machines for use by parallel programs; this recruitment threshold  </abstract>::line_number::17
<abstract> was just 3 minutes for the research cluster we measured. Finally,  </abstract>::line_number::18
<abstract> we quantify the effects of the additional parallel load upon interactive users by keeping track of the potential number of user  </abstract>::line_number::19
<abstract> delays in our simulations. When we limit the maximum number  </abstract>::line_number::20
<abstract> of delays per user, we can still maintain acceptable parallel program performance. In summary, we find that for our workloads a  </abstract>::line_number::21
<abstract> 2:1 rule applies: a NOW cluster of approximately 60 machines can  </abstract>::line_number::22
<abstract> sustain a 32-node parallel workload in addition to the sequential  </abstract>::line_number::23
<abstract> load placed upon it by interactive users.   </abstract>::line_number::24
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> In this paper, we describe the design and implementation of a prototype  </abstract>::line_number::7
<abstract> software video production switcher, vps, that improves the quality of the content of MBone broadcasts. vps is modeled after the broadcast television industry's studio production switcher. It provides special effects processing to  </abstract>::line_number::8
<abstract> incorporate audience discussions, add titles and other information, and integrate stored videos into the presentation. vps is structured to work with other  </abstract>::line_number::9
<abstract> MBone conferencing tools. The ultimate goal is to automate the production of  </abstract>::line_number::10
<abstract> MBone broadcasts.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The analysis of nominal compound constructions has proven to be a recalcitrant problem  </abstract>::line_number::10
<abstract> for linguistic semantics and poses serious challenges for natural language processing systems.  </abstract>::line_number::11
<abstract> We argue for a compositional treatment of compound constructions which limits the need for  </abstract>::line_number::12
<abstract> listing of compounds in the lexicon. We argue that the development of a practical model of  </abstract>::line_number::13
<abstract> compound interpretation crucially depends on issues of lexicon design. The Generative Lexicon  </abstract>::line_number::14
<abstract> (Pustejovsky 1995) provides us with a model of the lexicon which couples sufficiently expressive  </abstract>::line_number::15
<abstract> lexical semantic representations with mechanisms which capture the relationship between those  </abstract>::line_number::16
<abstract> representations and their syntactic expression. In our approach, the qualia structures of the  </abstract>::line_number::17
<abstract> nouns in a compound provide relational structure enabling compositional interpretation of the  </abstract>::line_number::18
<abstract> modification of the head noun by the modifying noun. This brings compound interpretation  </abstract>::line_number::19
<abstract> under the same rubric as other forms of composition in natural language, including argument  </abstract>::line_number::20
<abstract> selection, adjectival modification, and type coercion (Pustejovsky (1991,1995), Bouillon 1995).  </abstract>::line_number::21
<abstract> We examine data from both English and Italian and develop analyses for both languages which use  </abstract>::line_number::22
<abstract> phrase structure schemata to account for the connections between lexical semantic representation  </abstract>::line_number::23
<abstract> and syntactic expression. In addition to applications in natural language understanding, machine  </abstract>::line_number::24
<abstract> translation, and generation, the model of compound interpretation developed here can be applied  </abstract>::line_number::25
<abstract> to multi-lingual information extraction tasks.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::2
<abstract> We present stochastic interactive semantics for propositional linear  </abstract>::line_number::3
<abstract> logic without modalities. The framework is based on interactive  </abstract>::line_number::4
<abstract> protocols considered in computational complexity theory, in which  </abstract>::line_number::5
<abstract> a prover with unlimited power interacts with a verifier that can  </abstract>::line_number::6
<abstract> only toss fair coins or perform simple tasks when presented with  </abstract>::line_number::7
<abstract> the given formula or with subsequent messages from the prover.  </abstract>::line_number::8
<abstract> The additive conjunction & is described as random choice, which  </abstract>::line_number::9
<abstract> reflects the intuitive idea that the verifier can perform only "random spot checks". This stochastic interactive semantic framework  </abstract>::line_number::10
<abstract> is shown to be sound and complete. Furthermore, the prover's  </abstract>::line_number::11
<abstract> winning strategies are basically proofs of the given formula. In  </abstract>::line_number::12
<abstract> this framework the multiplicative and additive connectives of linear logic are described by means of probabilistic operators, giving a  </abstract>::line_number::13
<abstract> new basis for intuitive reasoning about linear logic and a potential  </abstract>::line_number::14
<abstract> new tool in automated deduction.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::27
<abstract> In this paper we present an extensive experimental study comparing three general-purpose graph  </abstract>::line_number::28
<abstract> drawing algorithms. The three algorithms take as  </abstract>::line_number::29
<abstract> input general graphs (with no restrictions whatsoever on the connectivity, planarity, etc.) and construct orthogonal grid drawings, which are widely  </abstract>::line_number::30
<abstract> used in software and database visualization applications. The test data (available by anonymous  </abstract>::line_number::31
<abstract> ftp) are 11,582 graphs, ranging from 10 to 100  </abstract>::line_number::32
<abstract> vertices, which have been generated from a core  </abstract>::line_number::33
<abstract> set of 112 graphs used in "real-life" software engineering and database applications. The experiments provide a detailed quantitative evaluation of  </abstract>::line_number::34
<abstract> the performance of the three algorithms, and show  </abstract>::line_number::35
<abstract> that they exhibit trade-offs between "aesthetic"  </abstract>::line_number::36
<abstract> properties (e.g., crossings, bends, edge length) and  </abstract>::line_number::37
<abstract> running time. The observed practical behavior of  </abstract>::line_number::38
<abstract> the algorithms is consistent with their theoretical  </abstract>::line_number::39
<abstract> properties.  </abstract>::line_number::40
<abstract> Research supported in part by the US National Science Foundation, by the US Army Research Office, by the US Office of  </abstract>::line_number::41
<abstract> Naval Research and the Advanced Research Projects Agency, by  </abstract>::line_number::42
<abstract> the NATO Scientific Affairs Division, by the "Progetto Finalizzato  </abstract>::line_number::43
<abstract> Sistemi Informatici e Calcolo Parallelo (Sottoprogetto 6, Infokit)"  </abstract>::line_number::44
<abstract> and Grant 94.23.CT07 of the Italian National Research Council  </abstract>::line_number::45
<abstract> (CNR), and by the ESPRIT II Basic Research Actions Program of  </abstract>::line_number::46
<abstract> the European Community (project ALgorithms and Complexity).   </abstract>::line_number::47
<abstract>  0.1 Still To Do  </abstract>::line_number::3
<abstract> * 6 more fold proofs, precondition proofs  </abstract>::line_number::4
<abstract> * Adjust primitives for Int, Str and Char to be synchronized with the Theta operators for these types  </abstract>::line_number::5
<abstract> * Add floats  </abstract>::line_number::6
<abstract> * Add section describing preconditions  </abstract>::line_number::7
<abstract> * Add section on semantic optimizations, nested query optimization  </abstract>::line_number::8
<abstract> * Fix awk script to generate Latex version of Larch scripts without typeface glitches   </abstract>::line_number::9
<abstract>  We are interested in efficiently accessing data in an object-oriented database.  </abstract>::line_number::5
<abstract> We have developed a query algebra which fully supports object identity and  </abstract>::line_number::6
<abstract> abstract data types, and have identified a variety of algebraic query transformations. The equivalence of two queries is complicated by the presence of  </abstract>::line_number::7
<abstract> object identity. In this paper we define a hierarchy of notions of equivalence  </abstract>::line_number::8
<abstract> for queries, and present examples of equivalent query transformations for each  </abstract>::line_number::9
<abstract> level of the hierarchy.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Relational database systems and most object-oriented database systems provide support for queries.  </abstract>::line_number::8
<abstract> Usually these queries represent retrievals over sets or  </abstract>::line_number::9
<abstract> multisets. Many new applications for databases, such  </abstract>::line_number::10
<abstract> as multimedia systems and digital libraries, need support for queries on complex bulk types such as lists  </abstract>::line_number::11
<abstract> and trees. In this paper we describe an object-oriented  </abstract>::line_number::12
<abstract> query algebra for lists and trees. The operators in the  </abstract>::line_number::13
<abstract> algebra preserve the ordering between the elements of a  </abstract>::line_number::14
<abstract> list or tree, even when the result list or tree contains an  </abstract>::line_number::15
<abstract> arbitrary set of nodes from the original tree. We also  </abstract>::line_number::16
<abstract> present predicate languages for lists and trees which  </abstract>::line_number::17
<abstract> allow order-sensitive queries because they use pattern  </abstract>::line_number::18
<abstract> matching to examine groups of list or tree nodes rather  </abstract>::line_number::19
<abstract> than individual nodes. The ability to decompose predicate patterns enables optimizations that make use of  </abstract>::line_number::20
<abstract> indices.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper is concerned with modeling  </abstract>::line_number::7
<abstract> planning problems involving uncertainty as  </abstract>::line_number::8
<abstract> discrete-time, finite-state stochastic automata.  </abstract>::line_number::9
<abstract> Solving planning problems is reduced to computing policies for Markov decision processes.  </abstract>::line_number::10
<abstract> Classical methods for solving Markov decision  </abstract>::line_number::11
<abstract> processes cannot cope with the size of the  </abstract>::line_number::12
<abstract> state spaces for typical problems encountered  </abstract>::line_number::13
<abstract> in practice. As an alternative, we investigate  </abstract>::line_number::14
<abstract> methods that decompose global planning problems into a number of local problems, solve the  </abstract>::line_number::15
<abstract> local problems separately, and then combine  </abstract>::line_number::16
<abstract> the local solutions to generate a global solution. We present algorithms that decompose  </abstract>::line_number::17
<abstract> planning problems into smaller problems given  </abstract>::line_number::18
<abstract> an arbitrary partition of the state space. The  </abstract>::line_number::19
<abstract> local problems are interpreted as Markov decision processes and solutions to the local problems are interpreted as policies restricted to the  </abstract>::line_number::20
<abstract> subsets of the state space defined by the partition. One algorithm relies on constructing and  </abstract>::line_number::21
<abstract> solving an abstract version of the original decision problem. A second algorithm iteratively  </abstract>::line_number::22
<abstract> approximates parameters of the local problems  </abstract>::line_number::23
<abstract> to converge to an optimal solution. We show  </abstract>::line_number::24
<abstract> how properties of a specified partition affect the  </abstract>::line_number::25
<abstract> time and storage required for these algorithms.   </abstract>::line_number::26
<abstract>  We are concerned with temporal reasoning problems where there is uncertainty about the order  </abstract>::line_number::5
<abstract> in which events occur. The task of temporal reasoning is to derive an event sequence consistent with  </abstract>::line_number::6
<abstract> a given set of ordering constraints to achieve a goal. Previous research shows that the associated  </abstract>::line_number::7
<abstract> decision problems are hard even for very restricted cases. In this paper, we investigate locality in  </abstract>::line_number::8
<abstract> event ordering and causal dependencies. We present a localized temporal reasoning algorithm that  </abstract>::line_number::9
<abstract> uses subgoals and abstract events to exploit locality. The computational efficiency of our algorithm  </abstract>::line_number::10
<abstract> for a problem instance is quantified by the inherent locality in the instance. We theoretically  </abstract>::line_number::11
<abstract> demonstrate the substantial improvement in performance gained by exploiting locality. This work  </abstract>::line_number::12
<abstract> provides a solid evidence of the usefulness of localized reasoning in exploiting locality.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::11
<abstract> We investigate the use of temporally abstract  </abstract>::line_number::12
<abstract> actions, or macro-actions, in the solution of  </abstract>::line_number::13
<abstract> Markov decision processes. Unlike current models that combine both primitive actions and  </abstract>::line_number::14
<abstract> macro-actions and leave the state space unchanged, we propose a hierarchical model (using  </abstract>::line_number::15
<abstract> an abstract MDP) that works with macro-actions  </abstract>::line_number::16
<abstract> only, and that significantly reduces the size of the  </abstract>::line_number::17
<abstract> state space. This is achieved by treating macro-actions as local policies that act in certain regions  </abstract>::line_number::18
<abstract> of state space, and by restricting states in the abstract MDP to those at the boundaries of regions.  </abstract>::line_number::19
<abstract> The abstract MDP approximates the original and  </abstract>::line_number::20
<abstract> can be solved more efficiently. We discuss several ways in which macro-actions can be generated to ensure good solution quality. Finally,  </abstract>::line_number::21
<abstract> we consider ways in which macro-actions can be  </abstract>::line_number::22
<abstract> reused to solve multiple, related MDPs; and we  </abstract>::line_number::23
<abstract> show that this can justify the computational over  </abstract>::line_number::24
<abstract> head of macro-action generation.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::13
<abstract> This paper investigates the power of genetic algorithms at solving the MAX-CLIQUE problem. We measure the performance of a standard genetic algorithm on an elementary set of  </abstract>::line_number::14
<abstract> problem instances consisting of embedded cliques in random graphs. We indicate the need  </abstract>::line_number::15
<abstract> for improvement, and introduce a new genetic algorithm, the multi-phase annealed GA, which  </abstract>::line_number::16
<abstract> exhibits superior performance on the same problem set.  </abstract>::line_number::17
<abstract> As we scale up the problem size and test on "hard" benchmark instances, we notice a  </abstract>::line_number::18
<abstract> degraded performance in the algorithm caused by premature convergence to local minima. To  </abstract>::line_number::19
<abstract> alleviate this problem, a sequence of modifications are implemented ranging from changes in  </abstract>::line_number::20
<abstract> input representation to systematic local search. The most recent version, called union GA,  </abstract>::line_number::21
<abstract> incorporates the features of union cross-over, greedy replacement, and diversity enhancement.  </abstract>::line_number::22
<abstract> It shows a marked speed-up in the number of iterations required to find a given solution, as well  </abstract>::line_number::23
<abstract> as some improvement in the clique size found.  </abstract>::line_number::24
<abstract> We discuss issues related to the SIMD implementation of the genetic algorithms on a Thinking Machines CM-5, which was necessitated by the intrinsically high time complexity (O(n 3 ))  </abstract>::line_number::25
<abstract> of the serial algorithm for computing one iteration.  </abstract>::line_number::26
<abstract> Our preliminary conclusions are: (1) a genetic algorithm needs to be heavily customized to  </abstract>::line_number::27
<abstract> work "well" for the clique problem; (2) a GA is computationally very expensive, and its use is  </abstract>::line_number::28
<abstract> only recommended if it is known to find larger cliques than other algorithms; (3) although our  </abstract>::line_number::29
<abstract> customization effort is bringing forth continued improvements, there is no clear evidence, at this  </abstract>::line_number::30
<abstract> time, that a GA will have better success in circumventing local minima.   </abstract>::line_number::31
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Mitchell defined and axiomatized a subtyping relationship (also known  </abstract>::line_number::9
<abstract> as containment, coercibility, or subsumption) over the types of System F  </abstract>::line_number::10
<abstract> (with "!" and "8"). This subtyping relationship is quite simple and does  </abstract>::line_number::11
<abstract> not involve bounded quantification. Tiuryn and Urzyczyn quite recently  </abstract>::line_number::12
<abstract> proved this subtyping relationship to be undecidable. This paper supplies a new undecidability proof for this subtyping relationship. First, a  </abstract>::line_number::13
<abstract> new syntax-directed axiomatization of the subtyping relationship is defined. Then, this axiomatization is used to prove a reduction from the  </abstract>::line_number::14
<abstract> undecidable problem of semi-unification to subtyping. The undecidability of subtyping implies the undecidability of type checking for System F  </abstract>::line_number::15
<abstract> extended with Mitchell's subtyping, also known as "F plus eta".   </abstract>::line_number::16
<abstract>  ABSTRACT:  </abstract>::line_number::10
<abstract> In this paper, we overview the implementation of TCP Boston  </abstract>::line_number::11
<abstract> a novel fragmentation-tolerant transport protocol, especially  </abstract>::line_number::12
<abstract> suited for ATM's 53-byte cell-oriented switching architecture.  </abstract>::line_number::13
<abstract> TCP Boston integrates a standard TCP/IP protocol, such as  </abstract>::line_number::14
<abstract> Reno or Vegas, with a powerful redundancy control mechanism based on AIDAan adaptive version of Rabin's IDA dispersal and reconstruction algorithms. Our results show that  </abstract>::line_number::15
<abstract> TCP Boston improves TCP/IP's performance over ATMs for  </abstract>::line_number::16
<abstract> both network-centric metrics (e.g., effective throughput) and  </abstract>::line_number::17
<abstract> application-centric metrics (e.g., response time).   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::4
<abstract> The purpose of these notes is to describe some of the physical and mathematical properties  </abstract>::line_number::5
<abstract> of the equations occurring in global illumination. We first examine the physical assumptions  </abstract>::line_number::6
<abstract> that make the particle model of light an appropriate paradigm for computer graphics and  </abstract>::line_number::7
<abstract> then derive a balance equation for photons. In doing this we establish connections with the  </abstract>::line_number::8
<abstract> field of radiative transfer and its more abstract counterpart, transport theory. The resulting  </abstract>::line_number::9
<abstract> balance equation, known as the equation of transfer, accounts for large-scale interaction  </abstract>::line_number::10
<abstract> of light with participating media as well as complex reflecting surfaces. Under various  </abstract>::line_number::11
<abstract> simplifying assumptions the equation of transfer reduces to more conventional equations  </abstract>::line_number::12
<abstract> encountered in global illumination.   </abstract>::line_number::13
<abstract>  In this paper, we present an approach for the reconstruction of teeth model. Therefore,  </abstract>::line_number::5
<abstract> a tooth model has to be scanned from several directions with a 3D-laser scanner. Several  </abstract>::line_number::6
<abstract> views are necessary because of shadows and occluded areas in the range images. Then,  </abstract>::line_number::7
<abstract> all acquired range views are combined to build a CAD-model of the tooth. The idea is  </abstract>::line_number::8
<abstract> that every part of the surface should be visible in at least one view. The reconstruction  </abstract>::line_number::9
<abstract> process is divided into the steps registration, volume sculpturing and generation of an  </abstract>::line_number::10
<abstract> accurate polygonal representation.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Industrial assembly involves sensing the pose (orientation and position) of a part. Efficient and reliable  </abstract>::line_number::7
<abstract> sensing strategies can be developed for an assembly  </abstract>::line_number::8
<abstract> task if the shape of the part is known in advance. In  </abstract>::line_number::9
<abstract> this paper we investigate the problem of determining  </abstract>::line_number::10
<abstract> the pose of a convex n-gon from a set of m supporting  </abstract>::line_number::11
<abstract> cones, i.e., cones with both sides supporting the polygon. An algorithm with running time O(nm) which  </abstract>::line_number::12
<abstract> almost always reduces to O(n + m log n) is presented  </abstract>::line_number::13
<abstract> to solve for all possible poses of the polygon. As a consequence, the polygon inscription problem of finding all  </abstract>::line_number::14
<abstract> possible poses for a convex n-gon inscribed in another  </abstract>::line_number::15
<abstract> convex m-gon, can be solved within the same asymptotic time bound. We prove that the number of possible poses cannot exceed 6n, given m 2 supporting  </abstract>::line_number::16
<abstract> cones with distinct vertices. Experiments demonstrate  </abstract>::line_number::17
<abstract> that two supporting cones are sufficient to determine  </abstract>::line_number::18
<abstract> the real pose of the n-gon in most cases.  </abstract>::line_number::19
<abstract> Our results imply that sensing in practice can be  </abstract>::line_number::20
<abstract> carried out by obtaining viewing angles of a planar  </abstract>::line_number::21
<abstract> part at multiple exterior sites in the plane. As a conclusion, we generalize this and other sensing methods  </abstract>::line_number::22
<abstract> into a scheme named sensing by inscription.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The theory revision problem is the problem of how best to go about revising a deficient  </abstract>::line_number::10
<abstract> domain theory using information contained in examples that expose inaccuracies. In this paper we  </abstract>::line_number::11
<abstract> present our approach to the theory revision problem for propositional domain theories. The  </abstract>::line_number::12
<abstract> approach described here, called PTR, uses probabilities associated with domain theory elements to  </abstract>::line_number::13
<abstract> numerically track the ``ow'' of proof through the theory. This allows us to measure the precise  </abstract>::line_number::14
<abstract> role of a clause or literal in allowing or preventing a (desired or undesired) derivation for a given  </abstract>::line_number::15
<abstract> example. This information is used to efficiently locate and repair awed elements of the theory.  </abstract>::line_number::16
<abstract> PTR is proved to converge to a theory which correctly classifies all examples, and shown  </abstract>::line_number::17
<abstract> experimentally to be fast and accurate even for deep theories.   </abstract>::line_number::18
<abstract>  Abstract:  </abstract>::line_number::7
<abstract> Current and emerging real-time and multimedia applications like multi-party collaboration, internet telephony and  </abstract>::line_number::8
<abstract> distributed command control systems require the exchange of information over distributed and heterogeneous nodes.  </abstract>::line_number::9
<abstract> Multiple data types including voice, video, sensor data, real-time intelligence data and text are being transported  </abstract>::line_number::10
<abstract> widely across today's information, control and surveillance networks. All such applications can benefit enormously  </abstract>::line_number::11
<abstract> from middleware, operating system and networking services that can support QoS guarantees, high availability,  </abstract>::line_number::12
<abstract> dynamic reconfigurability and scalability.  </abstract>::line_number::13
<abstract> In this paper, we propose a middleware layer called a "Real-Time Push-Pull Communications Service" to easily and quickly disseminate information across heterogeneous nodes with an underlying architecture to satisfy the  </abstract>::line_number::14
<abstract> above-mentioned requirements. Push-Pull Communications is an extension of the real-time publisher/subscriber  </abstract>::line_number::15
<abstract> model [4], and represents both "push" (data transfer initiated by a sender) and "pull" (data transfer initiated by a  </abstract>::line_number::16
<abstract> receiver) communications. Nodes with widely differing processing power and networking bandwidth can coordinate  </abstract>::line_number::17
<abstract> and co-exist by the provision of appropriate and automatic support for transformation on data and supports scaling.  </abstract>::line_number::18
<abstract> Different information sources and sinks can operate at different frequencies and also can choose another (intermedi-ate) node to act as their proxy and and deliver data at the desired frequency. This service has been implemented  </abstract>::line_number::19
<abstract> on RT-Mach, a resource-centric kernel using resource kernel primitives [7]. This paper presents an overview of the  </abstract>::line_number::20
<abstract> design, implementation and preliminary performance evaluation of the model.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Quality-of-Service (QoS) routing tries to select a path that satisfies a set of  </abstract>::line_number::7
<abstract> QoS constraints, while also achieving overall network resource efficiency. We  </abstract>::line_number::8
<abstract> present initial results on QoS path selection for traffic requiring bandwidth  </abstract>::line_number::9
<abstract> and delay guarantees. For traffic with bandwidth guarantees, we found that  </abstract>::line_number::10
<abstract> several routing algorithms that favor paths with fewer hops perform well. For  </abstract>::line_number::11
<abstract> traffic with delay guarantees, we show that for a broad class of WFQ-like  </abstract>::line_number::12
<abstract> scheduling algorithms, the problem of finding a path satisfying bandwidth,  </abstract>::line_number::13
<abstract> delay, delay-jitter, and/or buffer space constraints while at the same time  </abstract>::line_number::14
<abstract> deriving the bandwidth that has to be reserved to meet these constraints, is  </abstract>::line_number::15
<abstract> solvable by a modified version of the Bellman-Ford shortest-path algorithm  </abstract>::line_number::16
<abstract> in polynomial time.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Abstraction is one of the most promising approaches to improve the performance of problem  </abstract>::line_number::8
<abstract> solvers. In several domains abstraction by dropping sentences of a domain description as  </abstract>::line_number::9
<abstract> used in most hierarchical planners has proven useful. In this paper we present examples  </abstract>::line_number::10
<abstract> which illustrate significant drawbacks of abstraction by dropping sentences. To overcome  </abstract>::line_number::11
<abstract> these drawbacks, we propose a more general view of abstraction involving the change of  </abstract>::line_number::12
<abstract> representation language. We have developed a new abstraction methodology and a related  </abstract>::line_number::13
<abstract> sound and complete learning algorithm that allows the complete change of representation  </abstract>::line_number::14
<abstract> language of planning cases from concrete to abstract. However, to achieve a powerful  </abstract>::line_number::15
<abstract> change of the representation language, the abstract language itself as well as rules which  </abstract>::line_number::16
<abstract> describe admissible ways of abstracting states must be provided in the domain model.  </abstract>::line_number::17
<abstract> This new abstraction approach is the core of Paris (Plan Abstraction and Refinement  </abstract>::line_number::18
<abstract> in an Integrated System), a system in which abstract planning cases are automatically  </abstract>::line_number::19
<abstract> learned from given concrete cases. An empirical study in the domain of process planning  </abstract>::line_number::20
<abstract> in mechanical engineering shows significant advantages of the proposed reasoning from  </abstract>::line_number::21
<abstract> abstract cases over classical hierarchical planning.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The FAA Aging Aircraft Research Program is  </abstract>::line_number::10
<abstract> supporting the development of a robotic mobile  </abstract>::line_number::11
<abstract> nondestructive inspection (NDI) instrument  </abstract>::line_number::12
<abstract> deployment tool at Carnegie Mellon University  </abstract>::line_number::13
<abstract> (CMU) with the active participation of USAir. The  </abstract>::line_number::14
<abstract> program has spawned several new relationships  </abstract>::line_number::15
<abstract> and entities: an alliance with an ARPA-funded  </abstract>::line_number::16
<abstract> research program at CMU having the capability to  </abstract>::line_number::17
<abstract> add 3D-stereoscopic enhanced visual inspection  </abstract>::line_number::18
<abstract> capability, a start-up company organized to  </abstract>::line_number::19
<abstract> commercialize the combined technologies, and  </abstract>::line_number::20
<abstract> State of Pennsylvania funding to foster this  </abstract>::line_number::21
<abstract> commercialization. As a result of these activities  </abstract>::line_number::22
<abstract> and connections the civilian sector appears to be  </abstract>::line_number::23
<abstract> ahead of the military sector in important aspects of  </abstract>::line_number::24
<abstract> automation for deployment of aircraft inspection  </abstract>::line_number::25
<abstract> equipment. A partnership between the university  </abstract>::line_number::26
<abstract> researchers, the airline operator, the start-up  </abstract>::line_number::27
<abstract> company, and the state government is thus  </abstract>::line_number::28
<abstract> emerging as the likely agent for transfer of the  </abstract>::line_number::29
<abstract> civilian-developed technology to the military sector.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Because the World Wide Web consists primarily of  </abstract>::line_number::9
<abstract> text, information extraction is central to any effort that  </abstract>::line_number::10
<abstract> would use the Web as a resource for knowledge discovery. We show how information extraction can be cast  </abstract>::line_number::11
<abstract> as a standard machine learning problem, and argue for  </abstract>::line_number::12
<abstract> the suitability of relational learning in solving it. The  </abstract>::line_number::13
<abstract> implementation of a general-purpose relational learner  </abstract>::line_number::14
<abstract> for information extraction, SRV, is described. In contrast with earlier learning systems for information extraction, SRV makes no assumptions about document  </abstract>::line_number::15
<abstract> structure and the kinds of information available for use  </abstract>::line_number::16
<abstract> in learning extraction patterns. Instead, structural and  </abstract>::line_number::17
<abstract> other information is supplied as input in the form of an  </abstract>::line_number::18
<abstract> extensible token-oriented feature set. We demonstrate  </abstract>::line_number::19
<abstract> the effectiveness of this approach by adapting SRV for  </abstract>::line_number::20
<abstract> use in learning extraction rules for a domain consisting  </abstract>::line_number::21
<abstract> of university course and research project pages sampled  </abstract>::line_number::22
<abstract> from the Web. Making SRV Web-ready only involves  </abstract>::line_number::23
<abstract> adding several simple HTML-specific features to its basic feature set.   </abstract>::line_number::24
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> We present an overview of Candide, a system for automatic  </abstract>::line_number::7
<abstract> translation of French text to English text. Candide uses  </abstract>::line_number::8
<abstract> methods of information theory and statistics to develop a  </abstract>::line_number::9
<abstract> probability model of the translation process. This model,  </abstract>::line_number::10
<abstract> which is made to accord as closely as possible with a large  </abstract>::line_number::11
<abstract> body of French and English sentence pairs, is then used to  </abstract>::line_number::12
<abstract> generate English translations of previously unseen French  </abstract>::line_number::13
<abstract> sentences. This paper provides a tutorial in these methods,  </abstract>::line_number::14
<abstract> discussions of the training and operation of the system, and  </abstract>::line_number::15
<abstract> a summary of test results.   </abstract>::line_number::16
<abstract>  Abstract. The design of linear logic programming languages and theorem provers opens a number of new implementation challenges not  </abstract>::line_number::11
<abstract> present in more traditional logic languages such as Horn clauses (Prolog)  </abstract>::line_number::12
<abstract> and hereditary Harrop formulas (Prolog). Among these, the problem of  </abstract>::line_number::13
<abstract> efficiently managing the linear context when solving a goal is of crucial  </abstract>::line_number::14
<abstract> importance for the use of these systems in non-trivial applications. This  </abstract>::line_number::15
<abstract> paper studies this problem in the case of Lolli [6] (though its results have  </abstract>::line_number::16
<abstract> application to other systems). We first give a proof-theoretic presentation of the operational semantics of this language as a resolution calculus.  </abstract>::line_number::17
<abstract> We then present a series of resource management systems designed to  </abstract>::line_number::18
<abstract> eliminate the non-determinism in the distribution of linear formulas that  </abstract>::line_number::19
<abstract> undermines the efficiency of a direct implementation of this system.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::7
<abstract> A proof of the soundness of Tofte's imperative type discipline with respect to a structured operational  </abstract>::line_number::8
<abstract> semantics is given. The presentation is based on a semantic formalism that combines the benefits of the  </abstract>::line_number::9
<abstract> approaches considered by Wright and Felleisen, and by Tofte, leading to a particularly simple proof of  </abstract>::line_number::10
<abstract> soundness of Tofte's type discipline.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Probabilistic models have recently been utilized for the optimization of large combinatorial search problems. However,  </abstract>::line_number::10
<abstract> complex probabilistic models that attempt to capture inter-parameter dependencies can have prohibitive computational  </abstract>::line_number::11
<abstract> costs. The algorithm presented in this paper, termed  </abstract>::line_number::12
<abstract> COMIT, provides a method for using probabilistic models in  </abstract>::line_number::13
<abstract> conjunction with fast search techniques. We show how  </abstract>::line_number::14
<abstract> COMIT can be used with two very different fast search algorithms: hillclimbing and Population-based incremental  </abstract>::line_number::15
<abstract> learning (PBIL). The resulting algorithms maintain many of  </abstract>::line_number::16
<abstract> the benefits of probabilistic modeling, with far less computational expense. Extensive empirical results are provided;  </abstract>::line_number::17
<abstract> COMIT has been successfully applied to jobshop scheduling, traveling salesman, and knapsack problems. This paper  </abstract>::line_number::18
<abstract> also presents a review of probabilistic modeling for combi  </abstract>::line_number::19
<abstract> natorial optimization.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::2
<abstract> We describe logarithmic times optimal approximation  </abstract>::line_number::3
<abstract> algorithms for the NP-hard graph optimization problems of minimum linear arrangement, minimum containing interval graph, and minimum storage-time  </abstract>::line_number::4
<abstract> product. This improves on the best previous approximation bounds of Even, Naor, Rao, and Schieber for  </abstract>::line_number::5
<abstract> these problems by an (log log n) factor.  </abstract>::line_number::6
<abstract> Even, Naor, Rao, and Schieber defined "spreading  </abstract>::line_number::7
<abstract> metrics" for each of the ordering problems above (and  </abstract>::line_number::8
<abstract> to other problems); for each of these problems, they  </abstract>::line_number::9
<abstract> provided a spreading metric of volume W , such that W  </abstract>::line_number::10
<abstract> is a lower bound on the cost of a solution to the problem.  </abstract>::line_number::11
<abstract> They used this spreading metric to find a solution of  </abstract>::line_number::12
<abstract> cost O(W log n log log n) (for simplicity, assume that  </abstract>::line_number::13
<abstract> all tasks have unit processing time in the minimum  </abstract>::line_number::14
<abstract> storage-time product problem). In this paper, we show  </abstract>::line_number::15
<abstract> how to find a solution within a logarithmic factor times  </abstract>::line_number::16
<abstract> W for these problems.  </abstract>::line_number::17
<abstract> We develop a recursion where at each level we  </abstract>::line_number::18
<abstract> identify cost which, if incurred, yields subproblems  </abstract>::line_number::19
<abstract> with reduced spreading metric volume. Specifically, we  </abstract>::line_number::20
<abstract> present a divide-and-conquer strategy where the cost of  </abstract>::line_number::21
<abstract> a solution to a problem at a recursive level is C plus the  </abstract>::line_number::22
<abstract> cost of a solution to the subproblems at this level, and  </abstract>::line_number::23
<abstract> where the spreading metric volume on the subproblems  </abstract>::line_number::24
<abstract> is less than the original volume by (C= log n). This  </abstract>::line_number::25
<abstract> ensures that the resulting solution has cost O(log n)  </abstract>::line_number::26
<abstract> times the original spreading metric volume.  </abstract>::line_number::27
<abstract> We note that this is an existentially tight bound on  </abstract>::line_number::28
<abstract> the relationship between the spreading metric volume  </abstract>::line_number::29
<abstract> W and the true optimal values for these problems.  </abstract>::line_number::30
<abstract> For planar graphs, we combine a structural theorem  </abstract>::line_number::31
<abstract> of Klein, Plotkin, and Rao with our new recursion technique to show that the spreading metric cost volumes  </abstract>::line_number::32
<abstract> are within an O(log log n) factor of the cost of an optimal solution for the minimum linear arrangement, and  </abstract>::line_number::33
<abstract> the minimum containing interval graph problems.   </abstract>::line_number::34
<abstract>  Abstract.  </abstract>::line_number::8
<abstract> Rogue is an architecture built on a real robot which provides algorithms for the integration of high-level planning, low-level robotic execution, and learning. Rogue addresses successfully several of the  </abstract>::line_number::9
<abstract> challenges of a dynamic office gopher environment. This article presents the techniques for the integration  </abstract>::line_number::10
<abstract> of planning and execution.  </abstract>::line_number::11
<abstract> Rogue uses and extends a classical planning algorithm to create plans for multiple interacting goals  </abstract>::line_number::12
<abstract> introduced by asynchronous user requests. Rogue translates the planner's actions to robot execution  </abstract>::line_number::13
<abstract> actions and monitors real world execution. Rogue is currently implemented using the prodigy4.0  </abstract>::line_number::14
<abstract> planner and the Xavier robot. This article describes how plans are created for multiple asynchronous goals,  </abstract>::line_number::15
<abstract> and how task priority and compatibility information is used to achieve appropriate efficient execution. We  </abstract>::line_number::16
<abstract> describe how Rogue communicates with the planner and the robot to interleave planning with execution  </abstract>::line_number::17
<abstract> so that the planner can replan for failed actions, identify the actual outcome of an action with multiple  </abstract>::line_number::18
<abstract> possible outcomes, and take opportunities from changes in the environment.  </abstract>::line_number::19
<abstract> Rogue represents a successful integration of a classical artificial intelligence planner with a real mobile  </abstract>::line_number::20
<abstract> robot.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The World Wide Web (WWW) has recently become a very popular facility for the dissemination of  </abstract>::line_number::9
<abstract> information. As a result of this popularity, it is experiencing rapidly increasing traffic load. Single  </abstract>::line_number::10
<abstract> machine servers cannot keep pace with the ever greater load being placed upon them. To alleviate this  </abstract>::line_number::11
<abstract> problem, we have implemented a distributed Web server group. The server group can effectively balance request load amongst its members (within about 10% of optimal), and client response time is no  </abstract>::line_number::12
<abstract> worse than in the single server case. Client response time was not improved because the measured client traffic consumed all available network throughput. The distributed operation of the server groups is  </abstract>::line_number::13
<abstract> completely transparent to standard Web clients.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::2
<abstract> Presented is a new algorithm to generate soft shadows. It  </abstract>::line_number::3
<abstract> employs graphics hardware, including texture mapping and  </abstract>::line_number::4
<abstract> accumulation buffering, to produce shadows resulting from  </abstract>::line_number::5
<abstract> area light sources quickly.   </abstract>::line_number::6
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Multimedia has generated widespread interest in real-time support within general purpose  </abstract>::line_number::10
<abstract> operating systems. Multimedia also places new demands on operating systems for interprocess  </abstract>::line_number::11
<abstract> communication. The Multimedia Testbed is a set of applications that stress consistent low-latency response and efficient interprocess communication for large blocks of data. The  </abstract>::line_number::12
<abstract> Multimedia Testbed was ported to Real-Time Mach in the hopes of providing predictable low-latency response and, consequently, good synchronization and low jitter as required for  </abstract>::line_number::13
<abstract> multimedia applications. Our work compares the performance of Real-Time Mach with that of  </abstract>::line_number::14
<abstract> Mach 3.0. Although the fixed-priority scheduling of Real-Time Mach is a substantial  </abstract>::line_number::15
<abstract> improvement, user threads are still preempted by device drivers, and the overall real-time  </abstract>::line_number::16
<abstract> performance is not suitable for multimedia applications. We discuss areas where Real-Time  </abstract>::line_number::17
<abstract> Mach needs improvement.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper describes an end-to-end method for extracting moving targets from a real-time video stream,  </abstract>::line_number::7
<abstract> classifying them into predefined categories according  </abstract>::line_number::8
<abstract> to image-based properties, and then robustly tracking  </abstract>::line_number::9
<abstract> them. Moving targets are detected using the pixelwise  </abstract>::line_number::10
<abstract> difference between consecutive image frames. A classi-ficatoin metric is applied these targets with a temporal  </abstract>::line_number::11
<abstract> consistency constraint to classify them into three categories: human, vehicle or background clutter. Once  </abstract>::line_number::12
<abstract> classified, targets are tracked by a combination of temporal differencing and template matching.  </abstract>::line_number::13
<abstract> The resulting system robustly identifies targets of  </abstract>::line_number::14
<abstract> interest, rejects background clutter, and continually  </abstract>::line_number::15
<abstract> tracks over large distances and periods of time despite  </abstract>::line_number::16
<abstract> occlusions, appearance changes and cessation of target  </abstract>::line_number::17
<abstract> motion.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Weak connectivity, in the form of intermittent, low-bandwidth, or expensive networks is a fact of life in mobile computing.  </abstract>::line_number::5
<abstract> In this paper, we describe how the Coda File System has evolved to exploit such networks. The underlying theme of this  </abstract>::line_number::6
<abstract> evolution has been the systematic introduction of adaptivity to eliminate hidden assumptions about strong connectivity.  </abstract>::line_number::7
<abstract> Many aspects of the system, including communication, cache validation, update propagation and cache miss handling have  </abstract>::line_number::8
<abstract> been modified. As a result, Coda is able to provide good performance even when network bandwidth varies over four orders  </abstract>::line_number::9
<abstract> of magnitude from modem speeds to LAN speeds.   </abstract>::line_number::10
<abstract>  Abstract.  </abstract>::line_number::4
<abstract> This paper presents an analysis of the following load balancing algorithm. At each step, each node in a network examines the number  </abstract>::line_number::5
<abstract> of tokens at each of its neighbors and sends a token to each neighbor with at least 2d + 1 fewer tokens, where d is the maximum degree  </abstract>::line_number::6
<abstract> of any node in the network. We show that within O(=ff) steps, the algorithm reduces the maximum difference in tokens between any  </abstract>::line_number::7
<abstract> two nodes to at most O((d 2 log n)=ff), where is the global imbalance in tokens (i.e., the maximum difference between the number of  </abstract>::line_number::8
<abstract> tokens at any node initially and the average number of tokens), n is the number of nodes in the network, and ff is the edge expansion of  </abstract>::line_number::9
<abstract> the network. The time bound is tight in the sense that for any graph with edge expansion ff, and for any value , there exists an initial  </abstract>::line_number::10
<abstract> distribution of tokens with imbalance for which the time to reduce the imbalance to even =2 is at least (=ff). The bound on the  </abstract>::line_number::11
<abstract> final imbalance is tight in the sense that there exists a class of networks that can be locally balanced everywhere (i.e., the maximum  </abstract>::line_number::12
<abstract> difference in tokens between any two neighbors is at most 2d), while the global imbalance remains ((d 2 log n)=ff). Furthermore, we show  </abstract>::line_number::13
<abstract> that upon reaching a state with a global imbalance of O((d 2 log n)=ff), the time for this algorithm to locally balance the network can be  </abstract>::line_number::14
<abstract> as large as (n 1=2 ). We extend our analysis to a variant of this algorithm for dynamic and asynchronous networks. We also present tight  </abstract>::line_number::15
<abstract> bounds for a randomized algorithm in which each node sends at most one token in each step.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper describes a media-independent, compositional, plan-based approach to representing attributive descriptions for use in integrated text and graphics generation. An attributive  </abstract>::line_number::7
<abstract> description's main function is to convey information directly contributing to the communicative  </abstract>::line_number::8
<abstract> goals of a discourse, whereas a referential description's only function is to enable the audience  </abstract>::line_number::9
<abstract> to identify a particular referent. This approach has been implemented as part of an architecture  </abstract>::line_number::10
<abstract> for generating integrated text and information graphics. Uses of referential and attributive descriptions are represented as two distinct types of communicative acts in a media-independent  </abstract>::line_number::11
<abstract> plan. It is particularly important to distinguish the two types of acts, since they have different  </abstract>::line_number::12
<abstract> consequences for dialogue and text generation, and for graphic design.   </abstract>::line_number::13
<abstract>  Abstract.  </abstract>::line_number::7
<abstract> We describe a simple reduction from the problem of PAC-learning from multiple-instance examples to that of PAC-learning with one-sided random classification noise. Thus, all concept classes  </abstract>::line_number::8
<abstract> learnable with one-sided noise, which includes all concepts learnable in the usual 2-sided random  </abstract>::line_number::9
<abstract> noise model plus others such as the parity function, are learnable from multiple-instance examples. We also describe a more efficient (and somewhat technically more involved) reduction to  </abstract>::line_number::10
<abstract> the Statistical-Query model that results in a polynomial-time algorithm for learning axis-parallel  </abstract>::line_number::11
<abstract> rectangles with sample complexity ~ O(d 2 r=* 2 ), saving roughly a factor of r over the results of Auer  </abstract>::line_number::12
<abstract> et al. (1997).   </abstract>::line_number::13
<abstract>  Abstract. In this paper we describe a new method for automated tuning of high level parameters of supervised  </abstract>::line_number::5
<abstract> learning systems. It uses memory-based learning principles and follows certain ideas of experimental design. The  </abstract>::line_number::6
<abstract> described method allows not only for an efficient search through a decision space, but also for a concurrent validation  </abstract>::line_number::7
<abstract> of the learning algorithm performance on a given data. Potential usefulness of the proposed approach is illustrated  </abstract>::line_number::8
<abstract> with the Fuzzy-ARTMAP neural network application to learning a qualitative positioning of an indoor mobile robot  </abstract>::line_number::9
<abstract> equipped with sonar range sensors. Automatically selected neural network setpoints reach a comparable performance  </abstract>::line_number::10
<abstract> to those achieved by human experts in relatively simple 2D cases. Migration of the proposed method to higher order  </abstract>::line_number::11
<abstract> optimization domains bears a big promise, but requires further research.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::11
<abstract> Physically-based modeling has been used in the past to support a variety of interactive modeling tasks including free-form surface design, mechanism design, constrained drawing, and interactive camera control. In these systems, the user interacts with the model  </abstract>::line_number::12
<abstract> by exerting virtual forces, to which the system responds subject  </abstract>::line_number::13
<abstract> to the active constraints. In the past, this kind of interaction has  </abstract>::line_number::14
<abstract> been applicable only to models that are governed by continuous  </abstract>::line_number::15
<abstract> parameters. In this paper we present an extension to mixed con-tinuous/discrete models, emphasizing constrained layout problems  </abstract>::line_number::16
<abstract> that arise in architecture and other domains. When the object being  </abstract>::line_number::17
<abstract> dragged is blocked from further motion by geometric constraints, a  </abstract>::line_number::18
<abstract> local discrete search is triggered, during which transformations such  </abstract>::line_number::19
<abstract> as swapping of adjacent objects may be performed. The result of the  </abstract>::line_number::20
<abstract> search is a nearby state in which the target object has been moved  </abstract>::line_number::21
<abstract> in the indicated direction and in which all constraints are satisfied.  </abstract>::line_number::22
<abstract> The transition to this state is portrayed using simple but effective animated visual effects. Following the transition, continuous dragging  </abstract>::line_number::23
<abstract> is resumed. The resulting seamless transitions between discrete and  </abstract>::line_number::24
<abstract> continuous manipulation allow the user to easily explore the mixed  </abstract>::line_number::25
<abstract> design space just by dragging objects. We demonstrate the method  </abstract>::line_number::26
<abstract> in application to architectural floor plan design, circuit board layout,  </abstract>::line_number::27
<abstract> art analysis, and page layout.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In this paper we show that application-aware adaptation, a  </abstract>::line_number::6
<abstract> collaborative partnership between the operating system and  </abstract>::line_number::7
<abstract> applications, offers the most general and effective approach  </abstract>::line_number::8
<abstract> to mobile information access. We describe the design of  </abstract>::line_number::9
<abstract> Odyssey, a prototype implementing this approach, and show  </abstract>::line_number::10
<abstract> how it supports concurrent execution of diverse mobile applications. We identify agility as a key attribute of adaptive systems, and describe how to quantify and measure it.  </abstract>::line_number::11
<abstract> We present the results of our evaluation of Odyssey, indicating performance improvements up to a factor of 5 on a  </abstract>::line_number::12
<abstract> benchmark of three applications concurrently using remote  </abstract>::line_number::13
<abstract> services over a network with highly variable bandwidth.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::18
<abstract> Increased reliance on agile manufacturing techniques has created a demand for systems to solve integrated process-planning  </abstract>::line_number::19
<abstract> and production-scheduling problems in large-scale dynamic environments. To be effective, these systems should provide user-oriented interactive functionality for managing the various user  </abstract>::line_number::20
<abstract> tasks and objectives and reacting to unexpected events. This paper describes the mixed-initiative problem-solving features of  </abstract>::line_number::21
<abstract> IP3S, an Integrated Process-Planning/Production-Scheduling  </abstract>::line_number::22
<abstract> shell for agile manufacturing. IP3S is a blackboard -based system  </abstract>::line_number::23
<abstract> that supports the concurrent development and dynamic revision  </abstract>::line_number::24
<abstract> of integrated process-planning and production-scheduling solutions and the maintenance of multiple problem instances and  </abstract>::line_number::25
<abstract> solutions, as well as other flexible user-oriented decision-making  </abstract>::line_number::26
<abstract> capabilities, allowing the user to control the scope of the problem and explore alternate tradeoffs (what-if scenarios) interactively. The system is scheduled for initial deployment  </abstract>::line_number::27
<abstract> and evaluation in a large and highly dynamic machine shop at  </abstract>::line_number::28
<abstract> Raytheon's Andover manufacturing facility.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::5
<abstract> This paper explores the feasibility of using lottery scheduling, a proportional-share resource management algorithm,  </abstract>::line_number::6
<abstract> to schedule processes under the FreeBSD operating system.  </abstract>::line_number::7
<abstract> Proportional-share scheduling enables flexible control over  </abstract>::line_number::8
<abstract> relative process execution rates and processor load insulation among groups of processes. We show that a straight implementation of lottery scheduling performs worse than the  </abstract>::line_number::9
<abstract> standard FreeBSD scheduler. This initial result prompted  </abstract>::line_number::10
<abstract> us to extend lottery scheduling. Except for one test we  </abstract>::line_number::11
<abstract> run, our resulting system performs within one percent of  </abstract>::line_number::12
<abstract> the FreeBSD scheduler. We describe our design, evaluate  </abstract>::line_number::13
<abstract> our implementation, and relate our experience in deploying  </abstract>::line_number::14
<abstract> our lottery scheduler on production machines.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::15
<abstract> Instrumental (or operant) conditioning, a form of animal learning, is similar to reinforcement learning  </abstract>::line_number::16
<abstract> (Watkins, 1989) in that it allows an agent to adapt its actions to gain maximally from the environment  </abstract>::line_number::17
<abstract> while only being rewarded for correct performance. But animals learn much more complicated behaviors  </abstract>::line_number::18
<abstract> through instrumental conditioning than robots presently acquire through reinforcement learning. We  </abstract>::line_number::19
<abstract> describe a new computational model of the conditioning process that attempts to capture some of the  </abstract>::line_number::20
<abstract> aspects that are missing from simple reinforcement learning: conditioned reinforcers, shifting reinforcement contingencies, explicit action sequencing, and state space refinement. We apply our model to a task  </abstract>::line_number::21
<abstract> commonly used to study working memory in rats and monkeys: the DMTS (Delayed Match to Sample)  </abstract>::line_number::22
<abstract> task. Animals learn this task in stages. In simulation, our model also acquires the task in stages, in a  </abstract>::line_number::23
<abstract> similar manner. We have used the model to train an RWI B21 robot.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::18
<abstract> When documents are organized in a large  </abstract>::line_number::19
<abstract> number of topic categories, the categories  </abstract>::line_number::20
<abstract> are often arranged in a hierarchy. The U.S.  </abstract>::line_number::21
<abstract> patent database and Yahoo are two examples.  </abstract>::line_number::22
<abstract> This paper shows that the accuracy of a naive  </abstract>::line_number::23
<abstract> Bayes text classifier can be significantly improved by taking advantage of a hierarchy of  </abstract>::line_number::24
<abstract> classes. We adopt an established statistical  </abstract>::line_number::25
<abstract> technique called shrinkage that smoothes parameter estimates of a data-sparse child with  </abstract>::line_number::26
<abstract> its parent in order to obtain more robust parameter estimates. The approach is also employed in deleted interpolation, a technique  </abstract>::line_number::27
<abstract> for smoothing n-grams in language modeling  </abstract>::line_number::28
<abstract> for speech recognition.  </abstract>::line_number::29
<abstract> Our method scales well to large data sets,  </abstract>::line_number::30
<abstract> with numerous categories in large hierarchies.  </abstract>::line_number::31
<abstract> Experimental results on three real-world data  </abstract>::line_number::32
<abstract> sets from UseNet, Yahoo, and corporate web  </abstract>::line_number::33
<abstract> pages show improved performance, with a reduction in error up to 29% over the tradi  </abstract>::line_number::34
<abstract> tional flat classifier.   </abstract>::line_number::35
<abstract>  ABSTRACT: Functions of time are often used to represent continuous parameters and the passage  </abstract>::line_number::5
<abstract> of musical time (tempo). A new approach generalizes previous work in three ways. First, common  </abstract>::line_number::6
<abstract> temporal operations of stretching and shifting are special cases of a new general time-warping  </abstract>::line_number::7
<abstract> operation. Second, these operations are ``abstract.'' Instead of operating directly on signals or  </abstract>::line_number::8
<abstract> events, they operate on abstract behaviors that interpret the operations at an appropriate structural  </abstract>::line_number::9
<abstract> level. Third, time warping can be applied to both discrete events and continuous signals.   </abstract>::line_number::10
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> Digital interactive media augments interactive computing with video, audio, computer graphics and text,  </abstract>::line_number::6
<abstract> allowing multimedia presentations to be individually and dynamically tailored to the user. Multimedia, and  </abstract>::line_number::7
<abstract> particularly continuous media pose interesting problems for system designers, including those of latency  </abstract>::line_number::8
<abstract> and synchronization. These problems are especially evident when multimedia data is remote and must be  </abstract>::line_number::9
<abstract> accessed via networks. Latency and synchronization issues are discussed, and an integrated system,  </abstract>::line_number::10
<abstract> Tactus, is described. Tactus facilitates the implementation of interactive multimedia computer programs by  </abstract>::line_number::11
<abstract> managing latency and synchronization in the framework of an object-oriented graphical user interface  </abstract>::line_number::12
<abstract> toolkit.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Memory latency is an important bottleneck in system performance  </abstract>::line_number::8
<abstract> that cannot be adequately solved by hardware alone. Several promising software techniques have been shown to address this problem  </abstract>::line_number::9
<abstract> successfully in specific situations. However, the generality of these  </abstract>::line_number::10
<abstract> software approaches has been limited because current architectures  </abstract>::line_number::11
<abstract> do not provide a fine-grained, low-overhead mechanism for  </abstract>::line_number::12
<abstract> observing and reacting to memory behavior directly. To fill this  </abstract>::line_number::13
<abstract> need, we propose a new class of memory operations called informing memory operations, which essentially consist of a memory  </abstract>::line_number::14
<abstract> operation combined (either implicitly or explicitly) with a conditional branch-and-link operation that is taken only if the reference  </abstract>::line_number::15
<abstract> suffers a cache miss. We describe two different implementations of  </abstract>::line_number::16
<abstract> informing memory operationsone based on a cache-outcome  </abstract>::line_number::17
<abstract> condition code and another based on low-overhead trapsand find  </abstract>::line_number::18
<abstract> that modern in-order-issue and out-of-order-issue superscalar processors already contain the bulk of the necessary hardware support.  </abstract>::line_number::19
<abstract> We describe how a number of software-based memory optimizations can exploit informing memory operations to enhance performance, and look at cache coherence with fine-grained access  </abstract>::line_number::20
<abstract> control as a case study. Our performance results demonstrate that  </abstract>::line_number::21
<abstract> the runtime overhead of invoking the informing mechanism on the  </abstract>::line_number::22
<abstract> Alpha 21164 and MIPS R10000 processors is generally small  </abstract>::line_number::23
<abstract> enough to provide considerable exibility to hardware and software designers, and that the cache coherence application has  </abstract>::line_number::24
<abstract> improved performance compared to other current solutions. We  </abstract>::line_number::25
<abstract> believe that the inclusion of informing memory operations in  </abstract>::line_number::26
<abstract> future processors may spur even more innovative performance  </abstract>::line_number::27
<abstract> optimizations.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::12
<abstract> Neural networks have been successfully applied in a wide range of supervised and unsupervised learning applications. Neural-network methods are not commonly used for data-mining  </abstract>::line_number::13
<abstract> tasks, however, because they often produce incomprehensible models and require long training  </abstract>::line_number::14
<abstract> times. In this article, we describe neural-network learning algorithms that are able to produce  </abstract>::line_number::15
<abstract> comprehensible models, and that do not require excessive training times. Specifically, we discuss  </abstract>::line_number::16
<abstract> two classes of approaches for data mining with neural networks. The first type of approach,  </abstract>::line_number::17
<abstract> often called rule extraction, involves extracting symbolic models from trained neural networks.  </abstract>::line_number::18
<abstract> The second approach is to directly learn simple, easy-to-understand networks. We argue that,  </abstract>::line_number::19
<abstract> given the current state of the art, neural-network methods deserve a place in the tool boxes of  </abstract>::line_number::20
<abstract> data-mining specialists.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We argue that discourse plans must capture the intended causal and decompositional relations between communicative actions. We present a planning algorithm, DPOCL, that builds plan structures that properly capture these relations, and show  </abstract>::line_number::8
<abstract> how these structures are used to solve the problems that plagued previous discourse planners, and allow a system to participate  </abstract>::line_number::9
<abstract> effectively and flexibly in an ongoing dialogue.  </abstract>::line_number::10
<abstract> A version of this paper appears in the Proceedings of the Sixteenth Annual Meeting  </abstract>::line_number::11
<abstract> of the Cognitive Science Society, Atlanta, GA, 1994.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::12
<abstract> This paper describes an algorithm for simulating soft shadows at interactive rates using graphics hardware. On current graphics  </abstract>::line_number::13
<abstract> workstations, the technique can calculate the soft shadows cast by moving, complex objects onto multiple planar surfaces in  </abstract>::line_number::14
<abstract> about a second. In a static, diffuse scene, these high quality shadows can then be displayed at 30 Hz, independent of the number  </abstract>::line_number::15
<abstract> and size of the light sources.  </abstract>::line_number::16
<abstract> For a diffuse scene, the method precomputes a radiance texture that captures the shadows and other brightness variations on  </abstract>::line_number::17
<abstract> each polygon. The texture for each polygon is computed by creating registered projections of the scene onto the polygon from  </abstract>::line_number::18
<abstract> multiple sample points on each light source, and averaging the resulting hard shadow images to compute a soft shadow image.  </abstract>::line_number::19
<abstract> After this precomputation, soft shadows in a static scene can be displayed in real-time with simple texture mapping of the  </abstract>::line_number::20
<abstract> radiance textures. All pixel operations employed by the algorithm are supported in hardware by existing graphics workstations.  </abstract>::line_number::21
<abstract> The technique can be generalized for the simulation of shadows on specular surfaces.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In this paper we present NIFDY, a network interface that uses admission control to reduce congestion and ensures that packets are  </abstract>::line_number::6
<abstract> received by a processor in the order in which they were sent, even  </abstract>::line_number::7
<abstract> if the underlying network delivers the packets out of order. The  </abstract>::line_number::8
<abstract> basic idea behind NIFDY is that each processor is allowed to have at  </abstract>::line_number::9
<abstract> most one outstanding packet to any other processor unless the destination processor has granted the sender the right to send multiple  </abstract>::line_number::10
<abstract> unacknowledged packets. Further, there is a low upper limit on the  </abstract>::line_number::11
<abstract> number of outstanding packets to all processors.  </abstract>::line_number::12
<abstract> We present results from simulations of a variety of networks  </abstract>::line_number::13
<abstract> (meshes, tori, butterflies, and fat trees) and traffic patterns to verify NIFDY's efficacy. Our simulations show that NIFDY increases  </abstract>::line_number::14
<abstract> throughput and decreases overhead. The utility of NIFDY increases  </abstract>::line_number::15
<abstract> as a network's bisection bandwidth decreases. When combined  </abstract>::line_number::16
<abstract> with the increased payload allowed by in-order delivery NIFDY increases total bandwidth delivered for all networks. The resources  </abstract>::line_number::17
<abstract> needed to implement NIFDY are small and constant with respect to  </abstract>::line_number::18
<abstract> network size.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> General media-processing programs are easily expressed with bit-addressing and variable-sized bit-fields. But the natural implementation of bit-addressing relies on dynamic shift offsets and repeated  </abstract>::line_number::6
<abstract> loads, resulting in slow execution. If the code is specialized to the  </abstract>::line_number::7
<abstract> alignment of the data against word boundaries, the offsets become  </abstract>::line_number::8
<abstract> static and many repeated loads can be removed. We show how introducing modular arithmetic into an automatic compiler generator  </abstract>::line_number::9
<abstract> enables the transformation of a program that uses bit-addressing  </abstract>::line_number::10
<abstract> into a synthesizer of fast specialized programs.  </abstract>::line_number::11
<abstract> In partial-evaluation jargon we say: modular arithmetic is supported by extending the binding time lattice used by the static analysis in a polyvariant compiler generator. The new binding time  </abstract>::line_number::12
<abstract> Cyclic functions like a partially static integer.  </abstract>::line_number::13
<abstract> A software cache combined with a fast, optimistic sharing analysis built into the compilers eliminates repeated loads and stores.  </abstract>::line_number::14
<abstract> The utility of the transformation is demonstrated with a collection  </abstract>::line_number::15
<abstract> of examples and benchmark data. The examples include vector  </abstract>::line_number::16
<abstract> arithmetic, audio synthesis, image processing, and a base-64 codec.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Inversion of multilayer synchronous networks is a method which tries to answer questions  </abstract>::line_number::6
<abstract> like "What kind of input will give a desired output?" or "Is it possible to get a desired  </abstract>::line_number::7
<abstract> output (under special input/output constraints)?".  </abstract>::line_number::8
<abstract> We will describe two methods of inverting a connectionist network. Firstly, we extend  </abstract>::line_number::9
<abstract> inversion via backpropagation (Linden/Kindermann [4], Williams [11]) to recurrent (El-man [1], Jordan [3], Mozer [5], Williams/Zipser [10]), time-delayed (Waibel at al. [9])  </abstract>::line_number::10
<abstract> and discrete versions of continuous networks (Pineda [7], Pearlmutter [6]). The result  </abstract>::line_number::11
<abstract> of inversion is an input vector. The corresponding output vector is equal to the target  </abstract>::line_number::12
<abstract> vector except a small remainder. The knowledge of those attractors may help to understand the function and the generalization qualities of connectionist systems of this  </abstract>::line_number::13
<abstract> kind.  </abstract>::line_number::14
<abstract> Secondly, we introduce a new inversion method for proving the non-existence of an  </abstract>::line_number::15
<abstract> input combination under special constraints, e.g. in a subspace of the input space. This  </abstract>::line_number::16
<abstract> method works by iterative exclusion of invalid activation values. It might be a helpful  </abstract>::line_number::17
<abstract> way to judge the properties of a trained network.  </abstract>::line_number::18
<abstract> We conclude with simulation results of three different tasks: XOR, morse signal decoding  </abstract>::line_number::19
<abstract> and handwritten digit recognition.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We describe our impressions of the SUPRENUM project and of its primary  </abstract>::line_number::7
<abstract> supercomputer result, the Suprenum-1 prototype. We comment on the significance  </abstract>::line_number::8
<abstract> of the architecture, its role among contemporary systems and its relevance to  </abstract>::line_number::9
<abstract> current systems. We similarly discuss the SUPRENUM software and its impact on  </abstract>::line_number::10
<abstract> distributed systems. Finally we discuss the successes and failures observed  </abstract>::line_number::11
<abstract> throughout this exciting project and relate these to the organizational decisions on  </abstract>::line_number::12
<abstract> which SUPRENUM was based.  </abstract>::line_number::13
<abstract> As an illustration of Suprenum-1 capabilities, we describe the  </abstract>::line_number::14
<abstract> implementation of a fluid dynamical benchmark on the 256 node Suprenum-1  </abstract>::line_number::15
<abstract> parallel computer. The benchmark, the Shallow Water Equations, is frequently used  </abstract>::line_number::16
<abstract> as a model for both oceanographic and atmospheric circulation. We describe the  </abstract>::line_number::17
<abstract> steps involved in implementing the algorithm on the Suprenum-1 and we provide  </abstract>::line_number::18
<abstract> details of performance obtained. For such regular grid-based algorithms the system  </abstract>::line_number::19
<abstract> delivers a very impressive fraction (25%) of its theoretical peak rate of 5 Gflops.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Given a set of training examples, determining the appropriate number of free parameters is a challenging problem. Constructive  </abstract>::line_number::8
<abstract> learning algorithms attempt to solve this problem automatically by  </abstract>::line_number::9
<abstract> adding hidden units, and therefore free parameters, during learning. We explore an alternative class of algorithms|called metamorphosis algorithms|in which the number of units is fixed, but  </abstract>::line_number::10
<abstract> the number of free parameters gradually increases during learning.  </abstract>::line_number::11
<abstract> The architecture we investigate is composed of RBF units on a lattice, which imposes flexible constraints on the parameters of the  </abstract>::line_number::12
<abstract> network. Virtues of this approach include variable subset selection, robust parameter selection, multiresolution processing, and  </abstract>::line_number::13
<abstract> interpolation of sparse training data.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::12
<abstract> Sybil is a database integration and evolution environment for supporting large, heterogeneous applications.  </abstract>::line_number::13
<abstract> We are interested in using Sybil to support the data integration and evolution needs of applications that are using legacy databases and are looking to integrate with  </abstract>::line_number::14
<abstract> more modern database systems. The Sybil approach is  </abstract>::line_number::15
<abstract> based on loosely coupling databases or other persistent  </abstract>::line_number::16
<abstract> tools into lightweight alliances tailored for specific applications. Such alliances are built via four sorts of constructs: heterogeneous views, inter-database constraints,  </abstract>::line_number::17
<abstract> inter-database propagations, and integration supported  </abstract>::line_number::18
<abstract> by domain specific information.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::10
<abstract> When the schema of an object database system is modified, the database needs to be changed  </abstract>::line_number::11
<abstract> in such a way that the schema and the database remain consistent with each other. This paper  </abstract>::line_number::12
<abstract> uses the OO1 benchmark [2], appropriately modified, to compare the two most used approaches for  </abstract>::line_number::13
<abstract> transforming the database, namely the immediate and the deferred database transformation [4].   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Recent work in feature-based classification has focused on non-parametric techniques that can classify instances even when the underlying feature distributions are  </abstract>::line_number::9
<abstract> unknown. The inference algorithms for training these techniques, however, are designed  </abstract>::line_number::10
<abstract> to maximize the accuracy of the classifier, with all errors weighted equally. In many  </abstract>::line_number::11
<abstract> applications, certain errors are far more costly than others, and the need arises for  </abstract>::line_number::12
<abstract> non-parametric classification techniques that can be trained to optimize task-specific  </abstract>::line_number::13
<abstract> cost functions. This paper reviews the Linear Machine Decision Tree (LMDT) algorithm for inducing multivariate decision trees, and shows how LMDT can be altered to  </abstract>::line_number::14
<abstract> induce decision trees that minimize arbitrary misclassification cost functions (MCFs).  </abstract>::line_number::15
<abstract> Demonstrations of pixel classification in outdoor scenes show how MCFs can optimize  </abstract>::line_number::16
<abstract> the performance of embedded classifiers within the context of larger image understand  </abstract>::line_number::17
<abstract> ing systems.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Neural networks are trained for balancing 1  </abstract>::line_number::7
<abstract> and 2 poles attached to a cart on a fixed  </abstract>::line_number::8
<abstract> track. For one variant of the single pole system, only pole angle and cart position variables are supplied as inputs; the network  </abstract>::line_number::9
<abstract> must learn to compute velocities. All of the  </abstract>::line_number::10
<abstract> problems are solved using a fixed architecture  </abstract>::line_number::11
<abstract> and using a new version of cellular encoding that evolves an application specific architecture with real-valued weights. The learning times and generalization capabilities are  </abstract>::line_number::12
<abstract> compared for neural networks developed using both methods. After a post processing  </abstract>::line_number::13
<abstract> simplification, topologies produced by cellular encoding were very simple and could be  </abstract>::line_number::14
<abstract> analyzed. Architectures with no hidden units  </abstract>::line_number::15
<abstract> were produced for the single pole and the two  </abstract>::line_number::16
<abstract> pole problem when velocity information is  </abstract>::line_number::17
<abstract> supplied as an input. Moreover, these linear  </abstract>::line_number::18
<abstract> solutions display good generalization. For all  </abstract>::line_number::19
<abstract> the control problems, cellular encoding can  </abstract>::line_number::20
<abstract> automatically generate architectures whose  </abstract>::line_number::21
<abstract> complexity and structure reflect the features  </abstract>::line_number::22
<abstract> of the problem to solve.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Template matching is an effective means of locating vehicles in outdoor scenes, but it tends to be  </abstract>::line_number::7
<abstract> a computationally expensive. To reduce processing time, we use large neural networks to predict, or  </abstract>::line_number::8
<abstract> index, a small subset of templates that are likely to match each window in an image. Results on actual  </abstract>::line_number::9
<abstract> LADAR range images show that limiting the templates to those selected by the neural networks reduces  </abstract>::line_number::10
<abstract> the computation time by a factor of 5 without sacrificing the accuracy of the results.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We have studied the performance of a high-speed  </abstract>::line_number::8
<abstract> commercial spread-spectrum wireless LAN that uses the  </abstract>::line_number::9
<abstract> CSMA/CA multiple-access strategy. Employing synthetic workloads, we measured packet capture success  </abstract>::line_number::10
<abstract> more so than signal propagation characteristics. Specifically, we measured throughput, packet loss rates, range,  </abstract>::line_number::11
<abstract> and patterns of errors within packets. We conclude  </abstract>::line_number::12
<abstract> that CSMA/CA is quite successful in allocating bandwidth under stress, but that packet capture rate degrades very quickly once the LAN's effective range is  </abstract>::line_number::13
<abstract> exceeded. Hence, network maintainers should plan the  </abstract>::line_number::14
<abstract> layout of wireless networks at least as carefully as they  </abstract>::line_number::15
<abstract> plan wired networks.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> In this paper, we present new algorithms to balance  </abstract>::line_number::9
<abstract> the computation of parallel hash joins over heterogeneous processors in the presence of data skew and external loads. Heterogeneity in our model consists of  </abstract>::line_number::10
<abstract> disparate computing elements, as well as general purpose computing ensembles that are subject to external loading (e.g., a LAN connected workstation cluster). Data skew manifests itself as significant non-uniformities in the distribution of attribute values of  </abstract>::line_number::11
<abstract> underlying relations that are involved in a join.  </abstract>::line_number::12
<abstract> We develop cost models and predictive dynamic  </abstract>::line_number::13
<abstract> load balancing protocols to detect imbalance during  </abstract>::line_number::14
<abstract> the computation of a single large join. New predictive bucket scheduling algorithms are presented that  </abstract>::line_number::15
<abstract> smooth out the load over the entire ensemble by reallocating buckets whenever imbalance is detected. Our  </abstract>::line_number::16
<abstract> algorithms can account for imbalance due to data skew  </abstract>::line_number::17
<abstract> as well as heterogeneity in the computing environment.  </abstract>::line_number::18
<abstract> Significant performance gains are reported for a wide  </abstract>::line_number::19
<abstract> range of test cases on a prototype implementation of  </abstract>::line_number::20
<abstract> the system.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> In this paper we discuss a data mining framework for constructing intrusion detection models.  </abstract>::line_number::8
<abstract> The key ideas are to mine system audit data for consistent and useful patterns of program and  </abstract>::line_number::9
<abstract> user behavior, and use the set of relevant system features presented in the patterns to compute  </abstract>::line_number::10
<abstract> (inductively learned) classifiers that can recognize anomalies and known intrusions. Our past experiments showed that classifiers can be used to detect intrusions, provided that sufficient audit  </abstract>::line_number::11
<abstract> data is available for training and the right set of system features are selected. We propose to use  </abstract>::line_number::12
<abstract> the association rules and frequent episodes computed from audit data as the basis for guiding the  </abstract>::line_number::13
<abstract> audit data gathering and feature selection processes. We modify these two basic algorithms to use  </abstract>::line_number::14
<abstract> axis attribute(s) as a form of item constraints to compute only the relevant (useful) patterns, and  </abstract>::line_number::15
<abstract> an iterative level-wise approximate mining procedure to uncover the low frequency (but important)  </abstract>::line_number::16
<abstract> patterns. We report our experiments in using these algorithms on real-world audit data.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::15
<abstract> In this paper we study the issue of how to scale machine learning algorithms, that  </abstract>::line_number::16
<abstract> typically are designed to deal with main-memory based datasets, to efficiently learn  </abstract>::line_number::17
<abstract> models from large distributed databases. We have explored an approach called meta-learning that is related to the traditional approaches of data reduction commonly  </abstract>::line_number::18
<abstract> employed in distributed database query processing systems. We explore the scalability  </abstract>::line_number::19
<abstract> of learning arbiter and combiner trees from partitioned data. Arbiter and combiner  </abstract>::line_number::20
<abstract> trees integrate classifiers trained in parallel from small disjoint subsets. Previous work  </abstract>::line_number::21
<abstract> demonstrated the efficacy of these meta-learning architectures in terms of accuracy  </abstract>::line_number::22
<abstract> of the computed meta-classifiers. Here we discuss the computational performance  </abstract>::line_number::23
<abstract> of constructing arbiter and combiner trees in terms of speedup and scalability as a  </abstract>::line_number::24
<abstract> function of database size and number of partitions. The performance of serial learning  </abstract>::line_number::25
<abstract> algorithms is evaluated. We then analyze the performance of the algorithms used to  </abstract>::line_number::26
<abstract> construct combiner and arbiter trees in parallel. Our empirical results validate these  </abstract>::line_number::27
<abstract> analyses and indicate that the techniques can effectively scale up to large datasets with  </abstract>::line_number::28
<abstract> millions of records using cheap commodity hardware.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We introduce a new model of distributions generated by random walks on graphs. This model  </abstract>::line_number::7
<abstract> suggests a variety of learning problems, using the definitions and models of distribution  </abstract>::line_number::8
<abstract> learning defined in [6]. Our framework is general enough to model previously studied distribution learning problems, as well as to suggest  </abstract>::line_number::9
<abstract> new applications. We describe special cases of  </abstract>::line_number::10
<abstract> the general problem, and investigate their relative difficulty. We present algorithms to solve  </abstract>::line_number::11
<abstract> the learning problem under various conditions.   </abstract>::line_number::12
<abstract>  Abstract. This paper presents Kenmore, a general framework for knowledge acquisition for natural language processing (NLP) systems. To ease  </abstract>::line_number::8
<abstract> the acquisition of knowledge in new domains, Kenmore exploits an online corpus using robust sentence analysis and embedded symbolic machine learning techniques while requiring only minimal human intervention. By treating all problems in ambiguity resolution as classification  </abstract>::line_number::9
<abstract> tasks, the framework uniformly addresses a range of subproblems in sentence analysis, each of which traditionally had required a separate computational mechanism. In a series of experiments, we demonstrate the  </abstract>::line_number::10
<abstract> successful use of Kenmore for learning solutions to several problems in  </abstract>::line_number::11
<abstract> lexical and structural ambiguity resolution. We argue that the learning  </abstract>::line_number::12
<abstract> and knowledge acquisition components should be embedded components  </abstract>::line_number::13
<abstract> of the NLP system in that (1) learning should take place within the  </abstract>::line_number::14
<abstract> larger natural language understanding system as it processes text, and  </abstract>::line_number::15
<abstract> (2) the learning components should be evaluated in the context of prac  </abstract>::line_number::16
<abstract> tical language-processing tasks.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Many high-level language compilers generate C code and  </abstract>::line_number::8
<abstract> then invoke a C compiler for code generation. To date, most  </abstract>::line_number::9
<abstract> of these compilers link the resulting code against a conservative mark-sweep garbage collector in order to reclaim unused  </abstract>::line_number::10
<abstract> memory. We introduce a new collector, MCC, based on an  </abstract>::line_number::11
<abstract> extension of mostly-copying collection.  </abstract>::line_number::12
<abstract> We analyze the various design decisions made in MCC  </abstract>::line_number::13
<abstract> and provide a performance comparison to the most widely  </abstract>::line_number::14
<abstract> used conservative mark-sweep collector (the Boehm-Demers-Weiser collector). Our results show that a good mostly-copying collector can outperform a mature highly-optimized  </abstract>::line_number::15
<abstract> mark-sweep collector when physical memory is large relative  </abstract>::line_number::16
<abstract> to the live data. A surprising result of our analysis is that  </abstract>::line_number::17
<abstract> cache behavior can have a greater impact on overall performance than either collector time, or allocation code.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::2
<abstract> We consider a number of search and exploration problems, from the perspective of  </abstract>::line_number::3
<abstract> robot navigation in a simple polygon. These problems are "on-line" in the sense that  </abstract>::line_number::4
<abstract> the robot does not have access to the map of the polygon; it must make decisions as it  </abstract>::line_number::5
<abstract> proceeds, based only on what it has seen so far. For the problem of exploring a simple  </abstract>::line_number::6
<abstract> rectilinear polygon (under the L 1 norm), Deng, Kameda, and Papadimitriou give a  </abstract>::line_number::7
<abstract> 2-competitive deterministic algorithm; we present a randomized exploration algorithm  </abstract>::line_number::8
<abstract> which is 5=4-competitive. Using similar techniques, we are able to give an algorithm  </abstract>::line_number::9
<abstract> for searching an arbitrary, unknown rectilinear polygon. No constant competitive ratio  </abstract>::line_number::10
<abstract> is attainable in this case, but our algorithm is within a constant factor of optimal in  </abstract>::line_number::11
<abstract> the worst case; in a sense, it is a generalization of some of the strategies of Baeza-Yates, Culberson, and Rawlins to a much more general class of search spaces. Finally,  </abstract>::line_number::12
<abstract> we examine a type of polygon for which competitive search is possible | the class of  </abstract>::line_number::13
<abstract> "streets" considered by Klein, who gave a 1 + 3  </abstract>::line_number::14
<abstract> 2 -competitive algorithm for the search  </abstract>::line_number::15
<abstract> problem in this case. We present a simple algorithm with a competitive ratio of at  </abstract>::line_number::16
<abstract> most  </abstract>::line_number::17
<abstract> q  </abstract>::line_number::18
<abstract> p  </abstract>::line_number::19
<abstract> 8 (~ 2:61); in rectilinear streets it achieves the optimal competitive ratio  </abstract>::line_number::20
<abstract> of  </abstract>::line_number::21
<abstract> 2.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::10
<abstract> We consider the problem of planning sensor control strategies that enable a  </abstract>::line_number::11
<abstract> sensor to be automatically configured for robot tasks. In this paper we present  </abstract>::line_number::12
<abstract> robust and efficient algorithms for computing the regions from which a sensor  </abstract>::line_number::13
<abstract> has unobstructed or partially obstructed views of a target in a goal. We apply  </abstract>::line_number::14
<abstract> these algorithms to the Error Detection and Recovery problem of recognizing  </abstract>::line_number::15
<abstract> whether a goal or failure region has been achieved. Based on these methods and  </abstract>::line_number::16
<abstract> strategies for visually-cued camera control, we have built a robot surveillance  </abstract>::line_number::17
<abstract> system in which one mobile robot navigates to a viewing position from which  </abstract>::line_number::18
<abstract> it has an unobstructed view of a goal region, and then uses visual recognition  </abstract>::line_number::19
<abstract> to detect when a specific target has entered the region.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::26
<abstract> Recently, several new algorithms have been developed for the minimum cut problem.  </abstract>::line_number::27
<abstract> These algorithms are very different from the earlier ones and from each other and substantially improve worst-case time bounds for the problem. We conduct experimental evaluation  </abstract>::line_number::28
<abstract> the relative performance of these algorithms. In the process, we develop heuristics and data  </abstract>::line_number::29
<abstract> structures that substantially improve practical performance of the algorithms. We also develop problem families for testing minimum cut algorithms. Our work leads to a better  </abstract>::line_number::30
<abstract> understanding of practical performance of the minimum cut algorithms and produces very  </abstract>::line_number::31
<abstract> efficient codes for the problem.   </abstract>::line_number::32
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The Fast Fourier Transform (FFT) plays a key role in many areas of computational science  </abstract>::line_number::9
<abstract> and engineering. Although most one-dimensional FFT problems can be entirely solved entirely in  </abstract>::line_number::10
<abstract> main memory, some important classes of applications require out-of-core techniques. For these,  </abstract>::line_number::11
<abstract> use of parallel I/O systems can improve performance considerably. This paper shows how to  </abstract>::line_number::12
<abstract> perform one-dimensional FFTs using a parallel disk system with independent disk accesses. We  </abstract>::line_number::13
<abstract> present both analytical and experimental results for performing out-of-core FFTs in two ways:  </abstract>::line_number::14
<abstract> using traditional virtual memory with demand paging, and using a provably asymptotically  </abstract>::line_number::15
<abstract> optimal algorithm for the Parallel Disk Model (PDM) of Vitter and Shriver. When run on a  </abstract>::line_number::16
<abstract> DEC 2100 server with a large memory and eight parallel disks, the optimal algorithm for the  </abstract>::line_number::17
<abstract> PDM runs up to 144.7 times faster than in-core methods under demand paging. Moreover, even  </abstract>::line_number::18
<abstract> including I/O costs, the normalized times for the optimal PDM algorithm are competitive, or  </abstract>::line_number::19
<abstract> better than, those for in-core methods even when they run entirely in memory.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Agent Tcl is a transportable agent system. The agents are written in an extended version of the  </abstract>::line_number::8
<abstract> Tool Command Lanuage (Tcl). Each agent can suspend its execution at an arbitrary point, transport  </abstract>::line_number::9
<abstract> to another machine and resume execution on the new machine. This migration is accomplished with  </abstract>::line_number::10
<abstract> the agent jump command. agent jump captures the current state of the Tcl script and transfers this  </abstract>::line_number::11
<abstract> state to the destination machine. The state is restored on the new machine and the Tcl script continues  </abstract>::line_number::12
<abstract> its execution from the command immediately after the agent jump. In addition to migration, agents  </abstract>::line_number::13
<abstract> can send messages to each other and can establish direct connections. A direct connection is more  </abstract>::line_number::14
<abstract> efficient than message passing for bulk data transfer. Finally, agents can use the Tk toolkit to create  </abstract>::line_number::15
<abstract> graphical user interfaces on their current machine. Agent Tcl is implemented as two components. The  </abstract>::line_number::16
<abstract> first component is an extended Tcl interpreter. The second component is a server which runs on each  </abstract>::line_number::17
<abstract> machine. The server accepts incoming agents, messages and connection requests and keeps track of the  </abstract>::line_number::18
<abstract> agents that are running on its machine. An alpha release of Agent Tcl is available for public use. This  </abstract>::line_number::19
<abstract> documentation describes how to obtain and compile the source code, how to run the server and how to  </abstract>::line_number::20
<abstract> write transportable agents.   </abstract>::line_number::21
<abstract>  Abstract. Generalized FFTs are efficient algorithms for computing a Fourier  </abstract>::line_number::5
<abstract> transform of a function defined on finite group, or a bandlimited function defined on a compact group. The development of such algorithms has been accompanied and motivated by a growing number of both potential and realized  </abstract>::line_number::6
<abstract> applications. This paper will attempt to survey some of these applications.  </abstract>::line_number::7
<abstract> Appendices include some more detailed examples.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Given a set of n points, what is the description complexity of their convex hull? In our world, this question  </abstract>::line_number::9
<abstract> is understood with an implicit "in the worst case", and the answer is n bd=2c where d is the dimension of  </abstract>::line_number::10
<abstract> the underlying space. This is not entirely satisfactory, as this description complexity can vary tremendously  </abstract>::line_number::11
<abstract> depending on the positions of the points. Another approach is to look at the expected description complexity  </abstract>::line_number::12
<abstract> when the points are drawn from a given distribution. This type of analysis, initiated by Renyi and Sulanke  </abstract>::line_number::13
<abstract> [RS63] and pursued by others gets its value from the fact that this expectation is in general much smaller  </abstract>::line_number::14
<abstract> than in the worst case, and, more importantly, in that it often allows one to design algorithms that have  </abstract>::line_number::15
<abstract> expected running times against which worst case aware algorithms cannot compete. For instance, the convex  </abstract>::line_number::16
<abstract> hull of n points drawn independently uniformly at random from a d-dimensional hypercube has expected  </abstract>::line_number::17
<abstract> complexity O(log d1 n), and can be computed in expected linear time.  </abstract>::line_number::18
<abstract> In parallel, in the past decade, a number of papers have considered a setting where points are allowed  </abstract>::line_number::19
<abstract> to move along low degree algebraic trajectories. Different questions have been asked in this context. In  </abstract>::line_number::20
<abstract> particular, Atallah [Ata85], studied the number of times the combinatorial description of the convex hull  </abstract>::line_number::21
<abstract> or closest pair can change, in the worst case ("dynamic computational geometry"). More recently, Basch,  </abstract>::line_number::22
<abstract> Guibas, and Hershberger [BGH97] have designed kinetic data structures to maintain these attributes in an  </abstract>::line_number::23
<abstract> online setting, measuring the quality of a kinetic data structure by the ratio of the worst case number of  </abstract>::line_number::24
<abstract> changes to the configuration of interest, to the worst case number of changes to the data structure itself, for  </abstract>::line_number::25
<abstract> low degree algebraic motions. However, an experimental study undertaken in [BGSZ97] to assess the quality  </abstract>::line_number::26
<abstract> of these data structures in practice shows that the worst case analysis can hide vastly different results in  </abstract>::line_number::27
<abstract> terms of expectation when the point positions and speeds are drawn at random from some distributions. It  </abstract>::line_number::28
<abstract> is this study that motivated the present paper.  </abstract>::line_number::29
<abstract> In this communication, we report several results on the expected number of changes to various combinatorial structures for the case when points are drawn from the uniform distribution on the unit square. These  </abstract>::line_number::30
<abstract> results can be generalized for any dimension d &gt; 2.   </abstract>::line_number::31
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The geometric point set matching problem in 2 and 3 dimensions is a well-studied problem with application to areas such as computer vision and pattern recognition, computational chemistry and other fields  </abstract>::line_number::8
<abstract> such as cartography and computer animation. The basic problems can be formulated as follows. Given  </abstract>::line_number::9
<abstract> some choice of a space of transformations and a similarity measure d(P; Q) for two point sets P and Q in  </abstract>::line_number::10
<abstract> Euclidean space.  </abstract>::line_number::11
<abstract> Problem 1 (Pattern Matching (PM)) Given point sets P and Q, where jP j = k and jQj = n with  </abstract>::line_number::12
<abstract> k n, and an * &gt; 0, find a transformation T for which d(T (P ); Q) * or return none if no such T exists.  </abstract>::line_number::13
<abstract> Problem 2 (Largest Common Point-set (LCP)) Given point sets P and Q, where jP j = m and jQj =  </abstract>::line_number::14
<abstract> n, K &gt; 0 and * &gt; 0, find a transformation T and a set P 0 P of size jP 0 j K such that jd(T (P 0 ); Q)j *  </abstract>::line_number::15
<abstract> or return none if no such T and P 0 exist.  </abstract>::line_number::16
<abstract> We restrict T to the space of rigid Euclidean translations and rotations. The similarity measures of interest  </abstract>::line_number::17
<abstract> to us are: the exact metric 1 d E (P; Q) (binary-valued, requiring each point in P to be mapped to a point in  </abstract>::line_number::18
<abstract> Q); the Hausdorff metric d H (P; Q) (maximum over all points in P of the distance to the nearest point in  </abstract>::line_number::19
<abstract> Q); and, the matching metric d M (bottleneck matching distance).  </abstract>::line_number::20
<abstract> A detailed study of this set of problems was initiated by Alt, Mehlhorn, Wagener, and Welzl [AMWW88].  </abstract>::line_number::21
<abstract> In this seminal work, they propose a suite of algorithms for the exact and matching metrics. More recent work  </abstract>::line_number::22
<abstract> led to improved bounds for pattern matching and LCP under the exact metric. The problem of estimating  </abstract>::line_number::23
<abstract> the minimum Hausdorff distance between two point sets in 2 and 3 dimensions has been studied extensively.  </abstract>::line_number::24
<abstract> Clearly, any real application of such algorithms has to deal with the presence of noise in data, requiring  </abstract>::line_number::25
<abstract> the algorithms to perform matching within the limits of some reasonable noise model. In fact, our interest  </abstract>::line_number::26
<abstract> in these problems arose during an attempt to implement such algorithms for applications in computer vision  </abstract>::line_number::27
<abstract> and in computational biology and chemistry, particularly rational drug design [FKL + 97]. We discovered that  </abstract>::line_number::28
<abstract> noise present in real data rendered most known algorithms inoperative. In hindsight, this is not surprising  </abstract>::line_number::29
<abstract> for, as noted in the survey by Alt and Guibas [AG96], these algorithms are likely to be "difficult to implement  </abstract>::line_number::30
<abstract> and numerically unstable due to the necessary computation of intersections of complex algebraic surfaces."  </abstract>::line_number::31
<abstract> Worse still, they have unacceptably high running times: for example, even in R 2 , LCP under the matching  </abstract>::line_number::32
<abstract> metric requires O(n 8 ) time, although under additional restrictions on noise regions the running times can be   </abstract>::line_number::33
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Classification is a key function of many "business  </abstract>::line_number::7
<abstract> intelligence" toolkits and a fundamental building block  </abstract>::line_number::8
<abstract> in data mining. Immense data may be needed to train  </abstract>::line_number::9
<abstract> a classifier for good accuracy. The state-of-art classifiers [21, 25] need an in-memory data structure of  </abstract>::line_number::10
<abstract> size O(N ), where N is the size of the training data,  </abstract>::line_number::11
<abstract> to achieve efficiency. For large data sets, such a data  </abstract>::line_number::12
<abstract> structure will not fit in the internal memory. The best  </abstract>::line_number::13
<abstract> previously known classifier does a quadratic number of  </abstract>::line_number::14
<abstract> I/Os for large N .  </abstract>::line_number::15
<abstract> In this paper, we propose a novel classification algorithm (classifier) called MIND (MINing in  </abstract>::line_number::16
<abstract> Databases). MIND can be phrased in such a way that  </abstract>::line_number::17
<abstract> its implementation is very easy using the extended relational calculus SQL, and this in turn allows the classifier to be built into a relational database system directly. MIND is truly scalable with respect to I/O efficiency, which is important since scalability is a key  </abstract>::line_number::18
<abstract> requirement for any data mining algorithm.  </abstract>::line_number::19
<abstract> We built a prototype of MIND in the relational  </abstract>::line_number::20
<abstract> database manager DB2 and benchmarked its performance. We describe the working prototype and report  </abstract>::line_number::21
<abstract> the measured performance with respect to the previous  </abstract>::line_number::22
<abstract> method of choice. MIND scales not only with the size  </abstract>::line_number::23
<abstract> of the datasets but also with the number of processors  </abstract>::line_number::24
<abstract> on an IBM SP2 computer system. Even on uniproces-sors, MIND scales well beyond the dataset sizes previously published for classifiers. We also give some  </abstract>::line_number::25
<abstract> insights that may have an impact on the evolution of  </abstract>::line_number::26
<abstract> the extended relational calculus SQL.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::14
<abstract> Reinforcement learning is the problem of generating optimal behavior in a sequential decision-making environment given the opportunity of  </abstract>::line_number::15
<abstract> interacting with it. Many algorithms for solving reinforcement-learning  </abstract>::line_number::16
<abstract> problems work by computing improved estimates of the optimal value  </abstract>::line_number::17
<abstract> function. We extend prior analyses of reinforcement-learning algorithms  </abstract>::line_number::18
<abstract> and present a powerful new theorem that can provide a unified analysis of  </abstract>::line_number::19
<abstract> value-function-based reinforcement-learning algorithms. The usefulness  </abstract>::line_number::20
<abstract> of the theorem lies in how it allows the asynchronous convergence of a  </abstract>::line_number::21
<abstract> complex reinforcement-learning algorithm to be proven by verifying that  </abstract>::line_number::22
<abstract> a simpler synchronous algorithm converges. We illustrate the application  </abstract>::line_number::23
<abstract> of the theorem by analyzing the convergence of Q-learning, model-based  </abstract>::line_number::24
<abstract> reinforcement learning, Q-learning with multi-state updates, Q-learning  </abstract>::line_number::25
<abstract> for Markov games, and risk-sensitive reinforcement learning.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We describe a system for representing moving  </abstract>::line_number::6
<abstract> images with sets of overlapping layers. Each  </abstract>::line_number::7
<abstract> layer contains an intensity map that defines the  </abstract>::line_number::8
<abstract> additive values of each pixel, along with an alpha  </abstract>::line_number::9
<abstract> map that serves as a mask indicating the transparency. The layers are ordered in depth and  </abstract>::line_number::10
<abstract> they occlude each other in accord with the rules  </abstract>::line_number::11
<abstract> of compositing. Velocity maps define how the  </abstract>::line_number::12
<abstract> layers are to be warped over time. The layered  </abstract>::line_number::13
<abstract> representation is more flexible than standard image transforms and can capture many important  </abstract>::line_number::14
<abstract> properties of natural image sequences. We describe some methods for decomposing image sequences into layers using motion analysis, and we  </abstract>::line_number::15
<abstract> discuss how the representation may be used for  </abstract>::line_number::16
<abstract> image coding and other applications.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We describe a framework for composing end-to-end protocol functions. The framework comprises:  </abstract>::line_number::9
<abstract> a generic model of protocol processing; a metaheader protocol supporting per-packet configuration  </abstract>::line_number::10
<abstract> of protocol function and efficient demultiplexing of incoming data units; and an extensible set of  </abstract>::line_number::11
<abstract> modular protocol functions. This paper describes the pieces of the framework and motivates some  </abstract>::line_number::12
<abstract> of the design decisions.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::7
<abstract> A revolution is occurring in the scope and range  </abstract>::line_number::8
<abstract> of information, communication and education services  </abstract>::line_number::9
<abstract> that will be made available to schools, libraries, town-halls, clinics and, most importantly, residences. These  </abstract>::line_number::10
<abstract> services will be provided initially, primarily over hybrid fiber-cable systems, either by telephone companies  </abstract>::line_number::11
<abstract> or cable companies. The old cable plant is being upgraded and used in totally new ways.  </abstract>::line_number::12
<abstract> The topology and physical characteristics of the upstream channel present new challenges for efficient  </abstract>::line_number::13
<abstract> channel access. We present a media access protocol  </abstract>::line_number::14
<abstract> that efficiently transfers data on this channel. A primary goal in the design was to keep the portion of the  </abstract>::line_number::15
<abstract> protocol resident in the station as simple as possible.  </abstract>::line_number::16
<abstract> Thus we use centralized control located in the cable  </abstract>::line_number::17
<abstract> head-end and minimize intelligence in the station. We  </abstract>::line_number::18
<abstract> refer to this protocol as Centralized Priority Reservation or CPR. A station wishing to transmit sends a request to the head-end using a contention channel. The  </abstract>::line_number::19
<abstract> head-end acknowledges the request and then schedules  </abstract>::line_number::20
<abstract> the request, informing the station by means of a grant  </abstract>::line_number::21
<abstract> message when to transmit.  </abstract>::line_number::22
<abstract> The protocol performs well under heavy load. Performance is affected little by the number of stations,  </abstract>::line_number::23
<abstract> the speed of the system and the physical length of the  </abstract>::line_number::24
<abstract> system.   </abstract>::line_number::25
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> Research and development efforts in the parallel and  </abstract>::line_number::6
<abstract> distributed simulation field over the last 15 years  </abstract>::line_number::7
<abstract> has progressed, largely independently, in two separate camps: the largely academic high performance  </abstract>::line_number::8
<abstract> Parallel And Distributed (discrete event) Simulation (PADS) community, and the DoD-centered Distributed Interactive Simulation (DIS) community.  </abstract>::line_number::9
<abstract> This tutorial gives an overview and comparison of  </abstract>::line_number::10
<abstract> work in these two areas, emphasizing issues related to  </abstract>::line_number::11
<abstract> distributed execution where these fields have the most  </abstract>::line_number::12
<abstract> overlap. Differences in the fundamental assumptions  </abstract>::line_number::13
<abstract> routinely used within each community are contrasted,  </abstract>::line_number::14
<abstract> followed by overviews of work in each community.   </abstract>::line_number::15
<abstract>  1 Abstract  </abstract>::line_number::3
<abstract> In this paper, we evaluate storage system alternatives for movies-on-demand video servers. We begin by  </abstract>::line_number::4
<abstract> characterizing the movies-on-demand workload. Then we study disk farms in which one movie is stored per  </abstract>::line_number::5
<abstract> disk. This is a simple scheme, but it wastes substantial disk bandwidth, since disks holding less popular  </abstract>::line_number::6
<abstract> movies are under-utilized; also, good performance requires that movies be replicated to reflect the user  </abstract>::line_number::7
<abstract> request pattern. Next, we examine disk farms in which movies are striped across disks, and find that  </abstract>::line_number::8
<abstract> striped video servers offer close to full utilization of the disks by achieving better load balancing. Finally, we  </abstract>::line_number::9
<abstract> evaluate the use of storage hierarchies for video service that include a tertiary library along with a disk farm.  </abstract>::line_number::10
<abstract> Unfortunately, we show that the performance of neither magnetic tape libraries nor optical disk jukeboxes  </abstract>::line_number::11
<abstract> as part of a storage hierarchy is adequate to service the predicted distribution of movie accesses. We suggest  </abstract>::line_number::12
<abstract> changes to tertiary libraries that would make them better-suited to these applications.   </abstract>::line_number::13
<abstract>  Abstract| Generalized connectors provide the capability to connect a single input to one or more outputs. Such networks play an important role in supporting any application that involves the distribution of information from one source to many destinations or many sources to many destinations. We present the first analytic model for evaluating blocking probability in generalized connectors. The model allows flexibility in specifying traffic fanout characteristics and network routing algorithms. Equations are derived for computing blocking probability for the important class of series-parallel networks. We investigate the accuracy of the equations by comparing the blocking probability computed using the equations to results from simulation.   </abstract>::line_number::3
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We examine using a CASE tool, Interactive Development Environment's Software through Pictures (StP), to support reverse engineering. We generate structure charts in StP from the automated analysis  </abstract>::line_number::5
<abstract> of C source code. The advantages of this approach are that one can use  </abstract>::line_number::6
<abstract> the CASE tool's support for drawing, linking, and modifying pictorial  </abstract>::line_number::7
<abstract> notations for program design in order to make it easier to construct a  </abstract>::line_number::8
<abstract> reverse engineering tool. Additionally, one can then use the design rep  </abstract>::line_number::9
<abstract> resentations with the CASE tool to do reengineering for maintenance.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Association rules, introduced by Agrawal, Imielinski, and  </abstract>::line_number::7
<abstract> Swami, are rules of the form "for 90 % of the rows of the  </abstract>::line_number::8
<abstract> relation, if the row has value 1 in the columns in set W ,  </abstract>::line_number::9
<abstract> then it has 1 also in column B". Efficient methods exist for  </abstract>::line_number::10
<abstract> discovering association rules from large collections of data.  </abstract>::line_number::11
<abstract> The number of discovered rules can, however, be so large  </abstract>::line_number::12
<abstract> that browsing the rule set and finding interesting rules from  </abstract>::line_number::13
<abstract> it can be quite difficult for the user. We show how a simple  </abstract>::line_number::14
<abstract> formalism of rule templates makes it possible to easily describe the structure of interesting rules. We also give examples of visualization of rules, and show how a visualization  </abstract>::line_number::15
<abstract> tool interfaces with rule templates.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We describe a database system for writing, editing, and querying structured documents. The structure of text is described using a context-free  </abstract>::line_number::5
<abstract> grammar. The operations are implemented using a powerful query language. The system supports the use of user-defined multiple views of the  </abstract>::line_number::6
<abstract> documents: one view can contain all the structure explicitly, while another  </abstract>::line_number::7
<abstract> can contain only part of the document and have only part of the structure visible. This makes the system flexible for different editing tasks.  </abstract>::line_number::8
<abstract> The system is implemented in C using a relational database system.   </abstract>::line_number::9
<abstract>  Abstract. We present a new sublinear-size index structure for q-grams.  </abstract>::line_number::5
<abstract> A q-gram index of the text is used in many approximate pattern matching  </abstract>::line_number::6
<abstract> algorithms. All earlier q-gram indexes have at least linear size. The new  </abstract>::line_number::7
<abstract> method takes advantage of repetitions in the text found by Lempel-Ziv  </abstract>::line_number::8
<abstract> parsing.   </abstract>::line_number::9
<abstract>  Abstract. The core of multiple-view geometry is governed by the fundamental matrix and the trilinear  </abstract>::line_number::7
<abstract> tensor. In this paper we unify both representations by first re-deriving the fundamental matrix as a rank  </abstract>::line_number::8
<abstract> deficient tensor, and secondly by deriving a unified set of operators that are transparent to the number of  </abstract>::line_number::9
<abstract> views. As a result, we show that the basic building block of the geometry of multiple views is the trilinear  </abstract>::line_number::10
<abstract> tensor of three views and that this tensor specializes to the fundamental matrix (in it's tensor form) in  </abstract>::line_number::11
<abstract> the case of two views. The properties of the tensor (geometric interpretation, contraction properties,  </abstract>::line_number::12
<abstract> etc.) are independent of the number of views (two or three). As a byproduct, every two-view algorithm  </abstract>::line_number::13
<abstract> can be considered as a degenerate three-view algorithm and three-view algorithms can work with either  </abstract>::line_number::14
<abstract> two or three images, all using one standard set of tensor operations. To highlight the usefulness of this  </abstract>::line_number::15
<abstract> paradigm we provide two practical applications. First we present a novel view synthesis algorithm that  </abstract>::line_number::16
<abstract> starts with the fundamental matrix (in its tensor form) and seamlessly move to the general trilinear  </abstract>::line_number::17
<abstract> tensor, all using one set of tensor operations. The second application is a camera stabilization algorithm,  </abstract>::line_number::18
<abstract> originally introduced for three views, now working with two views without modification.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::4
<abstract> When a moldable job is submitted to a space-sharing  </abstract>::line_number::5
<abstract> parallel computer, it must choose whether to begin execution on a small, available cluster or wait in queue for  </abstract>::line_number::6
<abstract> more processors to become available. To make this decision, it must predict how long it will have to wait for  </abstract>::line_number::7
<abstract> the larger cluster. We propose statistical techniques for  </abstract>::line_number::8
<abstract> predicting these queue times, and develop an allocation  </abstract>::line_number::9
<abstract> strategy that uses these predictions. We present a workload model based on observed workloads at the San Diego  </abstract>::line_number::10
<abstract> Supercomputer Center and the Cornell Theory Center,  </abstract>::line_number::11
<abstract> and use this model to drive simulations of various allocation strategies. We find that prediction-based allocation  </abstract>::line_number::12
<abstract> not only improves the turnaround time of individual jobs;  </abstract>::line_number::13
<abstract> it also improves the utilization of the system as a whole.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::5
<abstract> The absence of powerful control structures and processes that synchronize, coordinate, switch between, choose among, regulate, direct, modulate interactions between, and  </abstract>::line_number::6
<abstract> combine distinct yet interdependent modules of large connectionist networks (CN) is  </abstract>::line_number::7
<abstract> probably one of the most important reasons why such networks have not yet succeeded at  </abstract>::line_number::8
<abstract> handling difficult tasks (e.g. complex object recognition and description, complex  </abstract>::line_number::9
<abstract> problem-solving, planning).  </abstract>::line_number::10
<abstract> In this paper we examine how CN built from large numbers of relatively simple  </abstract>::line_number::11
<abstract> neuron-like units can be given the ability to handle problems that in typical multi-computer networks and artificial intelligence programs along with all other types of  </abstract>::line_number::12
<abstract> programs are always handled using extremely elaborate and precisely worked out central control (coordination, synchronization, switching, etc.). We point out the several  </abstract>::line_number::13
<abstract> mechanisms for central control of this un-brain-like sort that CN already have built into  </abstract>::line_number::14
<abstract> them albeit in hidden, often overlooked, ways.  </abstract>::line_number::15
<abstract> We examine the kinds of control mechanisms found in computers, programs, fetal  </abstract>::line_number::16
<abstract> development, cellular function and the immune system, evolution, social organizations,  </abstract>::line_number::17
<abstract> and especially brains, that might be of use in CN. Particularly intriguing suggestions are  </abstract>::line_number::18
<abstract> found in the pacemakers, oscillators, and other local sources of the brain's complex partial synchronies; the diffuse, global effects of slow electrical waves and neurohormones;  </abstract>::line_number::19
<abstract> the developmental program that guides fetal development; communication and coordination within and among living cells; the working of the immune system; the evolutionary  </abstract>::line_number::20
<abstract> processes that operate on large populations of organisms; and the great variety of partially competing partially cooperating controls found in small groups, organizations, and  </abstract>::line_number::21
<abstract> larger societies. All these systems are rich in control but typically control that emerges  </abstract>::line_number::22
<abstract> from complex interactions of many local and diffuse sources. We explore how several  </abstract>::line_number::23
<abstract> different kinds of plausible control mechanisms might be incorporated into CN, and  </abstract>::line_number::24
<abstract> assess their potential benefits with respect to their cost.   </abstract>::line_number::25
<abstract>  Abstract: Practical pattern classification and knowledge discovery problems require selection of a  </abstract>::line_number::10
<abstract> subset of attributes or features (from a much larger set) to represent the patterns to be classified.  </abstract>::line_number::11
<abstract> This is due to the fact that the performance of the classifier (usually induced by some learning  </abstract>::line_number::12
<abstract> algorithm) and the cost of classification are sensitive to the choice of the features used to construct  </abstract>::line_number::13
<abstract> the classifier. Exhaustive evaluation of possible feature subsets is usually infeasible in practice because  </abstract>::line_number::14
<abstract> of the large amount of computational effort required. Genetic algorithms, which belong to a class of  </abstract>::line_number::15
<abstract> randomized heuristic search techniques, offer an attractive approach to find near-optimal solutions  </abstract>::line_number::16
<abstract> to such optimization problems. This paper presents an approach to feature subset selection using a  </abstract>::line_number::17
<abstract> genetic algorithm. Some advantages of this approach include the ability to accommodate multiple  </abstract>::line_number::18
<abstract> criteria such as accuracy and cost of classification into the feature selection process and to find feature  </abstract>::line_number::19
<abstract> subsets that perform well for particular choices of the inductive learning algorithm used to construct  </abstract>::line_number::20
<abstract> the pattern classifier. Our experiments with several benchmark real-world pattern classification  </abstract>::line_number::21
<abstract> problems demonstrate the feasibility of this approach to feature subset selection in the automated  </abstract>::line_number::22
<abstract> design of neural networks for pattern classification and knowledge discovery.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper describes a course in compiler design that focuses on the  </abstract>::line_number::8
<abstract> Scheme implementation of a Scheme compiler that generates native assembly code for a real architecture. The course is suitable for advanced  </abstract>::line_number::9
<abstract> undergraduate and beginning graduate students. It is intended both to  </abstract>::line_number::10
<abstract> provide a general knowledge about compiler design and implementation  </abstract>::line_number::11
<abstract> and to serve as a springboard to more advanced courses. Although this  </abstract>::line_number::12
<abstract> paper concentrates on the implementation of a compiler, an outline for an  </abstract>::line_number::13
<abstract> advanced topics course that builds upon the compiler is also presented.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Standard methods for abductive understanding are neutral to prior experience and current goals.  </abstract>::line_number::7
<abstract> Candidate explanations are built from scratch by backwards chaining, without considering how  </abstract>::line_number::8
<abstract> similar situations were previously explained, and selection of the candidate to accept is based on its  </abstract>::line_number::9
<abstract> likelihood, without considering the information needs beyond routine understanding. Problems arise  </abstract>::line_number::10
<abstract> when applying these methods to everyday understanding: The vast range of possible explanations  </abstract>::line_number::11
<abstract> makes it difficult to control the cost of explanation construction and to assure that the explanations  </abstract>::line_number::12
<abstract> generated will actually be useful.  </abstract>::line_number::13
<abstract> We argue that these problems can be overcome by using goals and experience to guide both  </abstract>::line_number::14
<abstract> explanation generation and evaluation. Our work is within the framework of case-based explanation, which builds explanations by retrieving and adapting prior explanations stored in memory.  </abstract>::line_number::15
<abstract> We substantiate our model by describing mechanisms that enable it to effectively generate good  </abstract>::line_number::16
<abstract> explanations. First, we demonstrate that there exists a theory of anomaly and explanation that can  </abstract>::line_number::17
<abstract> guide retrieval of relevant explanations. Second, we present a plausibility evaluation process that  </abstract>::line_number::18
<abstract> efficiently detects conflicts and confirmations of an explanation's assumptions by prior patterns,  </abstract>::line_number::19
<abstract> making it possible to focus explanation adaptation when retrieved explanations are implausible.  </abstract>::line_number::20
<abstract> Third, we present methods for judging whether explanations provide the information needed to satisfy explainer goals beyond routine understanding. By reflecting experience and goals in the search  </abstract>::line_number::21
<abstract> for explanations, case-based explanation provides a practical mechanism for guiding search towards  </abstract>::line_number::22
<abstract> explanations that are both plausible and useful.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The case-based reasoning process depends on  </abstract>::line_number::9
<abstract> multiple overlapping knowledge sources, each  </abstract>::line_number::10
<abstract> of which provides an opportunity for learning. Exploiting these opportunities requires  </abstract>::line_number::11
<abstract> not only determining the learning mechanisms  </abstract>::line_number::12
<abstract> to use for each individual knowledge source,  </abstract>::line_number::13
<abstract> but also how the different learning mechanisms interact and their combined utility. This  </abstract>::line_number::14
<abstract> paper presents a case study examining the  </abstract>::line_number::15
<abstract> relative contributions and costs involved in  </abstract>::line_number::16
<abstract> learning processes for three different knowledge sources|cases, case adaptation knowledge, and similarity information|in a case-based planner. It demonstrates the importance  </abstract>::line_number::17
<abstract> of interactions between different learning processes and identifies a promising method for integrating multiple learning methods to improve  </abstract>::line_number::18
<abstract> case-based reasoning.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Several ways of improving the realism of the results  </abstract>::line_number::9
<abstract> of traditional ray tracing are presented. The essential physical quantities of spectral radiant power and  </abstract>::line_number::10
<abstract> spectral radiance and their use in lighting calculations  </abstract>::line_number::11
<abstract> are discussed. Global illumination terms are derived  </abstract>::line_number::12
<abstract> by employing illumination ray tracing for calculation of  </abstract>::line_number::13
<abstract> quickly changing indirect lighting components, and ra-diosity ray tracing for slowly changing indirect lighting  </abstract>::line_number::14
<abstract> components. Direct lighting is calculated during the  </abstract>::line_number::15
<abstract> viewing phase allowing the use of bump maps. Finally,  </abstract>::line_number::16
<abstract> a method is introduced that reduces the total number  </abstract>::line_number::17
<abstract> of shadow rays to no more than the total number of  </abstract>::line_number::18
<abstract> viewing rays for a given picture.   </abstract>::line_number::19
<abstract>  ABSTRACT  </abstract>::line_number::7
<abstract> We present a novel robust methodology for corresponding a dense set of points on an  </abstract>::line_number::8
<abstract> object surface from photometric values, for 3-D stereo computation of depth. The methodology utilizes multiple stereo pairs of images, each stereo pair taken of exactly the same  </abstract>::line_number::9
<abstract> scene but under different illumination. With just 2 stereo pairs of images taken respectively for 2 different illumination conditions, a stereo pair of ratio images can be produced; one for the ratio of left images, and one for the ratio of right images. We  </abstract>::line_number::10
<abstract> demonstrate how the photometric ratios composing these images can be used for accurate  </abstract>::line_number::11
<abstract> correspondence of object points. Object points having the same photometric ratio with  </abstract>::line_number::12
<abstract> respect to 2 different illumination conditions comprise a well-defined equivalence class of  </abstract>::line_number::13
<abstract> physical constraints defined by local surface orientation relative to illumination conditions. We formally show that for diffuse reection the photometric ratio is invariant to  </abstract>::line_number::14
<abstract> varying camera characteristics, surface albedo, and viewpoint and that therefore the same  </abstract>::line_number::15
<abstract> photometric ratio in both images of a stereo pair implies the same equivalence class of  </abstract>::line_number::16
<abstract> physical constraints. Corresponding photometric ratios along epipolar lines in a stereo pair  </abstract>::line_number::17
<abstract> of images under different illumination conditions is therefore a robust correspondence of  </abstract>::line_number::18
<abstract> equivalent physical constraints, and determination of depth from stereo can be performed  </abstract>::line_number::19
<abstract> without explicitly knowing what these physical constraints being corresponded actually  </abstract>::line_number::20
<abstract> are. This implies a very practical shape-from-stereo methodology applicable to perspective views and not requiring any knowledge whatsoever of illumination conditions. This is  </abstract>::line_number::21
<abstract> particularly practical for determination of 3-D shape on smooth featureless surfaces which  </abstract>::line_number::22
<abstract> has previously been hard to perform using stereo. We demonstrate experimental 3-D shape  </abstract>::line_number::23
<abstract> determination from a dense set of points using our stereo technique on smooth objects of  </abstract>::line_number::24
<abstract> known ground truth shape that are accurate to well within 1% depth accuracy.   </abstract>::line_number::25
<abstract>  Abstract| In this paper we propose a theoretical model  </abstract>::line_number::4
<abstract> for analysis of classification methods, in which the teacher  </abstract>::line_number::5
<abstract> knows the classification algorithm and chooses examples in  </abstract>::line_number::6
<abstract> the best way possible. We apply this model using the nearest-neighbor learning algorithm, and develop upper and lower  </abstract>::line_number::7
<abstract> bounds on sample complexity for several different concept  </abstract>::line_number::8
<abstract> classes. For some concept classes, the sample complexity  </abstract>::line_number::9
<abstract> turns out to be exponential even using this best-case model,  </abstract>::line_number::10
<abstract> which implies that the concept class is inherently difficult  </abstract>::line_number::11
<abstract> for the nearest-neighbor algorithm. We identify several geometric properties that make learning certain concepts relatively easy. Finally we discuss the relation of our work  </abstract>::line_number::12
<abstract> to helpful teacher models, its application to decision-tree  </abstract>::line_number::13
<abstract> learning algorithms, and some of its implications for current experimental work.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::13
<abstract> This paper presents a deterministic sorting algorithm, called Sharesort, that sorts n  </abstract>::line_number::14
<abstract> records on an n-processor hypercube, shu*e-exchange, or cube-connected cycles in  </abstract>::line_number::15
<abstract> O(log n (log log n) 2 ) time in the worst case. The algorithm requires only a constant  </abstract>::line_number::16
<abstract> amount of storage at each processor. The fastest previous deterministic algorithm for  </abstract>::line_number::17
<abstract> this problem was Batcher's bitonic sort, which runs in O(log 2 n) time.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::9
<abstract> A distinct advantage of symbolic learning  </abstract>::line_number::10
<abstract> algorithms over artificial neural networks is  </abstract>::line_number::11
<abstract> that typically the concept representations  </abstract>::line_number::12
<abstract> they form are more easily understood by humans. One approach to understanding the  </abstract>::line_number::13
<abstract> representations formed by neural networks is  </abstract>::line_number::14
<abstract> to extract symbolic rules from trained networks. In this paper we describe and investigate an approach for extracting rules from  </abstract>::line_number::15
<abstract> networks that uses (1) the NofM extraction algorithm, and (2) the network training  </abstract>::line_number::16
<abstract> method of soft weight-sharing. Previously,  </abstract>::line_number::17
<abstract> the NofM algorithm had been successfully  </abstract>::line_number::18
<abstract> applied only to knowledge-based neural networks. Our experiments demonstrate that  </abstract>::line_number::19
<abstract> our extracted rules generalize better than  </abstract>::line_number::20
<abstract> rules learned using the C4.5 system. In addition to being accurate, our extracted rules  </abstract>::line_number::21
<abstract> are also reasonably comprehensible.   </abstract>::line_number::22
<abstract>  We report on work done to develop a benchmark problem for genetic programming, both  </abstract>::line_number::5
<abstract> as a difficult problem to test GP abilities and as a platform for tuning GP parameters.  </abstract>::line_number::6
<abstract> This benchmark, the royal tree, is a function that accounts for tree shape as part of its  </abstract>::line_number::7
<abstract> evaluation function, thus it controls for a parameter not often found in the GP literature.  </abstract>::line_number::8
<abstract> It also is a progressive function, allowing the user to set the difficulty of the problem  </abstract>::line_number::9
<abstract> attempted. We not only describe the function, but also report on results of using island  </abstract>::line_number::10
<abstract> parallelism for solving GP problems. The results obtained are somewhat surprising, as it  </abstract>::line_number::11
<abstract> appears that a single large population outperforms a group of smaller populations under  </abstract>::line_number::12
<abstract> all the conditions tested.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::12
<abstract> In this position paper, we make several  </abstract>::line_number::13
<abstract> observations about the state of the art in  </abstract>::line_number::14
<abstract> automatic word sense disambiguation. Motivated by these observations, we offer several specific proposals to the community regarding improved evaluation criteria, common training and testing resources, and the  </abstract>::line_number::15
<abstract> definition of sense inventories.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> A novel approach to learning first order logic formulae from positive and negative examples is incorporated in a system named ICL (Inductive Constraint  </abstract>::line_number::8
<abstract> Logic). In ICL, examples are viewed as interpretations which are true or false  </abstract>::line_number::9
<abstract> for the target theory, whereas in present inductive logic programming systems,  </abstract>::line_number::10
<abstract> examples are true and false ground facts (or clauses). Furthermore, ICL uses a  </abstract>::line_number::11
<abstract> clausal representation, which corresponds to a conjunctive normal form where  </abstract>::line_number::12
<abstract> each conjunct forms a constraint on positive examples, whereas classical learning  </abstract>::line_number::13
<abstract> techniques have concentrated on concept representations in disjunctive normal  </abstract>::line_number::14
<abstract> form.  </abstract>::line_number::15
<abstract> We present some experiments with this new system on the mutagenesis problem. These experiments illustrate some of the differences with other systems,  </abstract>::line_number::16
<abstract> and indicate that our approach should work at least as well as the more classical  </abstract>::line_number::17
<abstract> approaches.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Magnetic resonance imaging (MRI) of the brain, followed by automated segmentation of the corpus callosum  </abstract>::line_number::7
<abstract> (CC) in midsagittal sections have important applications  </abstract>::line_number::8
<abstract> in both clinical neurology and neurocognitive research  </abstract>::line_number::9
<abstract> since the size and shape of the CC are shown to be correlated to sex, age, neurodegenerative diseases and various lateralized behavior in man. Moreover, whole head,  </abstract>::line_number::10
<abstract> multispectral 3D MRI recordings enable voxel-based tissue classification and estimation of total brain volumes,  </abstract>::line_number::11
<abstract> in addition to CC morphometric parameters. We propose  </abstract>::line_number::12
<abstract> a new algorithm that uses both multispectral MRI measurements (intensity values) and prior information about  </abstract>::line_number::13
<abstract> shape (CC template) to segment CC in midsagittal slices  </abstract>::line_number::14
<abstract> with very little user interaction. The algorithm has been  </abstract>::line_number::15
<abstract> tested on a sample of 10 subjects scanned with multispec-tral 3D MRI, collected for a study of dyslexia, with very  </abstract>::line_number::16
<abstract> good agreement between the manually traced (true) CC  </abstract>::line_number::17
<abstract> outline and the detected CC outline. We conclude that  </abstract>::line_number::18
<abstract> the proposed method for CC segmentation is promising for  </abstract>::line_number::19
<abstract> clinical use when multispectral MR images are recorded.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper presents a study of the statistical characteristics and multiplexing of Variable-Bit-Rate (VBR)  </abstract>::line_number::7
<abstract> MPEG-coded video streams. Our results are based on  </abstract>::line_number::8
<abstract> 23 minutes of video obtained from the entertainment  </abstract>::line_number::9
<abstract> movie, The Wizard of Oz. The experimental setup  </abstract>::line_number::10
<abstract> which was used to capture, digitize, and compress the  </abstract>::line_number::11
<abstract> video stream is described. Although the study is conducted at the frame level (as opposed to the slice level),  </abstract>::line_number::12
<abstract> it is observed that the inter-frame correlation structure for the frame-size sequence involves complicated  </abstract>::line_number::13
<abstract> forms of pseudo-periodicity that are mainly affected  </abstract>::line_number::14
<abstract> by the compression pattern of the sequence. A simple model for an MPEG traffic source is developed in  </abstract>::line_number::15
<abstract> which frames are generated according to the compression pattern of the original captured video stream. The  </abstract>::line_number::16
<abstract> number of cells per frame is fitted by a lognormal distribution. Simulations are used to study the performance of an ATM multiplexer for MPEG streams.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Aditi is a deductive database system under development at the Collaborative Information  </abstract>::line_number::10
<abstract> Technology Research Institute by researchers from the University of Melbourne. The main  </abstract>::line_number::11
<abstract> language in which users interact with Aditi is Aditi-Prolog. This document is a reference  </abstract>::line_number::12
<abstract> manual for Aditi-Prolog.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Since the late eighties, much progress has been made in the theory of termination analysis for  </abstract>::line_number::6
<abstract> logic programs. However, from a practical point of view, the significance of much of the work  </abstract>::line_number::7
<abstract> on termination is hard to judge, since experimental evaluations rarely get published. Here we  </abstract>::line_number::8
<abstract> describe and evaluate a termination analyzer for Mercury, a strongly typed and moded logic-  </abstract>::line_number::9
<abstract> functional programming language. Mercury's high degree of referential transparency and the  </abstract>::line_number::10
<abstract> guaranteed availability of reliable mode information simplify the termination analysis of Mer-  </abstract>::line_number::11
<abstract> cury compared with that of other logic programming languages. We describe our termination  </abstract>::line_number::12
<abstract> analyzer, which uses a variant of a method developed by Plumer. It deals with full Mercury,  </abstract>::line_number::13
<abstract> including modules, declarative input/output, the foreign language interface, and higher-order  </abstract>::line_number::14
<abstract> features. In spite of these obstacles, it produces high-quality termination information, comparable to the results recently obtained by Lindenstrauss and Sagiv. Most important, in stark  </abstract>::line_number::15
<abstract> contrast with Lindenstrauss and Sagiv's experimental results, our analyzer has a negligible  </abstract>::line_number::16
<abstract> impact on the running time of the compiler of which it is part, even for large programs. This  </abstract>::line_number::17
<abstract> means that the Mercury compiler can produce valuable termination information at no real  </abstract>::line_number::18
<abstract> cost to the programmer.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We consider mixed semidefinite-quadratic-linear programs. These are  </abstract>::line_number::5
<abstract> linear optimization problems with three kinds of cone constraints, namely:  </abstract>::line_number::6
<abstract> the semidefinite cone, the quadratic cone and the nonnegative orthant. We  </abstract>::line_number::7
<abstract> outline a primal-dual path following method to solve these problems and  </abstract>::line_number::8
<abstract> highlight the main features of SDPpack, a Matlab package which solves  </abstract>::line_number::9
<abstract> such programs. We give some examples where such mixed programs arise,  </abstract>::line_number::10
<abstract> and provide numerical results on benchmark problems.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::6
<abstract> In comparision with other games, particularly chess, the research in computer bridge is  </abstract>::line_number::7
<abstract> immature, and the best bridge-playing programs are mediocre. We propose to study the  </abstract>::line_number::8
<abstract> automation of the card-playing segment of bridge (omitting bidding), using a number of  </abstract>::line_number::9
<abstract> different techniques. In this paper we first give an introduction to the state of computer  </abstract>::line_number::10
<abstract> bridge. Next, we propose two possible architectures for solving double-dummy bridge  </abstract>::line_number::11
<abstract> (i.e., a simplified bridge game with perfect information): The first is based on the  </abstract>::line_number::12
<abstract> combination of And-OR search and heuristic evaluation. The second forms a global plan  </abstract>::line_number::13
<abstract> by merging subplans for each individual suit. Next, to deal with uncertain information in  </abstract>::line_number::14
<abstract> real bridge, we present a new mechanism that combines the concepts of both minimax  </abstract>::line_number::15
<abstract> search and possible worlds. Finally we give a brief description of further work toward  </abstract>::line_number::16
<abstract> automating card-playing in real bridge.   </abstract>::line_number::17
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> The C programming language was devised in the early 1970s as a system  </abstract>::line_number::6
<abstract> implementation language for the nascent Unix operating system. Derived from  </abstract>::line_number::7
<abstract> the typeless language BCPL, it evolved a type structure; created on a tiny  </abstract>::line_number::8
<abstract> machine as a tool to improve a meager programming environment, it has become  </abstract>::line_number::9
<abstract> one of the dominant languages of today. This paper studies its evolution.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Explanation-Based Reinforcement Learning  </abstract>::line_number::7
<abstract> (EBRL) was introduced by Dietterich and  </abstract>::line_number::8
<abstract> Flann as a way of combining the ability of  </abstract>::line_number::9
<abstract> Reinforcement Learning (RL) to learn optimal plans with the generalization ability  </abstract>::line_number::10
<abstract> of Explanation-Based Learning (EBL) (Di-etterich & Flann, 1995). We extend this  </abstract>::line_number::11
<abstract> work to domains where the agent must order and achieve a sequence of subgoals in  </abstract>::line_number::12
<abstract> an optimal fashion. Hierarchical EBRL can  </abstract>::line_number::13
<abstract> effectively learn optimal policies in some of  </abstract>::line_number::14
<abstract> these sequential task domains even when the  </abstract>::line_number::15
<abstract> subgoals weakly interact with each other.  </abstract>::line_number::16
<abstract> We also show that when a planner that can  </abstract>::line_number::17
<abstract> achieve the individual subgoals is available,  </abstract>::line_number::18
<abstract> our method converges even faster.   </abstract>::line_number::19
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> This paper describes and evaluates distributed  </abstract>::line_number::6
<abstract> wavelength reservation protocols for all-optical WDM  </abstract>::line_number::7
<abstract> networks. These protocols are essential for applying  </abstract>::line_number::8
<abstract> WDM techniques to large scale all-optical networks.  </abstract>::line_number::9
<abstract> The protocols ensure that the wavelengths on the links  </abstract>::line_number::10
<abstract> along a path are reserved before communication takes  </abstract>::line_number::11
<abstract> place. A message is transmitted using the reserved  </abstract>::line_number::12
<abstract> wavelengths and remains in the optical domain utill  </abstract>::line_number::13
<abstract> it reaches the destination. Based upon the timing at  </abstract>::line_number::14
<abstract> which the reservation is performed, the protocols are  </abstract>::line_number::15
<abstract> classified into two categories: forward reservation protocols and backward reservation protocols. Although  </abstract>::line_number::16
<abstract> forward reservation protocols are simpler, our performance study shows that backward reservation protocols provide better performance.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::12
<abstract> A key question in conditional planning is: how many,  </abstract>::line_number::13
<abstract> and which of the possible execution failures should be  </abstract>::line_number::14
<abstract> planned for? One cannot, in general, plan for all the  </abstract>::line_number::15
<abstract> possible failures because the search space is too large.  </abstract>::line_number::16
<abstract> One cannot ignore all the possible failures, or one will  </abstract>::line_number::17
<abstract> fail to produce sufficiently flexible plans. In this paper,  </abstract>::line_number::18
<abstract> we describe an approach to conditional planning that  </abstract>::line_number::19
<abstract> attempts to identify the contingencies that contribute  </abstract>::line_number::20
<abstract> the most to a plan's overall utility. Plan generation  </abstract>::line_number::21
<abstract> proceeds by handling the most important contingencies first, extending the plan to include actions that  </abstract>::line_number::22
<abstract> will be taken in case the contingency fails. We discuss  </abstract>::line_number::23
<abstract> the representational issues that must be addressed in  </abstract>::line_number::24
<abstract> order to implement such an algorithm, and present an  </abstract>::line_number::25
<abstract> example which illustrates our approach.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The distribution of resources among processors, memory and  </abstract>::line_number::7
<abstract> caches is a crucial question faced by designers of large-scale  </abstract>::line_number::8
<abstract> parallel machines. If a machine is to solve problems with a  </abstract>::line_number::9
<abstract> certain data set size, should it be built with a large number of  </abstract>::line_number::10
<abstract> processors each with a small amount of memory, or a smaller  </abstract>::line_number::11
<abstract> number of processors each with a large amount of memory?  </abstract>::line_number::12
<abstract> How much cache memory should be provided per processor for  </abstract>::line_number::13
<abstract> cost-effectiveness? And how do these decisions change as larger  </abstract>::line_number::14
<abstract> problems are run on larger machines?  </abstract>::line_number::15
<abstract> In this paper, we explore the above questions based on the  </abstract>::line_number::16
<abstract> characteristics of five important classes of large-scale parallel scientific applications. We first show that all the applications have a hierarchy of well-defined per-processor working  </abstract>::line_number::17
<abstract> sets, whose size, performance impact and scaling characteristics  </abstract>::line_number::18
<abstract> can help determine how large different levels of a multiprocessor's cache hierarchy should be. Then, we use these working sets together with certain other important characteristics of  </abstract>::line_number::19
<abstract> the applications|such as communication to computation ratios,  </abstract>::line_number::20
<abstract> concurrency, and load balancing behavior|to reflect upon the  </abstract>::line_number::21
<abstract> broader question of the granularity of processing nodes in high-performance multiprocessors.  </abstract>::line_number::22
<abstract> We find that very small caches whose sizes do not increase  </abstract>::line_number::23
<abstract> with the problem or machine size are adequate for all but two of  </abstract>::line_number::24
<abstract> the application classes. Even in the two exceptions, the working  </abstract>::line_number::25
<abstract> sets scale quite slowly with problem size, and the cache sizes  </abstract>::line_number::26
<abstract> needed for problems that will be run in the foreseeable future  </abstract>::line_number::27
<abstract> are small. We also find that relatively fine-grained machines,  </abstract>::line_number::28
<abstract> with large numbers of processors and quite small amounts of  </abstract>::line_number::29
<abstract> memory per processor, are appropriate for all the applications.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Recently, several theoretical models of parallel architectures have been proposed to replace the PRAM as the model  </abstract>::line_number::7
<abstract> that is presented to an algorithm designer. A primary focus of  </abstract>::line_number::8
<abstract> the new models is to include the cost of interprocessor communication, which is increasingly important in modern parallel  </abstract>::line_number::9
<abstract> architectures. We argue that modeling the communication costs  </abstract>::line_number::10
<abstract> in the architecture or system is only one part of the problem.  </abstract>::line_number::11
<abstract> The other, and usually much more difficult, part is modeling  </abstract>::line_number::12
<abstract> the communication properties of the algorithm itself, which  </abstract>::line_number::13
<abstract> provides necessary inputs into the architectural model to determine overall complexity. In this context, we make three main  </abstract>::line_number::14
<abstract> points in this paper: (i) It is incomplete to describe communication without regard to its relationship with replication. We  </abstract>::line_number::15
<abstract> propose a description of the communication-replication relationship in terms of the working set hierarchy of an algorithm.  </abstract>::line_number::16
<abstract> (ii) Both inherent communication and the communication-replication relationship can be very difficult to model in irregular, dynamic computations that are crucial in many real-world  </abstract>::line_number::17
<abstract> applications. We present some examples that demonstrate this  </abstract>::line_number::18
<abstract> difficulty. (iii) We believe that substantial leverage can be  </abstract>::line_number::19
<abstract> obtained in this effort from the computer systems community,  </abstract>::line_number::20
<abstract> which can provide a hierarchy of simulation and profiling  </abstract>::line_number::21
<abstract> toolsfrom abstract to detailedtailored to the needs of the  </abstract>::line_number::22
<abstract> algorithm designers. We propose an initial set of simulation  </abstract>::line_number::23
<abstract> tools, and we discuss possible future refinements to this set.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Shared Virtual Memory (SVM) provides an inexpensive way to support the popular shared address  </abstract>::line_number::8
<abstract> space programming model on networks of workstations or personal computers. Despite recent advances  </abstract>::line_number::9
<abstract> in SVM systems, their performance for all but coarse-grained or regular applications is not well understood.  </abstract>::line_number::10
<abstract> Nor is there an understanding of whether and how  </abstract>::line_number::11
<abstract> fine-grained, irregular programs should be written differently for SVM, with its large granularities of communication and coherence, than for the more familiar  </abstract>::line_number::12
<abstract> hardware coherent at cache line granularity. In this  </abstract>::line_number::13
<abstract> paper we try to understand the performance and programming issues for emerging, irregular applications  </abstract>::line_number::14
<abstract> on SVM systems. We examine performance on both  </abstract>::line_number::15
<abstract> an aggressive all-software system as well as one with a  </abstract>::line_number::16
<abstract> little hardware support in the network interface. We  </abstract>::line_number::17
<abstract> also present approaches to improve the performance  </abstract>::line_number::18
<abstract> of irregular applications at both the programming and  </abstract>::line_number::19
<abstract> the system level. As a result of our experiences, we  </abstract>::line_number::20
<abstract> identify a set of guidelines and techniques that pertain  </abstract>::line_number::21
<abstract> specifically to programming SVM systems, beyond the  </abstract>::line_number::22
<abstract> guidelines commonly used for programming hardware-coherent systems as well. We also present a further  </abstract>::line_number::23
<abstract> relaxation of the memory consistency model, called  </abstract>::line_number::24
<abstract> scope consistency, which is particularly effective for  </abstract>::line_number::25
<abstract> such applications.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::5
<abstract> This paper describes network services to support  </abstract>::line_number::6
<abstract> large multi-user virtual environments. A client-server design is proposed in which multiple servers  </abstract>::line_number::7
<abstract> coordinate execution, manage communication, offload processing, and provide persistent storage for  </abstract>::line_number::8
<abstract> their clients. Using this design, it is possible to support real-time features, such as collision detection,  </abstract>::line_number::9
<abstract> voice bridging, persistent updates, physical simulation, and autonomous agents, that would be difficult to implement for large virtual environments  </abstract>::line_number::10
<abstract> with a peer-to-peer design. The paper includes a  </abstract>::line_number::11
<abstract> description of services being implemented in RING,  </abstract>::line_number::12
<abstract> a client-server system for interaction between many  </abstract>::line_number::13
<abstract> users in large virtual environments.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We simulate a multiagent market with production, consumption, and exchange  </abstract>::line_number::7
<abstract> mediated by a sealed-bid double auction. Marked price bubbles and subsequent  </abstract>::line_number::8
<abstract> crashes occur when value-based (fundamentals-driven) and trend-based traders are  </abstract>::line_number::9
<abstract> both present, and the market equilibrium price is ramped up exogenously. Similarly,  </abstract>::line_number::10
<abstract> negative price bubbles and recoveries occur when the equilibrium price is ramped  </abstract>::line_number::11
<abstract> down. Because the simulated market is auction-mediated, we can observe the operations of traders during these events, and study the interactions that produce and  </abstract>::line_number::12
<abstract> resolve bubbles. Some preliminary circuit-breaker experiments are described, in which  </abstract>::line_number::13
<abstract> bubbles are interrupted during their formation.   </abstract>::line_number::14
<abstract>  Abstract: The paper reports on the application of genetic  </abstract>::line_number::17
<abstract> algorithms, probabilistic search algorithms based on the  </abstract>::line_number::18
<abstract> model of organic evolution, to NP-complete combinatorial  </abstract>::line_number::19
<abstract> optimization problems. In particular, the subset sum, maximum cut, and minimum tardy task problems are considered.  </abstract>::line_number::20
<abstract> Except for the fitness function, no problem-specific changes  </abstract>::line_number::21
<abstract> of the genetic algorithm are required in order to achieve results of high quality even for the problem instances of size  </abstract>::line_number::22
<abstract> 100 used in the paper. For constrained problems, such as the  </abstract>::line_number::23
<abstract> subset sum and the minimum tardy task, the constraints are  </abstract>::line_number::24
<abstract> taken into account by incorporating a graded penalty term  </abstract>::line_number::25
<abstract> into the fitness function. Even for large instances of these  </abstract>::line_number::26
<abstract> highly multimodal optimization problems, an iterated application of the genetic algorithm is observed to find the global  </abstract>::line_number::27
<abstract> optimum within a number of runs. As the genetic algorithm  </abstract>::line_number::28
<abstract> samples only a tiny fraction of the search space, these results  </abstract>::line_number::29
<abstract> are quite encouraging.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Current graphic hardware have helped to develop scientific visualization tools,  </abstract>::line_number::5
<abstract> but this progress has not level with the magnitude of data genereted in some areas needing to be visualized. Techniques to navigate data have been developed,  </abstract>::line_number::6
<abstract> including new hardware and algorithms to improve the rendering speed and quality.  </abstract>::line_number::7
<abstract> This paper will describe the issues of navigation, current display and interaction  </abstract>::line_number::8
<abstract> technology, and algorithms. At the end a set of problems yet to be solved will be  </abstract>::line_number::9
<abstract> discussed   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The concept of the global information infrastructure and specifically that of the World  </abstract>::line_number::8
<abstract> Wide Web (WWW) has led to users accessing data of different media including images  </abstract>::line_number::9
<abstract> and video data over a wide area network. These data objects have sizes the order of  </abstract>::line_number::10
<abstract> megabytes and communication time is very large. The data size can be reduced without  </abstract>::line_number::11
<abstract> losing information by applying loss-inducing techniques and this will lead to reduction in  </abstract>::line_number::12
<abstract> communication time. Several loss-inducing techniques have been developed and each image  </abstract>::line_number::13
<abstract> is treated differently by each technique. In some cases an acceptable quality of the image  </abstract>::line_number::14
<abstract> is obtained and in some cases it is not. In this paper we develop a color-based technique  </abstract>::line_number::15
<abstract> to quantify the data loss when a loss-inducing technique is applied to an image. This will  </abstract>::line_number::16
<abstract> result in estimating whether the resulting image is indistinguishable from the original with  </abstract>::line_number::17
<abstract> respect to the human eye. We illustrate its use to classify images according to the loss they  </abstract>::line_number::18
<abstract> can tolerate. This avoids redundant communication of a high quality image when a lower  </abstract>::line_number::19
<abstract> quality image can satisfy the application resulting in the conservation and better usage  </abstract>::line_number::20
<abstract> of network resources. We present the technique, the communication time saved, and an  </abstract>::line_number::21
<abstract> experimental evaluation to prove the validity of the technique.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper presents an adaptive protocol for packet-level forward error-correction in dynamic networks. The objective is to facilitate best-effort real-time applications whose timing  </abstract>::line_number::9
<abstract> constraints rule out the use of retransmission-based ARQ schemes. The degree of redundancy  </abstract>::line_number::10
<abstract> is adjusted as a function of network state, decreasing when the network is well-behaved and  </abstract>::line_number::11
<abstract> increasing when it is not. The control problem is nontrivial due to the fact that increased redundancy, beyond a certain level, backfires resulting in self-induced congestion which impedes  </abstract>::line_number::12
<abstract> the timely recovery of information at the receiver.  </abstract>::line_number::13
<abstract> In the first part of the paper, we present a comprehensive analysis of the control problem  </abstract>::line_number::14
<abstract> associated with dynamic forward error-correction, concentrating on a particular protocol called  </abstract>::line_number::15
<abstract> Adaptive Forward Error-Correction (AFEC). We show that instabilities can arise from two  </abstract>::line_number::16
<abstract> distinct sources|desired operating point location and network delay|and we give solutions to  </abstract>::line_number::17
<abstract> handle them. The first causal factor is intimately tied to optimality, making its achievement  </abstract>::line_number::18
<abstract> potentially perilous in the context of QoS-greedy applications.  </abstract>::line_number::19
<abstract> The second part of the paper presents simulation results that confirm the qualitative dynamics predicted by the analysis. We quantitatively estimate the redundancy-recovery rate function  </abstract>::line_number::20
<abstract> which relates redundancy to the quality of service rendered at the receiver. We show under what  </abstract>::line_number::21
<abstract> conditions the curve's shape is unimodal and to what degree. We compare the performance of  </abstract>::line_number::22
<abstract> AFEC against a static FEC protocol in which the redundancy factor is fixed. We show that  </abstract>::line_number::23
<abstract> AFEC exhibits superior performance when the network is subject to structural changes that  </abstract>::line_number::24
<abstract> persist for nonnegligible durations. Under short-range dependent traffic conditions, AFEC is  </abstract>::line_number::25
<abstract> able to closely match the performance of optimum static FEC but not exceed it.   </abstract>::line_number::26
<abstract>  1. ABSTRACT  </abstract>::line_number::11
<abstract> Domain specific Problem Solving Environments (PSEs) are the key new ingredients that will aid in the widespread use of Computational Science & Engineering  </abstract>::line_number::12
<abstract> (CS&E) systems. Each PSE consists of a well defined library that supports the  </abstract>::line_number::13
<abstract> numerical and symbolic solution of certain mathematical model(s) characterizing a  </abstract>::line_number::14
<abstract> specific discipline, together with an easy to use software environment. This environment should ideally interact with the user in a language "natural" to the associated  </abstract>::line_number::15
<abstract> discipline, and provide a high level abstraction of the underlying, computationally  </abstract>::line_number::16
<abstract> complex, model. However, it appears that almost all extant PSEs assume that  </abstract>::line_number::17
<abstract> the user is familiar with the specific functionality/applicability of the PSE. Their  </abstract>::line_number::18
<abstract> primary design objective is to support some form of high level programming with  </abstract>::line_number::19
<abstract> predefined state-of-the-art algorithmic infrastructure. As the functionality of these  </abstract>::line_number::20
<abstract> systems increases, the user is expected to make complex decisions in the parametric space of the algorithmic infrastructure supported by the PSE. In this paper  </abstract>::line_number::21
<abstract> we describe a knowledge based system, PYTHIA, to automate this decision making process and aid in providing a high level abstraction to the user. Specifically,  </abstract>::line_number::22
<abstract> PYTHIA addresses the problem of (parameter, algorithm) pair selection within a  </abstract>::line_number::23
<abstract> scientific computing domain assuming some minimum user specified computational  </abstract>::line_number::24
<abstract> objectives and some characteristics of the given problem. PYTHIA's framework  </abstract>::line_number::25
<abstract> and methodology is general and applicable to any class of scientific problems and   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In the approximate pattern matching problem, the text area to be searched  </abstract>::line_number::6
<abstract> for an occurrence of a pattern can be pruned by applying a filtration condition. A q-gram based filtration condition defines potential text areas in terms  </abstract>::line_number::7
<abstract> of pattern q-grams, i.e., strings of length q. A text area will be checked by  </abstract>::line_number::8
<abstract> an accurate method only if the set of the q-grams in the text area satisfies a  </abstract>::line_number::9
<abstract> certain condition. One hopes that the filtration limits the number of checks  </abstract>::line_number::10
<abstract> to a minimum, thus making the algorithm quite efficient. However, computer experiments show that the filtration method works fine for cases when  </abstract>::line_number::11
<abstract> the allowed error level k is relatively small compared to the pattern length,  </abstract>::line_number::12
<abstract> but loses its efficiency quite sharply with an increasing k. This is a phase  </abstract>::line_number::13
<abstract> transition phenomenon that is quite often observed in nature. In this paper,  </abstract>::line_number::14
<abstract> we present a theoretical explanation for this phenomenon which will excuse  </abstract>::line_number::15
<abstract> us to introduce advanced mathematical analysis based on certain languages,  </abstract>::line_number::16
<abstract> correlation polynomials, generating functions and complex analysis. It is our  </abstract>::line_number::17
<abstract> view that nothing can be more exciting and rewarding than finding a theoretical justification for an abrupt manifestation of nature.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::7
<abstract> As databases increasingly integrate non-textual information  </abstract>::line_number::8
<abstract> it is becoming necessary to support efficient similarity searching in addition to range searching. Recently, declustering  </abstract>::line_number::9
<abstract> techniques have been proposed for improving the performance of similarity searches through parallel I/O. In this  </abstract>::line_number::10
<abstract> paper, we propose a new scheme which provides good declus-tering for similarity searching. In particular, it does global  </abstract>::line_number::11
<abstract> declustering as opposed to local declustering, exploits the  </abstract>::line_number::12
<abstract> availability of extra disks and does not limit the partitioning of the data space. Our technique is based upon the  </abstract>::line_number::13
<abstract> Cyclic declustering schemes which were developed for range  </abstract>::line_number::14
<abstract> and partial match queries. We establish, in general, that  </abstract>::line_number::15
<abstract> Cyclic declustering techniques outperform previously proposed techniques.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::4
<abstract> A sparse QR-factorization algorithm SPARQR for coarse-grained parallel  </abstract>::line_number::5
<abstract> computations is described. The coefficient matrix, which is assumed to be  </abstract>::line_number::6
<abstract> general sparse, is reordered in an attempt to bring as many zero elements in  </abstract>::line_number::7
<abstract> the lower left corner as possible. The reordered matrix is then partitioned into  </abstract>::line_number::8
<abstract> block rows, and Givens plane rotations are applied in each block-row. These are  </abstract>::line_number::9
<abstract> independent tasks and can be done in parallel. Row and column permutations  </abstract>::line_number::10
<abstract> are carried out within the diagonal blocks in an attempt to preserve better the  </abstract>::line_number::11
<abstract> sparsity of the matrix.  </abstract>::line_number::12
<abstract> The algorithm can be used for solving least squares problems either directly  </abstract>::line_number::13
<abstract> or combined with an iterative method (preconditioned conjugate gradients are  </abstract>::line_number::14
<abstract> used). Small non-zero elements can optionally be dropped in the latter case.  </abstract>::line_number::15
<abstract> This leads to a better preservation of the sparsity and, therefore, to a faster  </abstract>::line_number::16
<abstract> factorization. The price which has to be paid is some loss of accuracy. The  </abstract>::line_number::17
<abstract> iterative method is used to regain the accuracy lost during the factorization.  </abstract>::line_number::18
<abstract> Numerical results from several experiments with matrices from the well-known Harwell-Boeing collection as well as with some larger sparse matrices are  </abstract>::line_number::19
<abstract> presented in this work. An SGI Power Challenge computer with 16 processors  </abstract>::line_number::20
<abstract> has been used in the experiments.   </abstract>::line_number::21
<abstract>  Abstract. This paper introduces a novel method for constructing finite-state machines recognising context free (CF)  </abstract>::line_number::6
<abstract> grammars. The method utilizes the idea of a path through  </abstract>::line_number::7
<abstract> a finite-state machine (FSM). Certain paths form the basis  </abstract>::line_number::8
<abstract> for an unfolding process which is applied to the LR(0) characteristic finite-state machine (CFSM) corresponding to the  </abstract>::line_number::9
<abstract> grammar. The next section discusses the approximation algorithm, including this unfolding process, in more detail, and  </abstract>::line_number::10
<abstract> section 3 introduces the concept of an unfolding criterion.  </abstract>::line_number::11
<abstract> Section 4 proves the soundness of the approximation method,  </abstract>::line_number::12
<abstract> and its exactness to arbitrary, fixed recursive depths. Section  </abstract>::line_number::13
<abstract> 5 presents initial computational figures resulting from an implementation of the method. A variation of the method that  </abstract>::line_number::14
<abstract> is more computationally feasible is discussed. The final section compares the method with existing research on finite-state approximation of CF grammars, and presents preliminary conclusions regarding the method.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::9
<abstract> In this paper, we evaluate the use of software distributed  </abstract>::line_number::10
<abstract> shared memory (DSM) on a message passing machine as  </abstract>::line_number::11
<abstract> the target for a parallelizing compiler. We compare this approach to compiler-generated message passing, hand-coded  </abstract>::line_number::12
<abstract> software DSM, and hand-coded message passing. For this  </abstract>::line_number::13
<abstract> comparison, we use six applications: four that are regular  </abstract>::line_number::14
<abstract> and two that are irregular.  </abstract>::line_number::15
<abstract> Our results are gathered on an 8-node IBM SP/2 using the TreadMarks software DSM system. We use the APR  </abstract>::line_number::16
<abstract> shared-memory (SPF) compiler to generate the shared memory programs, and the APR XHPF compiler to generate message passing programs. The hand-coded message passing  </abstract>::line_number::17
<abstract> programs run with the IBM PVMe optimized message passing library. On the regular programs, both the compiler-generated and the hand-coded message passing outperform  </abstract>::line_number::18
<abstract> the SPF/TreadMarks combination: the compiler-generated  </abstract>::line_number::19
<abstract> message passing by 5.5% to 40%, and the hand-coded  </abstract>::line_number::20
<abstract> message passing by 7.5% to 49%. On the irregular programs, the SPF/TreadMarks combination outperforms the  </abstract>::line_number::21
<abstract> compiler-generated message passing by 38% and 89%, and  </abstract>::line_number::22
<abstract> only slightly underperforms the hand-coded message passing, differing by 4.4% and 16%. We also identify the factors  </abstract>::line_number::23
<abstract> that account for the performance differences, estimate their  </abstract>::line_number::24
<abstract> relative importance, and describe methods to improve the  </abstract>::line_number::25
<abstract> performance.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::10
<abstract> The Carlsberg prototype is a distributed operating system designed to provide efficient support for distributed-parallel applications on a cluster of high-performance workstations. A unique feature of Carlsberg is the integration of  </abstract>::line_number::11
<abstract> coherent shared memory, multithreading, and message passing in one system.  </abstract>::line_number::12
<abstract> In this paper we discuss the motivation for the Carlsberg system and we present  </abstract>::line_number::13
<abstract> aspects of its design.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::3
<abstract> We present an empirical study of the accuracy-cost tradeoffs of Anderson's method.  </abstract>::line_number::4
<abstract> The various parameters that control the degree of approximation of the computational  </abstract>::line_number::5
<abstract> elements and the separateness of interacting computational elements govern both the  </abstract>::line_number::6
<abstract> arithmetic complexity and the accuracy of the method. Our experiment shows that for  </abstract>::line_number::7
<abstract> a given error requirement, using a near-field containing only nearest neighbor boxes  </abstract>::line_number::8
<abstract> and a hierarchy depth that minimizes the number of arithmetic operations minimizes  </abstract>::line_number::9
<abstract> the total number of arithmetic operations.   </abstract>::line_number::10
<abstract>  Abstract: An ongoing research project involves the design and evaluation of a software system  </abstract>::line_number::14
<abstract> for simulating parallel computers. A major goal in the development of this system was to avoid the  </abstract>::line_number::15
<abstract> high overhead associated with the conventional instruction-level simulation of sequential  </abstract>::line_number::16
<abstract> computers, but to retain the accuracy of that technique derived from its use of the execution of real  </abstract>::line_number::17
<abstract> programs. The resulting system is program-driven, but the overhead is significantly reduced by  </abstract>::line_number::18
<abstract> profiling the program to get timing estimates for its basic blocks, which are then used at run time to  </abstract>::line_number::19
<abstract> generate process execution times dynamically while avoiding a detailed emulation of each  </abstract>::line_number::20
<abstract> instruction's execution. A number of experiments dealing with message-passing computer  </abstract>::line_number::21
<abstract> systems have been performed in order to determine the level of accuracy that can be expected from  </abstract>::line_number::22
<abstract> its performance predictions and to measure its overhead.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::4
<abstract> In this paper we describe a formal framework for the problem of mining association rules. The theoretical foundation is based on the field of formal concept analysis. A concept is composed of closed subsets of attributes (itemsets)  </abstract>::line_number::5
<abstract> and objects (transactions). We show that all frequent itemsets are uniquely determined by the frequent concepts. We  </abstract>::line_number::6
<abstract> further show how this lattice-theoretic framework can be used to find a small rule generating set, from which one can  </abstract>::line_number::7
<abstract> infer all other association rules.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We develop a mathematical model for the coating of ceramic fibers by chemical vapor  </abstract>::line_number::7
<abstract> deposition (CVD) in cylindrical hot- or cold-walled reactors. The model couples the  </abstract>::line_number::8
<abstract> Navier-Stokes equations for the mixture of a carrier gas and precursor species, an energy  </abstract>::line_number::9
<abstract> equation for the gaseous mixture, a convection-diffusion system for the reacting precursor  </abstract>::line_number::10
<abstract> species, a fiber coating model, and a fiber heat conduction equation. The system is heated  </abstract>::line_number::11
<abstract> by a combination of conduction, convection, and radiation.  </abstract>::line_number::12
<abstract> The partial differential system resulting from this model is solved by adaptive finite element software using automatic mesh refinement and coarsening on a quadtree-structured  </abstract>::line_number::13
<abstract> mesh. The results of parameter studies indicate the effectiveness of using adaptive solution techniques with CVD applications and also suggest some guidance for improving  </abstract>::line_number::14
<abstract> the process.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::9
<abstract> An automated design methodology incorporating industry-standard Navier-Stokes  </abstract>::line_number::10
<abstract> codes and a gradient-based optimizer has been developed. This system is used to redesign the well-known NASA P2 and P8 hypersonic inlets. First, the Navier-Stokes  </abstract>::line_number::11
<abstract> simulations of the original P2 and P8 inlet designs are validated using numerical convergence studies and comparison with wind-tunnel experimental data for the original  </abstract>::line_number::12
<abstract> inlets published by NASA in the early 1970s. Second, the P2 and P8 inlets are redesigned with the objective of canceling the cowl shock (and, in the case of the P8  </abstract>::line_number::13
<abstract> inlet, the additional cowl-generated compression) at the centerbody by appropriate  </abstract>::line_number::14
<abstract> contouring of the centerbody boundary. The original inlets were intended to achieve  </abstract>::line_number::15
<abstract> these same objectives, but detailed experimental measurements indicated that a substantial reflected shock system was present. The choice of the objective function, which  </abstract>::line_number::16
<abstract> is used to drive the optimization, has a significant impact on the final design. Several  </abstract>::line_number::17
<abstract> different formulations for the objective function have been employed, and improvements of 60% to 90% in the objective function have been achieved. This automated  </abstract>::line_number::18
<abstract> design system represents one of the first successful combinations of numerical optimization methods with Reynolds-averaged Navier-Stokes fluid dynamics simulation for high  </abstract>::line_number::19
<abstract> speed inlets, and demonstrates a new area in which High Performance Computing may  </abstract>::line_number::20
<abstract> have considerable impact on problems of military and industrial significance.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> People display regularities in almost everything they do. This  </abstract>::line_number::8
<abstract> paper proposes characteristics of an idealized algorithm that,  </abstract>::line_number::9
<abstract> when applied to sequences of user actions, would allow a user  </abstract>::line_number::10
<abstract> interface to adapt over time to an individual's pattern of use.  </abstract>::line_number::11
<abstract> We describe a simple predictive method with these characteristics and show its predictive accuracy on a large dataset of  </abstract>::line_number::12
<abstract> UNIX commands to be at least as good as others that have  </abstract>::line_number::13
<abstract> been considered, while using fewer computational and memory resources.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Massive rule induction has recently emerged as one of the  </abstract>::line_number::7
<abstract> powerful data mining techniques. The problem is known to  </abstract>::line_number::8
<abstract> be exponential in the size of the attributes, and given its ever  </abstract>::line_number::9
<abstract> increasing use, can greatly benefit from parallelization.  </abstract>::line_number::10
<abstract> In this paper, we study cost-effective approaches to paral-lelize rule generation algorithms. In particular, we consider  </abstract>::line_number::11
<abstract> the propositional rule generation algorithm of the Discovery  </abstract>::line_number::12
<abstract> Board system, and present our design and implementation of  </abstract>::line_number::13
<abstract> a parallel algorithm for the same task. We then present some  </abstract>::line_number::14
<abstract> early performance results of our parallelization scheme on  </abstract>::line_number::15
<abstract> hardware and software distributed shared memory multiprocessors.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Models of physical systems can differ according to  </abstract>::line_number::7
<abstract> computational cost, accuracy and precision, among  </abstract>::line_number::8
<abstract> other things. Depending on the problem solving  </abstract>::line_number::9
<abstract> task at hand, different models will be appropriate. Several investigators have recently developed  </abstract>::line_number::10
<abstract> methods of automatically selecting among multiple models of physical systems. Our research is  </abstract>::line_number::11
<abstract> novel in that we are developing model selection  </abstract>::line_number::12
<abstract> techniques specifically suited to computer-aided de  </abstract>::line_number::13
<abstract> sign. Our approach is based on the idea that artifact performance models for computer-aided design  </abstract>::line_number::14
<abstract> should be chosen in light of the design decisions  </abstract>::line_number::15
<abstract> they are required to support. We have developed  </abstract>::line_number::16
<abstract> a technique called "Gradient Magnitude Model Selection" (GMMS), which embodies this principle.  </abstract>::line_number::17
<abstract> GMMS operates in the context of a hillclimbing  </abstract>::line_number::18
<abstract> search process. It selects the simplest model that  </abstract>::line_number::19
<abstract> meets the needs of the hillclimbing algorithm in  </abstract>::line_number::20
<abstract> which it operates. We are using the domain of sailing yacht design as a testbed for this research. We  </abstract>::line_number::21
<abstract> have implemented GMMS and used it in hillclimb-ing search to decide between a computationally expensive potential-flow program and an algebraic  </abstract>::line_number::22
<abstract> approximation to analyze the performance of sailing yachts. Experimental tests show that GMMS  </abstract>::line_number::23
<abstract> makes the design process faster than it would be if  </abstract>::line_number::24
<abstract> the most expensive model were used for all design  </abstract>::line_number::25
<abstract> evaluations. GMMS achieves this performance improvement with little or no sacrifice in the quality  </abstract>::line_number::26
<abstract> of the resulting design.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::8
<abstract> There is an emerging consensus that an explicit architectural model  </abstract>::line_number::9
<abstract> would be invaluable for large evolving software systems, providing them  </abstract>::line_number::10
<abstract> with a framework within which such a system can be reasoned about and  </abstract>::line_number::11
<abstract> maintained. But the great promise of architectural models has not been  </abstract>::line_number::12
<abstract> fulfilled so far, due to a gap between the model and the system it purports  </abstract>::line_number::13
<abstract> to describe. It is our contention that this gap is best bridged if the model  </abstract>::line_number::14
<abstract> is not just stated, but is enforced.  </abstract>::line_number::15
<abstract> This gives rise to a concept enforced architectural model |or, a law |  </abstract>::line_number::16
<abstract> which is explored in this paper. We argue that this model has two major beneficial consequences: First, by bridging the above mentioned gap  </abstract>::line_number::17
<abstract> between an architectural model and the actual system, an enforced architectural model provides a truly reliable framework within which a system  </abstract>::line_number::18
<abstract> can be reasoned about and maintained. Second, our model provides software developers with a carefully circumscribed flexibility in molding the  </abstract>::line_number::19
<abstract> law of a project, during its evolutionary lifetime|while maintaining certain architectural principles as invariant of evolution.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The Law of Demeter [4] is accepted as a useful design principle that  </abstract>::line_number::10
<abstract> promotes tightly encapsulated classes and reduced coupling. Principles  </abstract>::line_number::11
<abstract> like this are routinely adopted in real-life projects, however neither the  </abstract>::line_number::12
<abstract> programming languages nor the existing environments provide enough  </abstract>::line_number::13
<abstract> support for effective realization of these principles. It is our thesis  </abstract>::line_number::14
<abstract> that broad structural principles should be formally specified, strictly  </abstract>::line_number::15
<abstract> enforced, and relaxed whenever relaxation is in order. In this paper  </abstract>::line_number::16
<abstract> we show how this can be done under our darwin-E environment using,  </abstract>::line_number::17
<abstract> the Law of Demeter as an illustration.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::5
<abstract> This paper describes DIDO, a system we have  </abstract>::line_number::6
<abstract> developed to carry out exploratory learning of  </abstract>::line_number::7
<abstract> unfamiliar domains without assistance from an  </abstract>::line_number::8
<abstract> external teacher. The program incorporates novel  </abstract>::line_number::9
<abstract> approaches to experience generation and representation  </abstract>::line_number::10
<abstract> generation. The experience generator uses a heuristic  </abstract>::line_number::11
<abstract> based on Shannon's uncertainty function to find  </abstract>::line_number::12
<abstract> informative examples. The representation generator  </abstract>::line_number::13
<abstract> makes conjectures on the basis of small amounts of  </abstract>::line_number::14
<abstract> evidence and retracts them if they prove to be wrong  </abstract>::line_number::15
<abstract> or useless. A number of experiments are described  </abstract>::line_number::16
<abstract> which demonstrate that the system can distribute its  </abstract>::line_number::17
<abstract> learning resources to steadily acquire a good  </abstract>::line_number::18
<abstract> representation of the whole of a domain, and that the  </abstract>::line_number::19
<abstract> system can readily acquire both disjunctive and  </abstract>::line_number::20
<abstract> conjunctive concepts even in the presence of noise.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Many important scientific problems can be formulated as systems of ordinary differential equations with two-point boundary value constraints (BVODE). Multiple shooting  </abstract>::line_number::5
<abstract> is one of the most widely used numerical techniques for solving BVODE problems.  </abstract>::line_number::6
<abstract> In this work, we present a new distributed parallel numerical algorithm for BVODEs  </abstract>::line_number::7
<abstract> which is based on multiple shooting. We investigate the numerical stability of this  </abstract>::line_number::8
<abstract> new distributed algorithm and identify difficulties that can arise. We propose a new  </abstract>::line_number::9
<abstract> parallel iterative refinement scheme to cope with some specific numerical difficulties  </abstract>::line_number::10
<abstract> identified in our investigation. Computational experience is presented to demonstrate  </abstract>::line_number::11
<abstract> the potential effectiveness of our approach.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::13
<abstract> We present new strategies for "probably approximately correct" (pac) learning that use  </abstract>::line_number::14
<abstract> fewer training examples than previous approaches. The idea is to observe training examples one-at-a-time and decide "on-line" when to  </abstract>::line_number::15
<abstract> return a hypothesis, rather than collect a large  </abstract>::line_number::16
<abstract> fixed-size training sample. This yields sequential learning procedures that pac-learn by observing a small random number of examples.  </abstract>::line_number::17
<abstract> We provide theoretical bounds on the expected  </abstract>::line_number::18
<abstract> training sample size of our procedure | but establish its efficiency primarily by a series of experiments which show sequential learning actually uses many times fewer training examples in  </abstract>::line_number::19
<abstract> practice. These results demonstrate that pac-learning can be far more efficiently achieved in  </abstract>::line_number::20
<abstract> practice than previously thought.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Real-valued random hidden variables can be useful for modelling  </abstract>::line_number::6
<abstract> latent structure that explains correlations among observed variables. I propose a simple unit that adds zero-mean Gaussian noise  </abstract>::line_number::7
<abstract> to its input before passing it through a sigmoidal squashing function. Such units can produce a variety of useful behaviors, ranging  </abstract>::line_number::8
<abstract> from deterministic to binary stochastic to continuous stochastic. I  </abstract>::line_number::9
<abstract> show how "slice sampling" (Neal 1996) can be used for inference  </abstract>::line_number::10
<abstract> and learning in top-down networks of these units and demonstrate  </abstract>::line_number::11
<abstract> learning on two simple problems.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::11
<abstract> While the task of answering queries from an  </abstract>::line_number::12
<abstract> arbitrary propositional theory is intractable in  </abstract>::line_number::13
<abstract> general, it can typically be performed efficiently  </abstract>::line_number::14
<abstract> if the theory is Horn. This suggests that it  </abstract>::line_number::15
<abstract> may be more efficient to answer queries using a "Horn approximation"; i.e., a horn theory that is semantically similar to the original  </abstract>::line_number::16
<abstract> theory. The utility of any such approximation  </abstract>::line_number::17
<abstract> depends on how often it produces answers to  </abstract>::line_number::18
<abstract> the queries that the system actually encounters;  </abstract>::line_number::19
<abstract> we therefore seek an approximation whose expected "coverage" is maximal. Unfortunately,  </abstract>::line_number::20
<abstract> there are several obstacles to achieving this goal  </abstract>::line_number::21
<abstract> in practice: (i) The optimal approximation depends on the query distribution, which is typically not known a priori; (ii) identifying the optimal approximation is intractable, even given  </abstract>::line_number::22
<abstract> the query distribution; and (iii) the optimal approximation might be too large to guarantee  </abstract>::line_number::23
<abstract> tractable inference. This paper presents an approach that overcomes (or side-steps) each of  </abstract>::line_number::24
<abstract> these obstacles. We define a learning process,  </abstract>::line_number::25
<abstract> AdComp, that uses observed queries to estimate the query distribution "online", and then  </abstract>::line_number::26
<abstract> uses these estimates to hill-climb, efficiently,  </abstract>::line_number::27
<abstract> in the space of size-bounded Horn approximations, until reaching one that is, with provably  </abstract>::line_number::28
<abstract> high probability, effectively at a local optimum.   </abstract>::line_number::29
<abstract>  Abstract. We present the first polynomial algorithm for recognizing tree powers. A graph G  </abstract>::line_number::6
<abstract> is a tree power if there is a tree T and a positive integer k such that T k ~ = G where x and are  </abstract>::line_number::7
<abstract> adjacent in T k if and only if d T (x; ) k. We also show that a natural extension of tree power  </abstract>::line_number::8
<abstract> recognition is NP-complete, namely, given a graph G and a positive integer r, determine if  </abstract>::line_number::9
<abstract> there is a tree power within r edges of G.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Coding segments are those sub-segments of the chromosome which contribute either positively or  </abstract>::line_number::8
<abstract> negatively to the fitness evaluation of the chromosome. We extract coding segments from chromosomes  </abstract>::line_number::9
<abstract> and we investigate the sharing of coding segments both inside and outside of the chromosome. We  </abstract>::line_number::10
<abstract> find duplication of coding segments inside the chromosomes provides a back-up mechanism for the  </abstract>::line_number::11
<abstract> search heuristics. We further find local search in a collective memory of coding segments outside of the  </abstract>::line_number::12
<abstract> chromosome, collective adaptation, enables the search heuristic to represent partial solutions which are  </abstract>::line_number::13
<abstract> larger than realistic chromosomes lengths and to express the solution outside of the chromosome.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::12
<abstract> To navigate effectively, an autonomous agent must be  </abstract>::line_number::13
<abstract> able to quickly and accurately determine its current  </abstract>::line_number::14
<abstract> location. Given an initial estimate of its position (perhaps based on dead-reckoning) and an image taken of  </abstract>::line_number::15
<abstract> a known environment, our agent first attempts to locate a set of landmarks (real-world objects at known  </abstract>::line_number::16
<abstract> locations), then uses their angular separation to obtain an improved estimate of its current position. Unfortunately, some landmarks may not be visible, or  </abstract>::line_number::17
<abstract> worse, may be confused with other landmarks, resulting in both time wasted in searching for invisible landmarks, and in further errors in the agent's estimate of  </abstract>::line_number::18
<abstract> its position. To address these problems, we propose a  </abstract>::line_number::19
<abstract> method that uses previous experiences to learn a selection function that, given the set of landmarks that  </abstract>::line_number::20
<abstract> might be visible, returns the subset which can reliably  </abstract>::line_number::21
<abstract> be found correctly, and so provide an accurate registration of the agent's position. We use statistical techniques to prove that the learned selection function is,  </abstract>::line_number::22
<abstract> with high probability, effectively at a local optimal in  </abstract>::line_number::23
<abstract> the space of such functions. This report also presents  </abstract>::line_number::24
<abstract> empirical evidence, using real-world data, that demonstrate the effectiveness of our approach.   </abstract>::line_number::25
<abstract>  Abstract. In many concurrent programming languages, concurrent programs are difficult to extend and modify: small changes in a concurrent  </abstract>::line_number::5
<abstract> program may require re-implementations of a large number of its components. In this paper a novel concurrent program composition mechanism  </abstract>::line_number::6
<abstract> is presented in which implementations of computations and synchronizations are completely separated. Separation of implementations facilitates  </abstract>::line_number::7
<abstract> extensions and modifications of programs by allowing one to change implementations of both computations and synchronizations. The paper  </abstract>::line_number::8
<abstract> also describes a concurrent programming model and a programming lan  </abstract>::line_number::9
<abstract> guage that support the proposed approach.   </abstract>::line_number::10
<abstract>  Abstract. We propose a method for solving a model of age-dependent population diusion  </abstract>::line_number::3
<abstract> with random dispersal. This method, unlike previous methods, allows for variable time steps and  </abstract>::line_number::4
<abstract> independent age and time discretizations. We use a moving age discretization that transforms the  </abstract>::line_number::5
<abstract> problem to a system of parabolic equations. The system is then solved by backward dierences in  </abstract>::line_number::6
<abstract> time and a Galerkin approximation in space; the equations that need to be solved at each step treat  </abstract>::line_number::7
<abstract> each age group separately. A priori L 2 error estimates are obtained by an energy analysis. These  </abstract>::line_number::8
<abstract> estimates are superconvergent in the age variable. We present a postprocessing technique which  </abstract>::line_number::9
<abstract> capitalizes on the superconvergence.   </abstract>::line_number::10
<abstract>  Abstract. A new wave of data-intensive and knowledge-based applications|such as data  </abstract>::line_number::7
<abstract> mining and decision support|require the introduction of complex application-specific aggregate functions. In this paper, we propose extensions for deductive database systems to  </abstract>::line_number::8
<abstract> support these new applications. We develop constructs, formal semantics, and implementation techniques for user-defined aggregates, and describe their realization in an extended  </abstract>::line_number::9
<abstract> LDL++ system recently built at UCLA. With these extensions, the system can support online aggregation, roll-ups for data cubing, temporal aggregates for time-series, iceberg queries,  </abstract>::line_number::10
<abstract> and other recently proposed operators used in decision support and data mining procedures.  </abstract>::line_number::11
<abstract> We then discuss the application of this technology to other DBMSs, and in particular to the  </abstract>::line_number::12
<abstract> SQL3 specifications that support the notion of user-defined aggregates. We show that SQL3  </abstract>::line_number::13
<abstract> suffers from limitations that severely restrict its use in new applications; thus we propose  </abstract>::line_number::14
<abstract> simple extensions similar to those used for LDL++ to overcome such limitations.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::7
<abstract> In the design of algorithms, the greedy paradigm provides a powerful tool for solving  </abstract>::line_number::8
<abstract> efficiently classical computational problems, within the framework of procedural languages. However, expressing these algorithms within the declarative framework of logic-based languages has proved to be a difficult research challenge. In this paper, we extend the framework of Datalog-like languages to obtain simple declarative formulations  </abstract>::line_number::9
<abstract> for such problems, and propose effective implementation techniques to ensure computational complexities comparable to those of procedural formulations. These advances are  </abstract>::line_number::10
<abstract> achieved through the use of the choice construct, that has semantics reducible to that of  </abstract>::line_number::11
<abstract> programs with negation under stable model semantics. Then we extend the fixpoint-based  </abstract>::line_number::12
<abstract> semantics of choice programs with preference annotations to guide search strategies and  </abstract>::line_number::13
<abstract> simple logic-based formulations of classical greedy algorithms.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Recovery from failures is important in distributed computing. A common technique to support  </abstract>::line_number::7
<abstract> recovery is asynchronous checkpointing, coupled with optimistic message logging. These schemes have  </abstract>::line_number::8
<abstract> low overheads during failure-free operations and can provide an acceptable degree of fault-tolerance.  </abstract>::line_number::9
<abstract> Central to these protocols is the determination of a maximal consistent global state, which is recoverable.  </abstract>::line_number::10
<abstract> Message semantics is not exploited in most existing recovery protocols to determine the recoverable state.  </abstract>::line_number::11
<abstract> We propose to identify messages that are not influential in the computation through message semantics.  </abstract>::line_number::12
<abstract> These messages can be logically removed from the computation without changing its meaning or result.  </abstract>::line_number::13
<abstract> In this paper, we illustrate with examples how the removal of these messages improves the theoretical  </abstract>::line_number::14
<abstract> maximal consistent global state. Taking semantics into account, recovery protocols are then developed  </abstract>::line_number::15
<abstract> to realize the idea. The semantics in object-oriented databases is adapted to special processes acting as  </abstract>::line_number::16
<abstract> servers for further improvements. This technique can also be applied to ensure a more timely commitment  </abstract>::line_number::17
<abstract> for output in a distributed computation.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Run-time compilation techniques have been shown effective  </abstract>::line_number::7
<abstract> for automating the parallelization of loops with unstructured  </abstract>::line_number::8
<abstract> indirect data accessing patterns. However, it is still an open  </abstract>::line_number::9
<abstract> problem to efficiently parallelize sparse matrix factorizations  </abstract>::line_number::10
<abstract> commonly used in iterative numerical problems. The difficulty is that a factorization process contains irregularly-interleaved communication and computation with varying  </abstract>::line_number::11
<abstract> granularities and it is hard to obtain scalable performance  </abstract>::line_number::12
<abstract> on distributed memory machines. In this paper, we present  </abstract>::line_number::13
<abstract> an inspector/executor approach for parallelizing such applications by embodying automatic graph scheduling techniques to optimize interleaved communication and computation. We describe a run-time system called RAPID that  </abstract>::line_number::14
<abstract> provides a set of library functions for specifying irregular  </abstract>::line_number::15
<abstract> data objects and tasks that access these objects. The system  </abstract>::line_number::16
<abstract> extracts a task dependence graph from data access patterns,  </abstract>::line_number::17
<abstract> and executes tasks efficiently on a distributed memory machine. We discuss a set of optimization strategies used in  </abstract>::line_number::18
<abstract> this system and demonstrate the application of this system  </abstract>::line_number::19
<abstract> in parallelizing sparse Cholesky and LU factorizations.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We propose a general framework for computing invariant features from images. The proposed  </abstract>::line_number::9
<abstract> approach is based on a simple concept of basis expansion. It is widely applicable to many popular  </abstract>::line_number::10
<abstract> basis representations, such as wavelets [4, 5, 24, 25], short-time Fourier analysis [15, 30], and  </abstract>::line_number::11
<abstract> splines [2, 6, 33]. Exploiting formulations that use both global and local information about  </abstract>::line_number::12
<abstract> shape and color, the new approach is neither strictly global nor local. It has the advantage of  </abstract>::line_number::13
<abstract> tolerating a certain degree of occlusion (unlike global analysis) and does not require estimating  </abstract>::line_number::14
<abstract> high-order derivatives in computing invariants (unlike local analysis), whence is more robust.  </abstract>::line_number::15
<abstract> Furthermore, it enables a quasi-localized, hierarchical shape analysis which is not possible with  </abstract>::line_number::16
<abstract> other known invariant techniques. Unlike most current research on image invariants which  </abstract>::line_number::17
<abstract> concentrates on either geometry or illumination invariants, the proposed framework is very  </abstract>::line_number::18
<abstract> general and produces invariants which are insensitive to rigid motion, general affine transform,  </abstract>::line_number::19
<abstract> changes of parameterization and scene illumination, and perspective transform.   </abstract>::line_number::20
<abstract>  Abstract. Two operations commute if the result of their execution is independent of the order in which they execute. Commuting operations can be executed  </abstract>::line_number::6
<abstract> concurrently provided they execute atomically on the objects they access. Statically  </abstract>::line_number::7
<abstract> recognizing commuting operations is of great interest because they increase the amount  </abstract>::line_number::8
<abstract> of concurrency a compiler can exploit. In this document we introduce commutativity  </abstract>::line_number::9
<abstract> analysis anew technique for automatically parallelizing serial programs. We then  </abstract>::line_number::10
<abstract> conduct a feasibility study of existing scientific applications as to the existence and  </abstract>::line_number::11
<abstract> exploitability of commuting operations. We study the commuting operations present  </abstract>::line_number::12
<abstract> in one such application the Barnes-Hut hierarchical N-body algorithm. We then  </abstract>::line_number::13
<abstract> parallelize this application using knowledge of commuting operations and present performance results of the parallel code for a shared-memory multiprocessor.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper describes a set of classes designed to  </abstract>::line_number::7
<abstract> facilitate concurrent programming using the sequential object-oriented language EIFFEL. The design and  </abstract>::line_number::8
<abstract> implementation presented here is the application of a  </abstract>::line_number::9
<abstract> more general Concurrency Model we have built to introduce concurrency to sequential OOPLs. The model  </abstract>::line_number::10
<abstract> views concurrency as a well-defined, inheritable property of objects specified in the class CONCURRENCY,  </abstract>::line_number::11
<abstract> and provides a methodology using inheritance to write  </abstract>::line_number::12
<abstract> concurrent object-orient applications. Key ideas involved in the methodology are: active objects, extensibility of protocols, synchronization programming,  </abstract>::line_number::13
<abstract> data-driven synchronization with asynchronous message passing.  </abstract>::line_number::14
<abstract> The novel feature of our work is in its describing  </abstract>::line_number::15
<abstract> concurrency in the context of sequential programming  </abstract>::line_number::16
<abstract> and using a object-oriented design methodology to describe and implement it.  </abstract>::line_number::17
<abstract> We illustrate the usefulness and expressiveness of  </abstract>::line_number::18
<abstract> the concurrency mechanism by presenting examples  </abstract>::line_number::19
<abstract> and analyzing them. The ability to express powerful  </abstract>::line_number::20
<abstract> synchronization constraints as reusable software components emerges as a strong point of our implementation.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The Scintilla project at UCSB studies SCI-based cluster  </abstract>::line_number::8
<abstract> computing. The Scalable Coherent Interface (SCI) is a  </abstract>::line_number::9
<abstract> recent communication standard for cluster interconnects.  </abstract>::line_number::10
<abstract> We focus on non-coherent SCI, using our cluster setup  </abstract>::line_number::11
<abstract> of SBus-based and PCI-based workstations connected via  </abstract>::line_number::12
<abstract> Dolphin SCI adapters. Our motivation for choosing SCI as  </abstract>::line_number::13
<abstract> network fabric is the very low latency and high bandwidth.  </abstract>::line_number::14
<abstract> We study how to map a variety of programming models efficiently onto the SCI hardware, focusing on message  </abstract>::line_number::15
<abstract> passing and global address space support, implementing  </abstract>::line_number::16
<abstract> Active Messages and Split-C. We present implementation  </abstract>::line_number::17
<abstract> trade-offs, present performance measurements and compare the PCI and SBus adapters.  </abstract>::line_number::18
<abstract> We found that the user-level load/store programming interface of SCI is very convenient to use, achieves low latencies, and is fully virtualized, simultaneously supporting  </abstract>::line_number::19
<abstract> multiple parallel programs and communication channels.  </abstract>::line_number::20
<abstract> On the other hand, neither of the programming models  </abstract>::line_number::21
<abstract> studied maps directly to SCI. Issues such as notification,  </abstract>::line_number::22
<abstract> atomic operations, and virtual address space limitations  </abstract>::line_number::23
<abstract> represent major implementation challenges, which we address with a combination of compiler and run-time support. Overall, we found the SCI network a good substrate  </abstract>::line_number::24
<abstract> for high-performance cluster computing.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Automatic scheduling for directed acyclic graphs (DAG) and its applications for coarse-grained irregular problems such as large n-body simulation have been studied in the literature.  </abstract>::line_number::8
<abstract> However solving irregular problems with mixed granularities such as sparse matrix factorization  </abstract>::line_number::9
<abstract> is challenging since it requires efficient run-time support to execute a DAG schedule. In this  </abstract>::line_number::10
<abstract> paper, we investigate run-time optimization techniques for executing general asynchronous  </abstract>::line_number::11
<abstract> DAG schedules on distributed memory machines. Our solution tightly integrates the run-time  </abstract>::line_number::12
<abstract> scheme with a fast communication mechanism to eliminate unnecessary overhead in message  </abstract>::line_number::13
<abstract> buffering and copying. We discuss a consistency model incorporating the above optimizations,  </abstract>::line_number::14
<abstract> and taking advantage of task dependence properties to ensure the correctness of execution.  </abstract>::line_number::15
<abstract> We demonstrate the applications of this scheme in sparse factorizations and triangular solver  </abstract>::line_number::16
<abstract> for which actual speedups are hard to obtain. Our experiments on Meiko CS-2 show that the  </abstract>::line_number::17
<abstract> automatically scheduled code has achieved scalable performance for these problems and the  </abstract>::line_number::18
<abstract> run-time overhead is small compared to the total execution time.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> The paper provides an organisation of order-sorted equational logic as  </abstract>::line_number::6
<abstract> an Institution.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We present a digital signature scheme which is based on the existence of any trapdoor  </abstract>::line_number::6
<abstract> permutation. Our scheme is secure in the strongest possible natural sense: namely, it is secure  </abstract>::line_number::7
<abstract> against existential forgery under adaptive chosen message attack.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::23
<abstract> Papadimitriou introduced several classes of NP search problems based on combinatorial principles which guarantee the  </abstract>::line_number::24
<abstract> existence of solutions to the problems. Many interesting  </abstract>::line_number::25
<abstract> search problems not known to be solvable in polynomial  </abstract>::line_number::26
<abstract> time are contained in these classes, and a number of them  </abstract>::line_number::27
<abstract> are complete problems. We consider the question of the relative complexity of these search problem classes. We prove  </abstract>::line_number::28
<abstract> several separations which show that in a generic relativized  </abstract>::line_number::29
<abstract> world, the search classes are distinct and there is a standard  </abstract>::line_number::30
<abstract> search problem in each of them that is not computation-ally equivalent to any decision problem. (Naturally, absolute separations would imply that P 6= NP.) Our separation  </abstract>::line_number::31
<abstract> proofs have interesting combinatorial content and go to the  </abstract>::line_number::32
<abstract> heart of the combinatorial principles on which the classes are  </abstract>::line_number::33
<abstract> based. We derive one result via new lower bounds on the  </abstract>::line_number::34
<abstract> degrees of polynomials asserted to exist by Hilbert's Null-stellensatz over finite fields.   </abstract>::line_number::35
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Fast networks have made it possible to coordinate distributed heterogeneous CPU,  </abstract>::line_number::8
<abstract> memory and storage resources to provide a powerful platform for executing high-performance applications. However, the performance of parallel applications on such  </abstract>::line_number::9
<abstract> systems is highly dependent on the mapping of application tasks to machines. In this  </abstract>::line_number::10
<abstract> paper, we propose a mapping strategy for applications formed by multiple tasks targeted  </abstract>::line_number::11
<abstract> to heterogeneous platforms. We first define a mapping model, the match-tree, which  </abstract>::line_number::12
<abstract> reects the data movement and conversion costs of distributed algorithms and allows for  </abstract>::line_number::13
<abstract> alternative implementations of individual tasks on different machines. We then define the  </abstract>::line_number::14
<abstract> find-mapping and split-partition algorithms, based on the match-tree model, to  </abstract>::line_number::15
<abstract> determine the best allocation of tasks to resources in heterogeneous systems. We  </abstract>::line_number::16
<abstract> illustrate the use of these algorithms with a sample distributed application.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::10
<abstract> In a previous paper the authors showed that almost all labelled  </abstract>::line_number::11
<abstract> cubic graphs are hamiltonian. In the present paper, this result is  </abstract>::line_number::12
<abstract> used to show that almost all r-regular graphs are hamiltonian for any  </abstract>::line_number::13
<abstract> fixed r 3, by an analysis of the distribution of 1-factors in random  </abstract>::line_number::14
<abstract> regular graphs. Moreover, almost all such graphs are r-edge-colourable  </abstract>::line_number::15
<abstract> if they have an even number of vertices. Similarly, almost all r-regular  </abstract>::line_number::16
<abstract> bipartite graphs are hamiltonian and r-edge-colourable for fixed r 3.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::29
<abstract> Execution speed of programs on modern computer architectures is sensitive, by a factor of two or more, to the order in which instructions  </abstract>::line_number::30
<abstract> are presented to the processor. To realize potential execution efficiency,  </abstract>::line_number::31
<abstract> it is now customary for an optimizing compiler to employ a heuristic  </abstract>::line_number::32
<abstract> algorithm for instruction scheduling. These algorithms are painstakingly  </abstract>::line_number::33
<abstract> hand-crafted, which is expenseive and time-consuming. We show how  </abstract>::line_number::34
<abstract> to cast the instruction scheduling problem as a learning task, so that one  </abstract>::line_number::35
<abstract> obtains the heuristic scheduling algorithm automatically. Our focus is the  </abstract>::line_number::36
<abstract> narrower problem of scheduling straight-line code, also known as a basic  </abstract>::line_number::37
<abstract> block of instructions. Our empirical results show that just a few features  </abstract>::line_number::38
<abstract> are adequate for quite good performance at this task for a real modern  </abstract>::line_number::39
<abstract> processor, and that any of several supervised learning methods perform  </abstract>::line_number::40
<abstract> nearly optimally with respect to the features used.   </abstract>::line_number::41
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Planning and learning at multiple levels of temporal abstraction is a key  </abstract>::line_number::7
<abstract> problem for artificial intelligence. In this paper we summarize an approach to this problem based on the mathematical framework of Markov  </abstract>::line_number::8
<abstract> decision processes and reinforcement learning. Current model-based reinforcement learning is based on one-step models that cannot represent  </abstract>::line_number::9
<abstract> common-sense higher-level actions, such as going to lunch, grasping an  </abstract>::line_number::10
<abstract> object, or flying to Denver. This paper generalizes prior work on temporally abstract models [Sutton, 1995] and extends it from the prediction  </abstract>::line_number::11
<abstract> setting to include actions, control, and planning. We introduce a more  </abstract>::line_number::12
<abstract> general form of temporally abstract model, the multi-time model, and establish its suitability for planning and learning by virtue of its relationship  </abstract>::line_number::13
<abstract> to the Bellman equations. This paper summarizes the theoretical framework of multi-time models and illustrates their potential advantages in a  </abstract>::line_number::14
<abstract> gridworld planning task.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::16
<abstract> Several researchers have proposed modeling  </abstract>::line_number::17
<abstract> temporally abstract actions in reinforcement  </abstract>::line_number::18
<abstract> learning by the combination of a policy and a termination condition, which we refer to as an option. Value functions over options and models of  </abstract>::line_number::19
<abstract> options can be learned using methods designed  </abstract>::line_number::20
<abstract> for semi-Markov decision processes (SMDPs).  </abstract>::line_number::21
<abstract> However, all these methods require an option to  </abstract>::line_number::22
<abstract> be executed to termination. In this paper we explore methods that learn about an option from  </abstract>::line_number::23
<abstract> small fragments of experience consistent with  </abstract>::line_number::24
<abstract> that option, even if the option itself is not executed. We call these methods intra-option learning methods because they learn from experience  </abstract>::line_number::25
<abstract> within an option. Intra-option methods are sometimes much more efficient than SMDP methods because they can use off-policy temporal-difference mechanisms to learn simultaneously  </abstract>::line_number::26
<abstract> about all the options consistent with an experience, not just the few that were actually executed. In this paper we present intra-option learning methods for learning value functions over options and for learning multi-time models of the  </abstract>::line_number::27
<abstract> consequences of options. We present computational examples in which these new methods  </abstract>::line_number::28
<abstract> learn much faster than SMDP methods and learn  </abstract>::line_number::29
<abstract> effectively when SMDP methods cannot learn at  </abstract>::line_number::30
<abstract> all. We also sketch a convergence proof for intra  </abstract>::line_number::31
<abstract> option value learning.   </abstract>::line_number::32
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The increasing development of mobile networks  </abstract>::line_number::8
<abstract> raises new security requirements and concerns. In addition to the basic need of authentication, confidentiality and key distribution services, a new problem involving privacy is the unauthorized tracking of users'  </abstract>::line_number::9
<abstract> migration. In other words, accessing any information  </abstract>::line_number::10
<abstract> related to the mobile user's location data without his  </abstract>::line_number::11
<abstract> consent, is a serious violation of his privacy. Moreover, if no care is taken, the disclosure of the mobile  </abstract>::line_number::12
<abstract> user real identity may appear during the authentication process. The basic solution to this problem is the  </abstract>::line_number::13
<abstract> use of aliases which insure non-traceability by hiding  </abstract>::line_number::14
<abstract> the user's real identity and also his relationship with  </abstract>::line_number::15
<abstract> domain authorities. In this paper we provide a classification of the different degrees of non-traceability and  </abstract>::line_number::16
<abstract> present a new efficient method for the computation of  </abstract>::line_number::17
<abstract> aliases. This technique can be used during authentication of mobile users and thus avoids the drawbacks of  </abstract>::line_number::18
<abstract> existing solutions such as GSM and CDPD.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We present a new symbolic model checking technique, which analyzes temporal properties in multi-typed transition systems. Specifically, the method uses multiple type-specific data encodings to represent  </abstract>::line_number::6
<abstract> system states, and it carries out fixpoint computations via the corresponding type-specific symbolic  </abstract>::line_number::7
<abstract> operations. In essence, different symbolic encodings are unified into one composite model checker. Any  </abstract>::line_number::8
<abstract> type-specific language can be included in this framework provided that the language is closed under  </abstract>::line_number::9
<abstract> Boolean connectives, propositions can be checked for satisfiability, and relational images can be computed.  </abstract>::line_number::10
<abstract> Our technique relies on conjunctive partitioning of transition relations of atomic events based on variable  </abstract>::line_number::11
<abstract> types involved, which allows independent computation of one-step pre- and post-conditions for each  </abstract>::line_number::12
<abstract> variable type.  </abstract>::line_number::13
<abstract> In this paper we demonstrate the effectiveness of our method on a nontrivial data-transfer protocol,  </abstract>::line_number::14
<abstract> which contains a mixture of integer and Boolean-valued variables. The protocol operates over an unreliable channel that can lose, duplicate or reorder messages. Moreover, the protocol's send and receive  </abstract>::line_number::15
<abstract> window sizes are not specified in advance; rather, they are represented as symbolic constants. The resulting system was automatically verified using our composite model checking approach, in concert with  </abstract>::line_number::16
<abstract> a conservative approximation technique.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::12
<abstract> Unlike wired links, wireless network bandwidth is highly limited  </abstract>::line_number::13
<abstract> and the channel usually suffers from frequent and bursty loss due  </abstract>::line_number::14
<abstract> to its vulnerability to various kinds of interference. At the same  </abstract>::line_number::15
<abstract> time, the traditional TCP with its congestion control is well known  </abstract>::line_number::16
<abstract> for its poor performance over wireless links. This paper proposes  </abstract>::line_number::17
<abstract> a new protocol that (1) replaces TCP/IP over the wireless link by  </abstract>::line_number::18
<abstract> a simpler protocol with smaller headers, if the link is the last hop  </abstract>::line_number::19
<abstract> along a data path, (2) shifts functions needed to communicate with  </abstract>::line_number::20
<abstract> an Internet host using TCP/IP from the mobile host to the base  </abstract>::line_number::21
<abstract> station, so that the distinct wireless link is hidden from the outside Internet, and (3) exploits link-layer acknowledgments and re-transmissions to quickly recover losses over the wireless link. Our  </abstract>::line_number::22
<abstract> simulation results show a substantial performance improvement  </abstract>::line_number::23
<abstract> achieved by the new protocol.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::12
<abstract> Association Rule Mining algorithms operate  </abstract>::line_number::13
<abstract> on a data matrix (e.g., customers fi products)  </abstract>::line_number::14
<abstract> to derive association rules [2, 23]. We propose a new paradigm, namely, Ratio Rules,  </abstract>::line_number::15
<abstract> which are quantifiable in that we can measure  </abstract>::line_number::16
<abstract> the "goodness" of a set of discovered rules.  </abstract>::line_number::17
<abstract> We propose to use the "guessing error" as a  </abstract>::line_number::18
<abstract> measure of the "goodness", that is, the root-mean-square error of the reconstructed values  </abstract>::line_number::19
<abstract> of the cells of the given matrix, when we pretend that they are unknown. Another contribution is a novel method to guess missing/hidden values from the Ratio Rules that  </abstract>::line_number::20
<abstract> our method derives. For example, if somebody bought $10 of milk and $3 of bread, our  </abstract>::line_number::21
<abstract> rules can "guess" the amount spent on, say,  </abstract>::line_number::22
<abstract> butter. Thus, we can perform a variety of important tasks such as forecasting, answering  </abstract>::line_number::23
<abstract> "what-if" scenarios, detecting outliers, and visualizing the data. Moreover, we show how to  </abstract>::line_number::24
<abstract> compute Ratio Rules in a single pass over the  </abstract>::line_number::25
<abstract> dataset with small memory requirements (a  </abstract>::line_number::26
<abstract> few small matrices), in contrast to traditional  </abstract>::line_number::27
<abstract> association rule mining methods that require  </abstract>::line_number::28
<abstract> multiple passes and/or large memory. Experiments   </abstract>::line_number::29
<abstract>  on several real datasets (e.g., basketball and baseball statistics, biological data)  </abstract>::line_number::42
<abstract> demonstrate that the proposed method consistently achieves a "guessing error" of up to  </abstract>::line_number::43
<abstract> 5 times less than the straightforward competi  </abstract>::line_number::44
<abstract> tor.   </abstract>::line_number::45
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper describes Dynamic Abstraction Planning  </abstract>::line_number::9
<abstract> (DAP), an abstraction planning technique that improves the efficiency of state-enumeration planners for  </abstract>::line_number::10
<abstract> real-time embedded systems such as CIRCA. Abstraction is used to remove detail from the state representation, reducing both the size of the state space that  </abstract>::line_number::11
<abstract> must be explored to produce a plan and the size of the  </abstract>::line_number::12
<abstract> resulting plan. The intuition behind this approach is  </abstract>::line_number::13
<abstract> simple: in some situations, certain world features are  </abstract>::line_number::14
<abstract> important, while in other situations those same features are not important.  </abstract>::line_number::15
<abstract> By automatically selecting the appropriate level of abstraction at each step during the planning process,  </abstract>::line_number::16
<abstract> DAP can significantly reduce the size of the search  </abstract>::line_number::17
<abstract> space. Furthermore, the planning process can supply  </abstract>::line_number::18
<abstract> initial plans that preserve safety but might, on further  </abstract>::line_number::19
<abstract> refinement, do a better job of goal achievement. DAP  </abstract>::line_number::20
<abstract> can also terminate with an executable abstract plan,  </abstract>::line_number::21
<abstract> which may be much smaller than the corresponding  </abstract>::line_number::22
<abstract> plan expanded to precisely-defined states. Preliminary  </abstract>::line_number::23
<abstract> results show dramatic improvements in planning speed  </abstract>::line_number::24
<abstract> and scalability.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::3
<abstract> Quantum computing has witnessed a surge of activity recently owing  </abstract>::line_number::4
<abstract> to some very exciting discoveries on both the theoretical and practical  </abstract>::line_number::5
<abstract> fronts. In this overview, we sketch an account of the developments in  </abstract>::line_number::6
<abstract> this scientifically intriguing field, starting in the early 80's when the first  </abstract>::line_number::7
<abstract> questions about the computability of quantum processes were raised,  </abstract>::line_number::8
<abstract> and which led to the formal definitions of a Quantum Computer and a  </abstract>::line_number::9
<abstract> Quantum Complexity Theory. Peter Shor's recent remarkable discovery of quantum algorithms to solve the problems of integer factoring  </abstract>::line_number::10
<abstract> and discrete log computing, which are believed to be extremely hard to  </abstract>::line_number::11
<abstract> solve efficiently on classical computers, is a compelling demonstration  </abstract>::line_number::12
<abstract> of the suspected superiority of quantum computing over the classical  </abstract>::line_number::13
<abstract> model that is in use today. We discuss one of his algorithms and the  </abstract>::line_number::14
<abstract> implications it has for classical cryptography. We discuss some of the  </abstract>::line_number::15
<abstract> latest work in this field which has brought us yet closer to achieving a  </abstract>::line_number::16
<abstract> physical realization of a quantum computer. Whenever it happens, if it  </abstract>::line_number::17
<abstract> happens, it would be yet another revolution in the field of computing,  </abstract>::line_number::18
<abstract> and maybe the biggest one to date.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Most case-based reasoning systems have used a  </abstract>::line_number::7
<abstract> single "best" or "most similar" case as the basis  </abstract>::line_number::8
<abstract> for a solution. For many problems, however,  </abstract>::line_number::9
<abstract> there is no single exact solution. Rather, there  </abstract>::line_number::10
<abstract> is a range of acceptable answers. We use cases  </abstract>::line_number::11
<abstract> not only as a basis for a solution, but also to  </abstract>::line_number::12
<abstract> indicate the boundaries within which a solution  </abstract>::line_number::13
<abstract> can be found. We solve problems by choosing  </abstract>::line_number::14
<abstract> some point within those boundaries.  </abstract>::line_number::15
<abstract> In this paper, I discuss this use of cases with  </abstract>::line_number::16
<abstract> illustrations from chiron, a system I have implemented in the domain of personal income  </abstract>::line_number::17
<abstract> tax planning.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Recently, content-based retrieval of images and video has become a hot research area. The reason for this  </abstract>::line_number::5
<abstract> is the need for effective and efficient techniques, that meet user requirements, to access large volumes of digital  </abstract>::line_number::6
<abstract> images and video data. In [GR 95], previous approaches to content-based retrieval is said to have taken two  </abstract>::line_number::7
<abstract> directions. In the first approach, image contents are modeled as a set of attributes extracted manually and  </abstract>::line_number::8
<abstract> managed within the framework of conventional database-management systems. The second approach depends  </abstract>::line_number::9
<abstract> on an integrated feature-extraction/object-recognition subsystem to overcome the limitations of attribute-based retrieval. However, it has been also stated that [GR 95] recent content-based image retrieval systems  </abstract>::line_number::10
<abstract> recognized the need for synergy between these two approaches.  </abstract>::line_number::11
<abstract> There has been numerous efforts to build content-based image retrieval systems. These include, Chabot  </abstract>::line_number::12
<abstract> [OS 95], SCORE [ATY 95, ATY 96], CONIVAS [AD 96], Photobook [PPS 93], CANDID [KCH 95], JACOB  </abstract>::line_number::13
<abstract> [ALDV 96, LA 96], VisualSEEk [SC 96] and QBIC [FSN+ 95]. In the first place, these systems differ in their  </abstract>::line_number::14
<abstract> querying capabilities. Images could be retrieved through the use of color, texture, sketch, shape, volume,  </abstract>::line_number::15
<abstract> spatial constraints, browsing, motion, text and domain concepts. Current approaches to content-based image  </abstract>::line_number::16
<abstract> retrieval also differ in terms of image features extracted, their level of abstraction and the degree of domain  </abstract>::line_number::17
<abstract> independence. In this paper, a comparative survey on these systems is conducted to figure out design tradeoffs  </abstract>::line_number::18
<abstract> and different approaches to content-based image retrieval. Furthermore, a taxonomy of content-based retrieval  </abstract>::line_number::19
<abstract> systems, as well as a generic architecture, is provided.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::17
<abstract> Ad hoc querying is difficult on very large datasets, since it  </abstract>::line_number::18
<abstract> is usually not possible to have the entire dataset on disk.  </abstract>::line_number::19
<abstract> While compression can be used to decrease the size of the  </abstract>::line_number::20
<abstract> dataset, compressed data is notoriously difficult to index  </abstract>::line_number::21
<abstract> or access.  </abstract>::line_number::22
<abstract> In this paper we consider a very large dataset comprising multiple distinct time sequences. Each point in the  </abstract>::line_number::23
<abstract> sequence is a numerical value. We show how to compress  </abstract>::line_number::24
<abstract> such a dataset into a format that supports ad hoc querying, provided that a small error can be tolerated when the  </abstract>::line_number::25
<abstract> data is uncompressed. Experiments on large, real world  </abstract>::line_number::26
<abstract> datasets (AT&T customer calling patterns) show that the  </abstract>::line_number::27
<abstract> proposed method achieves an average of less than 5% error  </abstract>::line_number::28
<abstract> in any data value after compressing to a mere 2.5% of the  </abstract>::line_number::29
<abstract> original space (i.e., a 40:1 compression ratio), with these  </abstract>::line_number::30
<abstract> numbers not very sensitive to dataset size. Experiments  </abstract>::line_number::31
<abstract> on aggregate queries achieved a 0.5% reconstruction error  </abstract>::line_number::32
<abstract> with a space requirement under 2%.   </abstract>::line_number::33
<abstract>  Abstract  </abstract>::line_number::6
<abstract> This paper attempts to raise some issues that  </abstract>::line_number::7
<abstract> are important for graduate students to be successful and to get as much out of the process  </abstract>::line_number::8
<abstract> as possible, and for advisors who wish to help  </abstract>::line_number::9
<abstract> their students be successful. The intent is not  </abstract>::line_number::10
<abstract> to provide prescriptive advice no formulas for  </abstract>::line_number::11
<abstract> finishing a thesis or twelve-step programs for becoming a better advisor are given but to raise  </abstract>::line_number::12
<abstract> awareness on both sides of the advisor-student  </abstract>::line_number::13
<abstract> relationship as to what the expectations are and  </abstract>::line_number::14
<abstract> should be for this relationship, what a graduate  </abstract>::line_number::15
<abstract> student should expect to accomplish, common  </abstract>::line_number::16
<abstract> problems, and where to go if the advisor is not  </abstract>::line_number::17
<abstract> forthcoming.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::20
<abstract> All mechanical designs pass through a series of formal and informal redesign steps, involving the analysis of functionality, manufacturability, cost and other life-cycle factors. The  </abstract>::line_number::21
<abstract> speed and efficacy of these steps has a major influence on the lead time of the product from  </abstract>::line_number::22
<abstract> conceptualization to launching. In this paper we propose a methodology for automatically  </abstract>::line_number::23
<abstract> generating redesign suggestions for reducing setup costs for machined parts.  </abstract>::line_number::24
<abstract> Given an interpretation of the design as a collection of machinable features, our approach  </abstract>::line_number::25
<abstract> is to generate alternate machining features by making geometric changes to the original  </abstract>::line_number::26
<abstract> features, and add them to the feature set of the original part to create an extended feature  </abstract>::line_number::27
<abstract> set. The designer may provide restrictions on the design indicating the type and extent of  </abstract>::line_number::28
<abstract> modifications allowed on certain faces and volumes, in which case all redesign suggestions  </abstract>::line_number::29
<abstract> generated by our approach honor those restrictions.  </abstract>::line_number::30
<abstract> By taking combinations of features from the extended feature set generated above, we can  </abstract>::line_number::31
<abstract> generate modified versions of the original design that still satisfy the designer's intent. By  </abstract>::line_number::32
<abstract> considering precedence constraints and approach directions for the machining operations as  </abstract>::line_number::33
<abstract> well as simple fixturability constraints, we can estimate the setup time that will be required  </abstract>::line_number::34
<abstract> for each design. Any modified design whose setup time is less than that of the original  </abstract>::line_number::35
<abstract> design can be presented to the designer as a possible way to modify the original design.   </abstract>::line_number::36
<abstract>  Abstract: A transport protocol that supports real-time communication of  </abstract>::line_number::8
<abstract> audio/video frames across campus-area packet switched networks is presented.  </abstract>::line_number::9
<abstract> It is a best effort protocol that attempts to ameliorate the effect of jitter, load  </abstract>::line_number::10
<abstract> variation, and packet loss, to provide low latency, synchronized audio and video  </abstract>::line_number::11
<abstract> communications. This goal is realized through four transport and display  </abstract>::line_number::12
<abstract> mechanisms, and a real-time implementation of these mechanisms that  </abstract>::line_number::13
<abstract> integrates operating system services ( e.g., scheduling and resource allocation,  </abstract>::line_number::14
<abstract> and device management) with network communication services ( e.g., transport  </abstract>::line_number::15
<abstract> protocols), and with application code ( e.g., display routines). The four  </abstract>::line_number::16
<abstract> mechanisms are: a facility for varying the synchronization between audio and  </abstract>::line_number::17
<abstract> video to achieve continuous audio in the face of jitter, a network congestion  </abstract>::line_number::18
<abstract> monitoring mechanism that is used to control audio/video latency, a queueing  </abstract>::line_number::19
<abstract> mechanism at the sender that is used to maximize frame throughput without  </abstract>::line_number::20
<abstract> unnecessarily increasing latency, and a forward error correction mechanism for  </abstract>::line_number::21
<abstract> transmitting audio frames multiple times to ameliorate the effects of packet loss  </abstract>::line_number::22
<abstract> in the network. The effectiveness of these techniques is demonstrated by  </abstract>::line_number::23
<abstract> measuring the performance of the protocol when transmitting audio and video  </abstract>::line_number::24
<abstract> across congested networks.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::5
<abstract> VBR compressed video is known to exhibit significant, multiple-  </abstract>::line_number::6
<abstract> time-scale bit rate variability. In this paper, we consider the transmission of stored video from a server to a client across a high speed  </abstract>::line_number::7
<abstract> network, and explore how the client buffer space can be used most  </abstract>::line_number::8
<abstract> effectively toward reducing the variability of the transmitted bit  </abstract>::line_number::9
<abstract> rate.  </abstract>::line_number::10
<abstract> We present two basic results. First, we present an optimal  </abstract>::line_number::11
<abstract> smoothing algorithm for achieving the greatest possible reduction  </abstract>::line_number::12
<abstract> in rate variability when transmitting stored video to a client with  </abstract>::line_number::13
<abstract> given buffer size. We provide a formal proof of optimality, and  </abstract>::line_number::14
<abstract> demonstrate the performance of the algorithm on a set of long  </abstract>::line_number::15
<abstract> MPEG-1 encoded video traces. Second, we evaluate the impact  </abstract>::line_number::16
<abstract> of optimal smoothing on the network resources needed for video  </abstract>::line_number::17
<abstract> transport, under two network service models: Deterministic Guar-  </abstract>::line_number::18
<abstract> anteed service [1, 11] and Renegotiated CBR (RCBR) service [9, 8].  </abstract>::line_number::19
<abstract> Under both models, we find the impact of optimal smoothing to be  </abstract>::line_number::20
<abstract> dramatic.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::9
<abstract> There is increasing demand to extend CORBA to support  </abstract>::line_number::10
<abstract> applications with stringent real-time requirements. However, conventional CORBA Object Request Brokers (ORBs)  </abstract>::line_number::11
<abstract> exhibit substantial priority inversion and non-determinism,  </abstract>::line_number::12
<abstract> which makes them unsuitable for applications with deterministic real-time requirements. This paper focuses on software  </abstract>::line_number::13
<abstract> architectures that help to alleviate priority inversion and non-determinism in real-time CORBA ORBs. It also illustrates empirically why conventional ORBs do not yet support real-time  </abstract>::line_number::14
<abstract> quality of service.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::12
<abstract> We have developed compiler algorithms that analyze explicitly parallel programs and restructure their shared data to  </abstract>::line_number::13
<abstract> reduce the number of false sharing misses. The algorithms  </abstract>::line_number::14
<abstract> analyze per-process shared data accesses, pinpoint the data  </abstract>::line_number::15
<abstract> structures that are susceptible to false sharing and choose  </abstract>::line_number::16
<abstract> an appropriate transformation to reduce it. The transformations either group data that is accessed by the same processor or separate individual data items that are shared.  </abstract>::line_number::17
<abstract> This paper evaluates that technique. We show through  </abstract>::line_number::18
<abstract> simulation that our analysis successfully identifies the data  </abstract>::line_number::19
<abstract> structures that are responsible for most false sharing misses,  </abstract>::line_number::20
<abstract> and then transforms them without unduly decreasing spatial  </abstract>::line_number::21
<abstract> locality. The reduction in false sharing positively impacts  </abstract>::line_number::22
<abstract> both execution time and program scalability when executed  </abstract>::line_number::23
<abstract> on a KSR2. Both factors combine to increase the maximum  </abstract>::line_number::24
<abstract> achievable speedup for all programs, more than doubling  </abstract>::line_number::25
<abstract> it for several. Despite being able to only approximate actual inter-processor memory accesses, the compiler-directed  </abstract>::line_number::26
<abstract> transformations always outperform programmer efforts to  </abstract>::line_number::27
<abstract> eliminate false sharing.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::9
<abstract> This paper reports on the design and implementation of a practical shape analysis for C. The purpose of the analysis is to aid in the disambiguation of  </abstract>::line_number::10
<abstract> heap-allocated data structures by estimating the shape  </abstract>::line_number::11
<abstract> (Tree, DAG, or Cyclic Graph) of the data structure accessible from each heap-directed pointer. This shape  </abstract>::line_number::12
<abstract> information can be used to improve dependence testing and in parallelization, and to guide the choice of  </abstract>::line_number::13
<abstract> more complex heap analyses.  </abstract>::line_number::14
<abstract> The method has been implemented as a context-sensitive interprocedural analysis in the McCAT compiler. Experimental results and observations are given  </abstract>::line_number::15
<abstract> for 16 benchmark programs. These results show that  </abstract>::line_number::16
<abstract> the analysis gives accurate and useful results for an  </abstract>::line_number::17
<abstract> important group of applications.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Real-time continuous media traffic, such as digital video and audio, is expected  </abstract>::line_number::9
<abstract> to comprise a large percentage of the network load on future high speed packet  </abstract>::line_number::10
<abstract> switch networks such as ATM. A major feature which distinguishes high speed  </abstract>::line_number::11
<abstract> networks from traditional slower speed networks is the large amount of data the  </abstract>::line_number::12
<abstract> network must manage. For efficient network usage, traffic control mechanisms are  </abstract>::line_number::13
<abstract> essential. Currently, most mechanisms for traffic control (such as flow control)  </abstract>::line_number::14
<abstract> have centered on the support of Available Bit Rate (ABR), i.e., non real-time,  </abstract>::line_number::15
<abstract> traffic. With regard to ATM, for ABR traffic, two major types of schemes which  </abstract>::line_number::16
<abstract> have been proposed are rate-control and credit-control schemes. Neither of these  </abstract>::line_number::17
<abstract> schemes are directly applicable to Real-time Variable Bit Rate (VBR) traffic such  </abstract>::line_number::18
<abstract> as continuous media traffic. Traffic control for continuous media traffic is an inherently difficult problem due to the time-sensitive nature of the traffic and its  </abstract>::line_number::19
<abstract> unpredictable burstiness. In this study, we present a scheme which controls traffic by dynamically allocating/de-allocating resources among competing VCs based  </abstract>::line_number::20
<abstract> upon their real-time requirements. This scheme incorporates a form of rate-control,  </abstract>::line_number::21
<abstract> real-time burst-level scheduling and link-link flow control. We show analytically potential performance improvements of our rate-control scheme and present a scheme  </abstract>::line_number::22
<abstract> for buffer dimensioning. We also present simulation results of our schemes and discuss the tradeoffs inherent in maintaining high network utilization and statistically  </abstract>::line_number::23
<abstract> guaranteeing many users' Quality of Service.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::11
<abstract> In this paper we present a parallel formulation of a multilevel k-way graph partitioning algorithm. The multilevel  </abstract>::line_number::12
<abstract> k-way partitioning algorithm reduces the size of the graph by collapsing vertices and edges (coarsening phase), finds  </abstract>::line_number::13
<abstract> a k-way partitioning of the smaller graph, and then it constructs a k-way partitioning for the original graph by projecting and refining the partition to successively finer graphs (uncoarsening phase). A key innovative feature of our  </abstract>::line_number::14
<abstract> parallel formulation is that it utilizes graph coloring to effectively parallelize both the coarsening and the refinement  </abstract>::line_number::15
<abstract> during the uncoarsening phase. Our algorithm is able to achieve a high degree of concurrency, while maintaining the  </abstract>::line_number::16
<abstract> high quality partitions produced by the serial algorithm. We test our scheme on a large number of graphs from finite  </abstract>::line_number::17
<abstract> element methods, and transportation domains. For graphs with a million vertices, our parallel formulation produces  </abstract>::line_number::18
<abstract> high quality 128-way partitions on 128 processors in a little over two seconds, on Cray T3D. Thus our parallel algorithm makes it feasible to perform frequent dynamic graph partition in adaptive computations without compromising  </abstract>::line_number::19
<abstract> quality.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Query optimization for parallel machines needs to  </abstract>::line_number::7
<abstract> consider machine architecture, processor and memory  </abstract>::line_number::8
<abstract> resources available, and different types of parallelism,  </abstract>::line_number::9
<abstract> making the search space much larger than the sequential case. In this paper our aim is to determine a plan  </abstract>::line_number::10
<abstract> that makes the execution of an individual query very  </abstract>::line_number::11
<abstract> fast, making minimizing parallel execution time the  </abstract>::line_number::12
<abstract> right objective. This creates the following circular dependence: a plan tree is needed for effective resource  </abstract>::line_number::13
<abstract> assignment, which is needed to estimate the parallel  </abstract>::line_number::14
<abstract> execution time, and this is needed for the cost-based  </abstract>::line_number::15
<abstract> search for a good plan tree. In this paper we propose  </abstract>::line_number::16
<abstract> a new search heuristic that breaks the cycle by constructing the plan tree layer by layer in a bottom-up  </abstract>::line_number::17
<abstract> manner. To select nodes at the next level, the lower  </abstract>::line_number::18
<abstract> and upper bounds on the execution time for plans consistent with the decisions made so far are estimated  </abstract>::line_number::19
<abstract> and are used to guide the search. A query plan representation for intra- and inter-operator parallelism,  </abstract>::line_number::20
<abstract> pipelining, and processor and memory assignment is  </abstract>::line_number::21
<abstract> proposed. Also proposed is a new approach to estimating the parallel execution time of a plan that considers  </abstract>::line_number::22
<abstract> sum and max of operators working sequentially and  </abstract>::line_number::23
<abstract> in parallel, respectively. The results obtained from a  </abstract>::line_number::24
<abstract> prototype optimizer are presented.   </abstract>::line_number::25
<abstract>  abstract: Building distributed operating systems benefits from the micro-kernel approach by allowing better support for modularization. However, we believe  </abstract>::line_number::6
<abstract> that we need to take this support a step further. A more modular, or object  </abstract>::line_number::7
<abstract> oriented approach is needed if we wish to cross the barrier of complexity that  </abstract>::line_number::8
<abstract> is holding back distributed operating system development. The Chorus Ob  </abstract>::line_number::9
<abstract> ject Oriented Layer (COOL) is a layer built above the Chorus micro-kernel  </abstract>::line_number::10
<abstract> designed to extend the micro-kernel abstractions with support for object oriented systems. COOL v2, the second iteration of this layer provides generic  </abstract>::line_number::11
<abstract> support for clusters of objects, in a distributed virtual memory model. It is  </abstract>::line_number::12
<abstract> built as a layered system where the lowest layer support only clusters and the  </abstract>::line_number::13
<abstract> upper layers support objects.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We present an integrated framework for developing real-time systems in which lock-free algorithms are employed to  </abstract>::line_number::6
<abstract> implement shared objects. There are two key objectives of  </abstract>::line_number::7
<abstract> our work. The first is to enable functionality for object sharing in lock-free real-time systems that is comparable to that  </abstract>::line_number::8
<abstract> in lock-based systems. Our main contribution toward this  </abstract>::line_number::9
<abstract> objective is an efficient approach for implementing multi-object lock-free operations and transactions. A second key  </abstract>::line_number::10
<abstract> objective of our work is to improve upon previously proposed  </abstract>::line_number::11
<abstract> scheduling conditions for tasks that share lock-free objects.  </abstract>::line_number::12
<abstract> When developing such conditions, the key issue is to bound  </abstract>::line_number::13
<abstract> the cost of operation interferences. We present a general  </abstract>::line_number::14
<abstract> approach for doing this, based on linear programming.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::3
<abstract> We present lock-free and wait-free universal constructions for implementing large  </abstract>::line_number::4
<abstract> shared objects. Most previous universal constructions require processes to copy the  </abstract>::line_number::5
<abstract> entire object state, which is impractical for large objects. Previous attempts to  </abstract>::line_number::6
<abstract> address this problem require programmers to explicitly fragment large objects into  </abstract>::line_number::7
<abstract> smaller, more manageable pieces, paying particular attention to how such pieces are  </abstract>::line_number::8
<abstract> copied. In contrast, our constructions are designed to largely shield programmers  </abstract>::line_number::9
<abstract> from this fragmentation. Furthermore, for many objects, our constructions result  </abstract>::line_number::10
<abstract> in lower copying overhead than previous ones.  </abstract>::line_number::11
<abstract> Fragmentation is achieved in our constructions through the use of load-linked,  </abstract>::line_number::12
<abstract> store-conditional, and validate operations on a "large" multi-word shared variable.  </abstract>::line_number::13
<abstract> Before presenting our constructions, we show that these operations can be efficiently  </abstract>::line_number::14
<abstract> implemented from similar one-word primitives.   </abstract>::line_number::15
<abstract>  1. ABSTRACT  </abstract>::line_number::4
<abstract> Hierarchical dynamic simplification (HDS) is a new approach to  </abstract>::line_number::5
<abstract> the problem of simplifying arbitrary polygonal environments.  </abstract>::line_number::6
<abstract> HDS operates dynamically, retessellating the scene continuously  </abstract>::line_number::7
<abstract> as the users viewing position shifts, and adaptively, processing  </abstract>::line_number::8
<abstract> the entire database without first decomposing the environment  </abstract>::line_number::9
<abstract> into individual objects. The resulting system allows real-time  </abstract>::line_number::10
<abstract> display of very complex polygonal CAD models consisting of  </abstract>::line_number::11
<abstract> thousands of parts and hundreds of thousands of polygons. HDS  </abstract>::line_number::12
<abstract> supports various preprocessing algorithms and various runtime  </abstract>::line_number::13
<abstract> criteria, providing a general framework for dynamic view-dependent simplification.  </abstract>::line_number::14
<abstract> Briefly, HDS works by clustering vertices together in a  </abstract>::line_number::15
<abstract> hierarchical fashion. The simplification process continuously  </abstract>::line_number::16
<abstract> queries this hierarchy to generate a scene containing only those  </abstract>::line_number::17
<abstract> polygons that are important from the current viewpoint. When  </abstract>::line_number::18
<abstract> the volume of space associated with a vertex cluster occupies less  </abstract>::line_number::19
<abstract> than a userspecified amount of the screen, all vertices within  </abstract>::line_number::20
<abstract> that cluster are collapsed together and degenerate polygons  </abstract>::line_number::21
<abstract> filtered out. HDS maintains an active list of visible polygons for  </abstract>::line_number::22
<abstract> rendering. Since frame-to-frame movements typically involve  </abstract>::line_number::23
<abstract> small changes in viewpoint, and therefore modify the active list  </abstract>::line_number::24
<abstract> by only a few polygons, the method takes advantage of temporal  </abstract>::line_number::25
<abstract> coherence for greater speed.  </abstract>::line_number::26
<abstract> CR Categories: I.3.5 [Computer Graphics]: Computational Geometry and  </abstract>::line_number::27
<abstract> Object Modeling - surfaces and object representations.  </abstract>::line_number::28
<abstract> Additional Keywords: polygonal simplification, level of detail, view  </abstract>::line_number::29
<abstract> dependent rendering.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Precise teleoperation of dextrous robotic hands by  </abstract>::line_number::5
<abstract> hand masters requires an accurate human hand model.  </abstract>::line_number::6
<abstract> A kinematic model of a human index finger is developed as an example for human hand modeling. The  </abstract>::line_number::7
<abstract> parameters of the model are determined by open-loop  </abstract>::line_number::8
<abstract> kinematic calibration. Singular value decomposition is  </abstract>::line_number::9
<abstract> used as a tool for analyzing the kinematic model and  </abstract>::line_number::10
<abstract> the identification process. Accurate and reliable results are obtained only when the numerical condition  </abstract>::line_number::11
<abstract> is minimized through parameter scaling, model reduction and pose set selection. The identified kinematic  </abstract>::line_number::12
<abstract> parameters show the kinematic model and calibration  </abstract>::line_number::13
<abstract> procedure have an accuracy on the order of a few millimeters.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We describe the design and implementation of a persistent object storage facility  </abstract>::line_number::7
<abstract> based on a dossier driven approach. Objects are characterized by dossiers which describe both their language defined and "extra-linguistic" properties. These dossiers are  </abstract>::line_number::8
<abstract> generated by a C++ preprocessor in concert with an augmented, but completely C++  </abstract>::line_number::9
<abstract> compatible, class description language. The design places very few burdens on the application programmer and can be used without altering the data member layout of application objects or inheriting from special classes. The storage format is kept simple to allow  </abstract>::line_number::10
<abstract> the use of a variety of data storage backends. In addition, these dossiers can be used to  </abstract>::line_number::11
<abstract> implement (or augment) a run-time typing facility compatible with the proposed ANSI  </abstract>::line_number::12
<abstract> C++ standard. Finally, by providing a generic object to byte stream conversion the persistent object facility can also be used in conjunction with an interprocess communication  </abstract>::line_number::13
<abstract> facility to provide object-level communication between processes. 1   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Software for a growing number of problem domains  </abstract>::line_number::10
<abstract> has complex, time varying behavior and unpredictable  </abstract>::line_number::11
<abstract> resource demands (e.g., WWW servers and parallel input/output systems). While current performance analysis tools provide insights into application dynamics  </abstract>::line_number::12
<abstract> and the causes of poor performance, with a posteriori analysis one cannot adapt to temporally varying  </abstract>::line_number::13
<abstract> application resource demands and system responses.  </abstract>::line_number::14
<abstract> We believe that the solution to this performance optimization conundrum is integration of dynamic performance instrumentation and on-the-fly performance  </abstract>::line_number::15
<abstract> data reduction with real-time adaptive control mechanisms that select and configure resource management  </abstract>::line_number::16
<abstract> algorithms automatically, based on observed application behavior, or interactively, through high-modality  </abstract>::line_number::17
<abstract> virtual environments. We motivate this belief by first  </abstract>::line_number::18
<abstract> describing our experiences with performance analysis tools, input/output characterization, and WWW  </abstract>::line_number::19
<abstract> server analysis, and then sketching the design of interactive and closed loop adaptive control systems.   </abstract>::line_number::20
<abstract>  Abstract. This paper describes the first results from research 1 on the  </abstract>::line_number::6
<abstract> compilation of constraint systems into task level parallel programs in a  </abstract>::line_number::7
<abstract> procedural language. This is the only research, of which we are aware,  </abstract>::line_number::8
<abstract> which attempts to generate efficient parallel programs for numerical  </abstract>::line_number::9
<abstract> computations from constraint systems. Computations are expressed as  </abstract>::line_number::10
<abstract> constraint systems. A dependence graph is derived from the constraint  </abstract>::line_number::11
<abstract> system and a set of input variables. The dependence graph, which exploits the parallelism in the constraints, is mapped to the target language CODE, which represents parallel computation structures as generalized dependence graphs. Finally, parallel C programs are generated.  </abstract>::line_number::12
<abstract> The granularity of the derived dependence graphs depends upon the  </abstract>::line_number::13
<abstract> complexity of the operations represented in the type system of the constraint specification language. To extract parallel programs of appropriate granularity, the following features have been included: (i) modularity, (ii) operations over structured types as primitives, (iii) definition  </abstract>::line_number::14
<abstract> of sequential C functions. A prototype of the compiler has been implemented. The execution environment or software architecture is specified  </abstract>::line_number::15
<abstract> separately from the constraint system. The domain of matrix computations has been targeted for applications. Some examples have been  </abstract>::line_number::16
<abstract> programmed. Initial results are very encouraging.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::3
<abstract> In this paper, we consider non-uniform wire-sizing. Given a  </abstract>::line_number::4
<abstract> wire segment of length L, let f(x) be the width of the wire  </abstract>::line_number::5
<abstract> at position x, 0 x L. We show that the optimal wire-sizing function that minimizes the Elmore delay through the  </abstract>::line_number::6
<abstract> wire is f(x) = ae bx , where a &gt; 0 and b &gt; 0 are constants  </abstract>::line_number::7
<abstract> that can be computed in O(1) time. In the case where lower  </abstract>::line_number::8
<abstract> bound (L &gt; 0) and upper bound (U &gt; 0) on the wire widths  </abstract>::line_number::9
<abstract> are given, we show that the optimal wire-sizing function f(x)  </abstract>::line_number::10
<abstract> is a truncated version of ae bx that can also be determined in  </abstract>::line_number::11
<abstract> O(1) time. Our wire-sizing formula can be iteratively applied  </abstract>::line_number::12
<abstract> to optimally size the wire segments in a routing tree.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Qualitative reasoning uses incomplete knowledge to compute a description of the possible behaviors for dynamic  </abstract>::line_number::10
<abstract> systems. For complex systems containing a large number  </abstract>::line_number::11
<abstract> of variables and constraints, the simulation frequently is  </abstract>::line_number::12
<abstract> intractable or results in a large, incomprehensible behavioral description. Abstraction and aggregation techniques are required during the simulation to eliminate  </abstract>::line_number::13
<abstract> irrelevant details and highlight the important characteristics of the behavior. The total temporal ordering of  </abstract>::line_number::14
<abstract> unrelated events provided by a traditional state-based  </abstract>::line_number::15
<abstract> qualitative representation is one such irrelevant distinction. Model decomposition and simulation addresses this  </abstract>::line_number::16
<abstract> problem.  </abstract>::line_number::17
<abstract> Model decomposition uses a causal analysis of the model  </abstract>::line_number::18
<abstract> to partition the variables into tightly connected components. The components are simulated separately in  </abstract>::line_number::19
<abstract> the order dictated by the causal analysis beginning with  </abstract>::line_number::20
<abstract> causally upstream components. Information from the  </abstract>::line_number::21
<abstract> simulation of causally upstream components is used to  </abstract>::line_number::22
<abstract> constrain the behavior of downstream components. If a  </abstract>::line_number::23
<abstract> feedback loop exists between components or a set of components are acausally related, then a concurrent simulation is performed for these components. A truth maintenance system is used to record and retract assumptions  </abstract>::line_number::24
<abstract> made during this concurrent simulation.  </abstract>::line_number::25
<abstract> Model decomposition provides a general architecture  </abstract>::line_number::26
<abstract> which separates the method of simulation from the model  </abstract>::line_number::27
<abstract> decomposition algorithm. This architecture can be used  </abstract>::line_number::28
<abstract> to introduce alternative abstraction techniques to eliminate other irrelevant distinctions.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::6
<abstract> MAWL is an application language for programming interactive services in the context of the Worldwide  </abstract>::line_number::7
<abstract> Web. The language is small, because no construct was introduced without compelling justification; as with  </abstract>::line_number::8
<abstract> yacc [8], general-purpose computation is done in a host language. MAWL offers conveniences such as control  </abstract>::line_number::9
<abstract> abstraction, persistent state management, synchronization, and shared memory. In addition, the MAWL  </abstract>::line_number::10
<abstract> compiler performs static checking designed to prevent common Web programming errors. In this paper we  </abstract>::line_number::11
<abstract> discuss the design and engineering of MAWL.  </abstract>::line_number::12
<abstract> We describe the problems MAWL is intended to solve, and then discuss our design choices in the context  </abstract>::line_number::13
<abstract> of our general language design philosophy, We also include an appendix of commentary on several short  </abstract>::line_number::14
<abstract> MAWL programs.   </abstract>::line_number::15
<abstract>  Abstract.  </abstract>::line_number::8
<abstract> Inertia is added to a continuous-time, Hopfield [1] effective-neuron system.  </abstract>::line_number::9
<abstract> We explore the effects on the stability of the fixed points of the system. A two  </abstract>::line_number::10
<abstract> neuron system with one or two inertial terms added is shown to exhibit chaos.  </abstract>::line_number::11
<abstract> The chaos is confirmed by Lyapunov exponents, power spectra, and phase space  </abstract>::line_number::12
<abstract> plots.   </abstract>::line_number::13
<abstract>  Abstract.  </abstract>::line_number::3
<abstract> We prove that all of Karp's 21 original NP -complete problems have a version that's hard to  </abstract>::line_number::4
<abstract> approximate. These versions are obtained from the original problems by adding essentially the same,  </abstract>::line_number::5
<abstract> simple constraint. We further show that these problems are absurdly hard to approximate. In fact, no  </abstract>::line_number::6
<abstract> polynomial-time algorithm can even approximate log (k) of the magnitude of these problems to within  </abstract>::line_number::7
<abstract> any constant factor, where log (k) denotes the logarithm iterated k times, unless N P is recognized by  </abstract>::line_number::8
<abstract> slightly superpolynomial randomized machines. We use the same technique to improve the constant  </abstract>::line_number::9
<abstract> * such that MAX CLIQUE is hard to approximate to within a factor of n * . Finally, we show that it  </abstract>::line_number::10
<abstract> is even harder to approximate two counting problems: counting the number of satisfying assignments  </abstract>::line_number::11
<abstract> to a monotone 2-SAT formula and computing the permanent of -1,0,1 matrices.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The ideal distributed file system would provide all its users with coherent, shared access to the same set of files,yet would be arbitrarily  </abstract>::line_number::8
<abstract> scalable to provide more storage space and higher performance to  </abstract>::line_number::9
<abstract> a growing user community. It would be highly available in spite of  </abstract>::line_number::10
<abstract> component failures. It would require minimal human administration, and administration would not become more complex as more  </abstract>::line_number::11
<abstract> components were added.  </abstract>::line_number::12
<abstract> Frangipani is a new file system that approximates this ideal, yet  </abstract>::line_number::13
<abstract> was relatively easy to build because of its two-layer structure. The  </abstract>::line_number::14
<abstract> lower layer is Petal (described in an earlier paper), a distributed  </abstract>::line_number::15
<abstract> storage service that provides incrementally scalable, highly available, automatically managed virtual disks. In the upper layer,  </abstract>::line_number::16
<abstract> multiple machines run the same Frangipani file system code on top  </abstract>::line_number::17
<abstract> of a shared Petal virtual disk, using a distributed lock service to  </abstract>::line_number::18
<abstract> ensure coherence.  </abstract>::line_number::19
<abstract> Frangipani is meant to run in a cluster of machines that are under  </abstract>::line_number::20
<abstract> a common administration and can communicate securely. Thus the  </abstract>::line_number::21
<abstract> machines trust one another and the shared virtual disk approach is  </abstract>::line_number::22
<abstract> practical. Of course, a Frangipani file system can be exported to  </abstract>::line_number::23
<abstract> untrusted machines using ordinary network file access protocols.  </abstract>::line_number::24
<abstract> We have implemented Frangipani on a collection of Alphas  </abstract>::line_number::25
<abstract> running DIGITAL Unix 4.0. Initial measurements indicate that  </abstract>::line_number::26
<abstract> Frangipani has excellent single-server performance and scales well  </abstract>::line_number::27
<abstract> as servers are added.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Message logging is a popular technique for building low-overhead protocols that tolerate  </abstract>::line_number::8
<abstract> process crash failures. Past research in message logging has focused on studying the relative  </abstract>::line_number::9
<abstract> overhead imposed by pessimistic, optimistic, and causal protocols during failure-free executions. In this paper, we give the first experimental evaluation of the performance of these  </abstract>::line_number::10
<abstract> protocols during recovery. We discover that, if a single failure is to be tolerated, pessimistic  </abstract>::line_number::11
<abstract> and causal protocols perform best, because they avoid rollbacks of correct processes. For  </abstract>::line_number::12
<abstract> multiple failures, however, the dominant factor in determining performance becomes where  </abstract>::line_number::13
<abstract> the recovery information is logged (i.e. at the sender, at the receiver, or replicated at a  </abstract>::line_number::14
<abstract> subset of the processes in the system) rather than when this information is logged (i.e. if  </abstract>::line_number::15
<abstract> logging is synchronous or asynchronous). From our results, we distil a few lessons that can  </abstract>::line_number::16
<abstract> guide the design of message-logging protocols that combine low-overhead during failure-free  </abstract>::line_number::17
<abstract> executions with fast recovery.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::24
<abstract> We address the problem of broadcasting on mesh architectures with arbitrary (non-power-two) dimensions. It is assumed that such mesh architectures employ cut-through or worm-hole routing. The  </abstract>::line_number::25
<abstract> primary focus is on avoiding network conflicts in the various proposed algorithms. We give algorithms  </abstract>::line_number::26
<abstract> for performing a conflict-free minimum-spanning tree broadcast, a pipelined algorithm that is similar to  </abstract>::line_number::27
<abstract> Ho and Johnsson's EDST algorithm for hypercubes, and a novel scatter-collect approach that is a natural  </abstract>::line_number::28
<abstract> choice for communication libraries due to its simplicity. Results obtained on the Intel Paragon system  </abstract>::line_number::29
<abstract> are included.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::11
<abstract> In this paper, we introduce a new parallel library effort, as part of the PLAPACK  </abstract>::line_number::12
<abstract> project, that attempts to address discrepencies between the needs of applications and  </abstract>::line_number::13
<abstract> parallel libraries. A number of contributions are made, including a new approach  </abstract>::line_number::14
<abstract> to matrix distribution, new insights into layering parallel linear algebra libraries, and  </abstract>::line_number::15
<abstract> the application of "object based" programming techniques which have recently become  </abstract>::line_number::16
<abstract> popular for (parallel) scientific libraries. We present an overview of a prototype library,  </abstract>::line_number::17
<abstract> the SL Library, which incorporates these ideas. Preliminary performance data shows  </abstract>::line_number::18
<abstract> this more application-centric approach to libraries does not necessarily adversely impact  </abstract>::line_number::19
<abstract> performance, compared to more traditional approaches.   </abstract>::line_number::20
<abstract>  Abstract In this paper, we describe the design  </abstract>::line_number::12
<abstract> and implementation of the Platform Independent  </abstract>::line_number::13
<abstract> Parallel Solver (PIPSolver) package for the out-of-core (OOC) solution of complex dense linear systems. Our approach is unique in that it allows essentially all of RAM to be filled with the current  </abstract>::line_number::14
<abstract> portion of the matrix (slab) to be updated and factored, thereby greatly improving the computation to  </abstract>::line_number::15
<abstract> I/O ratio over previous approaches. Experiences  </abstract>::line_number::16
<abstract> and performance are reported for the Cray T3D  </abstract>::line_number::17
<abstract> system.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::13
<abstract> This paper presents a new system, called NetSolve, that allows users to access computational resources, such as hardware and software, distributed across the network. The development of NetSolve  </abstract>::line_number::14
<abstract> was motivated by the need for an easy-to-use, efficient mechanism for using computational resources remotely. Ease of use is obtained as a result of different interfaces, some of which require no programming  </abstract>::line_number::15
<abstract> effort from the user. Good performance is ensured by a load-balancing policy that enables NetSolve to  </abstract>::line_number::16
<abstract> use the computational resources available as efficiently as possible. NetSolve offers the ability to look  </abstract>::line_number::17
<abstract> for computational resources on a network, choose the best one available, solve a problem (with retry for  </abstract>::line_number::18
<abstract> fault-tolerance), and return the answer to the user.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::14
<abstract> In this paper, we propose a definition of goal achievability: given a basic action theory describing an initial state of the world and some primitive actions available to a  </abstract>::line_number::15
<abstract> robot, including some actions which return binary sensing information, what goals can  </abstract>::line_number::16
<abstract> be achieved by the robot? The main technical result of the paper is a proof that a simple  </abstract>::line_number::17
<abstract> robot programming language is universal, in that any effectively achievable goal can be  </abstract>::line_number::18
<abstract> achieved by getting the robot to execute one of the robot programs. The significance of  </abstract>::line_number::19
<abstract> this result is at least two fold. First, it is in many ways similar to the equivalence theorem between Turing machines and recursive functions, but applied to robots whose  </abstract>::line_number::20
<abstract> actions are specified by an action theory. Secondly, it provides formal justifications for  </abstract>::line_number::21
<abstract> using the simple robot programming language as a foundation for our work on robotics.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Subgoal ordering is a type of control information that has received much attention  </abstract>::line_number::7
<abstract> in AI planning community. In this paper we formulate precisely a subgoal ordering  </abstract>::line_number::8
<abstract> in the situation calculus. We show how information about this subgoal ordering can  </abstract>::line_number::9
<abstract> be deduced from the background action theory. We also show for both linear and  </abstract>::line_number::10
<abstract> nonlinear planners how knowledge about this ordering can be used in a provably  </abstract>::line_number::11
<abstract> correct way to avoid unnecessary backtracking.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::7
<abstract> One way to think about STRIPS is as a mapping from databases to databases, in the following sense: Suppose we want to know what  </abstract>::line_number::8
<abstract> the world would be like if an action, represented by the STRIPS operator ff, were done  </abstract>::line_number::9
<abstract> in some world, represented by the STRIPS  </abstract>::line_number::10
<abstract> database D 0 . To find out, simply perform  </abstract>::line_number::11
<abstract> the operator ff on D 0 (by applying ff's elementary add and delete revision operators to  </abstract>::line_number::12
<abstract> D 0 ). We describe this process as progressing  </abstract>::line_number::13
<abstract> the database D 0 in response to the action ff.  </abstract>::line_number::14
<abstract> In this paper, we consider the general problem of progressing an initial database in response to a given sequence of actions. We  </abstract>::line_number::15
<abstract> appeal to the situation calculus and an axiomatization of actions which addresses the  </abstract>::line_number::16
<abstract> frame problem (Reiter [13], Lin and Reiter  </abstract>::line_number::17
<abstract> [8]). This setting is considerably more general than STRIPS. Our results concerning  </abstract>::line_number::18
<abstract> progression are mixed. The (surprising) bad  </abstract>::line_number::19
<abstract> news is that, in general, to characterize a progressed database we must appeal to second  </abstract>::line_number::20
<abstract> order logic. The good news is that there are  </abstract>::line_number::21
<abstract> many useful special cases for which we can  </abstract>::line_number::22
<abstract> compute the progressed database in first order logic; not only that, we can do so efficiently.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::5
<abstract> The rectilinear Steiner tree problem requires a shortest tree spanning a given vertex subset  </abstract>::line_number::6
<abstract> in the plane with rectilinear distance. It was proved that the output length of Zelikovsky's [25]  </abstract>::line_number::7
<abstract> and Berman/Ramaiyer [3] heuristics is at most 1.375 and 97  </abstract>::line_number::8
<abstract> 72 1:347 of the optimal length,  </abstract>::line_number::9
<abstract> respectively. It was claimed that these bounds are not tight. Here we improve these bounds to  </abstract>::line_number::10
<abstract> 1.3125 and 61  </abstract>::line_number::11
<abstract> 48 1:271, respectively, and give efficient algorithms to find approximations of such  </abstract>::line_number::12
<abstract> quality. We also prove that for Zelikovsky's heuristic this bound cannot be less than 1.3.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Recent attempts at incorporating concurrency into functional languages have  </abstract>::line_number::7
<abstract> identified synchronous communication via shared channels as a promising primitive. An additional useful feature found in many proposals is a nondeterministic  </abstract>::line_number::8
<abstract> choice operator. Similar in nature to the CSP alternative command, this operator  </abstract>::line_number::9
<abstract> allows different possible actions to be guarded by sends or receives. Choice is  </abstract>::line_number::10
<abstract> difficult to implement in a distributed environment because it requires offering  </abstract>::line_number::11
<abstract> many potential communications but closing only one. In this paper we present  </abstract>::line_number::12
<abstract> the first distributed, deadlock-free algorithm for choice.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The New Jersey Machine-Code Toolkit helps programmers write applications that process machine code.  </abstract>::line_number::7
<abstract> Applications that use the toolkit are written at an  </abstract>::line_number::8
<abstract> assembly-language level of abstraction, but they recognize and emit binary. Guided by a short instruction-set specification, the toolkit generates all the bit-manipulating code.  </abstract>::line_number::9
<abstract> The toolkit's specification language uses four concepts: fields and tokens describe parts of instructions,  </abstract>::line_number::10
<abstract> patterns describe binary encodings of instructions or  </abstract>::line_number::11
<abstract> groups of instructions, and constructors map between  </abstract>::line_number::12
<abstract> the assembly-language and binary levels. These concepts are suitable for describing both CISC and RISC  </abstract>::line_number::13
<abstract> machines; we have written specifications for the MIPS  </abstract>::line_number::14
<abstract> R3000, SPARC, and Intel 486 instruction sets.  </abstract>::line_number::15
<abstract> We have used the toolkit to help write two applications: a debugger and a linker. The toolkit generates  </abstract>::line_number::16
<abstract> efficient code; for example, the linker emits binary up  </abstract>::line_number::17
<abstract> to 15% faster than it emits assembly language, making  </abstract>::line_number::18
<abstract> it 1.7-2 times faster to produce an a.out directly than  </abstract>::line_number::19
<abstract> by using the assembler.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::5
<abstract> An implicit premise of existing routing methods is that the routing topology must correspond to a  </abstract>::line_number::6
<abstract> tree (i.e., it does not contain cycles). In this paper we investigate the consequences of abandoning this  </abstract>::line_number::7
<abstract> basic axiom, and instead we allow routing topologies that correspond to arbitrary graphs (i.e., where  </abstract>::line_number::8
<abstract> cycles are allowed). We show that non-tree routing can significantly improve signal propagation delay,  </abstract>::line_number::9
<abstract> reduce signal skew, and afford increased reliability with respect to open faults that may be caused by  </abstract>::line_number::10
<abstract> manufacturing defects and electro-migration. Simulations on uniformly-distributed nets indicate that  </abstract>::line_number::11
<abstract> depending on net size and technology parameters, our non-tree routing construction reduces maximum  </abstract>::line_number::12
<abstract> sourse-sink SPICE delay by an average of up to 62%, and reduces signal skew by an average of up to  </abstract>::line_number::13
<abstract> 63%, as compared with Steiner routing. Moreover, up to 77% of the total wirelength in non-trees can  </abstract>::line_number::14
<abstract> tolerate an open fault without disconnecting the circuit.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Several cache-coherent shared-memory multiprocessors have been  </abstract>::line_number::6
<abstract> developed that are scalable and offer a very tight coupling between  </abstract>::line_number::7
<abstract> the processing resources. They are therefore quite attractive for  </abstract>::line_number::8
<abstract> use as compute servers for multiprogramming and parallel application workloads. Process scheduling and memory management,  </abstract>::line_number::9
<abstract> however, remain challenging due to the distributed main memory found on such machines. This paper examines the effects of  </abstract>::line_number::10
<abstract> OS scheduling and page migration policies on the performance  </abstract>::line_number::11
<abstract> of such compute servers. Our experiments are done on the Stan-ford DASH, a distributed-memory cache-coherent multiprocessor.  </abstract>::line_number::12
<abstract> We show that for our multiprogramming workloads consisting of  </abstract>::line_number::13
<abstract> sequential jobs, the traditional Unix scheduling policy does very  </abstract>::line_number::14
<abstract> poorly. In contrast, a policy incorporating cluster and cache affinity along with a simple page-migration algorithm offers up to twofold performance improvement. For our workloads consisting of  </abstract>::line_number::15
<abstract> multiple parallel applications, we compare space-sharing policies  </abstract>::line_number::16
<abstract> that divide the processors among the applications to time-slicing  </abstract>::line_number::17
<abstract> policies such as standard Unix or gang scheduling. We show  </abstract>::line_number::18
<abstract> that space-sharing policies can achieve better processor utilization  </abstract>::line_number::19
<abstract> due to the operating point effect, but time-slicing policies benefit  </abstract>::line_number::20
<abstract> strongly from user-level data distribution. Our initial experience  </abstract>::line_number::21
<abstract> with automatic page migration suggests that policies based only  </abstract>::line_number::22
<abstract> on TLB miss information can be quite effective, and useful for  </abstract>::line_number::23
<abstract> addressing the data distribution problems of space-sharing sched-ulers.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Semantic query optimization refers to the process of using  </abstract>::line_number::9
<abstract> integrity constraints (ic's) in order to optimize the evaluation  </abstract>::line_number::10
<abstract> of queries. The process is well understood in the case  </abstract>::line_number::11
<abstract> of unions of select-project-join queries (i.e., nonrecursive  </abstract>::line_number::12
<abstract> datalog). For arbitrary datalog programs, however, the  </abstract>::line_number::13
<abstract> issue has largely remained an unsolved problem. This  </abstract>::line_number::14
<abstract> paper studies this problem and shows when semantic query  </abstract>::line_number::15
<abstract> optimization can be completely done in recursive rules  </abstract>::line_number::16
<abstract> provided that order constraints and negated EDB subgoals  </abstract>::line_number::17
<abstract> appear only in the recursive rules, but not in the ic's.  </abstract>::line_number::18
<abstract> If either order constraints or negated EDB subgoals are  </abstract>::line_number::19
<abstract> introduced in ic's, then the problem of semantic query  </abstract>::line_number::20
<abstract> optimization becomes undecidable. Since semantic query  </abstract>::line_number::21
<abstract> optimization is closely related to the containment problem  </abstract>::line_number::22
<abstract> of a datalog program in a union of conjunctive queries, our  </abstract>::line_number::23
<abstract> results also imply new decidability and undecidability results  </abstract>::line_number::24
<abstract> for that problem when order constraints and negated EDB  </abstract>::line_number::25
<abstract> subgoals are used.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Though the C preprocessor provides necessary language features, it does so in an unstructured way. The lexical nature of cpp creates numerous problems for software engineers  </abstract>::line_number::7
<abstract> and their tools, all stemming from the chasm between the engineer's view of the source code  </abstract>::line_number::8
<abstract> and the compiler's view. The simplest way to reduce this problem is to minimize use of the  </abstract>::line_number::9
<abstract> preprocessor. In light of the data collected in a prior empirical analysis, this paper describes  </abstract>::line_number::10
<abstract> a tool to aid the software engineer in analyses targeted at replacing preprocessor constructs  </abstract>::line_number::11
<abstract> with language features. Existing tools for analyzing C source in the context of the preprocessor are unsuitable for such transformations. This work introduces a new approach: tightly  </abstract>::line_number::12
<abstract> integrating the preprocessor with a C language parser, permitting the code to be analyzed at  </abstract>::line_number::13
<abstract> both the preprocessor and syntactic levels simultaneously. The front-end framework, called  </abstract>::line_number::14
<abstract> PCp 3 , combines a preprocessor, a parser, and arbitrary Perl subroutine "hooks" invoked upon  </abstract>::line_number::15
<abstract> various preprocessor and parser events. PCp 3 's strengths and weaknesses are discussed in the  </abstract>::line_number::16
<abstract> context of several program understanding and transformation tools, including a conservative  </abstract>::line_number::17
<abstract> analysis to support replacing cpp's #define directives with C++ language features.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::9
<abstract> This paper describes extensions to an automatic dynamic compilation framework to support  </abstract>::line_number::10
<abstract> optimized event dispatching in the SPIN extensible operating system.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::3
<abstract> Compiler-directed cache prefetching has the potential to hide much of the high memory latency seen by  </abstract>::line_number::4
<abstract> current and future high-performance processors. However, prefetching is not without costs, particularly on a  </abstract>::line_number::5
<abstract> multiprocessor. Prefetching can negatively affect bus utilization, overall cache miss rates, memory latencies and  </abstract>::line_number::6
<abstract> data sharing.  </abstract>::line_number::7
<abstract> We simulate the effects of a compiler-directed prefetching algorithm, running on a range of bus-based multiprocessors. We show that, despite a high memory latency, this architecture does not necessarily support prefetching  </abstract>::line_number::8
<abstract> well, in some cases actually causing performance degradations. We pinpoint several problems with prefetching on  </abstract>::line_number::9
<abstract> a shared memory architecture (additional conflict misses, no reduction in the data sharing traffic and associated  </abstract>::line_number::10
<abstract> latencies, a multiprocessor's greater sensitivity to memory utilization and the sensitivity of the cache hit rate to  </abstract>::line_number::11
<abstract> prefetch distance) and measure their effect on performance. We then solve those problems through architectural  </abstract>::line_number::12
<abstract> techniques and heuristics for prefetching that could be easily incorporated into a compiler: 1) victim caching,  </abstract>::line_number::13
<abstract> which eliminates most of the cache conflict misses caused by prefetching in a direct-mapped cache, 2) special  </abstract>::line_number::14
<abstract> prefetch algorithms for shared data, which significantly improve the ability of our basic prefetching algorithm  </abstract>::line_number::15
<abstract> to prefetch invalidation misses, and 3) compiler-based shared data restructuring, which eliminates many of the  </abstract>::line_number::16
<abstract> invalidation misses the basic prefetching algorithm doesn't predict. The combined effect of these improvements  </abstract>::line_number::17
<abstract> is to make prefetching effective over a much wider range of memory architectures.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Previous approaches of analyzing spontaneously spoken language often have been based  </abstract>::line_number::9
<abstract> on encoding syntactic and semantic knowledge manually and symbolically. While there  </abstract>::line_number::10
<abstract> has been some progress using statistical or connectionist language models, many current  </abstract>::line_number::11
<abstract> spoken-language systems still use a relatively brittle, hand-coded symbolic grammar or  </abstract>::line_number::12
<abstract> symbolic semantic component.  </abstract>::line_number::13
<abstract> In contrast, we describe a so-called screening approach for learning robust processing  </abstract>::line_number::14
<abstract> of spontaneously spoken language. A screening approach is a flat analysis which uses shallow sequences of category representations for analyzing an utterance at various syntactic,  </abstract>::line_number::15
<abstract> semantic and dialog levels. Rather than using a deeply structured symbolic analysis, we  </abstract>::line_number::16
<abstract> use a flat connectionist analysis. This screening approach aims at supporting speech and  </abstract>::line_number::17
<abstract> language processing by using (1) data-driven learning and (2) robustness of connectionist  </abstract>::line_number::18
<abstract> networks. In order to test this approach, we have developed the screen system which is  </abstract>::line_number::19
<abstract> based on this new robust, learned and flat analysis.  </abstract>::line_number::20
<abstract> In this paper, we focus on a detailed description of screen's architecture, the flat  </abstract>::line_number::21
<abstract> syntactic and semantic analysis, the interaction with a speech recognizer, and a detailed  </abstract>::line_number::22
<abstract> evaluation analysis of the robustness under the influence of noisy or incomplete input.  </abstract>::line_number::23
<abstract> The main result of this paper is that flat representations allow more robust processing of  </abstract>::line_number::24
<abstract> spontaneous spoken language than deeply structured representations. In particular, we  </abstract>::line_number::25
<abstract> show how the fault-tolerance and learning capability of connectionist networks can support  </abstract>::line_number::26
<abstract> a flat analysis for providing more robust spoken-language processing within an overall  </abstract>::line_number::27
<abstract> hybrid symbolic/connectionist framework.   </abstract>::line_number::28
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper presents a comprehensive approach for model-based diagnosis which includes proposals for characterizing and computing preferred diagnoses, assuming that the  </abstract>::line_number::9
<abstract> system description is augmented with a system structure (a directed graph explicating the  </abstract>::line_number::10
<abstract> interconnections between system components). Specifically, we first introduce the notion of  </abstract>::line_number::11
<abstract> a consequence, which is a syntactically unconstrained propositional sentence that characterizes all consistency-based diagnoses and show that standard characterizations of diagnoses,  </abstract>::line_number::12
<abstract> such as minimal conflicts, correspond to syntactic variations on a consequence. Second,  </abstract>::line_number::13
<abstract> we propose a new syntactic variation on the consequence known as negation normal form  </abstract>::line_number::14
<abstract> (NNF) and discuss its merits compared to standard variations. Third, we introduce a basic  </abstract>::line_number::15
<abstract> algorithm for computing consequences in NNF given a structured system description. We  </abstract>::line_number::16
<abstract> show that if the system structure does not contain cycles, then there is always a linear-size  </abstract>::line_number::17
<abstract> consequence in NNF which can be computed in linear time. For arbitrary system structures, we show a precise connection between the complexity of computing consequences  </abstract>::line_number::18
<abstract> and the topology of the underlying system structure. Finally, we present an algorithm  </abstract>::line_number::19
<abstract> that enumerates the preferred diagnoses characterized by a consequence. The algorithm is  </abstract>::line_number::20
<abstract> shown to take linear time in the size of the consequence if the preference criterion satisfies  </abstract>::line_number::21
<abstract> some general conditions.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Standard safety analysis techniques are often ineffective when computers and digital devices are integrated into plant control. The Safeware methodology and its  </abstract>::line_number::9
<abstract> set of supporting safety analysis techniques (and prototype tools) includes modeling  </abstract>::line_number::10
<abstract> and hazard analysis of complex systems where the components may be a mixture of  </abstract>::line_number::11
<abstract> humans, hardware, and software. This paper describes one of the Safeware hazard  </abstract>::line_number::12
<abstract> analysis techniques, Software Deviation Analysis, that incorporates the beneficial features of HAZOP (such as guidewords, deviations, exploratory analysis, and a systems  </abstract>::line_number::13
<abstract> engineering approach) into an automated procedure that is capable of handling the  </abstract>::line_number::14
<abstract> complexity and logical nature of computer software.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::5
<abstract> This paper describes PBSM (Partition Based Spatial-Merge), a new algorithm for performing spatial join operation. This algorithm is especially effective when neither of the inputs to the join have an index on the joining  </abstract>::line_number::6
<abstract> attribute. Such a situation could arise if both inputs to the join are intermediate results in a complex query, or in  </abstract>::line_number::7
<abstract> a parallel environment where the inputs must be dynamically redistributed. The PBSM algorithm partitions the  </abstract>::line_number::8
<abstract> inputs into manageable chunks, and joins them using a computational geometry based plane-sweeping technique. This paper also presents a performance study comparing the the traditional indexed nested loops join  </abstract>::line_number::9
<abstract> algorithm, a spatial join algorithm based on joining spatial indices, and the PBSM algorithm. These comparisons  </abstract>::line_number::10
<abstract> are based on complete implementations of these algorithms in Paradise, a database system for handling GIS applications. Using real data sets, the performance study examines the behavior of these spatial join algorithms in a  </abstract>::line_number::11
<abstract> variety of situations, including the cases when both, one, or none of the inputs to the join have an suitable index.  </abstract>::line_number::12
<abstract> The study also examines the effect of clustering the join inputs on the performance of these join algorithms. The  </abstract>::line_number::13
<abstract> performance comparisons demonstrates the feasibility, and applicability of the PBSM join algorithm.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::3
<abstract> An exhaustive dataflow-analysis algorithm associates with each point in a program a set of dataflow facts  </abstract>::line_number::4
<abstract> that are guaranteed to hold whenever that point is reached during program execution. By contrast, a  </abstract>::line_number::5
<abstract> demand dataflow-analysis algorithm determines whether a single given dataflow fact holds at a single given  </abstract>::line_number::6
<abstract> point.  </abstract>::line_number::7
<abstract> This paper presents a new demand algorithm for interprocedural dataflow analysis. The algorithm has  </abstract>::line_number::8
<abstract> four important properties:  </abstract>::line_number::9
<abstract> g It provides precise (meet-over-all-interprocedurally-valid-paths) solutions to a large class of problems.  </abstract>::line_number::10
<abstract> g It has a polynomial worst-case cost for both a single demand and a sequence of all possible demands.  </abstract>::line_number::11
<abstract> g The worst-case total cost of the sequence of all possible demands is no worse than the worst-case cost  </abstract>::line_number::12
<abstract> of a single run of the current best exhaustive algorithm.  </abstract>::line_number::13
<abstract> g Experimental results show that in many situations (e.g., when only a small number of demands are  </abstract>::line_number::14
<abstract> made, or when most demands are answered yes) the demand algorithm is superior to the current best  </abstract>::line_number::15
<abstract> exhaustive algorithm.   </abstract>::line_number::16
<abstract>  The lexical-analysis (or scanning) phase of a compiler attempts to partition the input stream into a sequence of tokens.  </abstract>::line_number::3
<abstract> The convention in most languages is that the input is scanned left to right, and each token identified is a maximal  </abstract>::line_number::4
<abstract> munch of the remaining inputthe longest prefix of the remaining input that is a token of the language. Most textbooks on compiling have extensive discussions of lexical analysis in terms of finite-state automata and regular expressions: Token classes are defined by a set of regular expressions R i , 1 i k, and the lexical analyzer is based on some  </abstract>::line_number::5
<abstract> form of finite-state automaton for recognizing the language L (R 1 + R 2 + . . . + R k ). However, the treatment is unsatisfactory in one respect: The theory of finite-state automata assumes that the end of the input stringi.e., the right-hand-side boundary of the candidate for recognitionis known a priori, whereas a scanner must identify the next token  </abstract>::line_number::6
<abstract> without knowing a definite bound on the extent of the token.  </abstract>::line_number::7
<abstract> Although most of the standard compiler textbooks discuss this issue, the solution they sketch out is one thatfor  </abstract>::line_number::8
<abstract> certain sets of token definitionscan cause the scanner to exhibit quadratic behavior in the worst case. This property is  </abstract>::line_number::9
<abstract> not only dissatisfying, it blemishes an otherwise elegant treatment of lexical analysis.  </abstract>::line_number::10
<abstract> In this paper, we rectify this defect: We show that, given a deterministic finite-state automaton that recognizes the  </abstract>::line_number::11
<abstract> tokens of a language, maximal-munch tokenization can always be performed in time linear in the size of the input.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::6
<abstract> DEVise is a data exploration system that allows users to easily develop, browse, and share visual presentations of large  </abstract>::line_number::7
<abstract> tabular datasets (possibly containing or referencing multimedia objects) from several sources. The DEVise framework  </abstract>::line_number::8
<abstract> is being implemented in a tool that has been already successfully applied to a variety of real applications by a number  </abstract>::line_number::9
<abstract> of user groups.  </abstract>::line_number::10
<abstract> Our emphasis is on developing an intuitive yet powerful set of querying and visualization primitives that can be  </abstract>::line_number::11
<abstract> easily combined to develop a rich set of visual presentations  </abstract>::line_number::12
<abstract> that integrate data from a wide range of application domains. While DEVise is a powerful visualization tool, its  </abstract>::line_number::13
<abstract> greatest strengths are the ability to interactively explore a  </abstract>::line_number::14
<abstract> visual presentation of the data at any level of detail (including retrieving individual data records), and the ability to  </abstract>::line_number::15
<abstract> seamlessly query and combine data from a variety of local  </abstract>::line_number::16
<abstract> and remote sources. In this paper, we present the DEVise  </abstract>::line_number::17
<abstract> framework, describe the current tool, and report on our experience in applying it to several real applications.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Web caches can not only reduce network traffic and  </abstract>::line_number::6
<abstract> downloading latency, but can also affect the distribution of web traffic over the network through cost-aware caching. This paper introduces GreedyDual-Size, which incorporates locality with cost and size  </abstract>::line_number::7
<abstract> concerns in a simple and non-parameterized fashion  </abstract>::line_number::8
<abstract> for high performance. Trace-driven simulations show  </abstract>::line_number::9
<abstract> that with the appropriate cost definition, GreedyDual-Size outperforms existing web cache replacement algorithms in many aspects, including hit ratios, latency reduction and network cost reduction. In addition, GreedyDual-Size can potentially improve the  </abstract>::line_number::10
<abstract> performance of main-memory caching of Web documents.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We examine the effects of latent variables, between  </abstract>::line_number::7
<abstract> individual variability and measurement error in the  </abstract>::line_number::8
<abstract> outcome on commonly used methods for the analysis of longitudinal ordinal data, such as marginal  </abstract>::line_number::9
<abstract> and cluster-specific models. The impact of such variability becomes very clear when viewed in the context of structural equation modeling (e.g. Muthen  </abstract>::line_number::10
<abstract> 1979, 1983, 1984, 1988). The structural equation  </abstract>::line_number::11
<abstract> formulation also provides insight into the assumptions and differences in interpretation of regression  </abstract>::line_number::12
<abstract> coefficients of these various methods of analysis. We  </abstract>::line_number::13
<abstract> explore the potential for using structural equations  </abstract>::line_number::14
<abstract> to model random effects and to adjust for measurement error, and in the process compare results  </abstract>::line_number::15
<abstract> from marginal modeling using a SAS GEE routine  </abstract>::line_number::16
<abstract> (Karim and Zeger, 1988), Qu's GAUSS program  </abstract>::line_number::17
<abstract> (Qu, 1992) for generalized mixed models using GEE,  </abstract>::line_number::18
<abstract> the MIXOR package for cluster-specific mixed effects models (Hedeker and Gibbons, 1994), and LIS-COMP (Muthen, 1988) for structural equation models. These approaches are illustrated in a longitudinal data set of sleep disorders.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The techniques which are used to implement interprocedural data flow analyzers can be generally  </abstract>::line_number::7
<abstract> divided into two parts: the call string and the functional approach [18]. Both differ in their time and space  </abstract>::line_number::8
<abstract> complexity as well as in the preciseness due to properties of the abstract domains and transfer functions.  </abstract>::line_number::9
<abstract> We have developed a data flow analyzer generator PAG [2] which is able to produce interprocedural  </abstract>::line_number::10
<abstract> analyzers for both techniques. We specified two variants of constant propagation working in an ANSI-C  </abstract>::line_number::11
<abstract> compiler; a copy constant propagation that uses distributive transfer function and can be solved precisely,  </abstract>::line_number::12
<abstract> even interprocedurally [13], and a full constant propagator which includes an interpreter for expressions  </abstract>::line_number::13
<abstract> of the language. We present the practical relevant results applying both analyzers to a rather fair set of  </abstract>::line_number::14
<abstract> real-world programs and compare the space/time consumption of the analyzers versus their preciseness.   </abstract>::line_number::15
<abstract>  ABSTRACT  </abstract>::line_number::16
<abstract> In an open network computing environment, a workstation cannot be trusted to  </abstract>::line_number::17
<abstract> identify its users correctly to network services. Kerberos provides an alternative  </abstract>::line_number::18
<abstract> approach whereby a trusted third-party authentication service is used to verify users'  </abstract>::line_number::19
<abstract> identities. This paper gives an overview of the Kerberos authentication model as implemented for MIT's Project Athena. It describes the protocols used by clients, servers, and  </abstract>::line_number::20
<abstract> Kerberos to achieve authentication. It also describes the management and replication of  </abstract>::line_number::21
<abstract> the database required. The views of Kerberos as seen by the user, programmer, and  </abstract>::line_number::22
<abstract> administrator are described. Finally, the role of Kerberos in the larger Athena picture is  </abstract>::line_number::23
<abstract> given, along with a list of applications that presently use Kerberos for user authentication. We describe the addition of Kerberos authentication to the Sun Network File System as a case study for integrating Kerberos with an existing application.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::6
<abstract> DEVise is a data exploration system that allows users to easily develop, browse, and share visual presentations of large  </abstract>::line_number::7
<abstract> tabular datasets (possibly containing or referencing multimedia objects) from several sources. The DEVise framework  </abstract>::line_number::8
<abstract> is being implemented in a tool that has been already successfully applied to a variety of real applications by a number  </abstract>::line_number::9
<abstract> of user groups.  </abstract>::line_number::10
<abstract> Our emphasis is on developing an intuitive yet powerful set of querying and visualization primitives that can be  </abstract>::line_number::11
<abstract> easily combined to develop a rich set of visual presentations  </abstract>::line_number::12
<abstract> that integrate data from a wide range of application domains. While DEVise is a powerful visualization tool, its  </abstract>::line_number::13
<abstract> greatest strengths are the ability to interactively explore a  </abstract>::line_number::14
<abstract> visual presentation of the data at any level of detail (includ-ing retrieving individual data records), and the ability to  </abstract>::line_number::15
<abstract> seamlessly query and combine data from a variety of local  </abstract>::line_number::16
<abstract> and remote sources. In this paper, we present the DEVise  </abstract>::line_number::17
<abstract> framework, describe the current tool, and report on our experience in applying it to several real applications.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The complexity of parallel applications and parallel processor scheduling policies makes both exact analysis and simulation difficult, if not intractable, for large systems. In this paper we propose a new approach  </abstract>::line_number::9
<abstract> to performance modeling of multiprogrammed processor scheduling policies, that of interpolation approximations. We first define a workload model that contains parameters for the essential properties of parallel  </abstract>::line_number::10
<abstract> applications with respect to scheduling discipline performance, yet lends itself to mathematical analysis. Key  </abstract>::line_number::11
<abstract> features of the workload model include general distribution of total job processing time, general distribution  </abstract>::line_number::12
<abstract> of available job parallelism, and a simple characterization of parallelism overheads. We then show that one  </abstract>::line_number::13
<abstract> can find specific values of the system parameters for which the parallel system under a given scheduling  </abstract>::line_number::14
<abstract> policy reduces to a queueing system with a known (closed-form) solution. Finally, interpolation between  </abstract>::line_number::15
<abstract> the points with known solutions is used to arrive at mean response time estimates that hold over the entire  </abstract>::line_number::16
<abstract> system parameter space. The interpolation approximations readily yield insight into policy behavior and are  </abstract>::line_number::17
<abstract> easy to evaluate for systems with hundreds of processors.  </abstract>::line_number::18
<abstract> We illustrate the approach by developing and validating models of three scheduling policies, under the  </abstract>::line_number::19
<abstract> assumptions of linear job execution rates and independence between job parallelism and processing time.  </abstract>::line_number::20
<abstract> We discuss several insights and results obtained from the analysis of the three policies under the assumed  </abstract>::line_number::21
<abstract> workloads. One result clarifies and generalizes observations in two previous simulation studies of how policy  </abstract>::line_number::22
<abstract> performance varies with the coefficient of variation in job processing requirement. Another result of the  </abstract>::line_number::23
<abstract> interpolation models yields new insight into how policy performance varies with job parallelism. We also  </abstract>::line_number::24
<abstract> comment on the generalizations of these insights for workloads with less restrictive assumptions.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We present new finite difference schemes for the incompressible Navier-Stokes equations. The schemes are based on two spatial differencing methods, one is fourth-order  </abstract>::line_number::5
<abstract> accurate and the other is sixth-order accurate. The temporal differencing is based on  </abstract>::line_number::6
<abstract> backward differencing formulas. The schemes use non-staggered grids and satisfy regularity estimates, guaranteeing smoothness of the solutions. The schemes are computationally  </abstract>::line_number::7
<abstract> efficient. Computational results demonstrating the accuracy are presented.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::11
<abstract> The performance potential of run-to-completion (RTC) parallel  </abstract>::line_number::12
<abstract> processor scheduling policies is investigated by examining  </abstract>::line_number::13
<abstract> whether (1) application execution rate characteristics such as average parallelism (avg) and processor working set (pws) and/or (2)  </abstract>::line_number::14
<abstract> limited preemption can be used to improve the performance of  </abstract>::line_number::15
<abstract> these policies. We address the first question by comparing policies  </abstract>::line_number::16
<abstract> (previous as well as new) that differ only in whether or not they  </abstract>::line_number::17
<abstract> use execution rate characteristics and by examining a wider range  </abstract>::line_number::18
<abstract> of the workload parameter space than previous studies. We address  </abstract>::line_number::19
<abstract> the second question by comparing a simple two-level queueing  </abstract>::line_number::20
<abstract> policy with RTC scheduling in the second level queue against  </abstract>::line_number::21
<abstract> RTC policies that don't allow any preemption and against dynamic  </abstract>::line_number::22
<abstract> equiallocation (EQ).  </abstract>::line_number::23
<abstract> Using simulation to estimate mean response times we find that for  </abstract>::line_number::24
<abstract> promising RTC policies such as adaptive static partitioning (ASP)  </abstract>::line_number::25
<abstract> and shortest demand first (SDF), a maximum allocation constraint  </abstract>::line_number::26
<abstract> that is for all practical purposes independent of avg and pws provides greater and more consistent improvement in policy performance than using avg or pws. Also, under the assumption that job  </abstract>::line_number::27
<abstract> demand information is unavailable to the scheduler we show that  </abstract>::line_number::28
<abstract> the ASP-max policy outperforms all previous high performance  </abstract>::line_number::29
<abstract> RTC policies for workloads with coefficient of variation in processing requirement greater than one. Furthermore, a two-level  </abstract>::line_number::30
<abstract> queue that allows at most one preemption per job outperforms  </abstract>::line_number::31
<abstract> ASP-max but is not competitive with EQ.   </abstract>::line_number::32
<abstract>  Abstract  </abstract>::line_number::14
<abstract> The Discrete Cosine Transform (DCT) is widely used in lossy image and video compression schemes  </abstract>::line_number::15
<abstract> such as JPEG and MPEG. In this paper we describe RD-OPT, an efficient algorithm for constructing  </abstract>::line_number::16
<abstract> DCT quantization tables with optimal rate-distortion tradeoffs for a given image. The algorithm uses  </abstract>::line_number::17
<abstract> DCT coefficient distribution statistics in a novel way and uses a dynamic programming strategy to  </abstract>::line_number::18
<abstract> produce optimal quantization tables over a wide range of rates and distortions. It can be used to  </abstract>::line_number::19
<abstract> compress images at any desired signal-to-noise ratio or compressed size.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We consider the problem of software generalization: Given a program component C, create  </abstract>::line_number::10
<abstract> a parameterized program component C 0 such that C 0 is usable in a wider variety of syntactic  </abstract>::line_number::11
<abstract> contexts than C. Furthermore, C 0 should be a semantically meaningful generalization of C;  </abstract>::line_number::12
<abstract> namely, there must exist an instantiation of C 0 that is equivalent in functionality to C.  </abstract>::line_number::13
<abstract> In this paper, we present an algorithm that generalizes C functions via type inference. The  </abstract>::line_number::14
<abstract> original functions operate on specific data types; the result of generalization is a collection of  </abstract>::line_number::15
<abstract> C++ function templates that operate on parameterized types. This version of the generalization  </abstract>::line_number::16
<abstract> problem is useful in the context of converting existing C programs to C++.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We show the interconvertibility of context-free-language reachability problems and a class  </abstract>::line_number::5
<abstract> of set-constraint problems: given a context-free-language reachability problem, we show how to  </abstract>::line_number::6
<abstract> construct a set-constraint problem whose answer gives a solution to the reachability problem;  </abstract>::line_number::7
<abstract> given a set-constraint problem, we show how to construct a context-free-language reachability  </abstract>::line_number::8
<abstract> problem whose answer gives a solution to the set-constraint problem. The interconvertibility  </abstract>::line_number::9
<abstract> of these two formalisms offers an conceptual advantage akin to the advantage gained from the  </abstract>::line_number::10
<abstract> interconvertibility of finite-state automata and regular expressions in language theory, namely,  </abstract>::line_number::11
<abstract> a problem can be formulated in whichever formalism is most natural. It also offers some insight into the "O(n 3 ) bottleneck" for different types of program-analysis problems, and allows  </abstract>::line_number::12
<abstract> results previously obtained for context-free-language reachability problems to be applied to set  </abstract>::line_number::13
<abstract> constraint problems.   </abstract>::line_number::14
<abstract>  Abstract. This paper provides a means for comparing various computer codes for solving large  </abstract>::line_number::12
<abstract> scale mixed complementarity problems. We discuss inadequacies in how solvers are currently  </abstract>::line_number::13
<abstract> compared, and present a testing environment that addresses these inadequacies. This testing  </abstract>::line_number::14
<abstract> environment consists of a library of test problems, along with GAMS and MATLAB interfaces that  </abstract>::line_number::15
<abstract> allow these problems to be easily accessed. The environment is intended for use as a tool by other  </abstract>::line_number::16
<abstract> researchers to better understand both their algorithms and their implementations, and to direct  </abstract>::line_number::17
<abstract> research toward problem classes that are currently the most challenging. As an initial benchmark,  </abstract>::line_number::18
<abstract> eight different algorithm implementations for large scale mixed complementarity problems are  </abstract>::line_number::19
<abstract> briefly described and tested with default parameter settings using the new testing environment.   </abstract>::line_number::20
<abstract>  Abstract. Several types of multi-coordination methods for block-angular programs are considered. We present a computational comparison of synchronous multi-coordination methods. The most  </abstract>::line_number::4
<abstract> efficient of these approaches is shown to involve an intermediate number of blocks in the coordination  </abstract>::line_number::5
<abstract> phase. We also develop a new stabilization algorithm and present asynchronous multi-coordination  </abstract>::line_number::6
<abstract> schemes, which are particularly useful when the number of blocks exceeds the number of available  </abstract>::line_number::7
<abstract> processors or when the block sizes vary significantly.   </abstract>::line_number::8
<abstract>  Abstract. In this paper we examine preconditioning operators for regular elliptic  </abstract>::line_number::10
<abstract> systems of partial differential operators. We obtain general conditions under which the  </abstract>::line_number::11
<abstract> preconditioned systems are bounded. We also provide some useful guidelines for choosing  </abstract>::line_number::12
<abstract> left and right preconditioning operators for regular elliptic systems. The condition numbers  </abstract>::line_number::13
<abstract> of the discrete operators arising from these preconditioned operators are shown to be  </abstract>::line_number::14
<abstract> bounded independent of grid spacing. Several examples of the two-dimensional regular  </abstract>::line_number::15
<abstract> elliptic systems are discussed, including scalar elliptic operators and the Stokes operator  </abstract>::line_number::16
<abstract> with several different boundary conditions. Several preconditioners for these regular elliptic  </abstract>::line_number::17
<abstract> systems are presented and used in numerical experiments illustrating the theoretical results.   </abstract>::line_number::18
<abstract>  ABSTRACT  </abstract>::line_number::8
<abstract> Software engineering applications require sophisticated  </abstract>::line_number::9
<abstract> object management system support for creating and  </abstract>::line_number::10
<abstract> manipulating software objects. One of the key issues for  </abstract>::line_number::11
<abstract> object management systems is distribution. Addressing this issue in the context of software engineering applications is particularly challenging because they have  </abstract>::line_number::12
<abstract> widely varying object access profiles. Two fundamental  </abstract>::line_number::13
<abstract> approaches to dealing with distribution are the object  </abstract>::line_number::14
<abstract> server architecture, where objects are shipped to the  </abstract>::line_number::15
<abstract> application program, and the operation server architecture, where operation requests are shipped to where the  </abstract>::line_number::16
<abstract> objects reside. We compare these architectures experimentally to determine the conditions under which each  </abstract>::line_number::17
<abstract> performs better.   </abstract>::line_number::18
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> Each of the Moufang identities in a quasigroup implies that the  </abstract>::line_number::6
<abstract> quasigroup is a loop.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In order to analyze a program that involves pointers, it  </abstract>::line_number::6
<abstract> is necessary to have (safe) information about what each  </abstract>::line_number::7
<abstract> pointer points to. There are many different approaches  </abstract>::line_number::8
<abstract> to computing points-to information. This paper addresses techniques for flow- and context-insensitive in-terprocedural analysis of stack-based storage.  </abstract>::line_number::9
<abstract> The paper makes two contributions to work in this  </abstract>::line_number::10
<abstract> area:  </abstract>::line_number::11
<abstract> * The first contribution is a set of experiments that  </abstract>::line_number::12
<abstract> explore the trade-offs between techniques previously defined by Lars Andersen and Bjarne Steens-gaard. The former has a cubic worst-case running  </abstract>::line_number::13
<abstract> time, while the latter is essentially linear. However, the former may be much more precise than  </abstract>::line_number::14
<abstract> the latter. We have found that in practice, Ander-sen's algorithm is consistently more precise than  </abstract>::line_number::15
<abstract> Steensgaard's. For small programs, there is very  </abstract>::line_number::16
<abstract> little difference in the times required by the two  </abstract>::line_number::17
<abstract> approaches; however, for larger programs, Ander-sen's algorithm can be much slower than Steens  </abstract>::line_number::18
<abstract> gaard's.  </abstract>::line_number::19
<abstract> * The second contribution is the definition of two  </abstract>::line_number::20
<abstract> new algorithms. The first algorithm can be "tuned"  </abstract>::line_number::21
<abstract> so that its worst-case time and space requirements,  </abstract>::line_number::22
<abstract> as well as its accuracy range from those of Steens-gaard to those of Andersen. We have experimented  </abstract>::line_number::23
<abstract> with several versions of this algorithm; one version  </abstract>::line_number::24
<abstract> provided a significant increase in accuracy over  </abstract>::line_number::25
<abstract> Steensgaard's algorithm, while keeping the running time within a factor of two.  </abstract>::line_number::26
<abstract> The second algorithm uses the first as a subroutine. Its worst-case time and space requirements  </abstract>::line_number::27
<abstract> are a factor of log N (where N is the number of  </abstract>::line_number::28
<abstract> variables in the program) worse than those of  </abstract>::line_number::29
<abstract> Steensgaard's algorithm. In practice, it appears to   </abstract>::line_number::30
<abstract>  run about ten times slower than Steensgaard's algorithm; however it is significantly more accurate  </abstract>::line_number::33
<abstract> than Steensgaard's algorithm, and significantly  </abstract>::line_number::34
<abstract> faster than Andersen's algorithm on large  </abstract>::line_number::35
<abstract> programs.   </abstract>::line_number::36
<abstract>  Abstract  </abstract>::line_number::7
<abstract> To speed up multidimensional data analysis,  </abstract>::line_number::8
<abstract> database systems frequently precompute aggregates on some subsets of dimensions and  </abstract>::line_number::9
<abstract> their corresponding hierarchies. This improves  </abstract>::line_number::10
<abstract> query response time. However, the decision of  </abstract>::line_number::11
<abstract> what and how much to precompute is a difficult one. It is further complicated by the fact  </abstract>::line_number::12
<abstract> that precomputation in the presence of hierarchies can result in an unintuitively large increase in the amount of storage required by the  </abstract>::line_number::13
<abstract> database. Hence, it is interesting and useful  </abstract>::line_number::14
<abstract> to estimate the storage blowup that will result from a proposed set of precomputations  </abstract>::line_number::15
<abstract> without actually computing them. We propose  </abstract>::line_number::16
<abstract> three strategies for this problem: one based on  </abstract>::line_number::17
<abstract> sampling, one based on mathematical approximation, and one based on probabilistic counting. We investigate the accuracy of these algorithms in estimating the blowup for different  </abstract>::line_number::18
<abstract> data distributions and database schemas. The  </abstract>::line_number::19
<abstract> algorithm based upon probabilistic counting is  </abstract>::line_number::20
<abstract> particularly attractive, since it estimates the  </abstract>::line_number::21
<abstract> storage blowup to within provable error bounds  </abstract>::line_number::22
<abstract> while performing only a single scan of the data.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::10
<abstract> An important problem faced by many database management  </abstract>::line_number::11
<abstract> systems is the "online object placement problem"|the  </abstract>::line_number::12
<abstract> problem of choosing a disk page to hold a newly allocated  </abstract>::line_number::13
<abstract> object. In the absence of clustering criteria, the goal is  </abstract>::line_number::14
<abstract> to maximize storage utilization. For main-memory based  </abstract>::line_number::15
<abstract> systems, simple heuristics exist that provide reasonable  </abstract>::line_number::16
<abstract> space utilization in the worst case and excellent utilization  </abstract>::line_number::17
<abstract> in typical cases. However, the storage management problem  </abstract>::line_number::18
<abstract> for databases includes significant additional challenges, such  </abstract>::line_number::19
<abstract> as minimizing I/O traffic, coping with crash recovery, and  </abstract>::line_number::20
<abstract> gracefully integrating space management with locking and  </abstract>::line_number::21
<abstract> logging.  </abstract>::line_number::22
<abstract> We survey several object placement algorithms, including  </abstract>::line_number::23
<abstract> techniques that can be found in commercial and research  </abstract>::line_number::24
<abstract> database systems. We then present a new object placement  </abstract>::line_number::25
<abstract> algorithm that we have designed for use in Shore, an  </abstract>::line_number::26
<abstract> object-oriented database system under development at the  </abstract>::line_number::27
<abstract> University of Wisconsin|Madison. Finally, we present  </abstract>::line_number::28
<abstract> results from a series of experiments involving actual Shore  </abstract>::line_number::29
<abstract> implementations of some of these algorithms. Our results  </abstract>::line_number::30
<abstract> show that while current object placement algorithms have  </abstract>::line_number::31
<abstract> serious performance deficiencies, including excessive CPU  </abstract>::line_number::32
<abstract> or main memory overhead, I/O traffic, or poor disk  </abstract>::line_number::33
<abstract> utilization, our new algorithm consistently demonstrates  </abstract>::line_number::34
<abstract> excellent performance in all of these areas.   </abstract>::line_number::35
<abstract>  Abstract  </abstract>::line_number::25
<abstract> A number of efficient learning algorithms achieve exact identification of an unknown function  </abstract>::line_number::26
<abstract> from some class using membership and equivalence queries. Using a standard transformation  </abstract>::line_number::27
<abstract> such algorithms can easily be converted to on-line learning algorithms that use membership  </abstract>::line_number::28
<abstract> queries. Under such a transformation the number of equivalence queries made by the query  </abstract>::line_number::29
<abstract> algorithm directly corresponds to the number of mistakes made by the on-line algorithm. In  </abstract>::line_number::30
<abstract> this paper we consider several of the natural classes known to be learnable in this setting, and  </abstract>::line_number::31
<abstract> investigate the minimum number of equivalence queries with accompanying counterexamples  </abstract>::line_number::32
<abstract> (or equivalently the minimum number of mistakes in the on-line model) that can be made by a  </abstract>::line_number::33
<abstract> learning algorithm that makes a polynomial number of membership queries and uses polynomial  </abstract>::line_number::34
<abstract> computation time. We are able both to reduce the number of equivalence queries used by the  </abstract>::line_number::35
<abstract> previous algorithms and often to prove matching lower bounds. As an example, consider the  </abstract>::line_number::36
<abstract> class of DNF formulas over n variables with at most k = O(log n) terms. Previously, the  </abstract>::line_number::37
<abstract> algorithm of Blum and Rudich [BR92] provided the best known upper bound of 2 O(k) log n for  </abstract>::line_number::38
<abstract> the minimum number of equivalence queries needed for exact identification. We greatly improve  </abstract>::line_number::39
<abstract> on this upper bound showing that exactly k counterexamples are needed if the learner knows k a  </abstract>::line_number::40
<abstract> priori and exactly k +1 counterexamples are needed if the learner does not know k a priori. This  </abstract>::line_number::41
<abstract> exactly matches known lower bounds [BC92]. For many of our results we obtain a complete  </abstract>::line_number::42
<abstract> characterization of the tradeoff between the number of membership and equivalence queries  </abstract>::line_number::43
<abstract> needed for exact identification. The classes we consider here are monotone DNF formulas, Horn  </abstract>::line_number::44
<abstract> sentences, O(log n)-term DNF formulas, read-k sat-j DNF formulas, read-once formulas over  </abstract>::line_number::45
<abstract> various bases, and deterministic finite automata.   </abstract>::line_number::46
<abstract>  Abstract. Network traffic can be reduced significantly if caching is utilized effectively. As an effort  </abstract>::line_number::3
<abstract> in this direction we study the replacement problem  </abstract>::line_number::4
<abstract> that arises in caching of multimedia objects. The size  </abstract>::line_number::5
<abstract> of objects and the cost of cache misses are assumed  </abstract>::line_number::6
<abstract> non-uniform. The non-uniformity of size is inherent in multimedia objects, and the non-uniformity of  </abstract>::line_number::7
<abstract> cost is due to the non-uniformity of size and the fact  </abstract>::line_number::8
<abstract> that the objects are scattered throughout the network.  </abstract>::line_number::9
<abstract> Although a special case of this problem, i.e. the case  </abstract>::line_number::10
<abstract> of uniform size and cost, has been extensively studied, the general case needs a great deal of study. We  </abstract>::line_number::11
<abstract> present a dynamic programming method of optimally  </abstract>::line_number::12
<abstract> solving the off-line and on-line versions of this problem, and discuss the complexity of this method.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::10
<abstract> High-performance Web servers are essential to meet the growing demands of the Internet and large-scale intranets. Satisfying these demands requires a thorough understanding of key  </abstract>::line_number::11
<abstract> factors affecting Web server performance. This paper presents  </abstract>::line_number::12
<abstract> empirical analysis illustrating how dynamic and static adaptivity can enhance Web server performance. Two research  </abstract>::line_number::13
<abstract> contributions support this conclusion.  </abstract>::line_number::14
<abstract> First, the paper presents results from a comprehensive empirical study of Web servers (such as Apache, Netscape Enterprise, PHTTPD, Zeus, and JAWS) over high-speed ATM networks. This study illustrates their relative performance and  </abstract>::line_number::15
<abstract> precisely pinpoints the server design choices that cause performance bottlenecks. We found that once network and disk  </abstract>::line_number::16
<abstract> I/O overheads are reduced to negligible constant factors, the  </abstract>::line_number::17
<abstract> main determinants of Web server performance are its protocol processing path and concurrency strategy. Moreover, no  </abstract>::line_number::18
<abstract> single strategy performs optimally for all load conditions and  </abstract>::line_number::19
<abstract> traffic types.  </abstract>::line_number::20
<abstract> Second, we describe the design techniques and optimizations used to develop JAWS, our high-performance, adaptive  </abstract>::line_number::21
<abstract> Web server. JAWS is an object-oriented Web server that was  </abstract>::line_number::22
<abstract> explicitly designed to alleviate the performance bottlenecks  </abstract>::line_number::23
<abstract> we identified in existing Web servers. It consistently outperforms all other Web servers over ATM networks. The performance optimizations used in JAWS include adaptive pre-spawned threading, fixed headers, cached date processing,  </abstract>::line_number::24
<abstract> and file caching. In addition, JAWS uses a novel software architecture that substantially improves its portability and flex  </abstract>::line_number::25
<abstract> This work was funded in part by NSF grant NCR-9628218, Object Technologies International, Eastman Kodak, and Siemens MED.  </abstract>::line_number::26
<abstract> ibility, relative to other Web servers. Our empirical results  </abstract>::line_number::27
<abstract> illustrate that highly efficient communication software is not  </abstract>::line_number::28
<abstract> antithetical to highly flexible software.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Conventional implementations of communication middle-ware (such as CORBA and traditional RPC toolkits) incur  </abstract>::line_number::10
<abstract> considerable overhead when used for performance-sensitive  </abstract>::line_number::11
<abstract> applications over high-speed networks. As gigabit networks  </abstract>::line_number::12
<abstract> become pervasive, inefficient middleware will force programmers to use lower-level mechanisms to achieve the necessary  </abstract>::line_number::13
<abstract> transfer rates. This is a serious problem for mission/life-critical applications (such as satellite surveillance and medical imaging).  </abstract>::line_number::14
<abstract> This paper compares the performance of several widely  </abstract>::line_number::15
<abstract> used communication middleware mechanisms on a high-speed ATM network. The middleware ranged from lower-level mechanisms (such as socket-based C interfaces and  </abstract>::line_number::16
<abstract> C++ wrappers for sockets) to higher-level mechanisms (such  </abstract>::line_number::17
<abstract> as RPC, hand-optimized RPC and two implementations of  </abstract>::line_number::18
<abstract> CORBA - Orbix 2.0.1 and ORBeline 2.0). These measurements reveal that the lower-level C and C++ implementations outperform the CORBA implementations significantly  </abstract>::line_number::19
<abstract> (the best CORBA throughput for remote transfer was roughly  </abstract>::line_number::20
<abstract> 75 to 80 percent of the best C/C++ throughput for sending scalar data types and only around 33 percent for sending structs containing binary fields), and the hand-optimized  </abstract>::line_number::21
<abstract> RPC code performs slightly better than the CORBA implementations. Our goal in precisely pinpointing the sources of  </abstract>::line_number::22
<abstract> overhead for communication middleware is to develop scalable and flexible CORBA implementations that can deliver  </abstract>::line_number::23
<abstract> gigabit data rates to applications.   </abstract>::line_number::24
<abstract>  Abstract. Computers today rely heavily on good utilization of their cache memory subsystems.  </abstract>::line_number::3
<abstract> Compilers are optimized for business applications, not scientific computing ones, however. Automatic  </abstract>::line_number::4
<abstract> tiling of basic numerical algorithms is simply not provided by any compiler. Thus, absolutely terrible  </abstract>::line_number::5
<abstract> cache performance is normal for scientific computing applications.  </abstract>::line_number::6
<abstract> Multigrid algorithms combine several numerical algorithms into a more complicated algorithm.  </abstract>::line_number::7
<abstract> In this paper, an algorithm is derived that allows for data to pass through cache exactly once per  </abstract>::line_number::8
<abstract> multigrid level during a V cycle before the level changes. This is optimal cache usage for large  </abstract>::line_number::9
<abstract> problems that do not fit entirely in cache.  </abstract>::line_number::10
<abstract> The new algorithm would appear to be quite complicated to implement, leading to spaghetti  </abstract>::line_number::11
<abstract> coding. Actually, an efficient implementation of the algorithm requires a rigid, highly structured  </abstract>::line_number::12
<abstract> coding style. A coding example is given that is suitable for almost all common discretization methods.  </abstract>::line_number::13
<abstract> Numerical experiments are provided that show that the new algorithm is up to an integer factor  </abstract>::line_number::14
<abstract> faster than the traditional implementation method for common multigrid parameter choices.   </abstract>::line_number::15
<abstract>  Abstract. We study a method for parallel solution of elliptic partial differential equations which  </abstract>::line_number::4
<abstract> decomposes the problem into a number of independent subproblems on subspaces of the underlying  </abstract>::line_number::5
<abstract> solution space. Using symmetries of the domain, we obtain up to 64 such subproblems for a 3  </abstract>::line_number::6
<abstract> dimensional cube and the method reduces to a direct solver. In the general case, or when the  </abstract>::line_number::7
<abstract> subproblems are solved only approximately, the method becomes an iterative method or can be used  </abstract>::line_number::8
<abstract> as a preconditioner. Bounds on the resulting convergence factors and condition numbers are given.   </abstract>::line_number::9
<abstract>  Abstract. Matrix-matrix multiplication is normally computed using one of the BLAS or a  </abstract>::line_number::4
<abstract> reinvention of part of the BLAS. Unfortunately, the BLAS were designed with small matrices in  </abstract>::line_number::5
<abstract> mind. When huge, well conditioned matrices are multiplied together, the BLAS perform like the  </abstract>::line_number::6
<abstract> blahs, even on vector machines. For matrices where the coefficients are well conditioned, Winograd's  </abstract>::line_number::7
<abstract> variant of Strassen's algorithm offers some relief, but is rarely available in a quality form on most  </abstract>::line_number::8
<abstract> computers. We reconsider this method and offer a highly portable solution based on the Level 3  </abstract>::line_number::9
<abstract> BLAS interface.   </abstract>::line_number::10
<abstract>  Abstract: This paper proposes a logic programming approach based on the  </abstract>::line_number::8
<abstract> application of a system of higher-order predicates put at disposal within ordinary logic programming languages such as prolog. These higher-order  </abstract>::line_number::9
<abstract> predicates parallel the higher-order functionals or combinators which form an  </abstract>::line_number::10
<abstract> established part of contemporary functional programming methodology.  </abstract>::line_number::11
<abstract> The suggested toolbox of higher-order predicates for composing logic programs  </abstract>::line_number::12
<abstract> is derived from one universal higher-order predicate. They take the form of  </abstract>::line_number::13
<abstract> recursion operators (in particular for expressing recursion along lists) intended  </abstract>::line_number::14
<abstract> to cover all commonly occurring recursion schemes in logic programming practice. Their theoretical sufficiency is proved and their practical adequacy is  </abstract>::line_number::15
<abstract> argued through examples.  </abstract>::line_number::16
<abstract> The recursion operators, denoting higher-order relations rather than functions, are brought about straightforwardly through a well-known metalogic  </abstract>::line_number::17
<abstract> programming technique, rendering superfluous the need for special higher-order unification mechanisms.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In this paper we present co-transformation, a novel approach to the mapping of execution information from the  </abstract>::line_number::6
<abstract> source code of a program to the object code for the purpose of worst-case execution time (WCET) analysis. Our  </abstract>::line_number::7
<abstract> approach is designed to handle the problems introduced by  </abstract>::line_number::8
<abstract> optimizing compilers, i.e. that the structure of the object  </abstract>::line_number::9
<abstract> code is very different from the structure of the source code.  </abstract>::line_number::10
<abstract> The co-transformer allows us to keep track of how different compiler transformations, including optimizations, influence the execution time of a program. This allows us to  </abstract>::line_number::11
<abstract> statically calculate the execution time of a program at the  </abstract>::line_number::12
<abstract> object code level, using information about the program execution obtained at the source code level.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This looks at the issues which arose in porting the pvmmake utility  </abstract>::line_number::9
<abstract> from PVM to MPI. Pvmmake is a PVM application which allows  </abstract>::line_number::10
<abstract> a user to send files, execute commands, and receive results from a  </abstract>::line_number::11
<abstract> single machine on any machine in the virtual machine. Its actions are  </abstract>::line_number::12
<abstract> controlled by the contents of a configuration file. Its most common  </abstract>::line_number::13
<abstract> use is to enable management of the development of a parallel program  </abstract>::line_number::14
<abstract> in a heterogeneous environment. A utility with the same features,  </abstract>::line_number::15
<abstract> mpimake, was coded up to run under LAM.  </abstract>::line_number::16
<abstract> Genetic programming is an algorithm which evolves an algorithm  </abstract>::line_number::17
<abstract> in the form of a program to solve your input problem. The implementation under MPI requires the transfer of dynamic data structures  </abstract>::line_number::18
<abstract> such as lists and trees. This paper discusses the match between the  </abstract>::line_number::19
<abstract> requirements of this algorithm and the datatype feature in MPI. A  </abstract>::line_number::20
<abstract> new library, MPI DataStruct is being developed which can transfer  </abstract>::line_number::21
<abstract> dynamic data structures, created with pointers, without intervention  </abstract>::line_number::22
<abstract> by the user.   </abstract>::line_number::23
<abstract>  Abstract. In the modern Internet environment, various types of  </abstract>::line_number::7
<abstract> data sources have become accessible, including multimedia data and web  </abstract>::line_number::8
<abstract> pages. Some of the fundamental assumptions in traditional databases,  </abstract>::line_number::9
<abstract> such as the existence of a global schema and data consistency maintained  </abstract>::line_number::10
<abstract> by a Data Base Administrator, are no longer true in many of the new  </abstract>::line_number::11
<abstract> data sources. We outline the DIOM [LP95b] object-oriented approach  </abstract>::line_number::12
<abstract> to build interoperable heterogeneous information systems despite the  </abstract>::line_number::13
<abstract> absence of global schema and the presence of data inconsistency. We describe the metadata catalog management component of DIOM, a key service in the support for interoperation among heterogeneous information  </abstract>::line_number::14
<abstract> sources. To support a flexible and customizable conection between information consumers and information producers, DIOM metadata catalog  </abstract>::line_number::15
<abstract> development utilizes the adaptive specification mechanisms, provided in  </abstract>::line_number::16
<abstract> DIOM interface description language, for explicit description of information consumers' domain query requirements and for object-oriented  </abstract>::line_number::17
<abstract> abstractions of information producers' information sources.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Modular architectures based on a microkernel are suitable bases for the design and implementation  </abstract>::line_number::6
<abstract> of operating systems. Prototype systems employing microkernel architectures are achieving the levels of  </abstract>::line_number::7
<abstract> functionality and performance expected and required of commercial products. Researchers at Carnegie  </abstract>::line_number::8
<abstract> Mellon University, the Open Software Foundation, and other sites are investigating implementations of a  </abstract>::line_number::9
<abstract> number of operating systems (e.g., Unix 1 , MS-DOS 2 ) that use the Mach microkernel. This paper describes  </abstract>::line_number::10
<abstract> the Mach microkernel, its use to support implementations of other operating systems, and the status of these  </abstract>::line_number::11
<abstract> efforts.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Optimistic replication is often viewed as essential for  </abstract>::line_number::6
<abstract> large scale systems and for supporting mobile computing. In optimistic replication, updates can be made concurrently to different file replicas, resulting in multiple  </abstract>::line_number::7
<abstract> versions of the file. To recover from these conflicting  </abstract>::line_number::8
<abstract> updates, after-the fact conflict resolution actions are  </abstract>::line_number::9
<abstract> required to recombine multiple versions into one. This  </abstract>::line_number::10
<abstract> paper defines these concepts and discusses approaches  </abstract>::line_number::11
<abstract> to measure them in optimistically replicated systems.  </abstract>::line_number::12
<abstract> Measurement of the number of conflicting updates  </abstract>::line_number::13
<abstract> and conflict resolution is important to judge the practicality of optimistic replication. An environment  </abstract>::line_number::14
<abstract> where conflicting updates are frequent will not be attractive since users cannot assume they have up-to-date  </abstract>::line_number::15
<abstract> data. Although many conflicts can be automatically  </abstract>::line_number::16
<abstract> resolved, some conflicts require user intervention; such  </abstract>::line_number::17
<abstract> conflicts cannot be too common. This paper shows an  </abstract>::line_number::18
<abstract> approach to measure the number of conflicting updates.  </abstract>::line_number::19
<abstract> From this measurement we derive the actual amount of  </abstract>::line_number::20
<abstract> work done by the user or system to resolve conflicts  </abstract>::line_number::21
<abstract> and the minimum amount of work required to resolve  </abstract>::line_number::22
<abstract> conflicts.   </abstract>::line_number::23
<abstract>  Abstract. We present a technique to study relations between weak and  </abstract>::line_number::6
<abstract> strong fi-normalisations in various typed -calculi. We first introduce a  </abstract>::line_number::7
<abstract> translation which translates a -term into a I-term, and show that a  </abstract>::line_number::8
<abstract> -term is strongly fi-normalisable if and only if its translation is weakly  </abstract>::line_number::9
<abstract> fi-normalisable. We then prove that the translation preserves typability  </abstract>::line_number::10
<abstract> of -terms in various typed -calculi. This enables us to establish the  </abstract>::line_number::11
<abstract> equivalence between weak and strong fi-normalisations in these typed  </abstract>::line_number::12
<abstract> -calculi. This translation can deal with Curry typing as well as Church  </abstract>::line_number::13
<abstract> typing, strengthening some recent closely related results. This may bring  </abstract>::line_number::14
<abstract> some insights into answering whether weak and strong fi-normalisations  </abstract>::line_number::15
<abstract> in all pure type systems are equivalent.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::10
<abstract> Multimedia applications are sensitive to I/O latency and jitter when accessing   </abstract>::line_number::11
<abstract> data in secondary storage. Transparent adaptive prefetching (TAP) uses software   </abstract>::line_number::12
<abstract> feedback to provide multimedia applications with file system quality of service   </abstract>::line_number::13
<abstract> (QoS) guarantees. We are investigating how QoS requirements can be communicated and how they can be met by adaptive resource management. A preliminary test of adaptive prefetching is presented.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::11
<abstract> This paper describes work on the linguistic  </abstract>::line_number::12
<abstract> analysis of texts within a project devoted to  </abstract>::line_number::13
<abstract> knowledge acquisition from text. We focus  </abstract>::line_number::14
<abstract> on syntactic processing and present some  </abstract>::line_number::15
<abstract> key elements of the projects parser that  </abstract>::line_number::16
<abstract> allow it to deal successfully with technical  </abstract>::line_number::17
<abstract> texts. The parser is fully implemented and  </abstract>::line_number::18
<abstract> tested on a variety of real texts;  </abstract>::line_number::19
<abstract> improvements and enhancements are in  </abstract>::line_number::20
<abstract> progress. Because our knowledge acquisition  </abstract>::line_number::21
<abstract> method assumes no a priori model of the  </abstract>::line_number::22
<abstract> domain of the source text, the parser relies  </abstract>::line_number::23
<abstract> as much as possible on lexical and syntactic  </abstract>::line_number::24
<abstract> clues. That is why it strives for full  </abstract>::line_number::25
<abstract> syntactic analysis rather than some form of  </abstract>::line_number::26
<abstract> text skimming. We present a practical  </abstract>::line_number::27
<abstract> approach to four acknowledged difficult  </abstract>::line_number::28
<abstract> problems which to date have no generally  </abstract>::line_number::29
<abstract> acceptable answers: phrase attachment; time  </abstract>::line_number::30
<abstract> constraints for problematic input (how to  </abstract>::line_number::31
<abstract> avoid long and unproductive computation);  </abstract>::line_number::32
<abstract> parsing conjoined structures (how to  </abstract>::line_number::33
<abstract> preserve broad coverage without losing  </abstract>::line_number::34
<abstract> control of the parsing process); and the  </abstract>::line_number::35
<abstract> treatment of fragmentary input or fragments  </abstract>::line_number::36
<abstract> that are a byproduct of a fallback parsing  </abstract>::line_number::37
<abstract> strategy. We review recent related work and  </abstract>::line_number::38
<abstract> conclude by listing several future work  </abstract>::line_number::39
<abstract> items.   </abstract>::line_number::40
<abstract>  Abstract  </abstract>::line_number::14
<abstract> We present a detailed description of a machine-assisted verification of an algorithm  </abstract>::line_number::15
<abstract> for self-stabilizing mutual exclusion that is due to Dijkstra [Dij74]. This verification was  </abstract>::line_number::16
<abstract> constructed using PVS. We compare the mechanical verification to the informal proof  </abstract>::line_number::17
<abstract> sketch on which it is based. This comparison yields several observations regarding the  </abstract>::line_number::18
<abstract> challenges of formalizing and mechanically verifying distributed algorithms in general.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> In the verification of cryptographic protocols along the  </abstract>::line_number::6
<abstract> approach of the logic for authentication by Burrows,  </abstract>::line_number::7
<abstract> Abadi, and Needham, it is possible to write a specification which does not faithfully represent the real world  </abstract>::line_number::8
<abstract> situation. Such a specification, though impossible or  </abstract>::line_number::9
<abstract> unreasonable to implement, can go undetected and be  </abstract>::line_number::10
<abstract> verified to be correct. It can also lead to logical statements that do not preserve causality, which in turn can  </abstract>::line_number::11
<abstract> have undesirable consequences. Such a specification,  </abstract>::line_number::12
<abstract> called an infeasible specification here, can be subtle and  </abstract>::line_number::13
<abstract> hard to locate. This note shows how the logic of cryptographic protocols by Gong, Needham, and Yahalom  </abstract>::line_number::14
<abstract> can be enhanced with a notion of eligibility to preserve  </abstract>::line_number::15
<abstract> causality of beliefs and detect infeasible specifications.  </abstract>::line_number::16
<abstract> It is conceivable that this technique can be adopted in  </abstract>::line_number::17
<abstract> other similar logics.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::6
<abstract> A distributed security architecture is proposed for  </abstract>::line_number::7
<abstract> incorporation into group oriented distributed systems,  </abstract>::line_number::8
<abstract> and in particular, into the Isis distributed programming toolkit. The primary goal of the architecture is  </abstract>::line_number::9
<abstract> to make common group oriented abstractions robust  </abstract>::line_number::10
<abstract> in hostile settings, in order to facilitate the construction of high performance distributed applications that  </abstract>::line_number::11
<abstract> can tolerate both component failures and malicious attacks. These abstractions include process groups and  </abstract>::line_number::12
<abstract> causal group multicast. Moreover, a delegation and  </abstract>::line_number::13
<abstract> access control scheme is proposed for use in group  </abstract>::line_number::14
<abstract> oriented systems. The focus of the paper is the security architecture; particular cryptosystems and key  </abstract>::line_number::15
<abstract> exchange protocols are not emphasized.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We propose a formal policy framework of MAC policies in multilevel relational databases.  </abstract>::line_number::7
<abstract> We identify the important components of such policies and their desirable properties. The  </abstract>::line_number::8
<abstract> framework provides a basis for systematically specifying such policies and characterizing  </abstract>::line_number::9
<abstract> their potential mismatches. Based on the framework, we compare and unify the MAC  </abstract>::line_number::10
<abstract> policies and policy components that are proposed in the literature or imposed in existing  </abstract>::line_number::11
<abstract> systems. Our framework could be used to capture and resolve MAC policy mismatches in  </abstract>::line_number::12
<abstract> the trusted interoperation of heterogeneous multilevel relational databases.   </abstract>::line_number::13
<abstract>  Abstract| Common security models such as Bell-LaPadula  </abstract>::line_number::3
<abstract> focus on the control of access to sensitive data but leave  </abstract>::line_number::4
<abstract> some important systems issues unspecified, such as the implementation of read-only objects, garbage collection, and  </abstract>::line_number::5
<abstract> object upgrade and downgrade paths. Consequently, different implementations of the same security model may have  </abstract>::line_number::6
<abstract> conflicting operational and security semantics. We propose  </abstract>::line_number::7
<abstract> the use of more expressive security labels for specifying these  </abstract>::line_number::8
<abstract> system issues within the security model, so that the semantics of a system design are precisely understood and are  </abstract>::line_number::9
<abstract> independent of implementation details.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper first gives an overview of standard PROLOG indexing and  </abstract>::line_number::9
<abstract> then shows, in a step-by-step manner, how it can be improved by slightly  </abstract>::line_number::10
<abstract> extending the WAM indexing instruction set to allow indexing on multiple  </abstract>::line_number::11
<abstract> arguments. Heuristics are described that overcome the difficulty of computing the indexing WAM code. In order to become independent from a  </abstract>::line_number::12
<abstract> concrete WAM instruction set, an abstract graphical representation based  </abstract>::line_number::13
<abstract> on DAGs (called DAXes) is introduced.  </abstract>::line_number::14
<abstract> The paper includes a COMMON LISP listing of the main heuristics  </abstract>::line_number::15
<abstract> implemented; the algorithms were developed for RELFUN, a relational-plus-functional language, but can easily be used in arbitrary PROLOG  </abstract>::line_number::16
<abstract> implementations.   </abstract>::line_number::17
<abstract>  Abstract. A relational-functional kernel language is introduced that  </abstract>::line_number::6
<abstract> integrates essential declarative constructs: logic variables and non-determinism from the relational paradigm with nested and higher-order operations from the functional paradigm. Operator definitions use  </abstract>::line_number::7
<abstract> `valued clauses', subsuming relational Horn clauses and functional  </abstract>::line_number::8
<abstract> (conditional or unconditional) directed equations. Their semantics complements the atoms in relational Herbrand models by `molecules', which  </abstract>::line_number::9
<abstract> pair functions, applied to argument terms, with returned-value terms.  </abstract>::line_number::10
<abstract> All abstract notions are illustrated by concrete declarative programs.   </abstract>::line_number::11
<abstract>  Abstract  </abstract>::line_number::5
<abstract> As semiconductor technology enters the deep submicron era, reliability has  </abstract>::line_number::6
<abstract> become a major challenge in the design and manufacturing of next generation  </abstract>::line_number::7
<abstract> VLSI circuits. In this paper we focus on one reliability issue the antenna  </abstract>::line_number::8
<abstract> effect in the context of 3-layer channel routing. We first present an antenna effect model in 3-layer channel routing and, based on this, an antenna effect cost  </abstract>::line_number::9
<abstract> function is proposed. A layer reassignment approach is adopted to minimize this  </abstract>::line_number::10
<abstract> cost function and we show that the layer reassignment problem can be formulated as a network bipartitioning problem. Experimental results show that the  </abstract>::line_number::11
<abstract> antenna effect can be reduced considerably by applying the proposed technique.  </abstract>::line_number::12
<abstract> Compared with previous work, one advantage of our approach is that no extra  </abstract>::line_number::13
<abstract> channel area is required for antenna effect minimization. We show that layer  </abstract>::line_number::14
<abstract> reassignment technique can be used in yield-related critical area minimization  </abstract>::line_number::15
<abstract> in 3-layer channel routing as well. The trade-off between these two objectives is  </abstract>::line_number::16
<abstract> also presented.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Crosstalk has become a major issue in VLSI design due to the high frequency, long  </abstract>::line_number::6
<abstract> interconnecting lines and small spacing between interconnects in today's integrated circuits.  </abstract>::line_number::7
<abstract> In this paper, we study the problem of crosstalk minimization in 3-layer HVH channel  </abstract>::line_number::8
<abstract> routing. A heuristic algorithm that combines layer reassignment and track reassignment  </abstract>::line_number::9
<abstract> is presented. This algorithm can iteratively modify the layout so that the crosstalk in the  </abstract>::line_number::10
<abstract> channel is minimized. Experimental results show that the proposed approach can reduce the  </abstract>::line_number::11
<abstract> crosstalk by an average of 16.4% on a set of benchmark examples.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Communication networks shared by selfish users are  </abstract>::line_number::6
<abstract> considered and modeled as noncooperative repeated  </abstract>::line_number::7
<abstract> games. Each user is interested only in optimizing its  </abstract>::line_number::8
<abstract> own performance by controlling the routing of its load.  </abstract>::line_number::9
<abstract> We investigate the existence of a NEP that achieves  </abstract>::line_number::10
<abstract> the system-wide optimal cost. The existence of a NEP  </abstract>::line_number::11
<abstract> that not only achieves the system-wide optimal cost but  </abstract>::line_number::12
<abstract> also yields a cost for each user no greater than its stage  </abstract>::line_number::13
<abstract> game NEP cost is shown for two-node multiple link networks. It is shown that more general networks where  </abstract>::line_number::14
<abstract> all users have the same source-destination pair have  </abstract>::line_number::15
<abstract> a NEP that achieves the minimum total system cost  </abstract>::line_number::16
<abstract> under a mild technical condition. It is shown general  </abstract>::line_number::17
<abstract> networks with users having multiple source-destination  </abstract>::line_number::18
<abstract> pairs don't necessarily have such an NEP.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We study the following problem: two agents Alice and Bob are connected to each other by independent discrete memoryless channels. They  </abstract>::line_number::6
<abstract> wish to generate common randomness by communicating interactively over  </abstract>::line_number::7
<abstract> the two channels. Assuming that Alice and Bob are allowed access to  </abstract>::line_number::8
<abstract> independent external random sources at rates (in bits per step of communication) of H A and H B , respectively, we show that they can generate common randomness at a rate of max f min [H A + H(W jQ); I(P ; V )] +  </abstract>::line_number::9
<abstract> min [H B + H(V jP ); I(Q; W )] g bits per step. Here, V is the channel from  </abstract>::line_number::10
<abstract> Alice to Bob, and W is the channel from Bob to Alice. The maximum  </abstract>::line_number::11
<abstract> is over all probability distributions P and Q on the input alphabets of V  </abstract>::line_number::12
<abstract> and W respectively. We also prove a strong converse which establishes the  </abstract>::line_number::13
<abstract> above rate as the highest attainable in this situation.   </abstract>::line_number::14
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> In signal analysis-synthesis, the analysis derives a set of parameters that the synthesis uses to reconstruct the original  </abstract>::line_number::6
<abstract> signal. In musical applications, this reconstruction should  </abstract>::line_number::7
<abstract> be perceptually accurate, and the parameterization should  </abstract>::line_number::8
<abstract> allow for such desirable signal modifications as time-scaling,  </abstract>::line_number::9
<abstract> pitch-shifting, and cross-synthesis; the analysis parameters  </abstract>::line_number::10
<abstract> should correspond to a signal model that is flexible enough  </abstract>::line_number::11
<abstract> to allow these transformations. Sinusoidal modeling meets  </abstract>::line_number::12
<abstract> this flexibility requirement, but has difficulty representing  </abstract>::line_number::13
<abstract> some salient features of musical signals such as attack transients and noiselike processes. In this paper, sinusoidal  </abstract>::line_number::14
<abstract> modeling is reviewed and some variations are proposed to  </abstract>::line_number::15
<abstract> account for its shortcomings; also, wavelet-based representations of musical signals are considered.   </abstract>::line_number::16
<abstract>  Abstract. We present a formal model for concurrent systems. The model represents  </abstract>::line_number::2
<abstract> synchronous and asynchronous components in a uniform framework that supports compositional (assume-guarantee) and hierarchical (stepwise-refinement) design and verification. While synchronous models are based on a notion of atomic computation step,  </abstract>::line_number::3
<abstract> and asynchronous models remove that notion by introducing stuttering, our model is  </abstract>::line_number::4
<abstract> based on a flexible notion of what constitutes a computation step: by applying an abstraction operator to a system, arbitrarily many consecutive steps can be collapsed into  </abstract>::line_number::5
<abstract> a single step. The abstraction operator, which may turn an asynchronous system into a  </abstract>::line_number::6
<abstract> synchronous one, allows us to describe systems at various levels of temporal detail. For  </abstract>::line_number::7
<abstract> describing systems at various levels of spatial detail, we use a hiding operator that may  </abstract>::line_number::8
<abstract> turn a synchronous system into an asynchronous one. We illustrate the model with diverse examples from synchronous circuits, asynchronous shared-memory programs, and  </abstract>::line_number::9
<abstract> synchronous message-passing protocols.   </abstract>::line_number::10
<abstract>  Abstract  </abstract>::line_number::3
<abstract> The Finite-State Markov Channel (FSMC) is a discrete-time varying channel whose variation is determined by a finite-state Markov process. These channels have memory due to the  </abstract>::line_number::4
<abstract> Markov channel variation. We obtain the FSMC capacity as a function of the conditional channel  </abstract>::line_number::5
<abstract> state probability. We also show that for i.i.d. channel inputs, this conditional probability converges  </abstract>::line_number::6
<abstract> weakly, and the channel's mutual information is then a closed-form continuous function of the input  </abstract>::line_number::7
<abstract> distribution.  </abstract>::line_number::8
<abstract> We next consider coding for FSMCs. In general, the complexity of maximum-likelihood  </abstract>::line_number::9
<abstract> decoding grows exponentially with the channel memory length. Therefore, in practice, interleaving  </abstract>::line_number::10
<abstract> and memoryless channel codes are used. This technique results in some performance loss relative  </abstract>::line_number::11
<abstract> to the inherent capacity of channels with memory. We propose a maximum-likelihood decision-feedback decoder with complexity that is independent of the channel memory. We calculate the  </abstract>::line_number::12
<abstract> capacity and cutoff rate of our technique, and show that it preserves the capacity of certain FSMCs.  </abstract>::line_number::13
<abstract> We also compare the performance of the decision-feedback decoder with that of interleaving and  </abstract>::line_number::14
<abstract> memoryless channel coding on a fading channel with 4PSK modulation.   </abstract>::line_number::15
<abstract>  Abstract. Hybrid automata model systems with both  </abstract>::line_number::2
<abstract> digital and analog components, such as embedded control programs. Many verification tasks for such programs  </abstract>::line_number::3
<abstract> can be expressed as reachability problems for hybrid automata. By improving on previous decidability and undecidability results, we identify the precise boundary between decidability and undecidability of the reachability  </abstract>::line_number::4
<abstract> problem for hybrid automata.  </abstract>::line_number::5
<abstract> On the positive side, we give an (optimal) PSPACE  </abstract>::line_number::6
<abstract> reachability algorithm for the case of initialized rectangular automata, where all analog variables follow trajectories within piecewise-linear envelopes and are reinitialized  </abstract>::line_number::7
<abstract> whenever the envelope changes. Our algorithm is based  </abstract>::line_number::8
<abstract> on a translation of an initialized rectangular automaton  </abstract>::line_number::9
<abstract> into a timed automaton that defines the same timed language. The translation has practical significance for verification, because it guarantees the termination of symbolic  </abstract>::line_number::10
<abstract> procedures for the reachability analysis of initialized rectangular automata.  </abstract>::line_number::11
<abstract> On the negative side, we show that several slight generalizations of initialized rectangular automata lead to an  </abstract>::line_number::12
<abstract> undecidable reachability problem. In particular, we prove  </abstract>::line_number::13
<abstract> that the reachability problem is undecidable for timed automata with a single stopwatch.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::3
<abstract> Most caching schemes in wide-area, distributed systems are client-initiated. Decisions of when and  </abstract>::line_number::4
<abstract> where to cache information are made without the benefit of the server's global knowledge of the usage  </abstract>::line_number::5
<abstract> patterns. In this paper, we present a new caching strategy: geographical push-caching. Using the server's  </abstract>::line_number::6
<abstract> global knowledge and a derived network topology, we distribute data to cooperating servers. The World  </abstract>::line_number::7
<abstract> Wide Web is an example of a wide-area system that will benefit from distance-sensitive caching, and we  </abstract>::line_number::8
<abstract> present an architecture that allows a Web server to autonomously replicate HTML pages. We use a trace-driven simulation to evaluate several competing caching strategies. Our results show that geographical  </abstract>::line_number::9
<abstract> push-caching reduces bandwidth consumption and sever load by the same amount as web proxy caching,  </abstract>::line_number::10
<abstract> but with a savings in global cache space of almost two orders of magnitude. More importantly, servers  </abstract>::line_number::11
<abstract> that wish to reduce Internet bandwidth consumption and their load can do so without waiting for web  </abstract>::line_number::12
<abstract> proxies to be implemented world-wide. Furthermore, geographical push-caching helps distribute server  </abstract>::line_number::13
<abstract> load for all web servers, not just the most popular as is the case with proxy caching.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The objective of this paper is to develop models that  </abstract>::line_number::8
<abstract> characterize the communication performance of a message-passing multicomputer by taking the IBM SP2 as a case  </abstract>::line_number::9
<abstract> study. The paper evaluates and models the three aspects  </abstract>::line_number::10
<abstract> of the communication performance: scheduling overhead,  </abstract>::line_number::11
<abstract> message-passing time, and synchronization overhead. Performance models are developed for the basic communication patterns, enabling the estimation of the communication  </abstract>::line_number::12
<abstract> times of a message-passing application. Such estimates facilitate activities such as application tuning, selection of the  </abstract>::line_number::13
<abstract> best available implementation technique, and performance  </abstract>::line_number::14
<abstract> comparisons among different multicomputers.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Modulo scheduling algorithms based on optimal  </abstract>::line_number::7
<abstract> solvers have been proposed to investigate and tune the  </abstract>::line_number::8
<abstract> performance of modulo scheduling heuristics. While  </abstract>::line_number::9
<abstract> recent advances have broadened the scope for which  </abstract>::line_number::10
<abstract> the optimal approach is applicable, this approach  </abstract>::line_number::11
<abstract> increasingly suffers from large execution times. In this  </abstract>::line_number::12
<abstract> paper, we propose a more efficient formulation of the  </abstract>::line_number::13
<abstract> modulo scheduling space that significantly decreases  </abstract>::line_number::14
<abstract> the execution time of solvers based on integer linear  </abstract>::line_number::15
<abstract> programs. For example, the total execution time is  </abstract>::line_number::16
<abstract> reduced by a factor of 8.6 when 782 loops from the  </abstract>::line_number::17
<abstract> Perfect Club, SPEC, and Livermore Fortran Kernels  </abstract>::line_number::18
<abstract> are scheduled for minimum register requirements using  </abstract>::line_number::19
<abstract> the more efficient formulation instead of the traditional  </abstract>::line_number::20
<abstract> formulation. Experimental evidence further indicates  </abstract>::line_number::21
<abstract> that significantly larger loops can be scheduled under  </abstract>::line_number::22
<abstract> realistic machine constraints.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Most of the recent color recognition/indexing approaches concentrate on establishing invariance to illumination color to improve the utility of color recognition. However, other effects caused by illumination pose and specularity on three-dimensional  </abstract>::line_number::9
<abstract> object surfaces have not received notable attention. We present a chromaticity recognition method that discounts the effects of illumination pose, illumination color and  </abstract>::line_number::10
<abstract> specularity. It utilizes a chromaticity space based on log-ratio of sensor responses for  </abstract>::line_number::11
<abstract> illumination pose and color invariance. A model-based specularity detection/rejection  </abstract>::line_number::12
<abstract> algorithm can be used to improve the chromaticity recognition and illumination estimation for objects including specular reflections.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::7
<abstract> As the use of the Internet for electronic commerce, audio  </abstract>::line_number::8
<abstract> and video conferencing, and other applications with sensitive content grows, the need for secure services becomes  </abstract>::line_number::9
<abstract> critical. Central to the success of these services is the support for secure public key distribution. Although there are  </abstract>::line_number::10
<abstract> several existing services available for this purpose, they  </abstract>::line_number::11
<abstract> are not very scalable, either because they depend on a centralized server or rely on ad hoc trust relationships.  </abstract>::line_number::12
<abstract> In this paper, we present and examine a flexible approach to certificate distribution scalable to arbitrarily  </abstract>::line_number::13
<abstract> large networks. We propose a two level hierarchy where  </abstract>::line_number::14
<abstract> certificates can be independently authenticated by one or  </abstract>::line_number::15
<abstract> more peer authorities, called keyservers. Certificates for  </abstract>::line_number::16
<abstract> end-user and host entities are managed within local domains, called enterprises. By administering certificates  </abstract>::line_number::17
<abstract> close to the source, we reduce the load on the key servers  </abstract>::line_number::18
<abstract> and the effects of network topology changes. We describe  </abstract>::line_number::19
<abstract> the design of our system and present a preliminary performance analysis based on traces of present-day DNS requests.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::9
<abstract> Recent developments have clarified the process of generating partially ordered, partially specified sequences of actions whose execution  </abstract>::line_number::10
<abstract> will achive an agent's goal. This paper summarizes a progression of  </abstract>::line_number::11
<abstract> least commitment planners, starting with one that handles the sim  </abstract>::line_number::12
<abstract> ple strips representation, and ending with one that manages actions  </abstract>::line_number::13
<abstract> with disjunctive precondition, conditional effects and universal quantification over dynamic universes. Along the way we explain how  </abstract>::line_number::14
<abstract> Chapman's formulation of the Modal Truth Criterion is misleading  </abstract>::line_number::15
<abstract> and why his NP-completeness result for reasoning about plans with  </abstract>::line_number::16
<abstract> conditional effects does not apply to our planner.   </abstract>::line_number::17
<abstract>  ABSTRACT  </abstract>::line_number::9
<abstract> The decentralized control problem that we address in  </abstract>::line_number::10
<abstract> this paper is that of several communicating supervisory  </abstract>::line_number::11
<abstract> controllers, each with different information, working in  </abstract>::line_number::12
<abstract> concert to exactly achieve a given legal sublanguage of  </abstract>::line_number::13
<abstract> the uncontrolled system's language model. We present  </abstract>::line_number::14
<abstract> a novel information structure formalism for dealing with  </abstract>::line_number::15
<abstract> this class of problems. Preliminary results are presented  </abstract>::line_number::16
<abstract> which elucidate a fundamental concept in decentralized  </abstract>::line_number::17
<abstract> control problems: the importance of controllers anticipating future possible communications.   </abstract>::line_number::18
<abstract>  ABSTRACT  </abstract>::line_number::8
<abstract> Some of the advanced real-time systems being proposed, such as the Next Generation Workstation/Machine  </abstract>::line_number::9
<abstract> Controller (NGC) for automated factories, require a built-in database to support concurrent data access and provide  </abstract>::line_number::10
<abstract> well-defined interfaces between software modules. However, conventional database systems do not provide the performance levels or response time guarantees needed by real-time applications. To address the need for high-performance  </abstract>::line_number::11
<abstract> real-time database systems, we propose to design, implement, and evaluate an object-oriented software system called  </abstract>::line_number::12
<abstract> Multiprocessor Database Architecture for Real-Time Systems (MDARTS). An important feature of MDARTS is that  </abstract>::line_number::13
<abstract> it supports explicit specification of real-time requirements and semantic constraints at an object-granularity level.  </abstract>::line_number::14
<abstract> The database examines these specifications at runtime during application initialization and dynamically adjusts  </abstract>::line_number::15
<abstract> its data management strategy accordingly to provide hard real-time guarantees. For maximum performance on  </abstract>::line_number::16
<abstract> shared-memory multiprocessors, MDARTS supports concurrent, direct, shared-memory data access. Prior real-time  </abstract>::line_number::17
<abstract> database systems do not support per-object dynamic configuration during initialization, and they either work only on  </abstract>::line_number::18
<abstract> uniprocessors or use relatively slow inter-process communication for all transactions. The unique design of MDARTS  </abstract>::line_number::19
<abstract> will support a transaction execution time two to three orders of magnitude faster than current real-time database  </abstract>::line_number::20
<abstract> systems for multiprocessors. For data access with less stringent timing constraints, MDARTS also supports remote  </abstract>::line_number::21
<abstract> transactions across networks and provides interfaces to external database systems. Once we have implemented the  </abstract>::line_number::22
<abstract> basic MDARTS architecture, we will demonstrate its capabilities by using it to develop distributed, open architecture  </abstract>::line_number::23
<abstract> controllers for actual manufacturing machine tools.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper examines the network inter-domain routing information exchanged between backbone service providers at  </abstract>::line_number::8
<abstract> the major U.S. public Internet exchange points. Internet  </abstract>::line_number::9
<abstract> routing instability, or the rapid fluctuation of network reach-ability information, is an important problem currently facing the Internet engineering community. High levels of network instability can lead to packet loss, increased network  </abstract>::line_number::10
<abstract> latency and time to convergence. At the extreme, high levels of routing instability have lead to the loss of internal  </abstract>::line_number::11
<abstract> connectivity in wide-area, national networks. In this paper,  </abstract>::line_number::12
<abstract> we describe several unexpected trends in routing instability,  </abstract>::line_number::13
<abstract> and examine a number of anomalies and pathologies observed in the exchange of inter-domain routing information.  </abstract>::line_number::14
<abstract> The analysis in this paper is based on data collected from  </abstract>::line_number::15
<abstract> BGP routing messages generated by border routers at five  </abstract>::line_number::16
<abstract> of the Internet core's public exchange points during a nine  </abstract>::line_number::17
<abstract> month period. We show that the volume of these routing updates is several orders of magnitude more than expected and  </abstract>::line_number::18
<abstract> that the majority of this routing information is redundant,  </abstract>::line_number::19
<abstract> or pathological. Furthermore, our analysis reveals several  </abstract>::line_number::20
<abstract> unexpected trends and ill-behaved systematic properties in  </abstract>::line_number::21
<abstract> Internet routing. We finally posit a number of explanations  </abstract>::line_number::22
<abstract> for these anomalies and evaluate their potential impact on  </abstract>::line_number::23
<abstract> the Internet infrastructure.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Recovery from failures and erroneous executions is a crucial but complicated issue for concurrently accessed data systems. Increasingly sophisticated techniques are being developed to improve performance  </abstract>::line_number::9
<abstract> and functionality of recovery protocols. To better understand and analyze recovery schemes, we reexamine the concept of spheres of control [Dav78], using it as a unifying framework for specifying diverse  </abstract>::line_number::10
<abstract> recovery models simply and precisely. We constrain sphere-of-control formulations appropriately to capture transaction-oriented recovery in both centralized and distributed environments and with different  </abstract>::line_number::11
<abstract> types of schedules, as well as semantics-based recovery and compensation. In addition, we discuss how  </abstract>::line_number::12
<abstract> the operational semantics methodology of evolving algebras [Gur95] can model spheres of control formally  </abstract>::line_number::13
<abstract> and refine them to lower levels of abstraction.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::11
<abstract> This paper presents an hierarchical end-to-end  </abstract>::line_number::12
<abstract> analysis technique that decomposes the very complex  </abstract>::line_number::13
<abstract> heterogeneous multi-resource scheduling problem into  </abstract>::line_number::14
<abstract> a set of single resource scheduling problems with well  </abstract>::line_number::15
<abstract> defined interactions. We define heterogeneity both in  </abstract>::line_number::16
<abstract> resource types, e.g., CPU, and in scheduling policies,  </abstract>::line_number::17
<abstract> e.g., rate-monotonic scheduling. This analysis  </abstract>::line_number::18
<abstract> technique is one phase of our systems integration  </abstract>::line_number::19
<abstract> framework for designing large-scale, heterogeneous,  </abstract>::line_number::20
<abstract> distributed real-time systems whose timing properties  </abstract>::line_number::21
<abstract> can be strictly controlled and analyzed. This approach,  </abstract>::line_number::22
<abstract> denoted the Distributed Pipelining Framework,  </abstract>::line_number::23
<abstract> exploits the natural pipelining execution pattern found  </abstract>::line_number::24
<abstract> in a large number of continuous (periodic) applications  </abstract>::line_number::25
<abstract> executing over heterogenous resources. A teleconference application is used in this paper to show the  </abstract>::line_number::26
<abstract> utility of the approach.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The construction of rational agents is one of the goals that has been pursued in  </abstract>::line_number::8
<abstract> Artificial Intelligence (AI). In most of the architectures that have been proposed for  </abstract>::line_number::9
<abstract> this kind of agents, its behaviour is guided by its set of beliefs. In our work, rational  </abstract>::line_number::10
<abstract> agents are those systems that are permanently engaged in the process of rational  </abstract>::line_number::11
<abstract> inquiry; thus, their beliefs keep evolving in time, as a consequence of their internal  </abstract>::line_number::12
<abstract> inference procedures and their interaction with the environment. Both AI researchers  </abstract>::line_number::13
<abstract> and philosophers are interested in having a formal model of this process, and this is  </abstract>::line_number::14
<abstract> the main topic in our work.  </abstract>::line_number::15
<abstract> Beliefs have been formally modelled in the last decades using doxastic logics. The  </abstract>::line_number::16
<abstract> possible worlds model and its associated Kripke semantics provide an intuitive semantics for these logics, but they seem to commit us to model agents that are logically  </abstract>::line_number::17
<abstract> omniscient and perfect reasoners. We avoid these problems by replacing possible  </abstract>::line_number::18
<abstract> worlds by conceivable situations, which are all the situations that the modelled agent  </abstract>::line_number::19
<abstract> is capable of considering.  </abstract>::line_number::20
<abstract> In this document we show how this notion of conceivable situations may be used  </abstract>::line_number::21
<abstract> to model the process of rational inquiry in which a non-ideal rational agent is engaged. We define a wide class of agents, called rational inquirers, which are a general  </abstract>::line_number::22
<abstract> abstraction of any kind of non-ideal agent. We show how the beliefs of these kind of  </abstract>::line_number::23
<abstract> agents evolve in time as a consequence of a multi-dimensional belief analysis, and we  </abstract>::line_number::24
<abstract> use the framework of conceivable situations in order to model this evolution.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::7
<abstract> The paper describes some geographical applications of a parallel GP code  </abstract>::line_number::8
<abstract> which is run on a Cray T3D 512 processor supercomputer to create new  </abstract>::line_number::9
<abstract> types of well performing mathematical models. A series of results are described which allude to the potential power of the method for which there  </abstract>::line_number::10
<abstract> are many practical applications in spatial data rich environments where  </abstract>::line_number::11
<abstract> there are no suitable existing models and no soundly based theoretical  </abstract>::line_number::12
<abstract> framework on which to base them.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::4
<abstract> This paper describes a general-purpose programming technique, called the Simulation of  </abstract>::line_number::5
<abstract> Simplicity, which can be used to cope with degenerate input data for geometric algorithms.  </abstract>::line_number::6
<abstract> It relieves the programmer from the task to provide a consistent treatment for every single  </abstract>::line_number::7
<abstract> special case that can occur. The programs that use the technique tend to be considerably  </abstract>::line_number::8
<abstract> smaller and more robust than those that do not use it. We believe that this technique will  </abstract>::line_number::9
<abstract> become a standard tool in writing geometric software.   </abstract>::line_number::10
<abstract>  Abstract. The simple Bayesian classifier is known to be optimal when attributes are independent  </abstract>::line_number::8
<abstract> given the class, but the question of whether other sufficient conditions for its optimality exist has  </abstract>::line_number::9
<abstract> so far not been explored. Empirical results showing that it performs surprisingly well in many  </abstract>::line_number::10
<abstract> domains containing clear attribute dependences suggest that the answer to this question may be  </abstract>::line_number::11
<abstract> positive. This article shows that, although the Bayesian classifier's probability estimates are only  </abstract>::line_number::12
<abstract> optimal under quadratic loss if the independence assumption holds, the classifier itself can be  </abstract>::line_number::13
<abstract> optimal under zero-one loss (misclassification rate) even when this assumption is violated by a  </abstract>::line_number::14
<abstract> wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian  </abstract>::line_number::15
<abstract> classifier has a much greater range of applicability than previously thought. For example, in this  </abstract>::line_number::16
<abstract> article it is shown to be optimal for learning conjunctions and disjunctions, even though they  </abstract>::line_number::17
<abstract> violate the independence assumption. Further, studies in artificial domains show that it will often  </abstract>::line_number::18
<abstract> outperform more powerful classifiers for common training set sizes and numbers of attributes, even  </abstract>::line_number::19
<abstract> if its bias is a priori much less appropriate to the domain. This article's results also imply that  </abstract>::line_number::20
<abstract> detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier,  </abstract>::line_number::21
<abstract> and this is also verified empirically.   </abstract>::line_number::22
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> Speech disfluencies (such as filled pauses, repetitions, restarts) are  </abstract>::line_number::7
<abstract> among the characteristics distinguishing spontaneous speech from  </abstract>::line_number::8
<abstract> planned or read speech. We introduce a language model that predicts disfluencies probabilistically and uses an edited, fluent context  </abstract>::line_number::9
<abstract> to predict following words. The model is based on a generalization  </abstract>::line_number::10
<abstract> of the standard N-gram language model. It uses dynamic programming to compute the probability of a word sequence, taking into  </abstract>::line_number::11
<abstract> account possible hidden disfluency events. We analyze the model's performance for various disfluency types on the Switchboard  </abstract>::line_number::12
<abstract> corpus. We find that the model reduces word perplexity in the  </abstract>::line_number::13
<abstract> neighborhood of disfluency events; however, overall differences  </abstract>::line_number::14
<abstract> are small and have no significant impact on recognition accuracy.  </abstract>::line_number::15
<abstract> We also note that for modeling of the most frequent type of dis-fluency, filled pauses, a segmentation of utterances into linguistic  </abstract>::line_number::16
<abstract> (rather than acoustic) units is required. Our analysis illustrates a  </abstract>::line_number::17
<abstract> generally useful technique for language model evaluation based on  </abstract>::line_number::18
<abstract> local perplexity comparisons.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We describe our method how to implement C-program sequences in torrent (T0)  </abstract>::line_number::10
<abstract> assembler code while there is no efficient automatic tool. We use re-structuring of  </abstract>::line_number::11
<abstract> the source code, vectorization, dataflow graphs, a simple scheduling strategy and a  </abstract>::line_number::12
<abstract> straight forward register allocation algorithm. We define some lower and an upper  </abstract>::line_number::13
<abstract> bound for the expected run time. For two functions, namely the color transformation  </abstract>::line_number::14
<abstract> and reverse DCT, we achieve almost 54, respectively 16 times the performance of a  </abstract>::line_number::15
<abstract> Sparc 2 workstation.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We present a computational model of how verbs might be learned within  </abstract>::line_number::8
<abstract> the limited domain of hand actions. We hypothesize that such verbs refer to  </abstract>::line_number::9
<abstract> the activities of underlying motor schemas, and leverage this constraint to  </abstract>::line_number::10
<abstract> build a system with strong enough biases that it can learn from a reasonably  </abstract>::line_number::11
<abstract> small number of examples, while still having adequate flexibility to learn the  </abstract>::line_number::12
<abstract> hand-action verbs of any language. The completed system should demonstrate its knowledge both by labelling its own behavior and by carrying out  </abstract>::line_number::13
<abstract> verbal commands in a simulated world.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We are analyzing storage structures for two and three dimensional raster type data which are used  </abstract>::line_number::7
<abstract> for feature retrieval. The features are one, two or three dimensional objects with regular outlines  </abstract>::line_number::8
<abstract> like a rectangle or a prism. The features could be parts of a map or image, an area of special  </abstract>::line_number::9
<abstract> interest for searching after oil, a sequence of ultra sound images, and so on. The storage medium  </abstract>::line_number::10
<abstract> is magnetic disk. The data are stored in chunks or blocks representing a regular part of the source  </abstract>::line_number::11
<abstract> object. We analyze the shape and the size to minimize the cost of retrieval. The optimization is  </abstract>::line_number::12
<abstract> based on minimum time to do retrieval. We have five combinations: Lines and areas from areas and  </abstract>::line_number::13
<abstract> volumes, and volumes from volumes. The optimal block sizes for random retrieval varies, with case,  </abstract>::line_number::14
<abstract> feature size and disk characteristics. One general observation is that longer disk tracks gives larger  </abstract>::line_number::15
<abstract> blocks. For line retrieval the optimal block size is only depending on disk track length. For other  </abstract>::line_number::16
<abstract> cases it is also depending on the feature size. For partly sequential retrieval the block size is not the  </abstract>::line_number::17
<abstract> actual block size used during retrieval, but the smallest addressing unit, and the optimal addressing  </abstract>::line_number::18
<abstract> unit could be rather small.  </abstract>::line_number::19
<abstract> The analysis reveals that using too small blocks could be very costly. The time could easily  </abstract>::line_number::20
<abstract> double or triple if small blocks are used. In many cases the optimal block size is several tracks.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Video servers are important for applications which make  </abstract>::line_number::7
<abstract> use of digital video. The video servers should provide better  </abstract>::line_number::8
<abstract> functionality than most of today's video servers offer, - e.g.,  </abstract>::line_number::9
<abstract> support of flexible and instant user interactions, delivery of  </abstract>::line_number::10
<abstract> multiple video formats and support of virtual video documents. In this paper we discuss the requirements that video  </abstract>::line_number::11
<abstract> servers should fulfill and we describe the design and implementation of the Elvira video server. The Elvira video server  </abstract>::line_number::12
<abstract> is built on a cluster of standard UNIX workstations interconnected by an ATM switch. The capacity of the Elvira server  </abstract>::line_number::13
<abstract> is evaluated and we show the effects of different strategies  </abstract>::line_number::14
<abstract> for allocation of video data across nodes and disks.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::6
<abstract> In a database system, read operations are much more  </abstract>::line_number::7
<abstract> common than write operations, and consequently, database  </abstract>::line_number::8
<abstract> systems have been read optimized. As the size of main memory increases, more of the database read requests will be satisfied from the buffer system, and the amount of disk write  </abstract>::line_number::9
<abstract> operations relative to disk read operations will increase.  </abstract>::line_number::10
<abstract> This calls for a focus on write optimized database systems.  </abstract>::line_number::11
<abstract> In this paper, we present solutions to this problem. We describe in detail the data structures and algorithms needed  </abstract>::line_number::12
<abstract> to realize a write optimized object-oriented database system  </abstract>::line_number::13
<abstract> in the context of Vagabond, an OODB currently being implemented at our department. In Vagabond, focus has been  </abstract>::line_number::14
<abstract> to provide support for applications which have earlier used  </abstract>::line_number::15
<abstract> file systems because of the limited data bandwidth in current  </abstract>::line_number::16
<abstract> database systems, typical examples are super computing applications and geographical information systems   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::4
<abstract> The computational requirements of high-quality, real-time rendering exceeds the limits of  </abstract>::line_number::5
<abstract> generally available computing power. However illumination effects, except shadows, are  </abstract>::line_number::6
<abstract> less noticeable on moving pictures. Shadows can be produced with the same techniques  </abstract>::line_number::7
<abstract> used for visibility computations, therefore the basic requirements of real-time rendering  </abstract>::line_number::8
<abstract> are transformations, pre-selection of the part of the scene to be displayed and visibility  </abstract>::line_number::9
<abstract> computations. Transformations scale well, ie, their time requirement grows linearly with  </abstract>::line_number::10
<abstract> the input size. Pre-selection, if implemented by the traditional way of polygon clipping,  </abstract>::line_number::11
<abstract> has a growing rate of N log N in the worst case, where N is the total number of edges in  </abstract>::line_number::12
<abstract> the scene. Visibility computations, exhibiting a quadratic growing rate, are the bottleneck  </abstract>::line_number::13
<abstract> from a theoretical point of view. Three approaches are discussed to speed up visibility  </abstract>::line_number::14
<abstract> computations: (i) reducing the expected running time to O(N log N ) (ii) using approximation algorithms with O(N K) worst-case time, where K is the linear resolution of the  </abstract>::line_number::15
<abstract> image, and (iii) applying parallel techniques leading to logarithmic time in the worst-case.  </abstract>::line_number::16
<abstract> Though the growing rate of the time requirement of pre-selection is significantly slower  </abstract>::line_number::17
<abstract> than that of visibility, it is demonstrated that pre-selection has to deal with a significantly  </abstract>::line_number::18
<abstract> higher amount of data than visibility computations, as the average clipping volume is 1/27  </abstract>::line_number::19
<abstract> of the volume of the model.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::12
<abstract> We describe the implementation of a multi-purpose data analysis laboratory, DataLab-J, in  </abstract>::line_number::13
<abstract> the programming language Java. We briefly trace the stages of the evolution of DataLab from a  </abstract>::line_number::14
<abstract> FORTRAN-IV system in 1973 to the current Java development. Description of this evolution allows  </abstract>::line_number::15
<abstract> us to discuss some key design and functionality decisions and issues that arose throughout the years;  </abstract>::line_number::16
<abstract> many of these issues remain topical, so, in addition to an evaluation of Java, we identify and discuss  </abstract>::line_number::17
<abstract> what are for us the major issues in the design of such software. Moreover, we address questions  </abstract>::line_number::18
<abstract> raised by the need to convert legacy systems, e.g. those programmed in C and various versions of  </abstract>::line_number::19
<abstract> FORTRAN. The experience of redesign and implementation in Java is described, together with a  </abstract>::line_number::20
<abstract> brief evaluation of the suitability of Java for 'number-crunching'. Overall conclusions are drawn,  </abstract>::line_number::21
<abstract> regarding design of such software, lessons learned, traps to avoid, and on Java itself.   </abstract>::line_number::22
<abstract>  Abstract. We describe the core of a rule-based CQL, devoted to the  </abstract>::line_number::6
<abstract> manipulation of 2-dimensional tabular databases. The rules provide a  </abstract>::line_number::7
<abstract> simple and declarative way to restructure and query tables, and the constraints allow to define cell contents by formulas over concrete domains.  </abstract>::line_number::8
<abstract> We define a model-theoretic semantics and develop an equivalent fixpoint  </abstract>::line_number::9
<abstract> theory that leads to a naive evaluation procedure.   </abstract>::line_number::10
<abstract>  ABSTRACT  </abstract>::line_number::4
<abstract> We present recent work on integration of visual information (automatic lip-reading) with acoustic speech for better overall speech recognition. A Multi-State Time Delay  </abstract>::line_number::5
<abstract> Neural Network performs the recognition of spelled letter  </abstract>::line_number::6
<abstract> sequences taking advantage of lip images from a standard  </abstract>::line_number::7
<abstract> camera. The problems addressed include efficient but effective representation of the visual information and optimum  </abstract>::line_number::8
<abstract> manner of combining the two modalities when rendering a  </abstract>::line_number::9
<abstract> decision. We show results for several alternatives to direct  </abstract>::line_number::10
<abstract> gray level image as the visual evidence. These are: Principal  </abstract>::line_number::11
<abstract> Components, Linear Discriminants, and DFT coefficients.  </abstract>::line_number::12
<abstract> Dimensionality of the input is decreased by a factor of 12  </abstract>::line_number::13
<abstract> while maintaining recognition rates. Combination of the  </abstract>::line_number::14
<abstract> visual and acoustic information is performed at three different levels of abstraction. Results suggest that integration  </abstract>::line_number::15
<abstract> of higher order input features works best. On a continuous  </abstract>::line_number::16
<abstract> spelling task, visual-alone recognition of 45-55%, when combined with acoustic data, lowers audio-alone error rates by  </abstract>::line_number::17
<abstract> 30-40%.   </abstract>::line_number::18
<abstract>  ABSTRACT  </abstract>::line_number::6
<abstract> A stochastically based approach for the semantic analysis component of a natural spoken language system for the ATIS task has been  </abstract>::line_number::7
<abstract> developed. The semantic analyzer of the spoken language system  </abstract>::line_number::8
<abstract> already in use at LIMSI makes use of a rule-based case grammar. In  </abstract>::line_number::9
<abstract> this work, the system of rules for the semantic analysis is replaced  </abstract>::line_number::10
<abstract> with a relatively simple, first order Hidden Markov Model. The  </abstract>::line_number::11
<abstract> performance of the two approaches can be compared because they  </abstract>::line_number::12
<abstract> use identical semantic representations despite their rather different  </abstract>::line_number::13
<abstract> methods for meaning extraction. We use an evaluation methodology  </abstract>::line_number::14
<abstract> that assesses performance at different semantic levels, including the  </abstract>::line_number::15
<abstract> database response comparison used in the ARPA ATIS paradigm.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::7
<abstract> In this paper we consider the problem of tracking a subset of a domain (called the target) which  </abstract>::line_number::8
<abstract> changes gradually over time. A single (unknown) probability distribution over the domain is used  </abstract>::line_number::9
<abstract> to generate random examples for the learning algorithm and measure the speed at which the target  </abstract>::line_number::10
<abstract> changes.  </abstract>::line_number::11
<abstract> Clearly, the more rapidly the target moves, the harder it is for the algorithm to maintain a good  </abstract>::line_number::12
<abstract> approximation of the target. Therefore we evaluate algorithms based on how much movement of  </abstract>::line_number::13
<abstract> the target can be tolerated between examples while predicting with accuracy *. Furthermore, the  </abstract>::line_number::14
<abstract> complexity of the class H of possible targets, as measured by d, its VC-dimension, also effects the  </abstract>::line_number::15
<abstract> difficulty of tracking the target concept.  </abstract>::line_number::16
<abstract> We show that if the problem of minimizing the number of disagreements with a sample from  </abstract>::line_number::17
<abstract> among concepts in a class H can be approximated to within a factor k, then there is a simple tracking  </abstract>::line_number::18
<abstract> algorithm for H which can achieve a probability * of making a mistake if the target movement rate  </abstract>::line_number::19
<abstract> is at most a constant times * 2 =(k(d + k) ln 1  </abstract>::line_number::20
<abstract> * ), where d is the Vapnik-Chervonenkis dimension of  </abstract>::line_number::21
<abstract> H. Also, we show that if H is properly PAC-learnable, then there is an efficient (randomized)  </abstract>::line_number::22
<abstract> algorithm that with high probability approximately minimizes disagreements to within a factor of  </abstract>::line_number::23
<abstract> 7d + 1, yielding an efficient tracking algorithm for H which tolerates drift rates up to a constant  </abstract>::line_number::24
<abstract> times * 2 =(d 2 ln 1  </abstract>::line_number::25
<abstract> In addition, we prove complementary results for the classes of halfspaces and axis-aligned hy  </abstract>::line_number::26
<abstract> perrectangles showing that the maximum rate of drift that any algorithm (even with unlimited  </abstract>::line_number::27
<abstract> computational power) can tolerate is a constant times * 2 =d.   </abstract>::line_number::28
<abstract>  Abstract. Feature selection is a problem of choosing a subset of relevant  </abstract>::line_number::7
<abstract> features. In general, only exhaustive search can bring about the optimal  </abstract>::line_number::8
<abstract> subset. With a monotonic measure, exhaustive search can be avoided  </abstract>::line_number::9
<abstract> without sacrificing optimality. Unfortunately, most error- or distance-based measures are not monotonic. A new measure is employed in this  </abstract>::line_number::10
<abstract> work that is monotonic and fast to compute. The search for relevant  </abstract>::line_number::11
<abstract> features according to this measure is guaranteed to be complete but not  </abstract>::line_number::12
<abstract> exhaustive. Experiments are conducted for verification.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Although backpropagation neural networks  </abstract>::line_number::7
<abstract> generally predict better than decision trees do  </abstract>::line_number::8
<abstract> for pattern classification problems, they are often regarded as black boxes, i.e., their predictions are not as interpretable as those of decision trees. This paper argues that this is because there has been no proper technique that  </abstract>::line_number::9
<abstract> enables us to do so. With an algorithm that  </abstract>::line_number::10
<abstract> can extract rules 1 , by drawing parallels with  </abstract>::line_number::11
<abstract> those of decision trees, we show that the predictions of a network can be explained via rules extracted from it, thereby, the network can be understood. Experiments demonstrate that rules  </abstract>::line_number::12
<abstract> extracted from neural networks are comparable with those of decision trees in terms of predictive accuracy, number of rules and average  </abstract>::line_number::13
<abstract> number of conditions for a rule; they preserve  </abstract>::line_number::14
<abstract> high predictive accuracy of original networks.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::7
<abstract> In order for a virtual environment to be effective as a training tool, it is not enough to  </abstract>::line_number::8
<abstract> concentrate on the fidelity of the renderings and the accuracy of the simulated behaviors.  </abstract>::line_number::9
<abstract> The environment should help trainees develop an understanding of the task being trained,  </abstract>::line_number::10
<abstract> and should provide guidance and assistance as needed. This paper describes a system for  </abstract>::line_number::11
<abstract> developing virtual environments in which pedagogical capabilities are incorporated into  </abstract>::line_number::12
<abstract> autonomous agents that interact with trainees. These pedagogical agents can monitor  </abstract>::line_number::13
<abstract> trainees progress and provide guidance and assistance. The agents interact with  </abstract>::line_number::14
<abstract> simulations of objects in the environment, and with trainees. The paper describes the  </abstract>::line_number::15
<abstract> architectural features of the environment and of the agents that permit the agents to meet  </abstract>::line_number::16
<abstract> instructional objectives within the virtual environment. It also discusses how agent-based  </abstract>::line_number::17
<abstract> instruction is combined with other methods of delivering instruction.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Large-scale generation of natural language requires an  </abstract>::line_number::7
<abstract> abstract meaning representation and a mechanism for  </abstract>::line_number::8
<abstract> integrating immense amounts of lexical, morphological, grammatical, and conceptual knowledge. The  </abstract>::line_number::9
<abstract> availability of corpus-based statistical knowledge motivates the invention of a new style of generation in  </abstract>::line_number::10
<abstract> which word lattices compactly encode many possible  </abstract>::line_number::11
<abstract> sentence renderings and a statistical extractor chooses  </abstract>::line_number::12
<abstract> the best ones. The focus of generation thus shifts  </abstract>::line_number::13
<abstract> to how word lattices can be generated from abstract  </abstract>::line_number::14
<abstract> meaning representation. This paper presents a flexible  </abstract>::line_number::15
<abstract> meaning representation scheme and generation mechanism. It includes an efficient generation algorithm and  </abstract>::line_number::16
<abstract> grammar formalism that maps from a meaning representation to a lattice. This mapping is flexible enough  </abstract>::line_number::17
<abstract> to allow meaning representation along a continuum of  </abstract>::line_number::18
<abstract> semantic depth.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::6
<abstract> In this paper, we propose a congestion control  </abstract>::line_number::7
<abstract> mechanism for reliable multicast applications that  </abstract>::line_number::8
<abstract> uses a small set of group members, or representatives,  </abstract>::line_number::9
<abstract> to provide timely and accurate feedback on behalf of  </abstract>::line_number::10
<abstract> congested subtrees of a multicast distribution tree.  </abstract>::line_number::11
<abstract> Our algorithm does not need to compute round-trip  </abstract>::line_number::12
<abstract> time (RTT) from all receivers to the source, nor does  </abstract>::line_number::13
<abstract> it require knowledge of group membership or network  </abstract>::line_number::14
<abstract> topology. Through simulations, we evaluate our algorithm with and without TCP cross traffic. This initial evaluation study shows that our algorithm takes  </abstract>::line_number::15
<abstract> advantage of network bandwidth when available, yet  </abstract>::line_number::16
<abstract> does not starve competing flows.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::13
<abstract> This paper reports the design, implementation, and performance of a scalable and efficient tool to replicate Internet information services. Our tool targets replication  </abstract>::line_number::14
<abstract> degrees of tens of thousands of weakly-consistent replicas scattered throughout the Internet's thousands of autonomously administered domains. The main goal of our  </abstract>::line_number::15
<abstract> replication tool is to make existing replication algorithms  </abstract>::line_number::16
<abstract> scale in today's exponentially-growing, autonomously-managed internetworks.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Information gathering agents can automate the task of retrieving and integrating data  </abstract>::line_number::9
<abstract> from a large number of diverse information sources. The key issue in their performance is  </abstract>::line_number::10
<abstract> efficient query planning that minimizes the number of information sources used to answer  </abstract>::line_number::11
<abstract> a query. Previous work on query planning has considered generating information gathering  </abstract>::line_number::12
<abstract> plans solely based on compile-time analysis of the query and the models of the information  </abstract>::line_number::13
<abstract> sources. We argue that at compile-time it may not be possible to generate an efficient  </abstract>::line_number::14
<abstract> plan for retrieving the requested information because of the large number of possibly  </abstract>::line_number::15
<abstract> relevant sources. We describe an approach that naturally extends query planning to use  </abstract>::line_number::16
<abstract> run-time information to optimize queries that involve many sources. First, we describe an  </abstract>::line_number::17
<abstract> algorithm for generating a discrimination matrix, which is a data structure that identifies  </abstract>::line_number::18
<abstract> the information that can be sensed at run-time to optimize a query plan. Next, we describe  </abstract>::line_number::19
<abstract> how the discrimination matrix is used to decide which of the possible run-time sensing  </abstract>::line_number::20
<abstract> actions to perform. Finally, we demonstrate that this approach yields significant savings  </abstract>::line_number::21
<abstract> (over 90% for some queries) in a real-world task.   </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Semantic query optimization can dramatically speed up database query answering by  </abstract>::line_number::7
<abstract> knowledge intensive reformulation. But the  </abstract>::line_number::8
<abstract> problem of how to learn required semantic  </abstract>::line_number::9
<abstract> rules has not previously been solved. This  </abstract>::line_number::10
<abstract> paper describes an approach using an inductive learning algorithm to solve the problem. In our approach, learning is triggered  </abstract>::line_number::11
<abstract> by user queries and then the system induces semantic rules from the information in  </abstract>::line_number::12
<abstract> databases. The inductive learning algorithm  </abstract>::line_number::13
<abstract> used in this approach can select an appropriate set of relevant attributes from a potentially huge number of attributes in real-world  </abstract>::line_number::14
<abstract> databases. Experimental results demonstrate  </abstract>::line_number::15
<abstract> that this approach can learn sufficient background knowledge to reformulate queries and  </abstract>::line_number::16
<abstract> provide a 57 percent average performance improvement.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::5
<abstract> One of the open problems listed in [ Rivest and  </abstract>::line_number::6
<abstract> Schapire, 1989 ] is whether and how that the  </abstract>::line_number::7
<abstract> copies of L in their algorithm can be combined into one for better performance. This  </abstract>::line_number::8
<abstract> paper describes an algorithm called D that  </abstract>::line_number::9
<abstract> does that combination. The idea is to represent  </abstract>::line_number::10
<abstract> the states of the learned model using observable  </abstract>::line_number::11
<abstract> symbols as well as hidden symbols that are constructed during learning. These hidden symbols are created to reflect the distinct behaviors  </abstract>::line_number::12
<abstract> of the model states. The distinct behaviors are  </abstract>::line_number::13
<abstract> represented as local distinguishing experiments  </abstract>::line_number::14
<abstract> (LDEs) (not to be confused with global distinguishing sequences), and these LDEs are created when the learner's prediction mismatches  </abstract>::line_number::15
<abstract> the actual observation from the unknown machine. To synchronize the model with the environment, these LDEs can also be concatenated to form a homing sequence. It can  </abstract>::line_number::16
<abstract> be shown that D can learn, with probability  </abstract>::line_number::17
<abstract> 1 ~, a model that is an *-approximation of  </abstract>::line_number::18
<abstract> the unknown machine, in a number of actions  </abstract>::line_number::19
<abstract> polynomial in the size of the environment and   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Intelligent interaction in multi-agent domains frequently requires an agent to track other  </abstract>::line_number::9
<abstract> agents' mental states: their current goals, beliefs, and intentions. Accuracy in this agent  </abstract>::line_number::10
<abstract> tracking task is critically dependent on the accuracy of the tracker's (tracking agent's) model  </abstract>::line_number::11
<abstract> of the trackee (tracked agent). Unfortunately, in real-world situations, model imperfections  </abstract>::line_number::12
<abstract> arise due to the tracker's resource and information constraints, as well as due to trackees'  </abstract>::line_number::13
<abstract> dynamic behavior modification. While such model imperfections are unavoidable, a tracker  </abstract>::line_number::14
<abstract> must nonetheless attempt to be adaptive in its agent tracking. This article identifies key issues  </abstract>::line_number::15
<abstract> in adaptive agent tracking and presents an approach called DEFT. At its core, DEFT is based  </abstract>::line_number::16
<abstract> on discrimination-based learning. The main idea is to identify the deficiency of a model based  </abstract>::line_number::17
<abstract> on tracking failures, and revise the model by using features that are critical in discriminating  </abstract>::line_number::18
<abstract> successful and failed tracking episodes. Because in real-world situations the set of candidate  </abstract>::line_number::19
<abstract> discriminating features is very large, DEFT relies on knowledge-based focusing to limit the  </abstract>::line_number::20
<abstract> discrimination to those features that it determines were relevant in successful tracking episodes  </abstract>::line_number::21
<abstract> with an autonomous explanation capability as a major source of this knowledge. This article  </abstract>::line_number::22
<abstract> reports on experiments with an implementation of key aspects of DEFT in a complex synthetic  </abstract>::line_number::23
<abstract> air-to-air combat domain.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Mixed-initiative systems present the challenge of finding an effective level of interaction between humans  </abstract>::line_number::7
<abstract> and computers. Machine learning presents a promising approach to this problem in the form of systems  </abstract>::line_number::8
<abstract> that automatically adapt their behavior to accommodate different users. In this paper, we present an empirical study of learning user models in an adaptive  </abstract>::line_number::9
<abstract> assistant for crisis scheduling. We describe the problem domain and the scheduling assistant, then present  </abstract>::line_number::10
<abstract> an initial formulation of the adaptive assistant's learning task and the results of a baseline study. After this,  </abstract>::line_number::11
<abstract> we report the results of three subsequent experiments  </abstract>::line_number::12
<abstract> that investigate the effects of problem reformulation  </abstract>::line_number::13
<abstract> and representation augmentation. The results suggest  </abstract>::line_number::14
<abstract> that problem reformulation leads to significantly better accuracy without sacrificing the usefulness of the  </abstract>::line_number::15
<abstract> learned behavior. The studies also raise several interesting issues in adaptive assistance for scheduling.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Much of the work on execution assumes that the agent  </abstract>::line_number::9
<abstract> constantly senses the environment, which lets it respond  </abstract>::line_number::10
<abstract> immediately to errors or unexpected events. In this paper, we argue that this purely reactive strategy is only  </abstract>::line_number::11
<abstract> optimal if sensing is inexpensive, and we formulate a simple model of execution that incorporates the cost of sensing. We present an average-case analysis of this model,  </abstract>::line_number::12
<abstract> which shows that in domains with high sensing cost or  </abstract>::line_number::13
<abstract> low probability of error, a more `automatic' strategy -  </abstract>::line_number::14
<abstract> one with long intervals between sensing can lead to  </abstract>::line_number::15
<abstract> less expensive execution. The analysis also shows that  </abstract>::line_number::16
<abstract> the distance to the goal has no effect on the optimal sensing interval. These results run counter to the prevailing  </abstract>::line_number::17
<abstract> wisdom in the planning community, but they promise a  </abstract>::line_number::18
<abstract> more balanced approach to the interleaving of execution  </abstract>::line_number::19
<abstract> and sensing.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::8
<abstract> As a classifier, a Set Enumeration (SE) tree can be viewed as a generalization of  </abstract>::line_number::9
<abstract> decision trees. We empirically characterize domains in which SE-trees are particularly  </abstract>::line_number::10
<abstract> advantageous relative to decision trees. Specifically, we show that:  </abstract>::line_number::11
<abstract> 1. SE-trees excel in domains in which relatively few examples are available; and  </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::3
<abstract> The concurrency control requirements for transaction processing in a multilevel secure file system are different from those in conventional transaction processing systems.  </abstract>::line_number::4
<abstract> In particular, there is the need to coordinate transactions at different security levels  </abstract>::line_number::5
<abstract> avoiding both potential timing covert channels and the starvation of transactions at  </abstract>::line_number::6
<abstract> higher security levels. Suppose a transaction at a lower security level attempts to write  </abstract>::line_number::7
<abstract> a data item that is being read by a transaction at a higher security level. On the one  </abstract>::line_number::8
<abstract> hand, a timing covert channel arises if the transaction at the lower security level is either  </abstract>::line_number::9
<abstract> delayed or aborted by the scheduler. On the other hand, the transaction at the high  </abstract>::line_number::10
<abstract> security level may be subjected to an indefinite delay if it is forced to abort repeatedly.  </abstract>::line_number::11
<abstract> This paper extends the classical two-phase locking mechanism to multilevel secure  </abstract>::line_number::12
<abstract> file systems. The scheme presented here prevents potential timing covert channels and  </abstract>::line_number::13
<abstract> avoids the abort of higher level transactions nonetheless guaranteeing serializability.  </abstract>::line_number::14
<abstract> The programmer is provided with a powerful set of linguistic constructs that supports  </abstract>::line_number::15
<abstract> exception handling, partial rollback and forward recovery. The proper use of these  </abstract>::line_number::16
<abstract> constructs can prevent the indefinite delay in completion of a higher level transaction,  </abstract>::line_number::17
<abstract> and allows the programmer to trade off starvation with transaction isolation.   </abstract>::line_number::18
<abstract>  Abstract  </abstract>::line_number::6
<abstract> We propose a new image retrieval method based  </abstract>::line_number::7
<abstract> on human perceptual clustering of color images. This  </abstract>::line_number::8
<abstract> color clustering produces for each image a small set of  </abstract>::line_number::9
<abstract> representative colors which captures the color properties of the image, and a small set of sizable contiguous  </abstract>::line_number::10
<abstract> regions which captures the spatial/geometrical properties of the image. The proposed method outperforms  </abstract>::line_number::11
<abstract> the traditional histogram and its improved methods not  </abstract>::line_number::12
<abstract> only with its richer image retrieval capabilities which  </abstract>::line_number::13
<abstract> cover a wider spectrum of user requirements, but also  </abstract>::line_number::14
<abstract> with its powerful indexing scheme which is essential to  </abstract>::line_number::15
<abstract> cater for large scale image databases.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Introspective reasoning about a system's own  </abstract>::line_number::9
<abstract> reasoning processes can form the basis for  </abstract>::line_number::10
<abstract> learning to refine those reasoning processes.  </abstract>::line_number::11
<abstract> The ROBBIE 1 system uses introspective reasoning to monitor the retrieval process of a  </abstract>::line_number::12
<abstract> case-based planner to detect retrieval of inappropriate cases. When retrieval problems  </abstract>::line_number::13
<abstract> are detected, the source of the problems is explained and the explanations are used to determine new indices to use during future case  </abstract>::line_number::14
<abstract> retrieval. The goal of ROBBIE's learning is to  </abstract>::line_number::15
<abstract> increase its ability to focus retrieval on relevant  </abstract>::line_number::16
<abstract> cases, with the aim of simultaneously decreasing the number of candidates to consider and  </abstract>::line_number::17
<abstract> increasing the likelihood that the system will be  </abstract>::line_number::18
<abstract> able to successfully adapt the retrieved cases to  </abstract>::line_number::19
<abstract> fit the current situation. We evaluate the benefits of the approach in light of empirical results  </abstract>::line_number::20
<abstract> examining the effects of index learning in the  </abstract>::line_number::21
<abstract> ROBBIE system.   </abstract>::line_number::22
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> This note addresses the following problem: Find conditions under which a continuous-time (nonlinear)  </abstract>::line_number::6
<abstract> system gives rise, under constant rate sampling, to a discrete-time system which satisfies the accessibility  </abstract>::line_number::7
<abstract> property.   </abstract>::line_number::8
<abstract>  Abstract  </abstract>::line_number::4
<abstract> This paper starts by placing neural net techniques in a general nonlinear  </abstract>::line_number::5
<abstract> control framework. After that, several basic theoretical results on networks  </abstract>::line_number::6
<abstract> are surveyed.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::17
<abstract> This paper deals with the problem of global stabilization of linear discrete time systems by means of  </abstract>::line_number::18
<abstract> bounded feedback laws. The main result proved is an analog of one proved for the continuous time case  </abstract>::line_number::19
<abstract> by the authors, and shows that such stabilization is possible if and only if the system is stabilizable  </abstract>::line_number::20
<abstract> with arbitrary controls and the transition matrix has spectral radius less or equal to one. The proof  </abstract>::line_number::21
<abstract> provides in principle an algorithm for the construction of such feedback laws, which can be implemented  </abstract>::line_number::22
<abstract> either as cascades or as parallel connections ("single hidden layer neural networks") of simple saturation  </abstract>::line_number::23
<abstract> functions.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::3
<abstract> We suggest a scheme for a block cipher which uses only one randomly chosen permutation, F . The key, consisting of two blocks, K 1  </abstract>::line_number::4
<abstract> and K 2 is used in the following way: The message block is XORed  </abstract>::line_number::5
<abstract> with K 1 before applying F , and the outcome is XORed with K 2 , to  </abstract>::line_number::6
<abstract> produce the cryptogram block. We show that the resulting cipher  </abstract>::line_number::7
<abstract> is secure (when the permutation is random or pseudorandom). This  </abstract>::line_number::8
<abstract> removes the need to store, or generate a multitude of permutations.   </abstract>::line_number::9
<abstract>  Abstract. Traditional decision theory has assumed that agents have complete, consistent and readily available beliefs and preferences. Obviously, even if  </abstract>::line_number::2
<abstract> an expert system has complete and consistent beliefs, it cannot have them readily  </abstract>::line_number::3
<abstract> available. Moreover, some beliefs about beliefs are not even approximately computable. It is shown that if all players have complete and consistent beliefs, they  </abstract>::line_number::4
<abstract> can compute approximate beliefs about beliefs of any order by considering events  </abstract>::line_number::5
<abstract> arbitrarily close in some well-defined sense to the ones in question.   </abstract>::line_number::6
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Abstract. The subject of this paper is finding small sample spaces for joint distributions of  </abstract>::line_number::7
<abstract> n discrete random variables. Such distributions  </abstract>::line_number::8
<abstract> are often only required to obey a certain limited set of constraints of the form P r(E) = .  </abstract>::line_number::9
<abstract> We show that the problem of deciding whether  </abstract>::line_number::10
<abstract> there exists any distribution satisfying a given  </abstract>::line_number::11
<abstract> set of constraints is NP-hard. However, if the  </abstract>::line_number::12
<abstract> constraints are consistent, then there exists a distribution satisfying them which is supported by  </abstract>::line_number::13
<abstract> a "small" sample space (one whose cardinality is  </abstract>::line_number::14
<abstract> equal to the number of constraints). For the important case of independence constraints, where  </abstract>::line_number::15
<abstract> the constraints have a certain form and are consistent with a joint distribution of n independent  </abstract>::line_number::16
<abstract> random variables, a small sample space can be  </abstract>::line_number::17
<abstract> constructed in polynomial time. This last result  </abstract>::line_number::18
<abstract> is also useful for de-randomizing algorithms. We  </abstract>::line_number::19
<abstract> demonstrate this technique by an application to  </abstract>::line_number::20
<abstract> the problem of finding large independent sets in  </abstract>::line_number::21
<abstract> sparse hypergraphs.   </abstract>::line_number::22
<abstract>  ABSTRACT  </abstract>::line_number::8
<abstract> Several methods of increasing the speed and simplicity of the computation of off-axis transmission holograms are  </abstract>::line_number::9
<abstract> presented, with applications to the real-time display of holographic images. A bipolar intensity approach enables a  </abstract>::line_number::10
<abstract> linear summation of interference fringes, a factor of two speed increase, and the elimination of image noise caused by  </abstract>::line_number::11
<abstract> object self-interference. An order of magnitude speed increase is obtained through the use of precomputed look-up  </abstract>::line_number::12
<abstract> tables containing a large array of elemental interference patterns corresponding to point source contributions from  </abstract>::line_number::13
<abstract> each of the possible locations in image space. Results achieved using a data-parallel supercomputer to compute  </abstract>::line_number::14
<abstract> horizontal-parallax-only holographic patterns containing 6 megasamples indicate that an image comprised of 10,000  </abstract>::line_number::15
<abstract> points with arbitrary brightness (grayscale) can be computed in under one second.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Authoring is usually one of the most difficult parts in the design and implementation of hypertext and  </abstract>::line_number::9
<abstract> hypermedia systems. This problem is exacerbated if the data to be presented by the system is speech,  </abstract>::line_number::10
<abstract> rather than text or graphics, because of the slow and serial nature of speech. This paper provides an  </abstract>::line_number::11
<abstract> overview of speech-only hypermedia, discusses the difficulties associated with authoring databases for  </abstract>::line_number::12
<abstract> such a system, and explores a variety of techniques to assist in the authoring process.   </abstract>::line_number::13
<abstract>  ABSTRACT  </abstract>::line_number::7
<abstract> This paper applies genetic programming  </abstract>::line_number::8
<abstract> to the evolution of intelligent agents that  </abstract>::line_number::9
<abstract> gradually build internal representations of  </abstract>::line_number::10
<abstract> their surroundings for later use in  </abstract>::line_number::11
<abstract> planning. The method used allows for the  </abstract>::line_number::12
<abstract> creation of dynamically determined  </abstract>::line_number::13
<abstract> representations that are not pre-designed  </abstract>::line_number::14
<abstract> by the human creator of the system. In an  </abstract>::line_number::15
<abstract> illustrative path-planning problem, evolved  </abstract>::line_number::16
<abstract> programs learn a model of their world and  </abstract>::line_number::17
<abstract> use this internal representation to plan  </abstract>::line_number::18
<abstract> their successive actions. The results show  </abstract>::line_number::19
<abstract> that the proposed method is successful in  </abstract>::line_number::20
<abstract> evolving programs that solve the planning  </abstract>::line_number::21
<abstract> problem and is thus a worthy basis for  </abstract>::line_number::22
<abstract> further investigation.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::8
<abstract> The information that a pattern of firing in the output layer of a feedforward  </abstract>::line_number::9
<abstract> network of threshold-linear neurons conveys about the network's inputs is  </abstract>::line_number::10
<abstract> considered. A replica-symmetric solution is found to be stable for all but  </abstract>::line_number::11
<abstract> small amounts of noise. The region of instability depends on the contribution  </abstract>::line_number::12
<abstract> of the threshold and the sparseness: for distributed pattern distributions,  </abstract>::line_number::13
<abstract> the unstable region extends to higher noise variances than for very sparse  </abstract>::line_number::14
<abstract> distributions, for which it is almost nonexistant.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Indexing of cases is an important topic for Memory-Based Reasoning(MBR). One key problem is how to  </abstract>::line_number::8
<abstract> assign weights to attributes of cases. Although several  </abstract>::line_number::9
<abstract> weighting methods have been proposed, some methods cannot handle numeric attributes directly, so it  </abstract>::line_number::10
<abstract> is necessary to discretize numeric values by classification. Furthermore, existing methods have no theoretical background, so little can be said about optimality.  </abstract>::line_number::11
<abstract> We propose a new weighting method based on a statistical technique called Quantification Method II. It can  </abstract>::line_number::12
<abstract> handle both numeric and symbolic attributes in the  </abstract>::line_number::13
<abstract> same framework. Generated attribute weights are optimal in the sense that they maximize the ratio of variance between classes to variance of all cases. Experiments on several benchmark tests show that in many  </abstract>::line_number::14
<abstract> cases, our method obtains higher accuracies than some  </abstract>::line_number::15
<abstract> other weighting methods. The results also indicate  </abstract>::line_number::16
<abstract> that it can distinguish relevant attributes from irrelevant ones, and can tolerate noisy data.   </abstract>::line_number::17
<abstract>  Abstract. This paper presents a comparative study of several methods for estimating  </abstract>::line_number::7
<abstract> the true error of treestructured regression models. We evaluate these methods in the  </abstract>::line_number::8
<abstract> context of regression tree pruning. Pruning is considered a key issue for obtaining  </abstract>::line_number::9
<abstract> reliable treestructured models in a real world scenario. The major step of a pruning  </abstract>::line_number::10
<abstract> process consists of obtaining accurate estimates of the error of alternative tree  </abstract>::line_number::11
<abstract> models. We evaluate experimentally four methods for obtaining these estimates in  </abstract>::line_number::12
<abstract> twelve domains. The goal of this evaluation was to characterise the performance of  </abstract>::line_number::13
<abstract> the methods in the task of selecting the best possible tree among the set of trees  </abstract>::line_number::14
<abstract> considered during pruning. The results of the comparison show that certain  </abstract>::line_number::15
<abstract> estimators lead to poor decisions in some domains. The Cross Validation variant that  </abstract>::line_number::16
<abstract> we have proposed achieved the best results on the setups we have considered.   </abstract>::line_number::17
<abstract>  Abstract. This paper describes the work on methods for combining rules  </abstract>::line_number::11
<abstract> obtained by machine learning systems. Three methods for obtaining the  </abstract>::line_number::12
<abstract> classification of examples with those rules are compared. The advantages and  </abstract>::line_number::13
<abstract> disadvantages of each method are discussed and the results obtained on three  </abstract>::line_number::14
<abstract> real world domains are commented. The methods compared are: selection of  </abstract>::line_number::15
<abstract> the best rule; PROSPECTOR-like probabilistic approximation for rule  </abstract>::line_number::16
<abstract> combination; and MYCIN-like approximation. Results show significant  </abstract>::line_number::17
<abstract> differences between methods indicating that the problemsolving strategy is  </abstract>::line_number::18
<abstract> important for accuracy of learning systems.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Recurrent neural networks readily process, recognize and generate temporal sequences. By encoding  </abstract>::line_number::6
<abstract> grammatical strings as temporal sequences, recurrent neural networks can be trained to behave like deterministic sequential finite-state automata. Algorithms have been developed for extracting grammatical  </abstract>::line_number::7
<abstract> rules from trained networks. Using a simple method for inserting prior knowledge (or rules) into recurrent  </abstract>::line_number::8
<abstract> neural networks, we show that recurrent neural networks are able to perform rule revision. Rule revision  </abstract>::line_number::9
<abstract> is performed by comparing the inserted rules with the rules in the finite-state automata extracted from  </abstract>::line_number::10
<abstract> trained networks. The results from training a recurrent neural network to recognize a known non-trivial,  </abstract>::line_number::11
<abstract> randomly generated regular grammar show that not only do the networks preserve correct rules but that  </abstract>::line_number::12
<abstract> they are able to correct through training inserted rules which were initially incorrect. (By incorrect, we  </abstract>::line_number::13
<abstract> mean that the rules were not the ones in the randomly generated grammar.)   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::6
<abstract> Recurrent neural networks have become popular models for system identification and time  </abstract>::line_number::7
<abstract> series prediction. NARX (Nonlinear AutoRegressive models with eXogenous inputs) neural  </abstract>::line_number::8
<abstract> network models are a popular subclass of recurrent networks and have been used in many  </abstract>::line_number::9
<abstract> applications. Though embedded memory can be found in all recurrent network models, it is  </abstract>::line_number::10
<abstract> particularly prominent in NARX models.  </abstract>::line_number::11
<abstract> We show that using intelligent memory order selection through pruning and good initial  </abstract>::line_number::12
<abstract> heuristics significantly improves the generalization and predictive performance of these nonlinear  </abstract>::line_number::13
<abstract> systems on problems as diverse as grammatical inference and time series prediction.   </abstract>::line_number::14
<abstract>  Abstract  </abstract>::line_number::13
<abstract> One of the most important aspects of any machine learning paradigm is how it scales according  </abstract>::line_number::14
<abstract> to problem size and complexity. Using a task with known optimal training error, and a pre-specified  </abstract>::line_number::15
<abstract> maximum number of training updates, we investigate the convergence of the backpropagation algorithm  </abstract>::line_number::16
<abstract> with respect to a) the complexity of the required function approximation, b) the size of the network in  </abstract>::line_number::17
<abstract> relation to the size required for an optimal solution, and c) the degree of noise in the training data. In  </abstract>::line_number::18
<abstract> general, for a) the solution found is worse when the function to be approximated is more complex, for  </abstract>::line_number::19
<abstract> b) oversized networks can result in lower training and generalization error in certain cases, and for c)  </abstract>::line_number::20
<abstract> the use of committee or ensemble techniques can be more beneficial as the level of noise in the training  </abstract>::line_number::21
<abstract> data is increased. For the experiments we performed, we do not obtain the optimal solution in any case.  </abstract>::line_number::22
<abstract> We further support the observation that larger networks can produce better training and generalization  </abstract>::line_number::23
<abstract> error using a face recognition example where a network with many more parameters than training points  </abstract>::line_number::24
<abstract> generalizes better than smaller networks.   </abstract>::line_number::25
<abstract>  Abstract   </abstract>::line_number::7
<abstract> World Wide Web (WWW) search engines (e.g. AltaVista, Infoseek, HotBot, etc.) have a number of  </abstract>::line_number::8
<abstract> deficiencies including: periods of downtime, low coverage of the WWW, inconsistent and inefficient user  </abstract>::line_number::9
<abstract> interfaces, out of date databases, poor relevancy ranking and precision, and difficulties with spamming  </abstract>::line_number::10
<abstract> techniques. Meta search engines have been introduced which address some of these and other difficulties in  </abstract>::line_number::11
<abstract> searching the WWW. However, current meta search engines retain some of these difficulties and may also  </abstract>::line_number::12
<abstract> introduce their own problems (e.g. reduced relevance because one or more of the search engines returns results  </abstract>::line_number::13
<abstract> with poor relevance). We present Inquirus, the NECI meta search engine, which addresses many of the  </abstract>::line_number::14
<abstract> deficiencies in current techniques. Rather than working with the list of documents and summaries returned by  </abstract>::line_number::15
<abstract> search engines, as current meta search engines typically do, the Inquirus meta search engine works by  </abstract>::line_number::16
<abstract> downloading and analyzing the individual documents. The Inquirus meta search engine makes improvements  </abstract>::line_number::17
<abstract> over existing search engines in a number of areas, e.g.: more useful document summaries incorporating query  </abstract>::line_number::18
<abstract> term context, identification of both pages which no longer exist and pages which no longer contain the query  </abstract>::line_number::19
<abstract> terms, advanced detection of duplicate pages, improved document ranking using proximity information,  </abstract>::line_number::20
<abstract> dramatically improved precision for certain queries by using specific expressive forms, and quick jump links  </abstract>::line_number::21
<abstract> and highlighting when viewing the full documents.    </abstract>::line_number::22
<abstract>  Abstract  </abstract>::line_number::8
<abstract> This paper shows that members of the fourier transform family are the only linear  </abstract>::line_number::9
<abstract> transforms that have a convolution theorem, that is, that can replace O(N 2 ) operations  </abstract>::line_number::10
<abstract> of a convolution in a time domain by O(N) operations in a transform domain. Generally,  </abstract>::line_number::11
<abstract> there is an additional cost to compute the transform itself. Our observation is motivated by  </abstract>::line_number::12
<abstract> recent activity in wavelet and subband decompositions and related spectral analyses, which  </abstract>::line_number::13
<abstract> are attractive alternatives for signal compression applications. A natural question when  </abstract>::line_number::14
<abstract> using such techniques is to determine if convolutions of N -point signals can be calculated  </abstract>::line_number::15
<abstract> with fewer operations in a compressed transform domain than in an uncompressed time  </abstract>::line_number::16
<abstract> domain. The answer is negative for a broad set of assumptions. This paper indicates what  </abstract>::line_number::17
<abstract> assumptions must be relaxed in seeking a linear transform that has a convolution theorem  </abstract>::line_number::18
<abstract> comparable to the convolution theorem for fourier transforms.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Time-indexed linear programming formulations have recently received a great deal of attention for their practical  </abstract>::line_number::5
<abstract> effectiveness in solving a number of single-machine scheduling problems. We show that these formulations are also an  </abstract>::line_number::6
<abstract> important tool in the design of approximation algorithms  </abstract>::line_number::7
<abstract> with good worst-case performance guarantees. We give simple new rounding techniques to convert an optimal fractional  </abstract>::line_number::8
<abstract> solution into a feasible schedule for which we can prove a  </abstract>::line_number::9
<abstract> constant-factor performance guarantee, thereby giving the  </abstract>::line_number::10
<abstract> first theoretical evidence of the strength of these relaxations.  </abstract>::line_number::11
<abstract> Specifically, we consider the problem of minimizing the  </abstract>::line_number::12
<abstract> total weighted job completion time on a single machine  </abstract>::line_number::13
<abstract> subject to precedence constraints, and give a polynomial-time (4 + *)-approximation algorithm, for any * &gt; 0;  </abstract>::line_number::14
<abstract> the best previously known guarantee for this problem was  </abstract>::line_number::15
<abstract> superlogarithmic. With somewhat larger constants, we also  </abstract>::line_number::16
<abstract> show how to extend this result to the case with release date  </abstract>::line_number::17
<abstract> constraints, and still more generally, to the case with m  </abstract>::line_number::18
<abstract> identical parallel machines. We give two other techniques for  </abstract>::line_number::19
<abstract> problems in which there are release dates, but no precedence  </abstract>::line_number::20
<abstract> constraints: the first is based on other new LP rounding  </abstract>::line_number::21
<abstract> algorithms, whereas the second is a general framework for  </abstract>::line_number::22
<abstract> designing on-line algorithms to minimize the total weighted  </abstract>::line_number::23
<abstract> completion time.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::10
<abstract> The Hamiltonian dynamics of spherically symmetric massive thin shells  </abstract>::line_number::11
<abstract> in the general relativity is considered. Two different constraint dynamical  </abstract>::line_number::12
<abstract> systems representing this dynamics have been described recently; the relation  </abstract>::line_number::13
<abstract> of these two systems is investigated. The symmetry groups of both systems  </abstract>::line_number::14
<abstract> are found. The systems are reduced to the presymplectic manifolds 1 and 2 ,  </abstract>::line_number::15
<abstract> lest non-physical aspects like gauge fixings or embeddings in extended phase  </abstract>::line_number::16
<abstract> spaces hinder the argument. The following facts are shown. 1 is three- and 2  </abstract>::line_number::17
<abstract> is five-dimensional; the description of the shell dynamics by 1 is incomplete  </abstract>::line_number::18
<abstract> so that some measurable properties of the shell cannot be predicted. 1 is  </abstract>::line_number::19
<abstract> locally equivalent to a subsystem of 2 and the corresponding local morphisms  </abstract>::line_number::20
<abstract> are not unique, due to the large symmetry group of 2 . The local equivalence  </abstract>::line_number::21
<abstract> explains why the same radial equation results from both systems; what is,  </abstract>::line_number::22
<abstract> however, the physical importance of just local, but not global equivalence of  </abstract>::line_number::23
<abstract> constraint dynamical systems remains unclear.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::7
<abstract> In this brief contribution we present the three principal laser remote  </abstract>::line_number::8
<abstract> sensing ( lidar) techniques developed to retrieve the vertical profiling of  </abstract>::line_number::9
<abstract> clouds and of the suspended aerosols (extinction and backscatter) in the  </abstract>::line_number::10
<abstract> lower atmosphere, namely in the 0-7 km altitude region. The three lidar  </abstract>::line_number::11
<abstract> techniques include the elastic ( Klett inversion, Doppler broadening) and  </abstract>::line_number::12
<abstract> the nonelastic backscattering techniques ( Raman scattering). We report  </abstract>::line_number::13
<abstract> on the potential of these techniques, as well as on the typical accuracies  </abstract>::line_number::14
<abstract> of these techniques in the retrieval of the cloud and aerosol extinction  </abstract>::line_number::15
<abstract> and backscatter vertical profiles in the troposphere (0-7 km ASL).   </abstract>::line_number::16
<abstract>  ABSTRACT  </abstract>::line_number::20
<abstract> Large scale distributed systems are becoming of  </abstract>::line_number::21
<abstract> paramount importance, due to the evolution of technology and to the interest of market. Their development,  </abstract>::line_number::22
<abstract> however, is not yet supported by a sound technological and methodological background, as the results developed for small size distributed systems often do not  </abstract>::line_number::23
<abstract> scale up. Recently, mobile code languages (MCLs) have  </abstract>::line_number::24
<abstract> been proposed as a technological answer to the problem.  </abstract>::line_number::25
<abstract> In this work, we abstract away from the details of these  </abstract>::line_number::26
<abstract> languages by deriving design paradigms exploiting code  </abstract>::line_number::27
<abstract> mobility that are independent of any particular technology. We present such design paradigms, together  </abstract>::line_number::28
<abstract> with a discussion of their features, their application domain, and some hints about the selection of the correct  </abstract>::line_number::29
<abstract> paradigm for a given distributed application.   </abstract>::line_number::30
<abstract>  Abstract  </abstract>::line_number::11
<abstract> We present computer simulations of a model of the brain  </abstract>::line_number::12
<abstract> mechanisms operating in short-term memory tasks that are  </abstract>::line_number::13
<abstract> consistent with the anatomy and physiology of prefrontal  </abstract>::line_number::14
<abstract> cortex and associated subcortical structures. These  </abstract>::line_number::15
<abstract> simulations include dynamical processes in thalamo-cortical loops which are used to generate short-term  </abstract>::line_number::16
<abstract> persistent responses in prefrontal cortex. We discuss this  </abstract>::line_number::17
<abstract> model in terms of the representation of input stimuli in  </abstract>::line_number::18
<abstract> cortical association areas and prefrontal short-term  </abstract>::line_number::19
<abstract> memory areas. We report on interference phenomena that  </abstract>::line_number::20
<abstract> result from the interaction of these dynamical processes  </abstract>::line_number::21
<abstract> and lateral projections within cortical columns. These  </abstract>::line_number::22
<abstract> interference phenomena can be used to elucidate the  </abstract>::line_number::23
<abstract> representational organization of short-term memory.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::5
<abstract> We develop necessary conditions for the development of asynchronous distributed  </abstract>::line_number::6
<abstract> software that will perform uniform actions (events that if performed by any process,  </abstract>::line_number::7
<abstract> must be performed at all processes). The paper focuses on dynamic uniformity, which  </abstract>::line_number::8
<abstract> differs from the classical problems in that processes continually leave and join the  </abstract>::line_number::9
<abstract> ongoing computation. Here, we first treat a static version of the problem (lacking joins),  </abstract>::line_number::10
<abstract> and then extend the results so obtained to also include joins. Our results demonstrate  </abstract>::line_number::11
<abstract> that in contrast to Consensus, which cannot be solved in asynchronous systems with  </abstract>::line_number::12
<abstract> even a single faulty process, dynamic uniformity can be solved using a failure detection  </abstract>::line_number::13
<abstract> mechanism that makes bounded numbers of mistakes. Because dynamic uniformity  </abstract>::line_number::14
<abstract> arises in systems that maintain safety within a "primary partition" of a network, our  </abstract>::line_number::15
<abstract> paper provides a rigorous characterization of the framework upon which several existing  </abstract>::line_number::16
<abstract> distributed programming environments are based.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We analyze the performance of top-down algorithms for decision tree learning, such as those employed  </abstract>::line_number::8
<abstract> by the widely used C4.5 and CART software packages. Our main result is a proof that such algorithms  </abstract>::line_number::9
<abstract> are boosting algorithms. By this we mean that if the functions that label the internal nodes of the  </abstract>::line_number::10
<abstract> decision tree can weakly approximate the unknown target function, then the top-down algorithms we  </abstract>::line_number::11
<abstract> study will amplify this weak advantage to build a tree achieving any desired level of accuracy. The bounds  </abstract>::line_number::12
<abstract> we obtain for this amplification show an interesting dependence on the splitting criterion used by the  </abstract>::line_number::13
<abstract> top-down algorithm. More precisely, if the functions used to label the internal nodes have error 1=2   </abstract>::line_number::14
<abstract> as approximations to the target function, then for the splitting criteria used by CART and C4.5, trees  </abstract>::line_number::15
<abstract> of size (1=*) O(1= 2 * 2 ) and (1=*) O(log(1=*)= 2 ) (respectively) suffice to drive the error below *. Thus (for  </abstract>::line_number::16
<abstract> example), a small constant advantage over random guessing is amplified to any larger constant advantage  </abstract>::line_number::17
<abstract> with trees of constant size. For a new splitting criterion suggested by our analysis, the much stronger  </abstract>::line_number::18
<abstract> bound of (1=*) O(1= 2 ) (which is polynomial in 1=*) is obtained, which is provably optimal for decision  </abstract>::line_number::19
<abstract> tree algorithms. The differing bounds have a natural explanation in terms of concavity properties of the  </abstract>::line_number::20
<abstract> splitting criterion.  </abstract>::line_number::21
<abstract> The primary contribution of this work is in proving that some popular and empirically successful  </abstract>::line_number::22
<abstract> heuristics that are based on first principles meet the criteria of an independently motivated theoretical  </abstract>::line_number::23
<abstract> model.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::10
<abstract> This paper re-examines the problem of parameter estimation in Bayesian networks with missing values and  </abstract>::line_number::11
<abstract> hidden variables from the perspective of recent work in  </abstract>::line_number::12
<abstract> on-line learning [12]. We provide a unified framework  </abstract>::line_number::13
<abstract> for parameter estimation that encompasses both on-line  </abstract>::line_number::14
<abstract> learning, where the model is continuously adapted to new  </abstract>::line_number::15
<abstract> data cases as they arrive, and the more traditional batch  </abstract>::line_number::16
<abstract> learning, where a pre-accumulated set of samples is used  </abstract>::line_number::17
<abstract> in a one-time model selection process. In the batch case,  </abstract>::line_number::18
<abstract> our framework encompasses both the gradient projection  </abstract>::line_number::19
<abstract> algorithm [2, 3] and the EM algorithm [14] for Bayesian  </abstract>::line_number::20
<abstract> networks. The framework also leads to new on-line and  </abstract>::line_number::21
<abstract> batch parameter update schemes, including a parameterized version of EM. We provide both empirical and theoretical results indicating that parameterized EM allows  </abstract>::line_number::22
<abstract> faster convergence to the maximum likelihood parame  </abstract>::line_number::23
<abstract> ters than does standard EM.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::7
<abstract> In recent years, networks with media rates of 100 Mbit/second or more have become widely available (FDDI, ATM,  </abstract>::line_number::8
<abstract> HIPPI, ..). However, many computer systems cannot make use of the available bandwidth because of the high  </abstract>::line_number::9
<abstract> overhead associated with network communication. In this paper we review the operations involved in communication over high-speed networks, and we describe optimizations of the network interface that improve network  </abstract>::line_number::10
<abstract> throughput. We also discuss how the payoff of the optimizations is influenced by features of the host software and  </abstract>::line_number::11
<abstract> architecture. This paper is based on our experience with the interfaces for the Nectar and Gigabit Nectar networks.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::14
<abstract> The use of primary effects of operators is an effective approach to improving the  </abstract>::line_number::15
<abstract> efficiency of planning. The characterization of "good" primary effects, however, has  </abstract>::line_number::16
<abstract> remained at an informal level and there have been no algorithms for selecting primary  </abstract>::line_number::17
<abstract> effects of operators.  </abstract>::line_number::18
<abstract> We formalize the use of primary effects in planning and present a criterion for  </abstract>::line_number::19
<abstract> selecting useful primary effects, which guarantees efficiency and completeness. We  </abstract>::line_number::20
<abstract> analyze the efficiency of planning with primary effects and the quality of the resulting  </abstract>::line_number::21
<abstract> plans.  </abstract>::line_number::22
<abstract> We then describe a learning algorithm that automatically selects primary effects  </abstract>::line_number::23
<abstract> and demonstrate, both analytically and empirically, that the use of this algorithm  </abstract>::line_number::24
<abstract> significantly reduces planning time and does not compromise completeness.   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::8
<abstract> In recent years, researchers have been dedicated to the  </abstract>::line_number::9
<abstract> study of underactuated manipulators which have more  </abstract>::line_number::10
<abstract> joints than control actuators. In previous works,  </abstract>::line_number::11
<abstract> assumptions were made as to the existence of enough  </abstract>::line_number::12
<abstract> dynamic coupling between the active and the passive  </abstract>::line_number::13
<abstract> joints of the manipulator for it to be possible to control  </abstract>::line_number::14
<abstract> the position of the passive joints via the dynamic  </abstract>::line_number::15
<abstract> coupling. In this work, the authors aim to develop an  </abstract>::line_number::16
<abstract> index to measure the dynamic coupling, so as to address  </abstract>::line_number::17
<abstract> when control of the underactuated system is possible,  </abstract>::line_number::18
<abstract> and how the motion and robot configuration can be  </abstract>::line_number::19
<abstract> designed. We discuss extensively the nature of the  </abstract>::line_number::20
<abstract> dynamic coupling and of the proposed coupling index,  </abstract>::line_number::21
<abstract> and their applications in the analysis and design of  </abstract>::line_number::22
<abstract> underactuated systems, and in control and planning of  </abstract>::line_number::23
<abstract> robot motion configuration.   </abstract>::line_number::24
<abstract>  Abstract  </abstract>::line_number::4
<abstract> Region Inference is a technique for inferring lifetimes of values in strict, higher-order programming languages such as Standard ML. The purpose of this paper is to show how ideas  </abstract>::line_number::5
<abstract> from Milner's polymorphic type discipline can serve as a basis for region inference, even in the  </abstract>::line_number::6
<abstract> presence of a limited form of polymorphic recursion.   </abstract>::line_number::7
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We present the spine calculus S !ffi&&gt; as an efficient representation for the linear -calculus !ffi&&gt;  </abstract>::line_number::8
<abstract> which includes intuitionistic functions (!), linear functions (ffi), additive pairing (&), and additive unit  </abstract>::line_number::9
<abstract> (&gt;). S !ffi&&gt; enhances the representation of Church's simply typed -calculus as abstract Bohm trees  </abstract>::line_number::10
<abstract> by enforcing extensionality and by incorporating linear constructs. This approach permits procedures  </abstract>::line_number::11
<abstract> such as unification to retain the efficient head access that characterizes first-order term languages without  </abstract>::line_number::12
<abstract> the overhead of performing -conversions at run time. Potential applications lie in proof search, logic  </abstract>::line_number::13
<abstract> programming, and logical frameworks based on linear type theories. We define the spine calculus, give  </abstract>::line_number::14
<abstract> translations of !ffi&&gt; into S !ffi&&gt; and vice-versa, prove their soundness and completeness with respect  </abstract>::line_number::15
<abstract> to typing and reductions, and show that the spine calculus is strongly normalizing and admits unique  </abstract>::line_number::16
<abstract> canonical forms.   </abstract>::line_number::17
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Substrates for most of today's electronic products contain many wiring layers  </abstract>::line_number::9
<abstract> which are individually fabricated, mechanically registered with one another,  </abstract>::line_number::10
<abstract> and laminated together. Alignment tolerances of 0.05 mm to 0.1 mm are  </abstract>::line_number::11
<abstract> sufficient to register the vertical connection pads or vias on each layer. More  </abstract>::line_number::12
<abstract> aggressive designs of the future will, however, require manufacturing accuracies of at least an order of magnitude better to accommodate much finer  </abstract>::line_number::13
<abstract> wire widths and pin spacings. Conventional equipment relying on mechanical  </abstract>::line_number::14
<abstract> "pin-in-slot" methods will likely be inadequate, and a new approach will be  </abstract>::line_number::15
<abstract> needed.  </abstract>::line_number::16
<abstract> We describe here a sensor-based approach for registration and stacking  </abstract>::line_number::17
<abstract> of electronic substrate sublaminates that replaces pin-in-slot methods, yet  </abstract>::line_number::18
<abstract> does not require accurate automation equipment. A pilot work cell for this  </abstract>::line_number::19
<abstract> approach is presented, which has an IBM 7576 coarse-positioning robot, a  </abstract>::line_number::20
<abstract> specially-developed fine-positioning robot, optical sensors, and several routine  </abstract>::line_number::21
<abstract> low accuracy fixtures. A novel robot bracing method was used to minimize  </abstract>::line_number::22
<abstract> environmental vibration during sublaminate stacking.  </abstract>::line_number::23
<abstract> Pairs of test sublaminates, each containing an identical pattern of 100  </abstract>::line_number::24
<abstract> m holes, were aligned, stacked and bonded. The accuracy of registration   </abstract>::line_number::25
<abstract>  Abstract  </abstract>::line_number::7
<abstract> Gesture-Based Programming is a new paradigm to ease  </abstract>::line_number::8
<abstract> the burden of programming robots. By tapping in to the  </abstract>::line_number::9
<abstract> users wealth of experience with contact transitions,  </abstract>::line_number::10
<abstract> compliance, uncertainty and operations sequencing, we  </abstract>::line_number::11
<abstract> hope to provide a more intuitive programming environment  </abstract>::line_number::12
<abstract> for complex, real-world tasks based on the expressiveness  </abstract>::line_number::13
<abstract> of non-verbal communication. A requirement for this to be  </abstract>::line_number::14
<abstract> accomplished is the ability to interpret gestures to infer the  </abstract>::line_number::15
<abstract> intentions behind them. As a first step toward this goal, this  </abstract>::line_number::16
<abstract> paper presents an application of distributed perception for  </abstract>::line_number::17
<abstract> inferring a users intentions by observing tactile gestures.  </abstract>::line_number::18
<abstract> These gestures consist of sparse, inexact, physical  </abstract>::line_number::19
<abstract> nudges applied to the robots end effector for the  </abstract>::line_number::20
<abstract> purpose of modifying its trajectory in free space. A set of  </abstract>::line_number::21
<abstract> independent agents - each with its own local, fuzzified,  </abstract>::line_number::22
<abstract> heuristic model of a particular trajectory parameter -  </abstract>::line_number::23
<abstract> observes data from a wrist force/torque sensor to evaluate  </abstract>::line_number::24
<abstract> the gestures. The agents then independently determine the  </abstract>::line_number::25
<abstract> confidence of their respective findings and distributed  </abstract>::line_number::26
<abstract> arbitration resolves the interpretation through voting.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::4
<abstract> This paper addresses the estimation of moving object trajectories within a geospatial coordinate system,  </abstract>::line_number::5
<abstract> using a network of video sensors. A high-resolution  </abstract>::line_number::6
<abstract> (0.5m grid spacing) digital elevation map (DEM) has  </abstract>::line_number::7
<abstract> been constructed using a helicopter-based laser range-finder. Object locations are estimated by intersecting viewing rays from a calibrated sensor platform  </abstract>::line_number::8
<abstract> with the DEM. Continuous object trajectories can then  </abstract>::line_number::9
<abstract> be assembled from sequences of single-frame location  </abstract>::line_number::10
<abstract> estimates using spatio-temporal filtering and domain  </abstract>::line_number::11
<abstract> knowledge.   </abstract>::line_number::12
<abstract>  Abstract  </abstract>::line_number::7
<abstract> We describe the design and implementation of a compiler that automatically translates ordinary  </abstract>::line_number::8
<abstract> programs written in a subset of ML into code that generates native code at run time. Run-time  </abstract>::line_number::9
<abstract> code generation can make use of values and invariants that cannot be exploited at compile time,  </abstract>::line_number::10
<abstract> yielding code that is superior to statically optimal code. But the cost of optimizing and generating  </abstract>::line_number::11
<abstract> code at run time can be prohibitive. We demonstrate how compile-time specialization can reduce  </abstract>::line_number::12
<abstract> the cost of run-time code generation by an order of magnitude without greatly affecting code  </abstract>::line_number::13
<abstract> quality. Several benchmark programs are examined, which exhibit an average cost of six cycles per  </abstract>::line_number::14
<abstract> instruction generated at run time.   </abstract>::line_number::15
<abstract>  Abstract. The interface specification of a procedure describes the procedure's  </abstract>::line_number::6
<abstract> behavior using pre- and postconditions. These pre- and postconditions are written using various functions. If some of these functions are partial, or underspec-ified, then the procedure specification may not be well-defined.  </abstract>::line_number::7
<abstract> We show how to write pre- and postcondition specifications that avoid such  </abstract>::line_number::8
<abstract> problems, by having the precondition "protect" the postcondition from the effects  </abstract>::line_number::9
<abstract> of partiality and underspecification. We formalize the notion of protection from  </abstract>::line_number::10
<abstract> partiality in the context of specification languages like VDM-SL and COLD-K.  </abstract>::line_number::11
<abstract> We also formalize the notion of protection from underspecification for the Larch  </abstract>::line_number::12
<abstract> family of specification languages, and for Larch show how one can prove that a  </abstract>::line_number::13
<abstract> procedure specification is protected from the effects of underspecification.   </abstract>::line_number::14
<abstract>  Abstract:  </abstract>::line_number::8
<abstract> Software architects use a number of commonly-recognized styles  </abstract>::line_number::9
<abstract> to guide their design of system structures. Each of these is appropriate for  </abstract>::line_number::10
<abstract> some classes of problems, but none is suitable for all problems. How, then,  </abstract>::line_number::11
<abstract> does a software designer choose an architecture suitable for the problem at  </abstract>::line_number::12
<abstract> hand? Two kinds of information are required: (1)   </abstract>::line_number::13
<abstract> careful discrimination  </abstract>::line_number::14
<abstract> among  </abstract>::line_number::15
<abstract> the candidate architectures and (2)   </abstract>::line_number::16
<abstract> design guidance  </abstract>::line_number::17
<abstract> on how to make  </abstract>::line_number::18
<abstract> appropriate choices. Here we support   </abstract>::line_number::19
<abstract> careful discrimination  </abstract>::line_number::20
<abstract> with a  </abstract>::line_number::21
<abstract> preliminary classification of styles. We use a two-dimensional classification  </abstract>::line_number::22
<abstract> strategy with control and data issues as the dominant organizing axes. We  </abstract>::line_number::23
<abstract> position the major styles within this space and use finer-grained  </abstract>::line_number::24
<abstract> discriminations to elaborate variations on the styles. This provides a  </abstract>::line_number::25
<abstract> framework for organizing   </abstract>::line_number::26
<abstract> design guidance  </abstract>::line_number::27
<abstract> , which we partially flesh out with  </abstract>::line_number::28
<abstract> rules of thumb.   </abstract>::line_number::29
<abstract>  Abstract  </abstract>::line_number::7
<abstract> This paper presents two strategies for reducing the impact force resulting from the collision of a  </abstract>::line_number::8
<abstract> kinematically redundant manipulator with its environment, where it is assumed that the impact  </abstract>::line_number::9
<abstract> event has some finite duration. The first, an impact control strategy, involves adding torques to the  </abstract>::line_number::10
<abstract> joints of the redundant manipulator to impede motion into the environment with which it is colliding. The second, an impact planning strategy, involves choosing the configuration best suited for  </abstract>::line_number::11
<abstract> minimizing the impact force from an impact event, the approximate location of which is known  </abstract>::line_number::12
<abstract> ahead of time. Simulated results from both strategies are presented and discussed, and it is shown  </abstract>::line_number::13
<abstract> that both are successful in minimizing the impact force resulting from planned and unplanned collisions.   </abstract>::line_number::14
<abstract>  ABSTRACT  </abstract>::line_number::5
<abstract> Digital interactive media augments interactive computing with video, audio, computer graphics and text,  </abstract>::line_number::6
<abstract> allowing multimedia presentations to be individually and dynamically tailored to the user. Multimedia, and  </abstract>::line_number::7
<abstract> particularly continuous media pose interesting problems for system designers, including those of latency  </abstract>::line_number::8
<abstract> and synchronization. These problems are especially evident when multimedia data is remote and must be  </abstract>::line_number::9
<abstract> accessed via networks. Latency and synchronization issues are discussed, and an integrated system,  </abstract>::line_number::10
<abstract> Tactus, is described. Tactus facilitates the implementation of interactive multimedia computer programs by  </abstract>::line_number::11
<abstract> managing latency and synchronization in the framework of an object-oriented graphical user interface  </abstract>::line_number::12
<abstract> toolkit.   </abstract>::line_number::13
<abstract>  Abstract  </abstract>::line_number::4
<abstract> The domain of applications that can be created with programming-by-demonstration  </abstract>::line_number::5
<abstract> (PBD) can be extended by improving the developers ability to communicate with the system. The  </abstract>::line_number::6
<abstract> techniques provided in this thesis will allow nonprogrammers to create a new variety of complete,  </abstract>::line_number::7
<abstract> interactive applications including many board games and educational software using PBD.  </abstract>::line_number::8
<abstract> A PBD software tool uses inferencing to induce programs by watching the developer demonstrate examples that show how the application should behave. Current systems reduce their scope  </abstract>::line_number::9
<abstract> or resort to having the developer program because they do not provide sufficient ways to express  </abstract>::line_number::10
<abstract> behaviors and the factors that affect them. Therefore, the goal of this thesis is to develop understandable forms of annotated expression and manipulation that help a system infer a broader range  </abstract>::line_number::11
<abstract> of behavior. To test these ideas, this proposal introduces a new system called Gamut that will  </abstract>::line_number::12
<abstract> present the techniques in a unified software tool.  </abstract>::line_number::13
<abstract> The first technique replaces the macro recorder method for demonstrating behavior used  </abstract>::line_number::14
<abstract> in other PBD systems with a technique called nudges. The developer demonstrates by correcting  </abstract>::line_number::15
<abstract> the system at important points during program execution and also using two nudge commands to  </abstract>::line_number::16
<abstract> communicate important situations. First, the Do Something! nudge causes the system to reconsider  </abstract>::line_number::17
<abstract> past learned behavior and try to generalize its knowledge to fit the current situation. Using the  </abstract>::line_number::18
<abstract> Stop That! nudge will point out improper behavior and generate negative examples.  </abstract>::line_number::19
<abstract> Second, Gamut will use a new deck-of-playing-cards metaphor to express concepts such  </abstract>::line_number::20
<abstract> as randomness, sequencing, and data storage. By constructing an appropriate deck, shufing, sorting, and playing cards at key moments, developers can incorporate many effects not available without programming in other systems.  </abstract>::line_number::21
<abstract> Third, Gamut will improve communication about behaviors by making them more manipulable than in previous systems. Behaviors will be represented as small icons near the objects they  </abstract>::line_number::22
<abstract> affect. Using the familiar cut, copy, and paste commands, the developer can transfer behavior  </abstract>::line_number::23
<abstract> between objects. Determining how to make a behavior operate in the new context will be inferred  </abstract>::line_number::24
<abstract> automatically. An objects state from the recent past will be represented as temporal ghosts in  </abstract>::line_number::25
<abstract> which objects become dimmed, translucent images. Many sorts of behavior refer to prior states  </abstract>::line_number::26
<abstract> such as a previous position or an old property value. The ghost objects will allow the developer to  </abstract>::line_number::27
<abstract> make explicit connections.  </abstract>::line_number::28
<abstract> Finally, to reduce the number of options the system must explore, the developer will be  </abstract>::line_number::29
<abstract> able to give hints by highlighting important objects and properties. A new inferencing algorithm  </abstract>::line_number::30
<abstract> will be created that will take advantage of the hints.  </abstract>::line_number::31
<abstract> By combining these techniques, Gamut will provide a rich medium for expressing developer intentions, fostering greater communication between the PBD system and the developer and  </abstract>::line_number::32
<abstract> enabling the developer to create highly interactive software with minimal programming expertise.   </abstract>::line_number::33
<abstract>  Abstract We introduce a new kind of language model, which models whole sentences or utterances directly using the Maximum Entropy  </abstract>::line_number::6
<abstract> paradigm. The new model is conceptually simpler, and more naturally  </abstract>::line_number::7
<abstract> suited to modeling whole-sentence phenomena, than the conditional ME  </abstract>::line_number::8
<abstract> models proposed to date. By avoiding the chain rule, the model treats  </abstract>::line_number::9
<abstract> each sentence or utterance as a "bag of features", where features are  </abstract>::line_number::10
<abstract> arbitrary computable properties of the sentence. The model is unnor-malizable, but this does not interfere with training (done via sampling)  </abstract>::line_number::11
<abstract> or with use. Using the model is computationally straightforward. The  </abstract>::line_number::12
<abstract> main computational cost of training the model is in generating sample  </abstract>::line_number::13
<abstract> sentences from a Gibbs distribution. Interestingly, this cost has different dependencies, and is potentially lower, than in the comparable  </abstract>::line_number::14
<abstract> conditional ME model.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The large latency of memory accesses is a major obstacle in obtaining high processor utilization in large  </abstract>::line_number::7
<abstract> scale shared-memory multiprocessors. Although the provision of coherent caches in many recent machines  </abstract>::line_number::8
<abstract> has alleviated the problem somewhat, cache misses still occur frequently enough that they significantly lower  </abstract>::line_number::9
<abstract> performance. In this paper we evaluate the effectiveness of non-binding software-controlled prefetching, as  </abstract>::line_number::10
<abstract> proposed in the Stanford DASH Multiprocessor, to address this problem. The prefetches are non-binding in  </abstract>::line_number::11
<abstract> the sense that the prefetched data is brought to a cache close to the processor, but is still available to the cache  </abstract>::line_number::12
<abstract> coherence protocol to keep it consistent. Prefetching is software-controlled since the program must explicitly  </abstract>::line_number::13
<abstract> issue prefetch instructions.  </abstract>::line_number::14
<abstract> The paper presents results from detailed simulation studies done in the context of the Stanford DASH  </abstract>::line_number::15
<abstract> multiprocessor. Our results show that for applications with regular data access patterns|we evaluate a particle-based simulator used in aeronautics and an LU-decomposition application|prefetching can be very effective.  </abstract>::line_number::16
<abstract> It was easy to augment the applications to do prefetching and it increased their performance by 100-150% when  </abstract>::line_number::17
<abstract> we prefetched directly into the processor's cache. However, for applications with complex data usage patterns,  </abstract>::line_number::18
<abstract> prefetching was less successful. After much effort, the performance of a distributed-time logic simulation  </abstract>::line_number::19
<abstract> application that made extensive use of pointers and linked lists could be increased only by 30%. The paper  </abstract>::line_number::20
<abstract> also evaluates the effects of various hardware optimizations such as separate prefetch issue buffers, prefetching  </abstract>::line_number::21
<abstract> with exclusive ownership, lockup-free caches, and weaker memory consistency models on the performance of  </abstract>::line_number::22
<abstract> prefetching.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::7
<abstract> To maximize the benefit and minimize the overhead of software-based latency tolerance techniques,  </abstract>::line_number::8
<abstract> we would like to apply them precisely to the set of  </abstract>::line_number::9
<abstract> dynamic references that suffer cache misses. Unfortunately, the information provided by the state-of-the-art cache miss profiling technique (summary profiling)  </abstract>::line_number::10
<abstract> is inadequate for references with intermediate miss  </abstract>::line_number::11
<abstract> ratios|it results in either failing to hide latency, or  </abstract>::line_number::12
<abstract> else inserting unnecessary overhead. To overcome this  </abstract>::line_number::13
<abstract> problem, we propose and evaluate a new technique|  </abstract>::line_number::14
<abstract> correlation profiling|which improves predictability by  </abstract>::line_number::15
<abstract> correlating the caching behavior with the associated dynamic context. Our experimental results demonstrate  </abstract>::line_number::16
<abstract> that roughly half of the 22 non-numeric applications  </abstract>::line_number::17
<abstract> we study can potentially enjoy significant reductions  </abstract>::line_number::18
<abstract> in memory stall time by exploiting at least one of the  </abstract>::line_number::19
<abstract> three forms of correlation profiling we consider.   </abstract>::line_number::20
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Autonomous robots must be able to learn and maintain models of their environments.  </abstract>::line_number::6
<abstract> Research on mobile robot navigation has produced two major paradigms for mapping indoor  </abstract>::line_number::7
<abstract> environments: grid-based and topological. While grid-based methods produce accurate  </abstract>::line_number::8
<abstract> metric maps, their complexity often prohibits efficient planning and problem solving in  </abstract>::line_number::9
<abstract> large-scale indoor environments. Topological maps, on the other hand, can be used much  </abstract>::line_number::10
<abstract> more efficiently, yet accurate and consistent topological maps are often difficult to learn  </abstract>::line_number::11
<abstract> and maintain in large-scale environments, particularly if momentary sensor data is highly  </abstract>::line_number::12
<abstract> ambiguous. This paper describes an approach that integrates both paradigms: grid-based  </abstract>::line_number::13
<abstract> and topological. Grid-based maps are learned using artificial neural networks and naive  </abstract>::line_number::14
<abstract> Bayesian integration. Topological maps are generated on top of the grid-based maps, by  </abstract>::line_number::15
<abstract> partitioning the latter into coherent regions. By combining both paradigms, the approach  </abstract>::line_number::16
<abstract> presented here gains advantages from both worlds: accuracy/consistency and efficiency.  </abstract>::line_number::17
<abstract> The paper gives results for autonomous exploration, mapping and operation of a mobile  </abstract>::line_number::18
<abstract> robot in populated multi-room environments.   </abstract>::line_number::19
<abstract>  Abstract  </abstract>::line_number::5
<abstract> World Wide Web electronic commerce applications  </abstract>::line_number::6
<abstract> often require consumers to enter private information (such as credit card numbers) into forms in the  </abstract>::line_number::7
<abstract> browser window. If third parties can insert trojan  </abstract>::line_number::8
<abstract> horse applications onto a consumer's machine, they  </abstract>::line_number::9
<abstract> can monitor keyboard strokes and steal private information.  </abstract>::line_number::10
<abstract> This paper outlines a simple way to accomplish  </abstract>::line_number::11
<abstract> this using Java or similar remote execution facilities.  </abstract>::line_number::12
<abstract> We implemented a simple version of this attack. We  </abstract>::line_number::13
<abstract> give a general method, window personalization, that  </abstract>::line_number::14
<abstract> can thwart or prevent this attack.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::9
<abstract> We consider the usual Normal linear mixed model for "components of variance" from a Bayesian  </abstract>::line_number::10
<abstract> viewpoint. Instead of using Gibbs sampling or other Markov Chain schemes that rely on full  </abstract>::line_number::11
<abstract> conditional distributions, we propose and investigate a method for simulating from posterior distributions based on rejection sampling. The method applies with arbitrary prior distributions but  </abstract>::line_number::12
<abstract> we also employ as a default reference prior a version of Jeffreys's prior based on the integrated  </abstract>::line_number::13
<abstract> ("restricted") likelihood. We demonstrate the ease of application and flexibility of this approach  </abstract>::line_number::14
<abstract> in several familiar settings, even in the presence of unbalanced data. A program implementing the  </abstract>::line_number::15
<abstract> algorithm discussed here will be available in the SAS MIXED procedure.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::4
<abstract> A scheme to compute smoothing spline ANOVA estimates for large data sets with a (near)  </abstract>::line_number::5
<abstract> tensor-product structure is proposed. Such data sets are common in spatial-temporal analysis and  </abstract>::line_number::6
<abstract> image analysis. This scheme combines backfitting algorithm with iterative imputation algorithm in  </abstract>::line_number::7
<abstract> order to save both computational space and time. The convergence of this algorithm and various  </abstract>::line_number::8
<abstract> ways to further speed it up, such as collapsing component functions and successive over-relaxation,  </abstract>::line_number::9
<abstract> are discussed. Issues related to its application in spatial-temporal analysis are discussed too. An  </abstract>::line_number::10
<abstract> application to a global analysis of historical surface temperature data is described.   </abstract>::line_number::11
<abstract>  Abstract. This study uncovers trading styles in the transaction records of US Treasury bond futures.  </abstract>::line_number::8
<abstract> It uses transaction-by-transaction data from the Commodity Futures Trading Commissions' (CFTC)  </abstract>::line_number::9
<abstract> Computerized Trade Reconstruction (CTR) records. The data set consists of 30 million transaction|  </abstract>::line_number::10
<abstract> the complete US T-bond futures market for 3 years. Each transaction record consists of time (by the  </abstract>::line_number::11
<abstract> minute), price, volume, buy/sell, and an identifier of the specific account.  </abstract>::line_number::12
<abstract> We use statistical clustering techniques to group together trades that are similar. Two sets of  </abstract>::line_number::13
<abstract> assumptions have to be made: (1) What is a trade? We define a trade to begin when an account opens  </abstract>::line_number::14
<abstract> a position, and to end when its position size returns to zero. We describe each trade by several trade-specific variables (e.g., length of trade, maximum position size, opening move, long or short) and several  </abstract>::line_number::15
<abstract> exogenous, market-specific variables (e.g., price, volatility, trading volume). (2) What process generated  </abstract>::line_number::16
<abstract> the data? We assume a mixture of Gaussians. An observed trade is interpreted as a noisy realization of  </abstract>::line_number::17
<abstract> one of the mixture components. This paper assumes identity covariance matrices. Furthermore, each  </abstract>::line_number::18
<abstract> trade is fully assigned to a single cluster. We compare this approach to diagonal and to full covariance  </abstract>::line_number::19
<abstract> structure with probabilistic assignments.  </abstract>::line_number::20
<abstract> Trade profit was held back in the clustering process. It turns out that the clusters differ significantly in their profit and risk characteristics. Using conditional distributions, we summarize features  </abstract>::line_number::21
<abstract> of profitable trading styles and contrast them with losing strategies. We find that profitable styles tend  </abstract>::line_number::22
<abstract> to hold trades longer, trade at higher volatility, and trade earlier in the contracts. We also show how  </abstract>::line_number::23
<abstract> some clusters uncover "technical" traders. Using the information about the individual accounts, the  </abstract>::line_number::24
<abstract> assignments of accounts to clusters are described by entropy, and the transitions of a given account  </abstract>::line_number::25
<abstract> through clusters is modeled by a first order Markov model.   </abstract>::line_number::26
<abstract>  Abstract. A knowledge-level analysis of complex tasks like diagnosis and design can give us a better understanding of these tasks in terms of the goals they  </abstract>::line_number::15
<abstract> aim to achieve and the different ways to achieve these goals. In this paper we  </abstract>::line_number::16
<abstract> present a knowledge-level analysis of redesign. Redesign is viewed as a family of  </abstract>::line_number::17
<abstract> methods based on some common principles, and a number of dimensions along  </abstract>::line_number::18
<abstract> which redesign problem solving methods can vary are distinguished. By examining the problem-solving behavior of a number of existing redesign systems and approaches, we came up with a collection of problem-solving methods for redesign  </abstract>::line_number::19
<abstract> and developed a task-method structure for redesign.  </abstract>::line_number::20
<abstract> In constructing a system for redesign a large number of knowledge-related choices  </abstract>::line_number::21
<abstract> and decisions are made. In order to describe all relevant choices in redesign problem solving, we have to extend the current notion of possible relations between  </abstract>::line_number::22
<abstract> tasks and methods in a PSM architecture. The realization of a task by a problem-solving method, and the decomposition of a problem-solving method into subtasks are the most common relations in a PSM architecture. However, we suggest  </abstract>::line_number::23
<abstract> to extend these relations with the notions of task refinement and method refinement. These notions represent intermediate decisions in a task-method structure,  </abstract>::line_number::24
<abstract> in which the competence of a task or method is refined without immediately paying attention to its operationalization in terms of subtasks. Explicit representation  </abstract>::line_number::25
<abstract> of this kind of intermediate decisions helps to make and represent decisions in a  </abstract>::line_number::26
<abstract> more piecemeal fashion.   </abstract>::line_number::27
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Plexus is a networking architecture that allows applications to achieve high performance with customized  </abstract>::line_number::9
<abstract> protocols. Application-specific protocols are written in  </abstract>::line_number::10
<abstract> a typesafe language and installed dynamically into the  </abstract>::line_number::11
<abstract> operating system kernel. Because these protocols execute within the kernel, they can access the network  </abstract>::line_number::12
<abstract> interface and other operating system services with low  </abstract>::line_number::13
<abstract> overhead. Protocols implemented with Plexus outperform equivalent protocols implemented on conventional monolithic systems. Plexus runs in the context  </abstract>::line_number::14
<abstract> of the SPIN extensible operating system.   </abstract>::line_number::15
<abstract>  Abstract:  </abstract>::line_number::9
<abstract> ATM networks will soon be moving from the experimental stage of test-beds to a commercial state  </abstract>::line_number::10
<abstract> where production networks are deployed and operated. The progress of ATM networks appears to be  </abstract>::line_number::11
<abstract> at risk due to the lack of a universal, open, and efficient ATM network control platform. The emerging  </abstract>::line_number::12
<abstract> Private Network to Network Interface (PNNI) standard introduces a control platform that can be used  </abstract>::line_number::13
<abstract> as an internetwork and possibly as an intra-network solution. However, the current PNNI still falls short  </abstract>::line_number::14
<abstract> in providing an acceptable universal solution, due to lack of performance optimizations for intra-network operation, limited functionality, and the lack of open interfaces for future functional extensions  </abstract>::line_number::15
<abstract> and services.  </abstract>::line_number::16
<abstract> OPENET is a common portable, open, and high-performance network control platform based on performance and functional enhancements to the PNNI standard. It is vendor-independent, scalable (in  </abstract>::line_number::17
<abstract> terms of network size and volume of calls), high-performance (in terms of call processing latency and  </abstract>::line_number::18
<abstract> throughput), and extensible (in terms of integrating customer-specific and value-added services).  </abstract>::line_number::19
<abstract> OPENET is designed as an extension to current PNNI so it can serve as a next generation PNNI. It is  </abstract>::line_number::20
<abstract> compatible with PNNI in the internetworking environment allowing large networks to be partitioned  </abstract>::line_number::21
<abstract> according to natural topological or organizational boundaries rather than the artificial use of internet-work interfaces at vendor boundaries.  </abstract>::line_number::22
<abstract> This report describes the OPENET architecture. The major novelties of the OPENET architecture compared to the current PNNI are: the use of native ATM switching for the dissemination of utilization  </abstract>::line_number::23
<abstract> updates; lightweight call setup; take down and modification signaling; a new signaling paradigm that  </abstract>::line_number::24
<abstract> better supports fast reservation and multicast services; and a rich signaling infrastructure that enables  </abstract>::line_number::25
<abstract> the development of augmented services (such as mobility, directory, etc.), leveraging the existing functions of the network control platform.   </abstract>::line_number::26
<abstract>  Abstract  </abstract>::line_number::4
<abstract> We present and examine the following Serialize-to-Parallelize Paradox: suppose a  </abstract>::line_number::5
<abstract> programmer has a parallel algorithm in mind; the programmer must serialize the algorithm, and is actually trained to suppress its parallelism, while writing code; later,  </abstract>::line_number::6
<abstract> however, compilation and runtime techniques are used to reverse the results of this serialization effort and extract as much parallelism as possible. This work actually provides  </abstract>::line_number::7
<abstract> examples where parallel or parallel-style code enables extracting more parallelism than  </abstract>::line_number::8
<abstract> standard serial code.  </abstract>::line_number::9
<abstract> The "arbitrary concurrent-write" convention is useful in parallel algorithms and programs and appears to be not too difficult to implement in hardware for serial machines.  </abstract>::line_number::10
<abstract> Still, typically concurrent-writes to the same memory location in a program are implemented by queuing the write operations, thus requiring time linear in the number of  </abstract>::line_number::11
<abstract> writes. We call this the Queuing Concurrent-Writes Paradox.  </abstract>::line_number::12
<abstract> Assuming that providing useful, easy-to-program programming paradigms to improve the overall effectiveness of computer systems is of interest, this work is a modest  </abstract>::line_number::13
<abstract> example for applying such software-driven considerations to computer architecture issues. This work may be the first to relate parallel algorithms and parallel programming  </abstract>::line_number::14
<abstract> with the technology of instruction level parallelism.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::10
<abstract> We describe an efficient method for localizing a mobile robot in an environment with landmarks. We assume that the robot can identify these landmarks  </abstract>::line_number::11
<abstract> and measure their bearings relative to each other. Given such noisy input, the  </abstract>::line_number::12
<abstract> algorithm estimates the robot's position and orientation with respect to the  </abstract>::line_number::13
<abstract> map of the environment. The algorithm makes efficient use of our representation of the landmarks by complex numbers. The algorithm runs in time linear  </abstract>::line_number::14
<abstract> in the number of landmarks. We present results of simulations and propose  </abstract>::line_number::15
<abstract> how to use our method for robot navigation.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::9
<abstract> The problem of recognizing objects imaged in complex real-world scenes is examined from  </abstract>::line_number::10
<abstract> a parametric perspective using the theory of statistical estimation. A scalar measure of an  </abstract>::line_number::11
<abstract> object's complexity, which is invariant under affine transformation and changes in image noise  </abstract>::line_number::12
<abstract> level, is extracted from the object's Fisher information. The volume of Fisher information is  </abstract>::line_number::13
<abstract> shown to provide an overall statistical measure of the object's recognizability in a particular  </abstract>::line_number::14
<abstract> image, while the complexity provides an intrinsically physical measure that characterizes the  </abstract>::line_number::15
<abstract> object in any image. An information-conserving method is then developed for recognizing  </abstract>::line_number::16
<abstract> an object imaged in a complex scene. Here the term "information-conserving" means that  </abstract>::line_number::17
<abstract> the method uses all the measured data pertinent to the object's recognizability, attains the  </abstract>::line_number::18
<abstract> theoretical lower bound on estimation error for any unbiased estimate of the parameter vector  </abstract>::line_number::19
<abstract> describing the object, and therefore is statistically optimal. This method is then successfully  </abstract>::line_number::20
<abstract> applied to finding objects imaged in thousands of complex real-world scenes.   </abstract>::line_number::21
<abstract>  Abstract  </abstract>::line_number::8
<abstract> We have integrated the distributed search of genetic  </abstract>::line_number::9
<abstract> programming based systems with collective memory  </abstract>::line_number::10
<abstract> to form a collective adaptation search method. Such a  </abstract>::line_number::11
<abstract> system significantly improves search as problem complexity is increased. However, there is still considerable scope for improvement. In collective adaptation, search agents gather knowledge of their environment and deposit it in a central information repository. Process agents are then able to manipulate that  </abstract>::line_number::12
<abstract> focused knowledge, exploiting the exploration of the  </abstract>::line_number::13
<abstract> search agents. We examine the utility of increasing  </abstract>::line_number::14
<abstract> the capabilities of the centralized process agents.   </abstract>::line_number::15
<abstract>  Abstract  </abstract>::line_number::8
<abstract> Users of digital image libraries are often not interested in image data per se but in derived  </abstract>::line_number::9
<abstract> products such as catalogs of objects of interest. Converting an image database into a usable  </abstract>::line_number::10
<abstract> catalog is typically carried out manually at present. For many larger image databases the  </abstract>::line_number::11
<abstract> purely manual approach is completely impractical. In this paper we describe the development  </abstract>::line_number::12
<abstract> of a trainable cataloging system: the user indicates the location of the objects of interest for  </abstract>::line_number::13
<abstract> a number of training images and the system learns to detect and catalog these objects in the  </abstract>::line_number::14
<abstract> rest of the database. In particular we describe the application of this system to the cataloging  </abstract>::line_number::15
<abstract> of small volcanoes in radar images of Venus. The volcano problem is of interest because of the  </abstract>::line_number::16
<abstract> scale (30,000 images, order of 1 million detectable volcanoes), technical difficulty (the variability  </abstract>::line_number::17
<abstract> of the volcanoes in appearance) and the scientific importance of the problem. The problem of  </abstract>::line_number::18
<abstract> uncertain or subjective ground truth is of fundamental importance in cataloging problems of this  </abstract>::line_number::19
<abstract> nature and is discussed in some detail. Experimental results are presented which quantify and  </abstract>::line_number::20
<abstract> compare the detection performance of the system relative to human detection performance. The  </abstract>::line_number::21
<abstract> paper concludes by discussing the limitations of the proposed system and the lessons learned of  </abstract>::line_number::22
<abstract> general relevance to the development of digital image libraries.   </abstract>::line_number::23
<abstract>  Abstract  </abstract>::line_number::5
<abstract> Recently Propp and Wilson [14] have proposed an algorithm, called  </abstract>::line_number::6
<abstract> Coupling from the Past (CFTP), which allows not only an approximate but perfect (i.e. exact) simulation of the stationary distribution  </abstract>::line_number::7
<abstract> of certain finite state space Markov chains. Perfect Sampling using  </abstract>::line_number::8
<abstract> CFTP has been successfully extended to the context of point processes, amongst other authors, by Haggstrom et al. [5]. In [5] Gibbs  </abstract>::line_number::9
<abstract> sampling is applied to a bivariate point process, the penetrable spheres  </abstract>::line_number::10
<abstract> mixture model [19]. However, in general the running time of CFTP  </abstract>::line_number::11
<abstract> in terms of number of transitions is not independent of the state sampled. Thus an impatient user who aborts long runs may introduce a  </abstract>::line_number::12
<abstract> subtle bias, the user impatience bias. Fill [3] introduced an exact sampling algorithm for finite state space Markov chains which, in contrast  </abstract>::line_number::13
<abstract> to CFTP, is unbiased for user impatience. Fill's algorithm is a form  </abstract>::line_number::14
<abstract> of rejection sampling and similar to CFTP requires sufficient mono-tonicity properties of the transition kernel used. We show how Fill's  </abstract>::line_number::15
<abstract> version of rejection sampling can be extended to an infinite state space  </abstract>::line_number::16
<abstract> context to produce an exact sample of the penetrable spheres mixture  </abstract>::line_number::17
<abstract> process and related models. Following [5] we use Gibbs sampling and  </abstract>::line_number::18
<abstract> make use of the partial order of the mixture model state space. Thus   </abstract>::line_number::19
<abstract>  A new notion of refinement for UNITY programs with local variables is defined. This  </abstract>::line_number::6
<abstract> notion is compositional in the following sense: programs can be refined in arbitrary contexts such that all unless and leadsto properties (i.e. temporal properties for both safety  </abstract>::line_number::7
<abstract> and progress) of the composition are preserved. The refinement notion is based on preservation of a new kind of UNITY-like property that takes into account the locality of  </abstract>::line_number::8
<abstract> variables. We do a small case study about registers.   </abstract>::line_number::9
<abstract>  ABSTRACT Stepwise refinement of programs has proven to be a suitable  </abstract>::line_number::8
<abstract> method for developing parallel and distributed programs. We examine and compare a  </abstract>::line_number::9
<abstract> number of different notions of program refinement for Unity. Two of these notions are  </abstract>::line_number::10
<abstract> based on execution sequences. Refinement corresponds to the reduction of the set of execution sequences, i.e. reducing the amount of nondeterminism. The other refinement  </abstract>::line_number::11
<abstract> notions are based on Unity properties as introduced by Chandy and Misra. The Unity approach is to refine specifications. Although it has proven a suitable formalism for deriving  </abstract>::line_number::12
<abstract> algorithms, it seems less suitable for handling implementation details. Following Sanders  </abstract>::line_number::13
<abstract> and Singh, we formalize program refinement in the Unity framework as the preservation  </abstract>::line_number::14
<abstract> of Unity properties. We show that Unity properties are not powerful enough to characterize execution sequences. As a consequence, the notion of property-preserving refinement  </abstract>::line_number::15
<abstract> differs from the notion of reducing the set of execution sequences.   </abstract>::line_number::16
<abstract>  Abstract  </abstract>::line_number::6
<abstract> The Internet, best known by most users as the WorldWide-Web, continues to expand at an amazing pace. We  </abstract>::line_number::7
<abstract> propose a new infrastructure to harness the combined resources, such as CPU cycles or disk storage, and make them  </abstract>::line_number::8
<abstract> available to everyone interested. This infrastructure has the  </abstract>::line_number::9
<abstract> potential for solving parallel supercomputing applications  </abstract>::line_number::10
<abstract> involving thousands of cooperating components. Our approach is based on recent advances in Internet connectivity  </abstract>::line_number::11
<abstract> and the implementation of safe distributed computing embodied in languages such as Java.  </abstract>::line_number::12
<abstract> We developed a prototype of a global computing infrastructure, called SuperWeb, that consists of hosts, brokers  </abstract>::line_number::13
<abstract> and clients. Hosts register a fraction of their computing resources (CPU time, memory, bandwidth, disk space) with  </abstract>::line_number::14
<abstract> resource brokers. Client computations are then mapped by  </abstract>::line_number::15
<abstract> the broker onto the registered resources. We examine an economic model for trading computing resources, and discuss  </abstract>::line_number::16
<abstract> several technical challenges associated with such a global  </abstract>::line_number::17
<abstract> computing environment.   </abstract>::line_number::18
